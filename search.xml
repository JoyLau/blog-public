<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MacBook Pro 使用绿联 TypeC 网卡关闭笔记本盖子时导致局域网网络不可用的问题解决</title>
      <link href="/2020/08/04/MacBookPro-uGreen-TypeC-Hub/"/>
      <url>/2020/08/04/MacBookPro-uGreen-TypeC-Hub/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>我的 MacBook Pro 使用的是绿联的外接扩展坞, 其中有一个网口<br>在京东购买的: <a href="https://item.jd.com/4445121.html" target="_blank" rel="noopener">https://item.jd.com/4445121.html</a></p><p>型号为: CM179<br>网卡芯片为: RTL8153B</p><p>最近发现只要我的 MacBook Pro 关闭了盖子, 会导致接在同一交换机下的路由器就无法上网<br>打开盖子后,网络又恢复正常了  </p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>搜索了一番没找到解决方式</p><p>于是就找到当时购买的这款产品的京东介绍页面看了看</p><p>想着去绿联的官网找找驱动试试: <a href="https://www.lulian.cn/download/list-34-cn.html" target="_blank" rel="noopener">https://www.lulian.cn/download/list-34-cn.html</a></p><p>找到对应的型号和网卡芯片: <a href="https://www.lulian.cn/download/38-cn.html" target="_blank" rel="noopener">https://www.lulian.cn/download/38-cn.html</a></p><p>下载并解压驱动压缩包，双击“RTUNICv1.0.20.pkg”文件，一直点击继续，安装完成后重启电脑即可。</p><p>重启后又试了下关闭盖子, 问题解决了!!!</p>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Awtrix App 开发 --- 开发一款显示个人博客访问人数的 App</title>
      <link href="/2020/08/02/Awtrix-BlogViews/"/>
      <url>/2020/08/02/Awtrix-BlogViews/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li>具备 Awtrix 硬件设备</li><li>博客的计数工具是<strong>不蒜子</strong></li></ol><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ol><li>JDK 8 的环境</li><li>开发工具： <a href="https://www.b4x.com/b4j.html" target="_blank" rel="noopener">B4J</a></li></ol><h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p><img src="http://image.joylau.cn/blog/Awtrix-preview-gif.gif" alt="gif"><br><img src="http://image.joylau.cn/blog/Awtrix-web-app.png" alt="app"><br><img src="http://image.joylau.cn/blog/Awtrix-web-config.png" alt="config"></p><h3 id="开发准备"><a href="#开发准备" class="headerlink" title="开发准备"></a>开发准备</h3><ol><li>模板文件</li></ol><p>AWTRIX.bas： 这个文件的内容不需要改动直接复制即可</p><pre><code class="text">    B4J=true    Group=Default Group    ModulesStructureVersion=1    Type=Class    Version=7.31    @EndOfDesignText@    &#39;This Class takes control of the Interface to AWTRIX, the Icon Renderer    &#39;and some useful functions to make the development more easier.    &#39;Usually you dont need to modify this Class!    #Event: Started    #Event: controllerButton(button as int,dir as boolean)    #Event: controllerAxis(axis as int, dir as float)    #Event: Exited    #Event: iconRequest    #Event: settingsChanged    #Event: startDownload(jobNr As Int) As String    #Event: evalJobResponse(Resp As JobResponse)    private Sub Class_Globals        Private Appduration As Int        Private mscrollposition As Int        Private show As Boolean = True        Private forceDown As Boolean        Private LockApp As Boolean = False        Private Icon As List        Private appName As String        Private AppVersion As String        Private TickInterval As Int        Private NeedDownloads As Int = 0        Private UpdateInterval As Int = 0        Private AppDescription As String        Private AppAuthor As String        Private SetupInfos As String        Private MatrixInfo As Map        Private appSettings As Map = CreateMap()        Private ServerVersion As String        Private DisplayTime As Int        Private MatrixWidth As Int = 32        Private MatrixHeight As Int = 8        Private DownloadHeader As Map        Private pluginversion As Int = 1        Private Tag As List = Array As String()        Private playdescription As String        Private Cover As Int        Private Game As Boolean        Private startTimestamp As Long        Private icoMap As Map        Private RenderedIcons As Map        Private animCounter As Map        Private iconList As List&#39;ignore        Private timermap As Map        Private set As Map &#39;ignore        Private Target As Object        Private commandList As List        Private colorCounter As Int        Private startTime As String =&quot;0&quot;        Private endtime As String = &quot;0&quot;        Private CharMap As Map        Private TextBuffer As String        Private TextLength As Int        Private UppercaseLetters As Boolean        Private SystemColor() As Int        Private event As String        Private Enabled As Boolean = True        Private noIcon() As Short = Array As Short(0, 0, 0, 63488, 63488, 0, 0, 0, 0, 0, 63488, 0, 0, 63488, 0, 0, 0, 0, 0, 0, 0, 63488, 0, 0, 0, 0, 0, 0, 63488, 0, 0, 0, 0, 0, 0, 63488, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63488, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)        Private isRunning As Boolean        Private Menu As Map        Private MenuList As List        Private bc As B4XSerializator        Private noIconMessage As Boolean        Private verboseLog As Boolean        Private finishApp As Boolean        Type JobResponse (jobNr As Int,Success As Boolean,ResponseString As String,Stream As InputStream)        Private httpMap As Map        Private OAuthToken As String        Private OAuth As Boolean        Private oauthmap As Map        Private mContentType As String        Private poll As Map = CreateMap(&quot;enable&quot;:False,&quot;sub&quot;:&quot;&quot;)        Private mHidden As Boolean    End Sub    &#39;Initializes the Helperclass.    Public Sub Initialize(class As Object, Eventname As String)        oauthmap.Initialize        Tag.Initialize        httpMap.Initialize        DownloadHeader.Initialize        event=Eventname        iconList.Initialize        Icon.Initialize        commandList.Initialize        RenderedIcons.Initialize        icoMap.Initialize        animCounter.Initialize        timermap.Initialize        set.Initialize        Menu.Initialize        MatrixInfo.Initialize        MenuList.Initialize        Target=class    End Sub    &#39;Checks if the app should shown    Private Sub timesComparative  As Boolean        Try            If startTime = endtime Then Return True            Dim startT() As String=Regex.Split(&quot;:&quot;,startTime)            Dim EndT() As String=Regex.Split(&quot;:&quot;,endtime)            Dim hour As Int=DateTime.GetHour(DateTime.Now)            Dim minute As Int=DateTime.GetMinute(DateTime.Now)            Dim second As Int=DateTime.GetSecond(DateTime.Now)            Dim now, start, stop As Int            now = ((hour * 3600) + (minute * 60) + second)            start = (startT(0) * 3600) + (startT(1) * 60)            stop = ( EndT(0)* 3600) + (EndT(1) * 60)            If (start &lt; stop) Then                Return (now &gt;= start And now &lt;= stop )            Else                Return (now &gt;= start Or now &lt;= stop)            End If        Catch            Log(&quot;Got Error from &quot; &amp; appName)            Log(&quot;Error in TimesComparative:&quot;)            Log(LastException)            Return True        End Try    End Sub    #Region IconRenderer    Private Sub startIconRenderer        isRunning=True        FirstTick        For Each k As Timer In timermap.Keys            k.Enabled=True            Sleep(1)        Next    End Sub    Private Sub stopIconRenderer        isRunning=False        For Each k As Timer In timermap.Keys            k.Enabled=False            Sleep(1)        Next    End Sub    Private Sub FirstTick        For Each IconID As Int In icoMap.Keys            Try                If icoMap.ContainsKey(IconID) Then                    Dim ico As List=icoMap.get(IconID)                    Dim parse As JSONParser                    If animCounter.Get(IconID)&gt;ico.Size-1 Then animCounter.put(IconID,0)                    parse.Initialize(ico.Get(animCounter.Get(IconID)))                    Dim bmproot As List = parse.NextArray                    Dim bmp(bmproot.Size) As Short                    For i=0 To bmproot.Size-1                        bmp(i)=bmproot.Get(i)                    Next                    RenderedIcons.Put(IconID,bmp)                    animCounter.put(IconID,animCounter.Get(IconID)+1)                Else                    Log(&quot;IconID&quot; &amp; IconID  &amp; &quot;doesnt exists&quot;)                End If            Catch                Log(&quot;Got Error from &quot; &amp; appName)                Log(&quot;Error in IconPreloader:&quot;)                Log(&quot;IconID:&quot; &amp; IconID)                Log(LastException)            End Try        Next    End Sub    Private Sub Timer_Tick        Try            Dim iconid As Int=timermap.Get(Sender)            If icoMap.ContainsKey(iconid) Then                Dim ico As List= icoMap.get(iconid)                Dim parse As JSONParser                If animCounter.Get(iconid)&gt;ico.Size-1 Then animCounter.put(iconid,0)                parse.Initialize(ico.Get(animCounter.Get(iconid)))                Dim bmproot As List = parse.NextArray                Dim bpm(bmproot.Size) As Short                For i=0 To bmproot.Size-1                    bpm(i)=bmproot.Get(i)                Next                RenderedIcons.Put(iconid,bpm)                animCounter.put(iconid,animCounter.Get(iconid)+1)            Else                Logger(&quot;IconID&quot; &amp; iconid  &amp; &quot;doesnt exists&quot;)            End If        Catch            Log(&quot;Got Error from &quot; &amp; appName)            Log(&quot;Error in IconRenderer:&quot;)            Log(LastException)            stopIconRenderer        End Try    End Sub    Private Sub addToIconRenderer(iconMap As Map)        Try            If iconMap.Size=0 Then Return            Dim runMarker As Boolean            If isRunning Then                stopIconRenderer                runMarker=True            End If            timermap.Clear            icoMap.Clear            animCounter.Clear            RenderedIcons.Clear            For Each ico As Int In iconMap.Keys                Dim ico1 As Map = iconMap.get(ico)                If ico1.ContainsKey(&quot;tick&quot;) Then                    icoMap.Put(ico,ico1.Get(&quot;data&quot;))                    animCounter.Put(ico,0)                    Dim timer As Timer                    timer.Initialize(&quot;Timer&quot;,ico1.Get(&quot;tick&quot;))                    Dim icoExists As Boolean=False                    For Each timerico As Int In timermap.Values                        If timerico=ico Then icoExists=True                    Next                    If Not(icoExists) Then timermap.Put(timer,ico)                Else                    RenderedIcons.Put(ico,ico1.Get(&quot;data&quot;))                End If            Next            If runMarker Then                startIconRenderer            End If        Catch            Log(&quot;Got Error from &quot; &amp; appName)            Log(&quot;Error in IconAdder:&quot;)            Log(LastException)        End Try    End Sub    &#39;returns the rendered Icon    Public Sub getIcon(ID As Int) As Short()        If RenderedIcons.ContainsKey(ID) Then            Return RenderedIcons.Get(ID)        Else            If noIconMessage = False Then                Logger(&quot;Icon &quot; &amp; ID &amp; &quot; not found&quot;)                noIconMessage=True            End If            Return noIcon        End If    End Sub    #End Region    &#39;This is the interface between AWTRIX and the App    Public Sub interface(function As String, Params As Map) As Object        Select Case function            Case &quot;start&quot;                mscrollposition=MatrixWidth                If SubExists(Target,event&amp;&quot;_Started&quot;) Then                    CallSub(Target,event&amp;&quot;_Started&quot;)                End If                Try                    Appduration = Params.Get(&quot;AppDuration&quot;)                    If DisplayTime&gt;0 Then                        Appduration=DisplayTime                    End If                    verboseLog =Params.Get(&quot;verboseLog&quot;)                    ServerVersion =    Params.Get(&quot;ServerVersion&quot;)                    MatrixWidth = Params.Get(&quot;MatrixWidth&quot;)                    MatrixHeight = Params.Get(&quot;MatrixHeight&quot;)                    UppercaseLetters = Params.Get(&quot;UppercaseLetters&quot;)                    CharMap = Params.Get(&quot;CharMap&quot;)                    SystemColor = Params.Get(&quot;SystemColor&quot;)                    MatrixInfo=Params.Get(&quot;MatrixInfo&quot;)                    set.Put(&quot;interval&quot;,TickInterval)                    set.Put(&quot;needDownload&quot;,NeedDownloads)                    set.Put(&quot;DisplayTime&quot;, DisplayTime)                    set.Put(&quot;forceDownload&quot;, forceDown)                Catch                    Log(&quot;Got Error from &quot; &amp; appName)                    Log(&quot;Error in start procedure&quot;)                    Log(LastException)                End Try                startTimestamp=DateTime.now                noIconMessage=False                If show Then                    set.Put(&quot;show&quot;,timesComparative)                Else                    set.Put(&quot;show&quot;,show)                End If                set.Put(&quot;isGame&quot;,Game)                set.Put(&quot;hold&quot;,LockApp)                set.Put(&quot;iconList&quot;,Icon)                Return set            Case &quot;downloadCount&quot;                Return NeedDownloads            Case &quot;startDownload&quot;                httpMap.Initialize                DownloadHeader.Initialize                mContentType=&quot;&quot;                If SubExists(Target,event&amp;&quot;_startDownload&quot;) Then                    CallSub2(Target,event&amp;&quot;_startDownload&quot;,Params.Get(&quot;jobNr&quot;))                End If                If DownloadHeader.Size&gt;0 Then                    httpMap.Put(&quot;Header&quot;,DownloadHeader)                End If                If mContentType.Length&gt;0 Then                    httpMap.Put(&quot;ContentType&quot;,mContentType)                End If                Return httpMap            Case &quot;httpResponse&quot;                Dim res As JobResponse                res.Initialize                res.jobNr=Params.Get(&quot;jobNr&quot;)                res.Success=Params.Get(&quot;success&quot;)                res.ResponseString=Params.Get(&quot;response&quot;)                res.Stream=Params.Get(&quot;InputStream&quot;)                If SubExists(Target,event&amp;&quot;_evalJobResponse&quot;) Then                    CallSub2(Target,event&amp;&quot;_evalJobResponse&quot;,res)                End If                Return True            Case &quot;running&quot;                startIconRenderer            Case &quot;tick&quot;                commandList.Clear                If finishApp Then                    finishApp=False                    commandList.Add(CreateMap(&quot;type&quot;:&quot;finish&quot;))                Else                    If SubExists(Target,event&amp;&quot;_genFrame&quot;) Then                        CallSub(Target,event&amp;&quot;_genFrame&quot;)&#39;ignore                    End If                End If                Return commandList            Case &quot;infos&quot;                Dim infos As Map                infos.Initialize                Dim isconfigured As Boolean = True                If File.Exists(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;) Then                    Dim m As Map = bc.ConvertBytesToObject(File.ReadBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;))                    For Each v As Object In m.Values                        If v=&quot;null&quot; Or v=&quot;&quot; Then                            isconfigured=False                        End If                    Next                    If OAuth And OAuthToken.Length=0 Then isconfigured=False                End If                infos.Put(&quot;isconfigured&quot;,isconfigured)                infos.Put(&quot;AppVersion&quot;,AppVersion)                infos.Put(&quot;tags&quot;,Tag)                infos.Put(&quot;poll&quot;,poll)                infos.Put(&quot;oauth&quot;,OAuth)                infos.Put(&quot;oauthmap&quot;,oauthmap)                infos.Put(&quot;isGame&quot;,Game)                infos.Put(&quot;CoverIcon&quot;,Cover)                infos.Put(&quot;pluginversion&quot;,pluginversion)                infos.Put(&quot;author&quot;,AppAuthor)                infos.Put(&quot;howToPLay&quot;,playdescription)                infos.Put(&quot;description&quot;,AppDescription)                infos.Put(&quot;setupInfos&quot;,SetupInfos)                infos.Put(&quot;hidden&quot;,mHidden)                Return infos            Case &quot;setSettings&quot;                makeSettings                Return True            Case &quot;getUpdateInterval&quot;                Return UpdateInterval            Case &quot;setEnabled&quot;                saveSingleSetting(&quot;Enabled&quot;,Params.Get(&quot;Enabled&quot;))                makeSettings            Case &quot;getEnable&quot;                Return Enabled            Case &quot;stop&quot;                If Game Then                    finishApp=False                    show=False                End If                stopIconRenderer                If SubExists(Target,event&amp;&quot;_Exited&quot;) Then                    CallSub(Target,event&amp;&quot;_Exited&quot;)                End If            Case &quot;getIcon&quot;                If SubExists(Target,event&amp;&quot;_iconRequest&quot;) Then                    CallSub(Target,event&amp;&quot;_iconRequest&quot;)                End If                Return CreateMap(&quot;iconList&quot;:Icon)            Case &quot;iconList&quot;                addToIconRenderer(Params)            Case &quot;externalCommand&quot;                externalCommand(Params)            Case &quot;controller&quot;                Control(Params)            Case &quot;getMenu&quot;                Menu.Initialize                Menu.Put(&quot;Version&quot;,&quot;1.6&quot;)                Menu.Put(&quot;Theme&quot;,&quot;Light Theme&quot;)                Menu.Put(&quot;Items&quot;,MenuList)                Return Menu            Case &quot;setToken&quot;                OAuthToken=Params.Get(&quot;token&quot;)            Case &quot;isReady&quot;                If SubExists(Target,event&amp;&quot;_isReady&quot;) Then                    Return CallSub(Target,event&amp;&quot;_isReady&quot;)                Else                    Return True                End If            Case &quot;shouldShow&quot;                Return show            Case &quot;poll&quot;                Dim s As String=Params.Get(&quot;sub&quot;)                If SubExists(Target,event &amp; &quot;_&quot; &amp; s) Then                    CallSub(Target,event &amp; &quot;_&quot; &amp; s)                End If        End Select        Return True    End Sub    &#39;This function calculates the ammount of pixels wich a text needs    Public Sub calcTextLength(text As String) As Int        If UppercaseLetters Then text = text.ToUpperCase        If TextBuffer&lt;&gt;text Then            Dim Length As Int            For i=0 To text.Length-1                If CharMap.ContainsKey(Asc(text.CharAt(i))) Then                    Length=Length+(CharMap.Get(Asc(text.CharAt(i))))                Else                    Length=Length+4                End If            Next            TextBuffer=text            TextLength=Length            Return Length        End If        Return TextLength    End Sub    &#39;This Helper automaticly display a text in a default app style    &#39;If the text is longer than the Matrixwitdh it will scroll the text    &#39;otherwise it will center the text. Call drawText to handle it manually.    &#39;    &#39;Text - the text to be displayed    &#39;IconOffset - wether you need an offset if you place an icon on the left side.    &#39;yPostition    &#39;Color - custom text color. Pass Null to use the Global textcolor (recommended).    &#39;    &#39;&lt;code&gt;App.genText(&quot;Hello World&quot;,True,Array as int(255,0,0),false)&lt;/code&gt;    Public Sub genText(Text As String,IconOffset As Boolean,yPostition As Int,Color() As Int,callFinish As Boolean)        If Text.Length=0 Then            finish            Return        End If        calcTextLength(Text)        Dim offset As Int        If IconOffset Then offset = 24 Else offset = 32        If TextLength&gt;offset Then            drawText(Text,mscrollposition,yPostition,Color)            mscrollposition=mscrollposition-1            If mscrollposition&lt; 0-TextLength  Then                If LockApp And callFinish Then                    finish                    Return                Else                    mscrollposition=MatrixWidth                End If            End If        Else            Dim x As Int            If TextLength&lt;offset+1 Then                If IconOffset Then                    x=((MatrixWidth/2)-TextLength/2)+4                Else                    x=(MatrixWidth/2)-TextLength/2                End If            End If            drawText(Text,x,yPostition,Color)        End If    End Sub    &#39;This functions build and savee the settings. You dont need to call this manually    Public Sub makeSettings        If Game Then show=False        If File.Exists(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;) Then            Dim data() As Byte = File.ReadBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;)            Dim m As Map = bc.ConvertBytesToObject(data)            For Each k As String In appSettings.Keys                If Not(m.ContainsKey(k)) Then                    m.Put(k,appSettings.Get(k))                Else                    appSettings.Put(k,m.Get(k))                End If            Next            For Counter = m.Size -1 To 0 Step -1                Dim SettingsKey As String = m.GetKeyAt(Counter)                If Not(SettingsKey=&quot;UpdateInterval&quot; Or SettingsKey=&quot;StartTime&quot; Or SettingsKey=&quot;EndTime&quot; Or SettingsKey=&quot;DisplayTime&quot; Or SettingsKey=&quot;Enabled&quot;)   Then                    If Not(appSettings.ContainsKey(SettingsKey)) Then m.Remove(SettingsKey)                End If            Next            Try                Enabled=m.Get(&quot;Enabled&quot;)                startTime=m.Get(&quot;StartTime&quot;)                endtime=m.Get(&quot;EndTime&quot;)                UpdateInterval=m.Get(&quot;UpdateInterval&quot;)                DisplayTime=m.Get(&quot;DisplayTime&quot;)                File.WriteBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;,bc.ConvertObjectToBytes(m))                If SubExists(Target,event&amp;&quot;_settingsChanged&quot;) Then                    CallSub(Target,event&amp;&quot;_settingsChanged&quot;)&#39;ignore                End If            Catch                Log(&quot;Got Error from &quot; &amp; appName)                Log(&quot;Error while saving settings&quot;)                Log(LastException)            End Try        Else            Dim m As Map            m.Initialize            m.Put(&quot;UpdateInterval&quot;,UpdateInterval)            m.Put(&quot;StartTime&quot;,&quot;00:00&quot;)            m.Put(&quot;EndTime&quot;,&quot;00:00&quot;)            m.Put(&quot;DisplayTime&quot;,&quot;0&quot;)            m.Put(&quot;Enabled&quot;,True)            For Each k As String In appSettings.Keys                m.Put(k,appSettings.Get(k))            Next            File.WriteBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;,bc.ConvertObjectToBytes(m))        End If    End Sub    &#39;Returns the value of a Settingskey    public Sub get(SettingsKey As String) As Object        If appSettings.ContainsKey(SettingsKey) Then            Return appSettings.Get(SettingsKey)        Else            Log(SettingsKey &amp; &quot; not found&quot;)            Return &quot;&quot;        End If    End Sub    Public Sub  saveSingleSetting(key As String, value As Object)        If File.Exists(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;) Then            Dim data() As Byte = File.ReadBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;)            Dim m As Map = bc.ConvertBytesToObject(data)            m.Put(key,value)            File.WriteBytes(File.Combine(File.DirApp,&quot;Apps&quot;),appName&amp;&quot;.ax&quot;,bc.ConvertObjectToBytes(m))        End If    End Sub    &#39;Draws a Bitmap    Public Sub drawBMP(x As Int,y As Int,bmp() As Short,width As Int, height As Int)        commandList.Add(CreateMap(&quot;type&quot;:&quot;bmp&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;bmp&quot;:bmp,&quot;width&quot;:width,&quot;height&quot;:height))    End Sub    &#39;Draws a Text    Public Sub drawText(text As String,x As Int, y As Int,Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;text&quot;,&quot;text&quot;:text,&quot;x&quot;:x,&quot;y&quot;:y))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;text&quot;,&quot;text&quot;:text,&quot;x&quot;:x,&quot;y&quot;:y,&quot;color&quot;:Color))        End If    End Sub    &#39;Draws a Circle    Public Sub drawCircle(X As Int, Y As Int, Radius As Int, Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;circle&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;r&quot;:Radius,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;circle&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;r&quot;:Radius,&quot;color&quot;:Color))        End If    End Sub    &#39;Draws a filled Circle    Public Sub fillCircle(X As Int, Y As Int, Radius As Int, Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;fillCircle&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;r&quot;:Radius,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;fillCircle&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;r&quot;:Radius,&quot;color&quot;:Color))        End If    End Sub    &#39;Draws a single Pixel    Public Sub drawPixel(X As Int,Y As Int,Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;pixel&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;pixel&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;color&quot;:Color))        End If    End Sub    &#39;Draws a Rectangle    Public Sub drawRect(X As Int,Y As Int,Width  As Int,Height As Int,Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;rect&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;w&quot;:Width,&quot;h&quot;:Height,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;rect&quot;,&quot;x&quot;:x,&quot;y&quot;:y,&quot;w&quot;:Width,&quot;h&quot;:Height,&quot;color&quot;:Color))        End If    End Sub    &#39;Draws a Line    Public Sub drawLine(X0 As Int,Y0 As Int,X1  As Int,Y1 As Int,Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;line&quot;,&quot;x0&quot;:X0,&quot;y0&quot;:Y0,&quot;x1&quot;:X1,&quot;y1&quot;:Y1,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;line&quot;,&quot;x0&quot;:X0,&quot;y0&quot;:Y0,&quot;x1&quot;:X1,&quot;y1&quot;:Y1,&quot;color&quot;:Color))        End If    End Sub    &#39;Sends a custom or undocumented command    Public Sub customCommand(cmd As Map)        commandList.Add(cmd)    End Sub    &#39;Fills the screen with a color    Public Sub fill(Color() As Int)        If Color=Null Then            commandList.Add(CreateMap(&quot;type&quot;:&quot;fill&quot;,&quot;color&quot;:SystemColor))        Else            commandList.Add(CreateMap(&quot;type&quot;:&quot;fill&quot;,&quot;color&quot;:Color))        End If    End Sub    &#39;Exits the app and force AWTRIX to switch to the next App    &#39;only needed if you have set LockApp to true    Public Sub finish        finishApp=True    End Sub    &#39;Returns a rainbowcolor wich is fading each tick    Public Sub rainbow As Int()        colorCounter=colorCounter+1        If colorCounter&gt;255 Then colorCounter=0        Return(wheel(colorCounter))    End Sub    Private Sub wheel(Wheelpos As Int) As Int() &#39;ignore        If(Wheelpos &lt; 85) Then            Return Array As Int(Wheelpos * 3, 255 - Wheelpos * 3, 0)        else if(Wheelpos &lt; 170) Then            Wheelpos =Wheelpos- 85            Return  Array As Int(255 - Wheelpos * 3, 0, Wheelpos * 3)        Else            Wheelpos =Wheelpos- 170            Return  Array As Int(0, Wheelpos * 3, 255 - Wheelpos * 3)        End If    End Sub    Public Sub Logger(msg As String)        If verboseLog Then            DateTime.DateFormat=DateTime.DeviceDefaultTimeFormat            Log(DateTime.Date(DateTime.Now) &amp;&quot;      &quot; &amp; appName &amp; &quot;:&quot; &amp; CRLF &amp;  msg)        End If    End Sub    Private Sub Control(controller As Map)        If controller.ContainsKey(&quot;GameStart&quot;) And Game Then            Dim state As Boolean = controller.Get(&quot;GameStart&quot;)            If state Then                show=True            Else                finishApp=True                show=False            End If            Return        End If        If controller.ContainsKey(&quot;button&quot;) Then            Dim buttonNR As Int = controller.Get(&quot;button&quot;)            Dim buttonDIR As Boolean = controller.Get(&quot;dir&quot;)            If SubExists(Target,event&amp;&quot;_controllerButton&quot;) Then                CallSub3(Target,event&amp;&quot;_controllerButton&quot;,buttonNR,buttonDIR)            End If            If verboseLog Then                If buttonDIR Then Logger($&quot;Button ${buttonNR} down&quot;$) Else Logger($&quot;Button ${buttonNR} up&quot;$)            End If            Return        End If        If controller.ContainsKey(&quot;axis&quot;) Then            Dim AxisNR As Int = controller.Get(&quot;axis&quot;)            Dim val As Float = controller.Get(&quot;dir&quot;)            If SubExists(Target,event&amp;&quot;_controllerAxis&quot;) Then                CallSub3(Target,event&amp;&quot;_controllerAxis&quot;,AxisNR,val)            End If            Return        End If    End Sub    Private Sub externalCommand(cmd As Map)        If SubExists(Target,event&amp;&quot;_externalCommand&quot;) Then            CallSub2(Target,event&amp;&quot;_externalCommand&quot;,cmd)        End If    End Sub    Public Sub throwError(message As String)        Logger(message)    End Sub    &#39;Returns the timestamp when the app was started.    Sub getstartedAt As Long        Return startTimestamp    End Sub    &#39;Gets or sets the app tags    Sub gettags As List        Return Tag    End Sub    Sub settags(Tags As List)        Tag=Tags    End Sub    &#39;Returns the runtime of the app    Sub getduration As Int        Return Appduration    End Sub    &#39;If set to true, awtrix will skip this app    Sub setshouldShow(shouldShow As Boolean)        show=shouldShow    End Sub    &#39;If set to true, AWTRIX will download new data before each start.    Sub setforceDownload(forceDownload As Boolean)        forceDown=forceDownload    End Sub    &#39;If set to true AWTRIX will wait for the &quot;finish&quot; command before switch to the next app.    Sub setlock(lock As Boolean)        LockApp=lock    End Sub    &#39;IconIDs from AWTRIXER. You can add multiple if you need more    Sub seticons(icons As List)        Icon=icons    End Sub    &#39;Sets or gets the appname    Sub getname As String        Return appName    End Sub    Sub setname(name As String)        appName=name    End Sub    &#39;Sets or gets the app description    Sub getdescription As String        Return AppDescription    End Sub    Sub setdescription(description As String)        AppDescription=description    End Sub    &#39;The developer if this App    Sub getauthor As String        Return AppAuthor    End Sub    Sub setauthor(author As String)        AppAuthor=author    End Sub    &#39;Sets or gets the appversion    Sub getversion As String        Return AppVersion    End Sub    Sub setversion(version As String)        AppVersion=version    End Sub    &#39;Sets or gets the tickinterval    Sub gettick As String        Return TickInterval    End Sub    Sub settick(tick As String)        TickInterval=tick    End Sub    &#39;How many downloadhandlers should be generated    Sub setdownloads(downloads As Int)        NeedDownloads=downloads    End Sub    &#39;Setup Instructions. You can use HTML to format it    Sub setsetupDescription(setupDescription As String)        SetupInfos=setupDescription    End Sub    &#39;gets all informations from the matrix as a map    Sub getmatrix As Map        Return MatrixInfo    End Sub    &#39;needed Settings for this App (wich can be configurate from user via webinterface)    Sub setsettings(settings As Map)        appSettings=settings    End Sub    &#39;returns the version of the serever    Sub getserver As String        Return ServerVersion    End Sub    &#39;returns the size of the Matrix as an array (height,width)    Sub getmatrixSize As Int()        Dim size() As Int = Array As Int(MatrixHeight,MatrixWidth)        Return size    End Sub    &#39;if this is a game you can set your play instructions here    Sub sethowToPlay(howToPlay As String)        playdescription=howToPlay    End Sub    &#39;Icon (ID) to be displayed in the Appstore and MyApps    Sub setcoverIcon(coverIcon As Int)        Cover=coverIcon    End Sub    &#39;set this to true if this is a game.    Sub setisGame(isGame As Boolean)        Game=isGame    End Sub    public Sub InitializeOAuth (AuthorizeURL As String, TokenURL As String, ClientId As String, ClientSecret As String, Scope As String)        OAuth=True        oauthmap=CreateMap(&quot;AuthorizeURL&quot;:AuthorizeURL,&quot;TokenURL&quot;:TokenURL,&quot;ClientId&quot;:ClientId,&quot;ClientSecret&quot;:ClientSecret,&quot;Scope&quot;:Scope)    End Sub    Sub getToken As String        Return OAuthToken    End Sub    Sub getScrollposition As Int        Return mscrollposition    End Sub    &#39;Sends a POST request with the given data as the post data.    Public Sub PostString(Link As String, Text As String)        httpMap=CreateMap(&quot;type&quot;:&quot;PostString&quot;,&quot;Link&quot;:Link,&quot;Text&quot;:Text)    End Sub    &#39;Sends a POST request with the given string as the post data    Public Sub PostBytes(Link As String, Data() As Byte)        httpMap=CreateMap(&quot;type&quot;:&quot;PostBytes&quot;,&quot;Link&quot;:Link,&quot;Data&quot;:Data)    End Sub    &#39;Sends a PUT request with the given data as the post data.    Public Sub PutString(Link As String, Text As String)        httpMap=CreateMap(&quot;type&quot;:&quot;PutString&quot;,&quot;Link&quot;:Link,&quot;Text&quot;:Text)    End Sub    &#39;Sends a PUT request with the given string as the post data    Public Sub PutBytes(Link As String, Data() As Byte)        httpMap=CreateMap(&quot;type&quot;:&quot;PutBytes&quot;,&quot;Link&quot;:Link,&quot;Data&quot;:Data)    End Sub    &#39;Sends a PATCH request with the given string as the request payload.    Public Sub PatchString(Link As String, Text As String)        httpMap=CreateMap(&quot;type&quot;:&quot;PatchString&quot;,&quot;Link&quot;:Link,&quot;Text&quot;:Text)    End Sub    &#39;Sends a PATCH request with the given data as the request payload.    Public Sub PatchBytes(Link As String, Data() As Byte)        httpMap=CreateMap(&quot;type&quot;:&quot;PatchBytes&quot;,&quot;Link&quot;:Link,&quot;Data&quot;:Data)    End Sub    &#39;Sends a HEAD request.    Public Sub Head(Link As String)        httpMap=CreateMap(&quot;type&quot;:&quot;Head&quot;,&quot;Link&quot;:Link)    End Sub    &#39;Sends a multipart POST request.    &#39;NameValues - A map with the keys and values. Pass Null if not needed.    &#39;Files - List of MultipartFileData items. Pass Null if not needed.    Public Sub PostMultipart(Link As String, NameValues As Map, Files As List)        httpMap=CreateMap(&quot;type&quot;:&quot;PostMultipart&quot;,&quot;Link&quot;:Link,&quot;NameValues&quot;:NameValues,&quot;Files&quot;:Files)    End Sub    &#39;Sends a POST request with the given file as the post data.    &#39;This method doesn&#39;t work with assets files.    Public Sub PostFile(Link As String, Dir As String, FileName As String)        httpMap=CreateMap(&quot;type&quot;:&quot;PostFile&quot;,&quot;Link&quot;:Link,&quot;Dir&quot;:Dir,&quot;FileName&quot;:FileName)    End Sub    &#39;Submits a HTTP GET request.    &#39;Consider using Download2 if the parameters should be escaped.    Public Sub Download(Link As String)        httpMap=CreateMap(&quot;type&quot;:&quot;Download&quot;,&quot;Link&quot;:Link)    End Sub    &#39;Submits a HTTP GET request.    &#39;Encodes illegal parameter characters.    &#39;&lt;code&gt;Example:    &#39;job.Download2(&quot;http://www.example.com&quot;, _    &#39;    Array As String(&quot;key1&quot;, &quot;value1&quot;, &quot;key2&quot;, &quot;value2&quot;))&lt;/code&gt;    Public Sub Download2(Link As String, Parameters() As String)        httpMap=CreateMap(&quot;type&quot;:&quot;Download2&quot;,&quot;Link&quot;:Link,&quot;Parameters&quot;:Parameters)    End Sub    &#39;Sets the header for the request as an map    &#39;(Headername,Headervalue)    Public Sub setHeader(header As Map)        DownloadHeader=header    End Sub    &#39;Sets the Mime header of the request.    &#39;This method should only be used with requests that have a payload.    Public Sub SetContentType(ContentType As String)        mContentType=ContentType    End Sub    &#39;enables pollingmode    &#39;pass the subname wich should be called every 5s. e.g for App_mySub :    &#39;&lt;code&gt;app.pollig(&quot;mySub&quot;):&lt;/code&gt;    &#39;if you pass a empty String (&quot;&quot;) AWTRIX will start the download    Public Sub polling(enable As Boolean,subname As String)        poll=CreateMap(&quot;enable&quot;:enable,&quot;sub&quot;:subname)    End Sub    &#39;hide this app from apploop    Sub setHidden(hide As Boolean)        mHidden=hide    End Sub</code></pre><ol start="2"><li>BlogViews.b4j: b4j 工程配置文件</li></ol><pre><code class="text">    AppType=StandardJava    Build1=Default,b4j.example    Group=Default Group    Library1=jcore    Library2=json    Library3=jrandomaccessfile    Module1=AWTRIX    Module2=BlogViews    NumberOfFiles=0    NumberOfLibraries=3    NumberOfModules=2    Version=8.5    @EndOfDesignText@    &#39;Draws a Rectangle&#39;Non-UI application (console / server application)    #Region Project Attributes         #LibraryName:BlogViews    #End Region    Sub Process_Globals    End Sub    Sub AppStart (Args() As String)    End Sub    &#39;Return true to allow the default exceptions handler to handle the uncaught exception.    Sub Application_Error (Error As Exception, StackTrace As String) As Boolean        Return True    End Sub</code></pre><p>其中修改：</p><ul><li>Module2</li><li>LibraryName</li></ul><ol start="3"><li>BlogViews.bas： 程序主文件</li></ol><pre><code class="text">    B4J=true    Group=Default Group    ModulesStructureVersion=1    Type=Class    Version=4.2    @EndOfDesignText@    Sub Class_Globals        Dim App As AWTRIX        &#39;Declare your variables here        Dim followers As Int = 0        Dim iconId As Int = 8    End Sub    &#39; ignore    public Sub GetNiceName() As String        Return App.Name    End Sub    &#39; ignore    public Sub Run(Tag As String, Params As Map) As Object        Return App.interface(Tag,Params)    End Sub    &#39; Config your App    Public Sub Initialize() As String        App.Initialize(Me,&quot;App&quot;)        &#39;App name (must be unique, avoid spaces)        App.Name=&quot;BlogViews&quot;        &#39;Version of the App        App.Version=&quot;1.0&quot;        &#39;Description of the App. You can use HTML to format it        App.Description=$&quot;Shows your website unique visitor on &lt;b&gt;busuanzi&lt;/b&gt; statistical tools&quot;$        App.Author=&quot;JoyLau&quot;        App.CoverIcon=iconId        &#39;SetupInstructions. You can use HTML to format it        App.setupDescription= $&quot;        &lt;b&gt;Website:&lt;/b&gt;  Your Website Address&lt;br/&gt;        &lt;b&gt;IconID:&lt;/b&gt;  Icon id&lt;br/&gt;        &quot;$        &#39;How many downloadhandlers should be generated        App.Downloads=1        &#39;IconIDs from AWTRIXER. You can add multiple if you want to display them at the same time        App.Icons=Array As Int(iconId)        &#39;Tickinterval in ms (should be 65 by default, for smooth scrolling))p://        App.Tick=65        &#39;needed Settings for this App (Wich can be configurate from user via webinterface)        App.settings=CreateMap(&quot;Website&quot;:&quot;http://blog.joylau.cn&quot;,&quot;IconID&quot;:iconId)        App.MakeSettings        Return &quot;AWTRIX20&quot;    End Sub    &#39;this sub is called right before AWTRIX will display your App    Sub App_Started    End Sub    &#39;Called with every update from Awtrix    &#39;return one URL for each downloadhandler    Sub App_startDownload(jobNr As Int)        Select jobNr            Case 1                App.Download(&quot;http://busuanzi.ibruce.info/busuanzi?jsonpCallback=callback&quot;)                App.Header = CreateMap(&quot;Referer&quot;:App.Get(&quot;Website&quot;),&quot;Cookie&quot;:&quot;busuanziId=D58737A150864C68B83F962028616CD6&quot;)        End Select    End Sub    &#39;process the response from each download handler    &#39;if youre working with JSONs you can use this online parser    &#39;to generate the code automaticly    &#39;https://json.blueforcer.de/     Sub App_evalJobResponse(Resp As JobResponse)        Try            If Resp.success Then                Select Resp.jobNr                    Case 1                        Dim parser As JSONParser                        parser.Initialize(Resp.ResponseString.replace(&quot;try{callback(&quot;,&quot;&quot;).replace(&quot;);}catch(e){}&quot;,&quot;&quot;))                        Dim root As Map = parser.NextObject                        followers = root.Get(&quot;site_uv&quot;)                End Select            End If        Catch            Log(&quot;Error in: &quot;&amp; App.Name &amp; CRLF &amp; LastException)            Log(&quot;API response: &quot; &amp; CRLF &amp; Resp.ResponseString)        End Try    End Sub    &#39;this sub is called right before AWTRIX will display your App    Sub App_iconRequest        App.Icons=Array As Int(App.Get(&quot;IconID&quot;))    End Sub    &#39;With this sub you build your frame.    Sub App_genFrame        App.genText(followers,True,1,Null,True)        App.drawBMP(0,0,App.getIcon(App.Get(&quot;IconID&quot;)),8,8)    End Sub</code></pre><p>配置项解释：</p><ol><li>App.name： 应用程序的名称。在Appstore，MyApps和文件名中使用  </li><li>App.version： 应用程序的版本。版本必须是数字，并且最多可以包含2个小数位（例如1.25）  </li><li>App.description： 应用程序的描述，简要地描述应用。可以选择将文本格式设置为HTML  </li><li>App.author： 应用程序的创建者。  </li><li>App.coverIcon：应用程序的图标。数据库中的 IconID。也可以在 Web 页面里创建并上传自己的图标  </li><li>App.settings： 应用程序的设置。生成一个由键和值组成的映射。例如```CreateMap（“ Key”：“ Value”）``可以输入缺省值，以便应用可以立即启动，也可以将值保留为空（“”），以便 AWTRIX 通知用户需要调整。在设置之前，AWTRIX 将不会加载该应用程序！  </li><li>App.setupDescription： 简要说明如何设置应用程序。可以将文本格式设置为HTML  </li><li>App.downloads： 指定您的应用需要下载多少次。如果一个下载依赖于另一下载，则需要多次下载。 </li><li>App.icons： 指定应用程序需要的图标。在启动应用程序之前，这些也将由 AWTRIX 下载。 </li><li>App.tick： 指定应用程序应运行的速度。对于简单的文本，65（ms）是最适合的。  </li></ol><p>程序解释： </p><ol><li>设置默认的访问量 0，默认使用的图标 id: 1230  </li><li>App 运行时请求接口： <a href="http://busuanzi.ibruce.info/busuanzi?jsonpCallback=callback，" target="_blank" rel="noopener">http://busuanzi.ibruce.info/busuanzi?jsonpCallback=callback，</a> 需要带上头信息 Referer，和 Cookie  </li></ol><p>Referer： 模拟浏览器请求，否则的话不蒜子的接口将不可用<br>Cookie： 带上 Cookie 的话相当于用户一直在刷新网页的效果，此时独立访客数不会 +1 的， 不带上的话每次访问接口都是导致数目 +1 ,造成数量不准确  </p><ol start="3"><li>解析返回的回调信息字符串结果， 获取想要的数据 <code>site_uv</code></li></ol><h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><ol><li>将以上项目导入 B4J</li><li>点击 <code>Tools</code> -&gt; <code>Configure Paths</code> , 设置 javac 的目录和 jar 包导出目录(Additional Libraries)</li><li>编译 jar 包： 点击 <code>Project</code> -&gt; <code>Compile to Library</code></li></ol><h3 id="手动安装"><a href="#手动安装" class="headerlink" title="手动安装"></a>手动安装</h3><ol><li>将已编译的 <code>jar</code> 包复制到服务端的 <code>Apps</code> 文件夹中</li><li>在 Awtrix Web 界面重新启动 AWTRIX</li></ol><pre><code class="bash">    reload apps</code></pre>]]></content>
      
      
      <categories>
          
          <category> Awtrix </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Awtrix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IntelliJ 软件代理报错：You have JVM property https.proxyHost set..</title>
      <link href="/2020/07/20/IntelliJIDEA-Proxy/"/>
      <url>/2020/07/20/IntelliJIDEA-Proxy/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="报错信息"><a href="#报错信息" class="headerlink" title="报错信息"></a>报错信息</h3><pre><code class="shell">    You have JVM property https.proxyHost set to &#39;...&#39;.    This may lead to incorrect behaviour. Proxy should be set in Settings | Proxy</code></pre><p>这是由于本地开启了科学上网代理服务造成的</p><h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p>select Help -&gt; Edit Custom VM Options add below:</p><p>-Dhttp.proxyHost<br>-Dhttp.proxyPort<br>-Dhttps.proxyHost<br>-Dhttps.proxyPort<br>-DsocksProxyHost<br>-DsocksProxyPort</p>]]></content>
      
      
      <categories>
          
          <category> IntelliJ IDEA篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IntelliJ IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>async 在箭头函数上的使用方式</title>
      <link href="/2020/07/10/JavaScript-Async/"/>
      <url>/2020/07/10/JavaScript-Async/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><pre><code class="js">    fun = async () =&gt; {       await .....    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaScript篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 多文件边压缩边下载</title>
      <link href="/2020/07/01/Java-Multi-Files-Compress-Downloading/"/>
      <url>/2020/07/01/Java-Multi-Files-Compress-Downloading/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>有时我们希望在后台实时生成文件并下载到客户端</p><pre><code class="java">    @GetMapping(value = &quot;download&quot;)    public void download(HttpServletResponse response) {       try(OutputStream outputStream = response.getOutputStream();          ZipOutputStream zipOutputStream = new ZipOutputStream(outputStream, StandardCharsets.UTF_8)       ) {          response.setContentType(&quot;application/octet-stream&quot;);          response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment; filename=&quot; + new String(&quot;压缩文件.zip&quot;.getBytes(&quot;UTF-8&quot;), &quot;ISO-8859-1&quot;));          File[] files = new File(&quot;&quot;).listFiles();          for (File file : files) {             // 单个文件压缩             compress(zipOutputStream, new FileInputStream(file), file.getName());          }          zipOutputStream.flush();       } catch (IOException e) {       }    }    /**     * 单个文件压缩     *     * @param zipOutputStream     * @param inputStream     * @param fileName     * @throws IOException     */    private static void compress(ZipOutputStream zipOutputStream, InputStream inputStream, String fileName) throws IOException {        if (inputStream == null) return;        zipOutputStream.putNextEntry(new ZipEntry(fileName));        int bytesRead;        byte[] buffer = new byte[FileUtil.BUFFER_SIZE];        while ((bytesRead = inputStream.read(buffer)) != -1) {            zipOutputStream.write(buffer, 0, bytesRead);        }        zipOutputStream.closeEntry();        inputStream.close();    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Java篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron ---- Better-Sqlite3 使用问题</title>
      <link href="/2020/06/10/Electron-Better-Sqlite3/"/>
      <url>/2020/06/10/Electron-Better-Sqlite3/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h3><pre><code class="bash">     The module &#39;/node_modules/better-sqlite3/build/better_sqlite3.node&#39;    was compiled against a different Node.js version using    NODE_MODULE_VERSION 57. This version of Node.js requires    NODE_MODULE_VERSION 64. Please try re-compiling or re-installing    the module (for instance, using `npm rebuild` or `npm install`).</code></pre><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p><code>npm install --save-dev electron-rebuild</code><br>使用electron-rebuild进行重新编译:</p><p><code>node_modules/.bin/electron-rebuild -f -w better-sqlite3</code></p><p>如果没有编译成功, 则查看是否安装了, node-gyp<br>因为在 electron-rebuild 项目的 README 里,<br>看到这句话: </p><pre><code class="bash">    If you have a good node-gyp config but you see an error about a missing element on Windows like `Could not load the Visual C++ component &quot;VCBuild.exe&quot;`, try to launch electron-rebuild in an npm script:</code></pre>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenVPN 配置文件说明</title>
      <link href="/2020/05/28/OpenVPN-Config/"/>
      <url>/2020/05/28/OpenVPN-Config/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>多客户端服务器的OpenVPN 2.0配置文件示例<br>本文件用于多客户端&lt;-&gt;单服务器端的<br>OpenVPN服务器端配置</p><h1 id="2-配置文件说明"><a href="#2-配置文件说明" class="headerlink" title="2. 配置文件说明"></a>2. 配置文件说明</h1><ul><li><a href="#21-服务端配置文件">2.1. 服务端配置文件</a></li><li><a href="#22-客户端配置文件">2.2. 客户端配置文件</a></li></ul><h2 id="2-1-服务端配置文件"><a href="#2-1-服务端配置文件" class="headerlink" title="2.1. 服务端配置文件"></a>2.1. 服务端配置文件</h2><p><a href="https://github.com/OpenVPN/openvpn/blob/master/sample/sample-config-files/server.conf" target="_blank" rel="noopener">英文原文</a></p><pre><code class="shell">################################################## 多客户端服务器的OpenVPN 2.0配置文件示例          ##                                               ## 本文件用于多客户端&lt;-&gt;单服务器端的                ## OpenVPN服务器端配置                            ##                                               ## OpenVPN也支持单机&lt;-&gt;单机的配置                  ## (在网站上的示例页面更多信息)                    ##                                               ## 这个配置可以在Windows或Linux/BSD系统上工作。     ## Windows的路径名需要加双引号并使用双反斜杠，如：   ## &quot;C:\\Program Files\\OpenVPN\\config\\foo.key&quot; ##                                               ## 前面加&#39;#&#39;或&#39;;&#39;的是注释                          ################################################### OpenVPN应该监听哪个本地IP地址（可选）# 如果不设置，默认监听所有IP;local a.b.c.d# OpenVPN应该监听哪个端口(TCP/UDP)# 如果想在同一台计算机上运行多个OpenVPN实例，可以使用不同的端口号来区分它们# 在防火墙上打开这个端口port 1194# 服务器使用TCP还是UDP协议;proto tcpproto udp# 指定OpenVPN创建的通信隧道类型# &quot;dev tun&quot;将会创建一个路由IP隧道# &quot;dev tap&quot;将会创建一个以太网隧道# 如果是以太网桥接模式，并且提前创建了一个名为&quot;tap0&quot;的与以太网接口进行桥接的虚拟接口，则你可以使用&quot;dev tap0&quot;# 如果想控制VPN的访问策略，必须为TUN/TAP接口创建防火墙规则# 在非Windows系统中，可以给出明确的单位编号，如&quot;tun0&quot;# 在Windows中，也可以使用&quot;dev-node&quot;# 在大多数系统上，除非部分或完全禁用了TUN/TAP接口的防火墙，否则VPN将不起作用。;dev tapdev tun# 如果想配置多个隧道，需要用到网络连接面板中TAP-Win32适配器的名称(如&quot;MyTap&quot;)# 在XP SP2或更高版本的系统中，可能需要有选择地禁用掉针对TAP适配器的防火墙# 通常情况下，非Windows系统则不需要该指令。;dev-node MyTap# 设置SSL/TLS根证书(ca)、证书(cert)和私钥(key)。# 每个客户端和服务器端都需要它们各自的证书和私钥文件。# 服务器端和所有的客户端都将使用相同的CA证书文件。## 通过easy-rsa目录下的一系列脚本可以生成所需的证书和私钥。# 服务器端和每个客户端的证书必须使用唯一的Common Name。## 也可以使用遵循X509标准的任何密钥管理系统来生成证书和私钥。# OpenVPN也支持使用一个PKCS #12格式的密钥文件(详情查看站点手册页面的&quot;pkcs12&quot;指令)ca ca.crtcert server.crtkey server.key  # 该文件应该保密# 迪菲·赫尔曼参数# 使用如下命令生成：#   openssl dhparam -out dh2048.pem 2048dh dh2048.pem# 网络拓扑结构# 应该为子网(通过IP寻址)# 除非必须支持Windows客户端v2.0.9及更低版本(net30即每个客户端/30)# 默认为&quot;net30&quot;(不建议);topology subnet# 设置服务器端模式，并提供一个VPN子网，以从中为客户端分配IP地址# 本例中服务器端自身占用10.8.0.1，其他的将分配给客户端使用# 每个客户端将能够通过10.8.0.1访问服务器# 如果使用的是以太网桥接模式，注释掉本行。更多信息请查看官方手册页面。server 10.8.0.0 255.255.255.0# 在此文件中维护客户端与虚拟IP地址之间的关联记录# 如果OpenVPN重启，重新连接的客户端可以被分配到先前分配的虚拟IP地址ifconfig-pool-persist ipp.txt# 该指令仅针对以太网桥接模式# 首先，必须使用操作系统的桥接能力将以太网网卡接口和TAP接口进行桥接# 然后，需要手动设置桥接接口的IP地址、子网掩码，这里假设为10.8.0.4和255.255.255.0# 最后，必须指定子网的一个IP范围(例如从10.8.0.50开始，到10.8.0.100结束)，以便于分配给连接的客户端# 如果不是以太网桥接模式，直接注释掉这行指令即可;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100# 该指令仅针对使用DHCP代理的以太网桥接模式# 此时客户端将请求服务器端的DHCP服务器，从而获得分配给它的IP地址和DNS服务器地址# 在此之前，也需要先将以太网网卡接口和TAP接口进行桥接# 注意：该指令仅用于OpenVPN客户端(如Windows)，并且该客户端的TAP适配器需要绑定到一个DHCP客户端上;server-bridge# 推送路由信息到客户端，以允许客户端能够连接到服务器后的其他私有子网# 即允许客户端访问VPN服务器可访问的其他局域网# 记住，这些私有子网还需要将OpenVPN客户端地址池（10.8.0.0/255.255.255.0）路由回到OpenVPN服务器;push &quot;route 192.168.10.0 255.255.255.0&quot;;push &quot;route 192.168.20.0 255.255.255.0&quot;# 要为指定的客户端分配特定的IP地址，或者客户端后的私有子网也要访问VPN# 可以针对该客户端的配置文件使用ccd子目录# 请参阅手册页获取更多信息# 示例1：假设有个Common Name为&quot;Thelonious&quot;的客户端后有一个小型子网也要连接到VPN# 该子网为192.168.40.128/255.255.255.248# 首先，去掉下面两行指令的注释：;client-config-dir ccd;route 192.168.40.128 255.255.255.248# 然后创建一个文件ccd/Thelonious，该文件的内容为(没有&quot;#&quot;)：#   iroute 192.168.40.128 255.255.255.248# 客户端所在的子网就可以访问VPN了# 注意，这个指令只能在基于路由模式而不是基于桥接模式下才能生效# 比如，你使用了&quot;dev tun&quot;和&quot;server&quot;指令# 示例1：假设要给Thelonious分配一个固定的IP地址10.9.0.1# 首先，去掉下面两行指令的注释：;client-config-dir ccd;route 10.9.0.0 255.255.255.252# 然后在文件ccd/Thelonious中添加如下指令(没有&quot;#&quot;)：#   ifconfig-push 10.9.0.1 10.9.0.2# 如果想要为不同群组的客户端启用不同的防火墙访问策略，你可以使用如下两种方法：# (1)运行多个OpenVPN守护进程，每个进程对应一个群组，并为每个进程(群组)启用适当的防火墙规则# (2)(进阶)创建一个脚本来动态地修改响应于来自不同客户的防火墙规则# 关于learn-address脚本的更多信息请参考官方手册页面;learn-address ./script# 如果启用该行指令，所有客户端的默认网关都将重定向到VPN# 这将导致诸如web浏览器、DNS查询等所有客户端流量都经过VPN# (为确保能正常工作，OpenVPN服务器所在计算机可能需要在TUN/TAP接口与以太网之间使用NAT或桥接技术进行连接);push &quot;redirect-gateway def1 bypass-dhcp&quot;# 某些具体的Windows网络设置可以被推送到客户端，例如DNS或WINS服务器地址# 下列地址来自opendns.com提供的Public DNS服务器;push &quot;dhcp-option DNS 208.67.222.222&quot;;push &quot;dhcp-option DNS 208.67.220.220&quot;# 去掉该行指令的注释将允许不同的客户端之间互相访问# 默认情况，客户端只能访问服务器# 为了确保客户端只能看见服务器，还可以在服务器端的TUN/TAP接口上设置适当的防火墙规则;client-to-client# 如果多个客户端可能使用相同的证书/私钥文件或Common Name进行连接，那么可以取消该指令的注释# 建议该指令仅用于测试目的。对于生产环境使用而言，每个客户端都应该拥有自己的证书和私钥# 如果没有为每个客户端分别生成Common Name唯一的证书/私钥，可以取消该行的注释(不推荐这样做);duplicate-cn# keepalive指令将导致类似于ping命令的消息被来回发送，以便于服务器端和客户端知道对方何时被关闭# 每10秒钟ping一次，如果120秒内都没有收到对方的回复，则表示远程连接已经关闭keepalive 10 120# 出于SSL/TLS之外更多的安全考虑，创建一个&quot;HMAC 防火墙&quot;可以帮助抵御DoS攻击和UDP端口淹没攻击# 可以使用以下命令来生成：#   openvpn --genkey --secret ta.key## 服务器和每个客户端都需要拥有该密钥的一个拷贝# 第二个参数在服务器端应该为&#39;0&#39;，在客户端应该为&#39;1&#39;tls-auth ta.key 0  # 该文件应该保密# 选择一个密码加密算法，该配置项也必须复制到每个客户端配置文件中# 注意，v2.4客户端/服务器将自动以TLS模式协商AES-256-GCM，请参阅手册中的ncp-cipher选项cipher AES-256-CBC# 在VPN链接上启用压缩并将选项推送到客户端（仅适用于v2.4 +，对于早期版本，请参阅下文）;compress lz4-v2;push &quot;compress lz4-v2&quot;# 对于与旧客户端兼容的压缩，使用comp-lzo# 如果在此启用，还必须在客户端配置文件中启用它;comp-lzo# 允许并发连接的客户端的最大数量;max-clients 100# 初始化后减少OpenVPN守护进程的权限是一个好主意# 该指令仅限于非Windows系统中使用;user nobody;group nobody# 持久化选项可以尽量避免访问那些在重启之后由于用户权限降低而无法访问的某些资源persist-keypersist-tun# 输出一个简短的状态文件，用于显示当前的连接状态，该文件每分钟都会清空并重写一次status openvpn-status.log# 默认情况下，日志消息将写入syslog(在Windows系统中，如果以服务方式运行，日志消息将写入OpenVPN安装目录的log文件夹中)# 可以使用log或者log-append来改变这种默认设置# &quot;log&quot;方式在每次启动时都会清空之前的日志文件# &quot;log-append&quot;是在之前的日志内容后进行追加# 你可以使用两种方式之一(不要同时使用);log         openvpn.log;log-append  openvpn.log# 为日志文件设置适当的冗余级别(0~9)# 冗余级别越高，输出的信息越详细## 0 表示静默运行，只记录致命错误# 4 表示合理的常规用法# 5和6 可以帮助调试连接错误# 9 表示极度冗余，输出非常详细的日志信息verb 3# 忽略过多的重复信息# 相同类别的信息只有前20条会输出到日志文件中;mute 20# 通知客户端，当服务器重新启动时，可以自动重新连接# 只能是UDP协议使用，TCP使用的话不能启动服务explicit-exit-notify 1# （如果不添加该指令则）默认值3600，也就是一个小时进行一次TSL重新协商# 这个参数在服务端和客户端设置都有效# 如果两边都设置了，就按照时间短的设定优先# 当两边同时设置成0，表示禁用TSL重协商。使用OTP认证需要禁用reneg-sec 0</code></pre><h2 id="2-2-客户端配置文件"><a href="#2-2-客户端配置文件" class="headerlink" title="2.2. 客户端配置文件"></a>2.2. 客户端配置文件</h2><p><a href="https://github.com/OpenVPN/openvpn/blob/master/sample/sample-config-files/client.conf" target="_blank" rel="noopener">英文原文</a></p><pre><code class="shell">############################################### 多客户端的OpenVPN 2.0的客户端配置文件示例     ##                                            ## 该配置文件可以被多个客户端使用                ## 不过每个客户端都应该有自己的证书和密钥文件     ##                                            ## 在Windows上此配置文件的后缀应该是&quot;.ovpn&quot;     ## 在Linux/BSD系统中后缀是&quot;.conf&quot;              ################################################ 指定这是一个客户端，这将从服务器获取某些配置文件指令client# 使用与服务器上相同的设置# 在大多数系统中，除非部分禁用或者完全禁用了TUN/TAP接口的防火墙，否则VPN将不起作用;dev tapdev tun# 在Windows系统中，如果想配置多个隧道，则需要该指令# 需要用到网络连接面板中TAP-Win32适配器的名称(例如&quot;MyTap&quot;)# 在XP SP2或更高版本的系统中，可能需要禁用掉针对TAP适配器的防火墙;dev-node MyTap# 指定连接的服务器是采用TCP还是UDP协议# 使用与服务器上相同的设置;proto tcpproto udp# 指定服务器的主机名(或IP)以及端口号# 如果有多个VPN服务器，为了实现负载均衡，可以设置多个remote指令remote my-server-1 1194;remote my-server-2 1194# 如果指定了多个remote指令，启用该指令将随机连接其中的一台服务器# 否则，客户端将按照指定的先后顺序依次尝试连接服务器;remote-random# 启用该指令，与服务器连接中断后将自动重新连接，# 这在网络不稳定的情况下(例如：笔记本电脑无线网络)非常有用resolv-retry infinite# 大多数客户端不需要绑定本机特定的端口号nobind# 在初始化完毕后，降低OpenVPN的权限(该指令仅限于非Windows系统中使用);user nobody;group nobody# 持久化选项可以尽量避免访问在重启时由于用户权限降低而无法访问的某些资源persist-keypersist-tun# 如果通过HTTP代理方式来连接到实际的VPN服务器# 在此处指定代理服务器的主机名(或IP)和端口号# 如果代理服务器需要身份认证，请参考官方手册;http-proxy-retry  # 连接失败时自动重试;http-proxy [proxy server] [proxy port #]# 无线网络通常会产生大量的重复数据包# 设置此标识将忽略掉重复数据包的警告信息;mute-replay-warnings# SSL/TLS参数配置# 更多描述信息请参考服务器端配置文件# 最好为每个客户端单独分配.crt/.key文件对# 单个CA证书可以供所有客户端使用ca ca.crtcert client.crtkey client.key# 通过检查证书具有正确的密钥使用设置来验证服务器证书# 这是防止此处讨论的潜在攻击的重要预防措施：#  http://openvpn.net/howto.html#mitm## 要使用此功能，EasyRSA生成服务器证书的时候进行相关设置remote-cert-tls server# 如果在服务器上使用tls-auth密钥，那么每个客户端也必须拥有密钥tls-auth ta.key 1# 选择一个加密算法，服务器使用的算法选项，也必须在这里指定它# 注意，v2.4客户端/服务器将自动以TLS模式协商AES-256-GCM。# 另请参阅手册中的ncp-cipher选项cipher AES-256-CBC# 在VPN连接中启用压缩# 除非在服务器配置文件中启用，否则不要启用它;comp-lzo# 设置日志文件冗余级别(0~9)# 0 表示静默运行，只记录致命错误# 4 表示合理的常规用法# 5和6 可以帮助调试连接错误# 9 表示极度冗余，输出非常详细的日志信息verb 3# 忽略过多的重复信息# 相同类别的信息只有前20条会输出到日志文件中;mute 20# （如果不添加该指令则）默认值3600，也就是一个小时进行一次TSL重新协商# 这个参数在服务端和客户端设置都有效# 如果两边都设置了，就按照时间短的设定优先# 当两边同时设置成0，表示禁用TSL重协商。使用OTP认证需要禁用reneg-sec 0</code></pre>]]></content>
      
      
      <categories>
          
          <category> OpenVPN篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenVPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenVPN HOWTO 文档翻译</title>
      <link href="/2020/05/27/OpenVPN-HowTO/"/>
      <url>/2020/05/27/OpenVPN-HowTO/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="HOWTO"><a href="#HOWTO" class="headerlink" title="HOWTO"></a>HOWTO</h2><p><a href="https://openvpn.net/" target="_blank" rel="noopener">OpenVPN</a>（OpenVPN官网所有内容需科学上网才能访问）是一个功能齐全的SSL VPN，它使用行业标准的SSL/TLS协议实现了OSI模型第2层（数据链路层）或第3层（网络层）的安全网络扩展。OpenVPN支持基于证书、智能卡以及用户名/密码等多种形式的灵活的客户端认证方法，并可以通过应用于VPN虚拟接口的防火墙规则为指定用户或用户组设置访问控制策略。</p><p>原文地址: <a href="https://openvpn.net/community-resources/how-to/" target="_blank" rel="noopener">https://openvpn.net/community-resources/how-to/</a></p><ul><li><a href="#11-安装openvpn">1.1. 安装OpenVPN</a></li><li><a href="#12-选择使用路由还是桥接">1.2. 选择使用路由还是桥接</a></li><li><a href="#13-设置私有子网">1.3. 设置私有子网</a></li><li><a href="#14-创建证书">1.4. 创建证书</a></li><li><a href="#15-创建配置文件">1.5. 创建配置文件</a></li><li><a href="#16-启动vpn并测试">1.6. 启动VPN并测试</a></li><li><a href="#17-系统启动时自动运行">1.7. 系统启动时自动运行</a></li><li><a href="#18-控制运行中的openvpn进程">1.8. 控制运行中的OpenVPN进程</a></li><li><a href="#19-服务器或客户端子网中的其他计算机互相访问">1.9. 服务器或客户端子网中的其他计算机互相访问</a><ul><li><a href="#191-防火墙规则">1.9.1. 防火墙规则</a></li></ul></li><li><a href="#110-推送dhcp选项到客户端">1.10. 推送DHCP选项到客户端</a></li><li><a href="#111-为指定客户端配置规则和访问策略">1.11. 为指定客户端配置规则和访问策略</a></li><li><a href="#112-使用其他身份验证方式">1.12. 使用其他身份验证方式</a></li><li><a href="#113-使用客户端的智能卡实现双重认证">1.13. 使用客户端的智能卡实现双重认证</a></li><li><a href="#114-路由所有客户端流量通过vpn">1.14. 路由所有客户端流量通过VPN</a></li><li><a href="#115-在动态ip地址上运行openvpn服务器">1.15. 在动态IP地址上运行OpenVPN服务器</a></li><li><a href="#116-通过http代理连接openvpn服务器">1.16. 通过HTTP代理连接OpenVPN服务器</a></li><li><a href="#117-通过openvpn连接samba网络共享服务器">1.17. 通过OpenVPN连接Samba网络共享服务器</a></li><li><a href="#118-实现负载均衡故障转移的配置">1.18. 实现负载均衡/故障转移的配置</a></li><li><a href="#119-增强openvpn的安全性">1.19. 增强OpenVPN的安全性</a></li><li><a href="#120-撤销证书">1.20. 撤销证书</a></li><li><a href="#121-关于中间人攻击的重要注意事项">1.21. 关于中间人攻击的重要注意事项</a></li></ul><h2 id="1-1-安装OpenVPN"><a href="#1-1-安装OpenVPN" class="headerlink" title="1.1. 安装OpenVPN"></a>1.1. 安装OpenVPN</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#install" target="_blank" rel="noopener">英文原文</a></p><p>可以<a href="https://openvpn.net/index.php/open-source/downloads.html" target="_blank" rel="noopener">在这里</a>下载OpenVPN源代码和Windows安装程序。最近的版本(2.2及以后版本)也发布了Debian和RPM包(.deb和.rpm)。详情查看<a href="https://community.openvpn.net/openvpn" target="_blank" rel="noopener">OpenVPN wiki</a>。出于安全考虑，建议下载完毕后检查一下文件的<a href="https://openvpn.net/index.php/open-source/documentation/sig.html" target="_blank" rel="noopener">签名信息</a>。OpenVPN可执行文件提供了服务器和客户端的所有功能，因此服务器和客户端都需要安装OpenVPN的可执行文件。</p><p><strong>Linux安装事项（使用RPM包管理工具）</strong></p><p>如果你使用的Linux发行版支持RPM包管理工具，例如：RedHat、CentOS、Fedora、SUSE等。最好使用这种方法来安装。最简单的方法就是找到一个可以在当前Linux发行版上使用的二进制RPM文件。你也可以使用如下命令创建(build)你自己的二进制RPM文件：</p><pre><code class="shell">rpmbuild -tb openvpn-[version].tar.gz</code></pre><p>有了<code>.rpm</code>格式的文件，就可以使用如下常规命令来安装它。</p><pre><code class="shell">rpm -ivh openvpn-[details].rpm</code></pre><p>或者升级现有的OpenVPN版本：</p><pre><code class="shell">rpm -Uvh openvpn-[details].rpm</code></pre><p>安装OpenVPN的RPM包，需要如下这些依赖软件包：</p><ul><li>openssl （SSL协议及相关内容的开源实现）</li><li>lzo （无损压缩算法）</li><li>pam （身份验证模块）</li></ul><p>此外，如果自己创建(build)二进制RPM包，需要如下几个依赖：</p><ul><li>openssl-devel</li><li>lzo-devel</li><li>pam-devel</li></ul><p>可以查看<a href="https://openvpn.net/index.php/open-source/documentation/install.html#rpm" target="_blank" rel="noopener">openvpn.spec</a>文件，该文件包含了在RedHat Linux 9上创建RPM包，或者在减少依赖的情况下创建RPM包的更多信息。</p><p><strong>Linux安装事项（非RPM）</strong></p><p>如果你使用的系统是Debian、Gentoo或其他不基于RPM的Linux发行版，你可以使用当前发行版指定的软件包管理机制，例如Debian的<code>apt-get</code>或者Gentoo的<code>emerge</code>。</p><pre><code class="shell">apt-get install openvpn  # 使用apt-get安装OpenVPNemerge openvpn  # 使用emerge安装OpenVPN</code></pre><p>也可以使用常规的<code>./configure</code>方法在安装Linux上安装OpenVPN。首先，解压<code>.tar.gz</code>文件：</p><pre><code class="shell">tar xfz openvpn-[version].tar.gz</code></pre><p>然后跳转到OpenVPN的顶级目录（<code>top-level directory</code>实际上就是OpenVPN解压后的目录），输入：</p><pre><code class="shell">./configuremakemake install</code></pre><p>通过<code>./configure</code>方式进行OpenVPN的编译安装之前，仍然需要先安装OpenVPN的依赖软件包<code>openssl</code>、<code>lzo</code>、<code>pam</code>。</p><p><strong>Windows安装事项</strong></p><p>对Windows系统而言，可以直接在下载exe格式的可执行文件来安装OpenVPN。OpenVPN只能够在Windows XP及以上版本的系统中运行。还要注意，必须具备管理员权限才能够安装运行OpenVPN（该限制是Windows自身造成的，而不是OpenVPN）。安装OpenVPN之后，你可以用Windows后台服务的方式启动OpenVPN来绕过该限制；在这种情况下，非管理员用户也能够正常访问VPN。你可以点击查看<a href="http://openvpn.se/files/howto/openvpn-howto_run_openvpn_as_nonadmin.html" target="_blank" rel="noopener">关于OpenVPN + Windows权限问题的更多讨论</a>。</p><p>官方版的OpenVPN Windows安装程序自带<a href="https://community.openvpn.net/openvpn/wiki/OpenVPN-GUI" target="_blank" rel="noopener">OpenVPN GUI</a>，OpenVPN GUI允许用户通过一个托盘程序来管理OpenVPN连接。也可以使用其他的<a href="https://community.openvpn.net/openvpn/wiki/OpenVPN-GUI" target="_blank" rel="noopener">GUI程序</a>。</p><p>安装OpenVPN之后，OpenVPN将会与扩展名为<code>.ovpn</code>的文件进行关联。想要运行OpenVPN，可以：</p><ul><li>右键点击OpenVPN配置文件<code>.ovpn</code>，在弹出的关联菜单中选择【Start OpenVPN on this configuration file】即可使用该配置文件启动OpenVPN。运行OpenVPN后，可以使用快捷键<code>F4</code>来退出程序。</li><li>以命令提示符的方式运行OpenVPN，例如：<code>openvpn myconfig.ovpn</code>。运行之后，同样可以使用快捷键<code>F4</code>来退出VPN。</li><li>在OpenVPN安装路径<code>/config</code>目录（一般默认为<code>C:\Program Files\OpenVPN\config</code>）中放置一个或多个<code>.ovpn</code>格式的配置文件，然后启动名为OpenVPN Service的Windows服务。你可以点击【开始】-&gt;【控制面板】-&gt;【管理工具】-&gt;【服务】，从而进入Windows服务管理界面。</li></ul><p><strong>Mac OS X安装事项</strong></p><p>Angelo Laub和Dirk Theisen已经开发出了<a href="https://tunnelblick.net/" target="_blank" rel="noopener">OpenVPN GUI for OS X</a>。</p><p><strong>其他操作系统</strong></p><p>通常情况下，其他操作系统也可以使用<code>./configure</code>方法来安装OpenVPN，或者也可以自行查找一个适用于你的操作系统/发行版的OpenVPN接口或安装包。</p><pre><code class="shell">./configuremakemake install</code></pre><p>更多安装说明参阅<a href="https://openvpn.net/index.php/open-source/documentation/install.html?start=1" target="_blank" rel="noopener">这里</a>。</p><h2 id="1-2-选择使用路由还是桥接"><a href="#1-2-选择使用路由还是桥接" class="headerlink" title="1.2. 选择使用路由还是桥接"></a>1.2. 选择使用路由还是桥接</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#vpntype" target="_blank" rel="noopener">英文原文</a></p><p>查看“路由 VS. 以太网桥接”的<a href="https://community.openvpn.net/openvpn/wiki/FAQ#bridge1" target="_blank" rel="noopener">FAQ</a>。也可以查看OpenVPN<a href="https://openvpn.net/index.php/open-source/documentation/miscellaneous/76-ethernet-bridging.html" target="_blank" rel="noopener">以太网桥接</a>页面以了解关于桥接的更多事项和细节。</p><p>总的来说，对于大多数人而言，“路由模式”可能是更好的选择，因为它可以比“桥接模式”更高效更简单地搭建一个VPN（基于OpenVPN自带的配置）。路由模式还提供了更强大的对指定客户端的访问权限进行控制的能力。</p><p>推荐使用“路由模式”，除非你需要用到只有“桥接模式”才具备的某些功能特性，例如：</p><ul><li>VPN需要处理非IP协议，例如IPX。</li><li>在VPN网络中运行的应用程序需要用到网络广播(network broadcasts)，例如：局域网游戏。</li><li>你想要在没有Samba或WINS服务器的情况下，能够通过VPN浏览Windows文件共享。</li></ul><h2 id="1-3-设置私有子网"><a href="#1-3-设置私有子网" class="headerlink" title="1.3. 设置私有子网"></a>1.3. 设置私有子网</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#numbering" target="_blank" rel="noopener">英文原文</a></p><p>创建一个VPN需要借助私有子网将不同地方的成员连接在一起。</p><p>互联网号码分配机构(IANA)专为私有网络保留了以下三块IP地址空间(制定于RFC 1918规范中)：</p><ul><li>10.0.0.0-10.255.255.255(10/8 prefix)</li><li>172.16.0.0-172.31.255.255(172.16/12 prefix)</li><li>192.168.0.0-192.168.255.255(192.168/16 prefix)</li></ul><p>在VPN配置中使用这些地址。对选择IP地址并将IP地址冲突或子网冲突的发生概率降到最低而言，这一点非常重要。以下是需要避免的冲突类型：</p><ul><li>VPN中不同的网络场所使用相同的局域网子网编号所产生的冲突。</li><li>远程访问连接自身使用的私有子网与VPN的私有子网发生冲突。</li></ul><p>简而言之，处于不同局域网的客户端和客户端之间，它们自身所在的局域网IP段不要发生冲突；客户端自身所在的局域网IP段也不要和VPN使用的局域网IP段发生冲突。</p><p>举个例子，假设你使用了流行的<code>192.168.0.0/24</code>作为VPN子网。现在，你尝试在一个网吧内连接VPN，该网吧的WIFI局域网使用了相同的子网。这将产生一个路由冲突，因为计算机不知道<code>192.168.0.1</code>是指本地WIFI的网关，还是指VPN上的相同地址。</p><p>再举个例子，假设你想通过VPN将多个网络场所连接在一起，但是每个网络场所都使用了<code>192.168.0.0/24</code>作为自己的局域网子网。如果不添加一个复杂的NAT翻译层，它们将无法工作。因为这些网络场所没有唯一的子网来标识它们自己，VPN不知道如何在多个网络场所之间路由数据包。</p><p>最佳的解决方案是避免使用<code>10.0.0.0/24</code>或者<code>192.168.0.0/24</code>作为VPN的私有子网。相反，你应该使用一些在你可能连接VPN的场所（例如咖啡厅、酒店、机场）不太可能使用的私有子网。最佳的候选者应该是在浩瀚的<code>10.0.0.0/8</code>网络块中间选择一个子网（例如：<code>10.66.77.0/24</code>）。</p><p>总的来说，为了避免跨多个网络场所的IP编号冲突，请始终使用唯一的局域网子网编号。</p><h2 id="1-4-创建证书"><a href="#1-4-创建证书" class="headerlink" title="1.4. 创建证书"></a>1.4. 创建证书</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#pki" target="_blank" rel="noopener">英文原文</a></p><p>以下并非按照原文来的。</p><p>可以从发行版软件仓库直接安装，安装后操作如下：</p><p><code>cd /usr/share/easy-rsa/2.0</code></p><p>编辑<code>vars</code>文件：</p><pre><code class="shell"># 密钥长度为2048，如果是1024可改为2048export KEY_SIZE=2048# CA证书有效时间3650天，根据需要修改export CA_EXPIRE=3650# 密钥有效时间3650天，根据需要修改export KEY_EXPIRE=3650export KEY_COUNTRY=&quot;CN&quot;  # 国家export KEY_PROVINCE=&quot;SC&quot;  # 省份export KEY_CITY=&quot;CD&quot;  # 城市export KEY_ORG=&quot;x&quot;  # 组织机构export KEY_EMAIL=&quot;x@x.com&quot;  # 邮箱export KEY_OU=&quot;x&quot;  # 单位或部门export KEY_NAME=&quot;OpenVPNServer&quot;  # openvpn服务器的名称</code></pre><p><code>source ./vars</code>  # 初始化</p><p><code>./clean-all</code>  # 清理keys</p><p><code>./build-ca</code>  # 生成<code>ca.crt</code>和<code>ca.key</code></p><p><code>./build-key-server server</code>  # 生成<code>server.crt</code>，<code>server.csr</code>和<code>server.key</code></p><p><code>./build-dh</code>  # 生成<code>dh2048.pem</code></p><p><code>openvpn --genkey --secret ta.key</code>  # 生成<code>ta.key</code></p><p>keys文件详解可<a href="http://www.williamlong.info/archives/3814.html" target="_blank" rel="noopener">参考这里</a>。</p><p>GitHub上的easy-rsa最新版本为easy-rsa3，生成证书命令有一些变化，如下操（有问题可官网查看或运行<code>./easyrsa help</code>）：</p><pre><code class="shell">wget https://github.com/OpenVPN/easy-rsa/archive/master.zipunzip master.zipcd easy-rsa-master/easyrsa3cp vars.example vars</code></pre><p>编辑<code>vars</code>文件：</p><pre><code class="shell"># 取消注释并修改对应内容set_var EASYRSA_REQ_COUNTRY    &quot;US&quot;  # 国家set_var EASYRSA_REQ_PROVINCE   &quot;California&quot;  # 省份set_var EASYRSA_REQ_CITY       &quot;San Francisco&quot;  # 城市set_var EASYRSA_REQ_ORG        &quot;Copyleft Certificate Co&quot;  # 组织机构set_var EASYRSA_REQ_EMAIL      &quot;me@example.net&quot;  # 邮箱set_var EASYRSA_REQ_OU         &quot;My Organizational Unit&quot;  # 单位或部门set_var EASYRSA_KEY_SIZE       2048  # 密钥长度2048set_var EASYRSA_CA_EXPIRE       3650  # CA有效期3650天set_var EASYRSA_CERT_EXPIRE     3650  # CERT有效期3650天# 客户端使用--ns-cert-type，取消下行注释并改值改为yes，（一般不推荐使用，而推荐使用--remote-cert-tls功能）#set_var EASYRSA_NS_SUPPORT     &quot;no&quot;# 其他内容可以根据自己需要修改</code></pre><p>保存后继续运行，生成服务器端证书：</p><pre><code class="shell">./easyrsa init-pki  # 初始化，会清空已有信息，并在当前目录创建PKI目录，用于存储一些中间变量及最终生成的证书./easyrsa build-ca  # 创建根证书，会提示设置密码，用于ca对之后生成的server和client证书签名时使用，然后提示设置Common Name./easyrsa gen-req server nopass  # 创建server证书和private key，nopass表示不加密private key，然后提示设置Common Name（使用与上一步不同的）./easyrsa sign-req server server  # 给server证书签名，确认信息后输入yes，然后输入build-ca时设置的密码./easyrsa gen-dh  # 创建Diffie-Hellman</code></pre><p>OpenVPN服务端需要的文件如下：</p><p><code>easyrsa3/pki/ca.crt</code></p><p><code>easyrsa3/pki/private/server.key</code></p><p><code>easyrsa3/pki/issued/server.crt</code></p><p><code>easyrsa3/pki/dh.pem</code></p><p><code>openvpn --genkey --secret ta.key</code>  # 生成<code>ta.key</code>的命令相同</p><p>生成客户端证书（如果客户端不使用证书认证，这一步就不需要了），在与上面生成服务端证书的easy-rsa不同的文件夹重新解压一次（网上查的资料说是在新目录重新生成，不知道可否直接在刚才的目录使用，未测试，如果要测试注意不要再次运行<code>./easyrsa init-pki</code>），进入新的<code>easy-rsa-master/easyrsa3</code>目录后同样设置一下<code>vars</code>文件，然后开始生成证书：</p><pre><code class="shell">./easyrsa init-pki./easyrsa gen-req client1 nopass  # 创建client1证书和private key，nopass表示不加密private key，然后提示设置Country Name（设置与上面不同的）</code></pre><p>切换到前面生成CA的目录，运行：</p><pre><code class="shell">./easyrsa import-req [上一步生成客户端证书的路径]/easyrsa3/pki/reqs/client1.req client1  # 导入req./easyrsa sign-req client client1  # # 给client1证书签名，确认信息后输入yes，然后输入build-ca时设置的密码</code></pre><p>文件位置如下：</p><p><code>easyrsa3/pki/issued/client.crt</code></p><p><code>easyrsa3/pki/private/client.key</code></p><p><strong>证书相关文件</strong></p><table><thead><tr><th>文件名</th><th>谁需要</th><th>作用</th><th>是否需保密</th></tr></thead><tbody><tr><td>ca.crt</td><td>服务器 + 所有客户端</td><td>根CA证书</td><td>NO</td></tr><tr><td>ca.key</td><td>密钥签名机</td><td>根CA密钥</td><td>YES</td></tr><tr><td>dh{n}.pem</td><td>服务器</td><td>迪菲·赫尔曼参数</td><td>NO</td></tr><tr><td>server.crt</td><td>服务器</td><td>服务器证书</td><td>NO</td></tr><tr><td>server.key</td><td>服务器</td><td>服务器密钥</td><td>YES</td></tr><tr><td>client1.crt</td><td>client1</td><td>Client1证书</td><td>NO</td></tr><tr><td>client1.key</td><td>client1</td><td>Client1密钥</td><td>YES</td></tr><tr><td>client2.crt</td><td>client2</td><td>Client2证书</td><td>NO</td></tr><tr><td>client2.key</td><td>client2</td><td>Client2密钥</td><td>YES</td></tr></tbody></table><p>关于证书、密钥安全性的问题可查看原文。</p><h2 id="1-5-创建配置文件"><a href="#1-5-创建配置文件" class="headerlink" title="1.5. 创建配置文件"></a>1.5. 创建配置文件</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#config" target="_blank" rel="noopener">英文原文</a></p><p><strong>取得示例配置文件</strong></p><p>最好使用[OpenVPN示例配置文件](../2. 配置文件说明.html)作为配置起点。这些文件可以在下列地方找到：</p><ul><li>OpenVPN源代码版的<code>sample-config-files</code>目录。</li><li>如果通过RPM或DEB来安装OpenVPN，则为<code>/usr/share/doc/packages/openvpn</code>或<code>/usr/share/doc/openvpn</code>中的<code>sample-config-files</code>目录。</li><li>Windows系统中的【开始】-&gt;【所有程序】-&gt;【OpenVPN】-&gt;【Shortcuts】-&gt;【OpenVPN Sample Configuration Files】，也就是OpenVPN安装路径<code>/sample-config</code>目录。</li></ul><p>注意：在Linux、BSD或类Unix系统中，示例配置文件叫做<code>server.conf</code>和<code>client.conf</code>。在Windows中叫做<code>server.ovpn</code>和<code>client.ovpn</code>。</p><p><strong>编辑服务器端配置文件</strong></p><p>服务器端配置文件示例是OpenVPN服务器端配置的最佳起始点。</p><p>该示例配置将使用一个虚拟的TUN网络接口（路由模式），在UDP端口1194（OpenVPN的官方端口号）监听远程连接，并从子网<code>10.8.0.0/24</code>中为连接的客户端分配虚拟地址。</p><p>在使用示例配置文件之前，先编辑<code>ca</code>、<code>cert</code>、<code>key</code>、<code>dh</code>参数，将它们分别指向对应文件。</p><p>此时，服务器端配置文件是可用的，但可以进一步自定义该文件：</p><ul><li>如果你使用的是<a href="https://openvpn.net/index.php/open-source/documentation/miscellaneous/76-ethernet-bridging.html" target="_blank" rel="noopener">以太网桥接</a>模式，必须使用<code>server-bridge</code>和<code>dev tap</code>指令来替代<code>server</code>和<code>dev tun</code>指令。</li><li>如果想让你的OpenVPN服务器监听一个TCP端口，而不是UDP端口，使用<code>proto tcp</code>替代<code>proto udp</code>（如果想同时监听UDP和TCP端口，必须启动两个单独的OpenVPN实例）。</li><li>如果你想使用<code>10.8.0.0/24</code>范围之外的虚拟IP地址，修改<code>server</code>指令。记住，虚拟IP地址范围必须是一个你当前网络未使用的私有范围。</li><li>如果你想让通过VPN连接的客户端和客户端之间能够互访，启用<code>client-to-client</code>指令（去掉注释）。默认情况下，客户端只能够访问服务器。</li><li>如果你正在使用Linux、BSD或类Unix操作系统，你可以使启用<code>user nobody</code>和<code>group nobody</code>指令来提高安全性。</li></ul><p>如果想要在同一计算机上运行多个OpenVPN实例，每一个示例都应该使用不同的配置文件。可能存在下列情形：</p><ul><li>每个示例使用不同的端口号（UDP和TCP协议使用不同的端口空间，因此你可以运行一个后台进程并同时监听UDP-1194和TCP-1194）。</li><li>如果你使用的是Windows系统，每个OpenVPN配置都需要有自己的TAP-Windows适配器。你可以通过【开始】-&gt;【所有程序】-&gt;【TAP-Windows】-&gt;【Add a new TAP-Windows virtual ethernet adapter】来添加一个额外的适配器。</li><li>如果你运行多个相同目录的OpenVPN实例，请确保编辑那些会创建输出文件的指令，以便于多个实例不会覆盖掉对方的输出文件。这些指令包括<code>log</code>、<code>log-append</code>、<code>status</code>和<code>ifconfig-pool-persist</code>。</li></ul><p><strong>编辑客户端配置文件</strong></p><p>客户端配置示例文件（在Linux/BSD/Unix中为<code>client.conf</code>，在Windows中为<code>client.ovpn</code>）参照了服务器配置示例文件的默认指令设置。</p><ul><li>与服务器配置文件类似，首先编辑<code>ca</code>、<code>cert</code>和<code>key</code>参数，使它们指向对应文件。注意，每个客户端都应该有自己的证书/密钥对。只有<code>ca</code>文件是OpenVPN和所有客户端通用的。</li><li>下一步，编辑<code>remote</code>指令，将其指向OpenVPN服务器的主机名/IP地址和端口号（如果OpenVPN服务器在防火墙或NAT网关之后的单网卡机器上运行，请使用网关的公网IP地址，和你在网关中配置的转发到OpenVPN服务器的端口号）。</li><li>最后，确保客户端配置文件和用于服务器配置的指令保持一致。主要检查dev（dev或tap）和proto（udp或tcp）指令是否一致。此外，如果服务器和客户端配置文件都使用了<code>comp-lzo</code>和<code>fragment</code>指令，也需要保持一致。</li></ul><h2 id="1-6-启动VPN并测试"><a href="#1-6-启动VPN并测试" class="headerlink" title="1.6. 启动VPN并测试"></a>1.6. 启动VPN并测试</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#start" target="_blank" rel="noopener">英文原文</a></p><p><strong>启动服务器</strong></p><p>首先，确保OpenVPN服务器能够正常连接网络。这意味着：</p><ul><li>开启防火墙上的UDP-1194端口（或者你配置的其他端口）。</li><li>或者，创建一个端口转发规则，将防火墙/网关的UDP-1194端口转发到运行OpenVPN服务器的计算机上。</li></ul><p>下一步，<a href="https://community.openvpn.net/openvpn/wiki/FAQ#firewall" target="_blank" rel="noopener">确保TUN/TAP接口没有被防火墙屏蔽</a>。</p><p>为了简化故障排除，最好使用命令行来初始化启动OpenVPN服务器（或者在Windows上右击.ovpn文件），而不是以后台进程或服务的方式启动：</p><pre><code class="shell">openvpn [服务器配置文件]</code></pre><p>正常的服务器启动应该像这样：</p><pre><code class="shell">Sun Feb  6 20:46:38 2005 OpenVPN 2.0_rc12 i686-suse-linux [SSL] [LZO] [EPOLL] built on Feb  5 2005Sun Feb  6 20:46:38 2005 Diffie-Hellman initialized with 1024 bit keySun Feb  6 20:46:38 2005 TLS-Auth MTU parms [ L:1542 D:138 EF:38 EB:0 ET:0 EL:0 ]Sun Feb  6 20:46:38 2005 TUN/TAP device tun1 openedSun Feb  6 20:46:38 2005 /sbin/ifconfig tun1 10.8.0.1 pointopoint 10.8.0.2 mtu 1500Sun Feb  6 20:46:38 2005 /sbin/route add -net 10.8.0.0 netmask 255.255.255.0 gw 10.8.0.2Sun Feb  6 20:46:38 2005 Data Channel MTU parms [ L:1542 D:1450 EF:42 EB:23 ET:0 EL:0 AF:3/1 ]Sun Feb  6 20:46:38 2005 UDPv4 link local (bound): [undef]:1194Sun Feb  6 20:46:38 2005 UDPv4 link remote: [undef]Sun Feb  6 20:46:38 2005 MULTI: multi_init called, r=256 v=256Sun Feb  6 20:46:38 2005 IFCONFIG POOL: base=10.8.0.4 size=62Sun Feb  6 20:46:38 2005 IFCONFIG POOL LISTSun Feb  6 20:46:38 2005 Initialization Sequence Completed</code></pre><p><strong>启动客户端</strong></p><p>和服务器端配置一样，最好使用命令行来初始化启动OpenVPN客户端（在Windows上，也可以直接右击client.ovpn文件），而不是以后台进程或服务的方式来启动。</p><pre><code class="shell">openvpn [客户端配置文件]</code></pre><p>Windows上正常的客户端启动看起来与前面服务器端的输出非常相似，并且应该以<code>Initialization Sequence Completed</code>信息作为结尾。</p><p>尝试从客户端通过VPN发送<code>ping</code>命令。</p><p>如果你使用的是路由模式（例如：在服务器配置文件中设置<code>dev tun</code>），运行：</p><pre><code class="shell">ping 10.8.0.1</code></pre><p>如果使用桥接模式（例如：在服务器配置文件中设置<code>dev tap</code>），尝试ping一个服务器端的以太网子网中的IP地址。</p><p>如果能够<code>ping</code>成功，那么就连接成功了。</p><p><strong>故障排除</strong></p><p>如果<code>ping</code>失败或者无法完成OpenVPN客户端的初始化，这里列出了一个常见问题以及对应解决方案的清单：</p><p>1、得到错误信息：<code>TLS Error: TLS key negotiation failed to occur within 60 seconds (check your network connectivity)</code>。该错误表明客户端无法与服务器建立一个网络连接。</p><p>解决方案：</p><ul><li>确保客户端配置中使用的服务器主机名/IP地址和端口号是正确的。</li><li>如果OpenVPN服务器所在计算机只有单个网卡，并处于受保护的局域网内，请确保服务器端的网关防火墙使用了正确的端口转发规则。举个例子，假设你的OpenVPN服务器在某个局域网内，IP为<code>192.168.4.4</code>，并在UDP端口1194上监听客户端连接。服务于子网<code>192.168.4.x</code>的NAT网关应该有一个端口转发规则，该规则将公网IP地址的UDP端口1194转发到<code>192.168.4.4</code>。</li><li>打开服务器防火墙，允许外部连接通过UDP-1194端口（或者在服务器配置文件中设置的其他端口）。</li></ul><p>2、得到错误信息：<code>Initialization Sequence Completed with errors</code>。该错误发生在：(a)你的Windows系统没有一个正在运行的DHCP客户端服务，(b)或者你在XP SP2上使用了某些第三方的个人防火墙。</p><p>解决方案：</p><ul><li>启动DHCP客户端服务器，并确保在XP SP2系统中使用的是一个工作正常的个人防火墙。</li></ul><p>3、得到信息<code>Initialization Sequence Completed</code>但是<code>ping</code>测试失败。这通常意味着服务器或客户端的防火墙屏蔽了TUN/TAP接口，从而阻塞了VPN网络。</p><p>解决方案：</p><ul><li>禁用客户端TUN/TAP接口上的防火墙（如果存在的话）。以Windows XP SP2为例，你可以进入【Windows安全中心】-&gt;【Windows 防火墙】-&gt;【高级】，并取消选中TAP-Windows适配器前面的复选框（从安全角度来说，禁止客户端防火墙屏蔽TUN/TAP接口通常是合理的，这是在告诉防火墙不要阻止可信的VPN流量）。此外，也需要确保服务器的TUN/TAP接口没有被防火墙屏蔽（不得不说的是，选择性地设置服务器端TUN/TAP接口的防火墙有助于提高一定的安全性，请参考访问策略部分）。</li><li>笔者注：也有可能本身已连通但是<code>ping</code>的主机防火墙阻止了ICMP，可以进行相关设置后再尝试</li></ul><p>4、当采用UDP协议的配置启动时，出现连接中断，并且服务器日志文件显示下行：</p><pre><code class="shell">TLS: Initial packet from x.x.x.x:x, sid=xxxxxxxx xxxxxxxx</code></pre><p>但客户端的日志文件不会显示相同的信息。</p><p>解决方案：</p><ul><li>你只有一个从客户端到服务器的单向连接。而从服务器到客户端的方向则被（通常是客户端这边的）防火墙阻挡了。该防火墙可能是运行于客户端的个人软件防火墙，或是客户端的NAT路由网关。请修改防火墙以允许从服务器到客户端的UDP数据包返回。</li></ul><p>想了解更多额外的故障排除信息，请查看<a href="https://community.openvpn.net/openvpn/wiki/FAQ" target="_blank" rel="noopener">FAQ</a>。</p><h2 id="1-7-系统启动时自动运行"><a href="#1-7-系统启动时自动运行" class="headerlink" title="1.7. 系统启动时自动运行"></a>1.7. 系统启动时自动运行</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#startup" target="_blank" rel="noopener">英文原文</a></p><p>关于这个问题并没有所谓的标准答案，也就是说大多数系统都有不同的方式来配置在系统启动时自动运行后台进程/服务。想要默认就具备该功能设置的最佳方式就是以软件包的形式安装OpenVPN，例如通过Linux系统的RPM、DEB或者使用Windows安装程序。</p><p><strong>Linux系统</strong></p><p>如果在Linux上通过RPM或DEB软件包来安装OpenVPN，安装程序将创建一个<code>initscript</code>。执行该脚本，<code>initscript</code>将会扫描<code>/etc/openvpn</code>目录下<code>.conf</code>格式的配置文件，如果能够找到，将会为每个文件分别启动一个独立的OpenVPN后台进程。</p><p><strong>Windows系统</strong></p><p>Windows安装程序将会建立一个服务器包装器(Service Wrapper)，不过默认情况下其处于关闭状态。如果想激活它，请进入【控制面板】-&gt;【管理工具】-&gt;【服务】，然后右键点击”OpenVPN Service”，在弹出的关联菜单中单击【属性】，并将属性面板中的”启动类型”设为”自动”。OpenVPN服务将会在下次重启系统时自动运行。</p><p>启动后，OpenVPN服务包装器将会扫描OpenVPN安装路径<code>/config</code>文件夹下<code>.ovpn</code>格式的配置文件，然后为每个文件启动一个单独的OpenVPN进程。</p><h2 id="1-8-控制运行中的OpenVPN进程"><a href="#1-8-控制运行中的OpenVPN进程" class="headerlink" title="1.8. 控制运行中的OpenVPN进程"></a>1.8. 控制运行中的OpenVPN进程</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#control" target="_blank" rel="noopener">英文原文</a></p><p><strong>运行于Linux/BSD/Unix</strong></p><ul><li>SIGUSR1  # 有条件的重新启动，设计用于没有root权限的重启</li><li>SIGHUP  # 硬重启</li><li>SIGUSR2  # 输出连接统计信息到日志文件或syslog中</li><li>SIGTERM, SIGINT  # 退出</li></ul><p>使用<code>writepid</code>指令将OpenVPN的后台进程PID写入到一个文件中，这样你就知道该向哪里发送信号（如果以<code>initscript</code>方式启动OpenVPN，该脚本可能已经通过openvpn命令行中的指令–writepid达到了该目的）。</p><p><strong>以GUI形式在Windows上运行</strong></p><p>请查看<a href="https://community.openvpn.net/openvpn/wiki/OpenVPN-GUI" target="_blank" rel="noopener">OpenVPN GUI页面</a>。</p><p><strong>运行于Windows命令提示符窗口</strong></p><p>在Windows中，可以通过右击一个OpenVPN配置文件（.ovpn文件），然后选择“Start OpenVPN on this config file”来启动OpenVPN。</p><p>一旦以这种方式运行，你可以使用如下几种按键命令：</p><ul><li><code>F1</code>  # 有条件的重启(无需关闭/重新打开TAP适配器)</li><li><code>F2</code>  # 显示连接统计信息</li><li><code>F3</code>  # 硬重启</li><li><code>F4</code>  # 退出</li></ul><p><strong>以Windows服务方式运行</strong></p><p>在Windows中，当OpenVPN以服务方式启动时，控制方式是：</p><ul><li>通过服务控制管理器（控制面板-&gt;管理工具-&gt;服务），其中提供了启动/终止操作。</li><li>通过管理接口（详情参考下面）。</li></ul><p><strong>修改使用中的OpenVPN配置</strong></p><p>虽然大多数配置更改必须重启服务器才能生效，但仍然有两个指令可以用于文件动态更新，并且能够直接生效而无需重启服务器进程。</p><ul><li><code>client-config-dir</code>  # 该指令设置一个客户端配置文件夹，OpenVPN服务器将会在每个外部连接到来时扫描该目录中的文件，用以查找为当前连接指定的客户端配置文件（详情查看<a href="https://openvpn.net/index.php/open-source/documentation/manuals/65-openvpn-20x-manpage.html" target="_blank" rel="noopener">手册页面</a>）。该目录中的文件可以随时更新，而无需重启服务器。请注意，该目录中发生的更改只对新的连接起作用，不包括之前已经存在的连接。如果你想通过指定客户端的配置文件更改来直接影响当前正在连接的客户端（或者该连接已经断开，但它在服务器中的实例对象并没有超时），你可以通过管理接口来杀掉该客户端的实例对象（详见下方描述）。这将导致客户端重新连接并使用新的<code>client-config-dir</code>文件。</li><li><code>crl-verify</code>  # 该指令指定一个证书撤销列表(CRL)文件，相关描述请参考后面的撤销证书部分。该CRL文件能够在运行中被修改，并且修改可以直接对新的连接或那些正在重新建立SSL/TLS通道的现有连接（默认每小时重新建立一次通道）生效。如果你想杀掉一个证书已经添加到CRL中，但目前已连接的客户端，请使用管理接口（详见下方描述）。</li></ul><p><strong>状态信息文件</strong></p><p>默认的server.conf文件有这样一行：</p><pre><code class="shell">status openvpn-status.log</code></pre><p>OpenVPN将每分钟输出一次当前客户端连接列表到文件openvpn-status.log中。</p><p><strong>使用管理接口</strong></p><p><a href="https://openvpn.net/index.php/open-source/documentation/miscellaneous/79-management-interface.html" target="_blank" rel="noopener">OpenVPN管理接口</a>可以对正在运行的OpenVPN进程进行大量的控制操作。</p><p>你可以通过远程登录管理接口的端口来直接使用管理接口，或者使用连接到管理接口的<a href="https://community.openvpn.net/openvpn/wiki/OpenVPN-GUI" target="_blank" rel="noopener">OpenVPN GUI</a>来间接使用管理接口。</p><p>要启用一个服务器或客户端的管理接口，在配置文件中添加如下指令：</p><pre><code class="shell">management localhost 7505</code></pre><p>这将告诉OpenVPN专为管理接口客户端监听TCP端口7505（端口7505是随意的选择，也可以使用其他任何闲置的端口）。</p><p>OpenVPN运行后，可以使用<code>telnet</code>客户端连接管理接口。例如：</p><pre><code class="shell">ai:~ # telnet localhost 7505Trying 127.0.0.1...Connected to localhost.Escape character is &#39;^]&#39;.&gt;INFO:OpenVPN Management Interface Version 1 -- type &#39;help&#39; for more infohelpManagement Interface for OpenVPN 2.4.4 x86_64-redhat-linux-gnu [Fedora EPEL patched] [SSL (OpenSSL)] [LZO] [LZ4] [EPOLL] [PKCS11] [MH/PKTINFO] [AEAD] built on Sep 26 2017Commands:auth-retry t           : Auth failure retry mode (none,interact,nointeract).bytecount n            : Show bytes in/out, update every n secs (0=off).echo [on|off] [N|all]  : Like log, but only show messages in echo buffer.exit|quit              : Close management session.forget-passwords       : Forget passwords entered so far.help                   : Print this message.hold [on|off|release]  : Set/show hold flag to on/off state, or                         release current hold and start tunnel.kill cn                : Kill the client instance(s) having common name cn.kill IP:port           : Kill the client instance connecting from IP:port.load-stats             : Show global server load stats.log [on|off] [N|all]   : Turn on/off realtime log display                         + show last N lines or &#39;all&#39; for entire history.mute [n]               : Set log mute level to n, or show level if n is absent.needok type action     : Enter confirmation for NEED-OK request of &#39;type&#39;,                         where action = &#39;ok&#39; or &#39;cancel&#39;.needstr type action    : Enter confirmation for NEED-STR request of &#39;type&#39;,                         where action is reply string.net                    : (Windows only) Show network info and routing table.password type p        : Enter password p for a queried OpenVPN password.remote type [host port] : Override remote directive, type=ACCEPT|MOD|SKIP.proxy type [host port flags] : Enter dynamic proxy server info.pid                    : Show process ID of the current OpenVPN process.pkcs11-id-count        : Get number of available PKCS#11 identities.pkcs11-id-get index    : Get PKCS#11 identity at index.client-auth CID KID    : Authenticate client-id/key-id CID/KID (MULTILINE)client-auth-nt CID KID : Authenticate client-id/key-id CID/KIDclient-deny CID KID R [CR] : Deny auth client-id/key-id CID/KID with log reason                             text R and optional client reason text CRclient-kill CID [M]    : Kill client instance CID with message M (def=RESTART)env-filter [level]     : Set env-var filter levelclient-pf CID          : Define packet filter for client CID (MULTILINE)rsa-sig                : Enter an RSA signature in response to &gt;RSA_SIGN challenge                         Enter signature base64 on subsequent lines followed by ENDcertificate            : Enter a client certificate in response to &gt;NEED-CERT challenge                         Enter certificate base64 on subsequent lines followed by ENDsignal s               : Send signal s to daemon,                         s = SIGHUP|SIGTERM|SIGUSR1|SIGUSR2.state [on|off] [N|all] : Like log, but show state history.status [n]             : Show current daemon status info using format #n.test n                 : Produce n lines of output for testing/debugging.username type u        : Enter username u for a queried OpenVPN username.verb [n]               : Set log verbosity level to n, or show if n is absent.version                : Show current version number.ENDexitConnection closed by foreign host.ai:~ #</code></pre><h2 id="1-9-服务器或客户端子网中的其他计算机互相访问"><a href="#1-9-服务器或客户端子网中的其他计算机互相访问" class="headerlink" title="1.9. 服务器或客户端子网中的其他计算机互相访问"></a>1.9. 服务器或客户端子网中的其他计算机互相访问</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#scope" target="_blank" rel="noopener">英文原文</a></p><p>VPN既然能够让服务器和客户端之间具备点对点的通信能力，那么扩展VPN的作用范围，从而使客户端能够访问服务器所在网络的其他计算机，而不仅仅是服务器自己，也是可能办得到的。</p><p><strong>包含基于桥接模式的VPN服务器端的多台计算机(dev tap)</strong></p><p>使用<a href="https://openvpn.net/index.php/open-source/documentation/miscellaneous/76-ethernet-bridging.html" target="_blank" rel="noopener">以太网桥接</a>的好处之一就是无需进行任何额外的配置就可以实现该目的。</p><p><strong>包含基于桥接模式的VPN客户端的多台计算机(dev tap)</strong></p><p>这需要更加复杂的设置（实际操作可能并不复杂，但详细解释就比较麻烦）：</p><ul><li>必须将客户端的TAP接口与连接局域网的网卡进行桥接。</li><li>必须手动设置客户端TAP接口的IP/子网掩码。</li><li>必须配置客户端计算机使用桥接子网中的IP/子网掩码，这可能要通过<a href="https://openvpn.net/index.php/open-source/documentation/install.html?start=1" target="_blank" rel="noopener">查询OpenVPN服务器的DHCP服务器</a>来完成。</li></ul><p><strong>包含基于路由模式的VPN服务器端的多台计算机(dev tun)</strong></p><p>假设服务器端所在局域网的网段为<code>10.66.0.0/24</code>，服务器IP地址为<code>10.66.0.5</code>，VPN IP地址池使用<code>10.8.0.0/24</code>作为OpenVPN服务器配置文件中<code>server</code>指令的传递参数。</p><p>首先，你必须声明，对于VPN客户端而言，<code>10.66.0.0/24</code>网段是可以通过VPN进行访问的。你可以通过在服务器端配置文件中简单地配置如下指令来实现该目的：</p><pre><code class="shell">push &quot;route 10.66.0.0 255.255.255.0&quot;</code></pre><p>下一步，必须在服务器端的局域网网关创建一个路由，从而将VPN的客户端网段<code>10.8.0.0/24</code>路由到OpenVPN服务器（只有OpenVPN服务器和局域网网关不在同一计算机才需要这样做）。</p><p>另外，确保已经在OpenVPN服务器所在计算机上启用了<a href="https://community.openvpn.net/openvpn/wiki/FAQ#ip-forward" target="_blank" rel="noopener">IP</a>和<a href="https://community.openvpn.net/openvpn/wiki/FAQ#firewall" target="_blank" rel="noopener">TUN/TAP</a>转发（参考下面内容）。</p><p><strong>包含基于路由模式的VPN客户端的多台计算机(dev tun)</strong></p><p>在典型的远程访问方案中，客户端都是作为单一的计算机连接到VPN。但是，假设客户端计算机是本地局域网的网关（例如一个家庭办公室），并且你想要让客户端局域网中的每台计算机都能够通过VPN。</p><p>假设你的客户端局域网网段为<code>192.168.4.0/24</code>，客户端IP地址为<code>192.168.4.10</code>，VPN客户端使用的证书的Common Name为<code>client2</code>。目标是建立一个客户端局域网的计算机和服务器局域网的计算机都能够通过VPN进行相互通讯。</p><p>在创建之前，下面是一些基本的前提条件：</p><ul><li>客户端局域网网段（本例中是<code>192.168.4.0/24</code>）不能和VPN的服务器或任意客户端使用相同的网段。每一个以路由方式加入到VPN的子网网段都必须是唯一的。</li><li>该客户端的证书的Common Name必须是唯一的（本例中是<code>client2</code>），并且OpenVPN服务器配置文件不能使用<code>duplicate-cn</code>标记。</li></ul><p>首先，确保该客户端所在计算机已经启用了IP和TUN/TAP转发。</p><p>各操作系统<a href="https://community.openvpn.net/openvpn/wiki/265-how-do-i-enable-ip-forwarding" target="_blank" rel="noopener">开启IP和TUN/TAP转发的设置</a>：</p><p><strong>Windows</strong>（<a href="https://technet.microsoft.com/en-us/library/cc962461.aspx" target="_blank" rel="noopener">官网IPEnableRouter相关文章<code>https://technet.microsoft.com/en-us/library/cc962461.aspx</code></a>）：</p><p>注册表编辑器<code>HKLM\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters</code>将<code>IPEnableRouter</code>的值改为<code>1</code>；运行<code>services.msc</code>将“Routing and Remote Access”设置为自动并启动；</p><p>检查：运行<code>ipconfig -all</code>，查看“Windows IP 配置”中显示<code>IP 路由已启用: 是</code></p><p><strong>Linux</strong>：</p><p><code>echo 1 &gt; /proc/sys/net/ipv4/ip_forward</code></p><p>如果不想重启后失效，运行：</p><pre><code class="shell">echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.confsysctl -p</code></pre><p>运行<code>cat /proc/sys/net/ipv4/ip_forward</code>检查状态。</p><p><strong>OS X</strong>：</p><p><code>sudo sysctl -w net.inet.ip.forwarding=1</code></p><p>下一步，需要在服务器端做一些必要的配置更改。如果当前的服务器配置文件没有引用一个客户端配置目录，添加一个：</p><pre><code class="shell">client-config-dir ccd</code></pre><p>在上面的指令中，<code>ccd</code>是一个已经在OpenVPN服务器运行的默认目录中预先创建好的文件夹的名称。在Linux中，运行的默认目录往往是<code>/etc/openvpn</code>；在Windows中，其通常是OpenVPN安装路径<code>/config</code>。当一个新的客户端连接到OpenVPN服务器，后台进程将会检查配置目录（这里是<code>ccd</code>）中是否存在一个与连接的客户端的Common Name匹配的文件（这里是<code>client2</code>）。如果找到了匹配的文件，OpenVPN将会读取该文件，作为附加的配置文件指令来处理，并应用于该名称的客户端。</p><p>下一步就是在<code>ccd</code>目录中创建一个名为<code>client2</code>的文件。该文件应该包含如下内容：</p><pre><code class="shell">iroute 192.168.4.0 255.255.255.0</code></pre><p>这将告诉OpenVPN服务器：子网网段<code>192.168.4.0/24</code>应该被路由到<code>client2</code>。</p><p>接着，在OpenVPN服务器配置文件（<strong>不是</strong><code>ccd/client2</code>文件）中添加如下指令：</p><pre><code class="shell">route 192.168.4.0 255.255.255.0</code></pre><p><code>route</code>语句控制从系统内核到OpenVPN服务器的路由，<code>iroute</code>控制从OpenVPN服务器到远程客户端的路由（不是太懂，照做就可以了）。</p><p>下一步，请考虑是否允许<code>client2</code>所在的子网（192.168.4.0/24）与OpenVPN服务器的其他客户端进行相互通讯。如果允许，在服务器配置文件中添加如下语句（笔者注：可以在<code>ccd</code>对应用户名加入，可以更精确控制使用范围）：</p><pre><code class="shell">client-to-clientpush &quot;route 192.168.4.0 255.255.255.0&quot;</code></pre><p>OpenVPN服务器将向其他正在连接的客户端宣告<code>client2</code>子网的存在。</p><p>最后一步，这也是经常被忘记的一步：在服务器的局域网网关处添加一个路由，用以将<code>192.168.4.0/24</code>定向到OpenVPN服务器（如果OpenVPN服务器和局域网网关在同一计算机上，则无需这么做）。假设缺少了这一步，当你从<code>192.168.4.8</code>向服务器局域网的某台计算机发送<code>ping</code>命令时，这个外部ping命令很可能能够到达目标计算机，但是却不知道如何路由一个<code>ping</code>回复，因为它不知道如何达到<code>192.168.4.0/24</code>。主要的使用规则是：当全部的局域网都通过VPN时（并且OpenVPN服务器和局域网网关不在同一计算机），请确保在局域网网关处将所有的VPN子网都路由到VPN服务器所在计算机。</p><p>类似地，如果OpenVPN客户端和客户端局域网网关不在同一计算机上，请在客户端局域网网关处创建路由，以确保通过VPN的所有子网都能转向OpenVPN客户端所在计算机。</p><p>笔者注：上面的看得有点晕，简单介绍下<strong>添加路由</strong>的几种方式：</p><ul><li>在网关添加路由。如在<code>10.66.0.0/24</code>网关处添加一条访问<code>192.168.4.0/24</code>时以<code>10.66.0.5</code>为网关，在<code>192.168.4.0/24</code>网关处添加一条访问<code>10.66.0.0/24</code>时以<code>192.168.4.10</code>为网关。</li><li>在其他终端上添加路由表。（服务器所在网段的）Windows如下添加：<code>route add 192.168.4.0 mask 255.255.255.0 10.66.0.5</code>，（客户端所在网段的）Windows如下添加：<code>route add 10.66.0.0 mask 255.255.255.0 192.168.4.10</code>，如果添加永久路由，使用<code>-p</code>参数。其它系统的自行网上找资料。</li><li>（客户端所在网段的）Windows需要添加：<code>route add 10.8.0.0 mask 255.255.255.0 192.168.4.10</code>，才能被服务器（或服务器所在网段的其他电脑）访问到。</li><li>可以综合参考以上方式，来控制加入此互访网络的终端。</li></ul><h3 id="1-9-1-防火墙规则"><a href="#1-9-1-防火墙规则" class="headerlink" title="1.9.1. 防火墙规则"></a>1.9.1. 防火墙规则</h3><p>基于路由模式（<code>dev tun</code>）时，OpenVPN服务器上防火墙配置（主要是关于防火墙如何工作，熟悉的可以略过了）简要归纳（开放监听端口不在此赘述）：</p><p>假设环境如下：</p><p>服务端网段<code>10.66.0.0/24</code>下设备：OpenVPN服务器IP地址<code>10.66.0.5</code>,A服务器（Windows）IP地址<code>10.66.0.33</code></p><p>OpenVPN虚拟IP网段<code>10.8.0.0/24</code></p><p>客户端网段<code>192.168.4.0</code>下设备：OpenVPN客户端IP地址<code>192.168.4.10</code>,X终端（Windows）IP地址<code>192.168.4.66</code></p><p>1、防火墙不添加任何设置：</p><p>只能客户端与服务器互相访问（两者正常情况都可以互相访问，下面不再单独说明，以下所有访问指的使用<code>ping</code>测试通过，测试时Windows系统注意关闭防火墙或者设置规则允许ICMP协议入站）</p><p>2、防火墙设置：</p><pre><code class="shell">*filter# 允许进tun接口目标为“10.8.0.0/24”的访问-A FORWARD -o tun+ -d 10.8.0.0/24 -j ACCEPT  # “+”也可改为实际的“tun[n]”，如“tun0”、“tun1”...# 允许源为“10.8.0.0/24”出tun接口的访问-A FORWARD -i tun+ -s 10.8.0.0/24 -j ACCEPT# 如果需要设置指定可以访问的服务器范围，删除上面一行,如下设置-A FORWARD -i tun+ -s 10.8.0.0/24 -d 10.66.0.33 -j ACCEPT  # OpenVPN客户端不能访问到除10.66.0.33外其他的服务器（如果存在）</code></pre><p>无其它设置时还是只能客户端与服务器互相访问，在A服务器添加路由表：<code>route add 10.8.0.0 mask 255.255.255.0 10.66.0.5</code>（或在服务器网关处添加类似路由，以下所有路由表都可以在网关处添加来替换该步骤，只不过作用范围不同，下面不再单独说明），<br>OpenVPN客户端和A服务器可以互相访问</p><p>3、防火墙设置：</p><pre><code class="shell">*nat# 添加下面一行，OpenVPN服务器可访问的地址，客户端也可以访问-A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE# 或如下设置指定网卡（若添指定了网卡，那么OpenVPN服务器自身通过该网卡不能访问的地址，客户端也不能访问）-A POSTROUTING -o eth0 -s 10.8.0.0/24 -j MASQUERADE*filter-A FORWARD -o tun+ -d 10.8.0.0/24 -j ACCEPT-A FORWARD -i tun+ -s 10.8.0.0/24 -j ACCEPT</code></pre><p>无其它设置时OpenVPN客户端可以访问到A服务器，A服务器访问不到OpenVPN客户端，在A服务器添加路由表：<code>route add 10.8.0.0 mask 255.255.255.0 10.66.0.5</code>，OpenVPN客户端和A服务器可以互相访问</p><p><strong>小结</strong>：</p><p>要客户端与服务器所在网段其他设备互相访问需要的防火墙设置为：</p><pre><code class="shell">*nat-A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE  # 可视实际情况（如配置了路由表或是网关配置了路由）选择不配置*filter-A FORWARD -o tun+ -d 10.8.0.0/24 -j ACCEPT-A FORWARD -i tun+ -s 10.8.0.0/24 -j ACCEPT-A FORWARD -i tun+ -s 10.8.0.0/24 -d 10.66.0.33 -j ACCEPT  # 此规则与上一行选一种来使用</code></pre><p>firewalld对应命令：</p><pre><code class="shell">firewall-cmd --zone=block --add-interface=tun+firewall-cmd --permanent --zone=block --add-interface=tun+firewall-cmd --direct --add-rule ipv4 nat POSTROUTING 0 -s 10.8.0.0/24 -j MASQUERADEfirewall-cmd --direct --add-rule ipv4 filter FORWARD 0 -o tun+ -d 10.8.0.0/24 -j ACCEPTfirewall-cmd --direct --add-rule ipv4 filter FORWARD 0 -i tun+ -s 10.8.0.0/24 -j ACCEPTfirewall-cmd --direct --add-rule ipv4 filter FORWARD 0 -i tun+ -s 10.8.0.0/24 -m iprange --dst-range 10.66.0.33-10.66.0.50 -j ACCEPT  # 或是指定允许访问的范围# --direct不能使用--permanent，即使没有报错，重启服务或服务器后，对应的命令也不会生效</code></pre><p>如果对tun接口的所有流量都允许，可最简（最宽松的防火墙设置，不建议，可根据具体使用场景来综合考虑使用配置）为：</p><pre><code class="shell">*nat-A POSTROUTING -j MASQUERADE*filter-A FORWARD -o tun+ -j ACCEPT-A FORWARD -i tun+ -j ACCEPT</code></pre><p>以下内容假设服务器已按“包含基于路由模式的VPN客户端的多台计算机”步骤配置好服务器和客户端（除开OpenVPN服务器防火墙相关内容）：</p><p>4、防火墙设置：</p><pre><code class="shell">*filter-A FORWARD -o tun+ -d 10.8.0.0/24 -j ACCEPT-A FORWARD -i tun+ -s 10.8.0.0/24 -j ACCEPT-A FORWARD -o tun+ -d 192.168.4.0/24 -j ACCEPT-A FORWARD -i tun+ -s 192.168.4.0/24 -j ACCEPT  # 同样可以加入类似“-d 10.66.0.33”对允许访问的服务器进行限制</code></pre><p>无其它设置时还是只能客户端与服务器互相访问，在A服务器添加路由表：<code>route add 192.168.4.0 mask 255.255.255.0 10.66.0.5</code>，在X终端添加路由表：<code>route add 10.66.0.0 mask 255.255.255.0 192.168.4.10</code>，<br>OpenVPN客户端、X终端、OpenVPN服务器及A服务器可以互相访问</p><p>5、一些其他测试：</p><pre><code class="shell">*filter-A FORWARD -o tun+ -d 192.168.4.0/24 -j ACCEPT-A FORWARD -i tun+ -s 192.168.4.0/24 -j ACCEPT</code></pre><p>去掉了关于<code>10.8.0.0/24</code>的内容，只要添加好了路由表，各设备之间还是可以通过真实局域网IP地址来访问</p><p>如果想客户端在服务端的设备不加路由表的情况（单向）访问各服务器，加入：</p><pre><code class="shell">-A POSTROUTING -s 192.168.4.0/24 -j MASQUERADE</code></pre><p>同样如果对tun接口的所有流量都允许，可以简化为：</p><pre><code class="shell">*filter-A FORWARD -o tun+ -j ACCEPT-A FORWARD -i tun+ -j ACCEPT</code></pre><h2 id="1-10-推送DHCP选项到客户端"><a href="#1-10-推送DHCP选项到客户端" class="headerlink" title="1.10. 推送DHCP选项到客户端"></a>1.10. 推送DHCP选项到客户端</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#dhcp" target="_blank" rel="noopener">英文原文</a></p><p>OpenVPN服务器能够推送诸如DNS、WINS服务器地址等DHCP选项参数到客户端（这里是一些值得注意的<a href="https://community.openvpn.net/openvpn/wiki/FAQ#dhcpcaveats" target="_blank" rel="noopener">附加说明</a>）。Windows客户端原生就能够接受被推送来的DHCP选项参数，但非Windows系统的客户端需要使用客户端的up脚本才能接受它们，<code>up</code>脚本能够解析<code>foreign_option_n</code>环境变量列表。请进入<a href="https://openvpn.net/index.php/open-source/documentation/manuals/65-openvpn-20x-manpage.html" target="_blank" rel="noopener">手册页面</a>或者<a href="https://openvpn.net/index.php/open-source/documentation/miscellaneous/61-mailing-lists.html" target="_blank" rel="noopener">OpenVPN用户的邮件列表档案</a>查看非Windows系统的<code>foreign_option_n</code>文档和脚本示例。</p><p>举个例子，假如你希望正在连接的客户端使用一个内部的DNS服务器<code>10.66.0.4</code>或<code>10.66.0.5</code>，和一个WINS服务器<code>10.66.0.8</code>，在OpenVPN服务器配置中添加下列语句：</p><pre><code class="shell">push &quot;dhcp-option DNS 10.66.0.4&quot;push &quot;dhcp-option DNS 10.66.0.5&quot;push &quot;dhcp-option WINS 10.66.0.8&quot;</code></pre><p>想要在Windows上测试该功能，在客户端连接OpenVPN服务器后，在命令提示符中运行如下命令：</p><pre><code class="shell">ipconfig -all</code></pre><p>其中，“TAP-Windows”部分应该显示服务器推送过来的DHCP选项参数。</p><h2 id="1-11-为指定客户端配置规则和访问策略"><a href="#1-11-为指定客户端配置规则和访问策略" class="headerlink" title="1.11. 为指定客户端配置规则和访问策略"></a>1.11. 为指定客户端配置规则和访问策略</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#policy" target="_blank" rel="noopener">英文原文</a></p><p>假设，创建了一个供企业使用的VPN，想要分别为3种不同级别的用户单独设置访问策略：</p><ul><li>系统管理员 – 允许访问网络内的所有终端</li><li>普通职工 – 只允许访问Samba/Email服务器</li><li>承包商 – 只允许访问特定的服务器</li></ul><p>所要采取的基本方法是：</p><ul><li>给不同级别的用户划分不同的虚拟IP地址范围</li><li>通过设置锁定客户端虚拟IP地址的防火墙规则来控制对计算机的访问。</li></ul><p>本例中假设有大量的普通职工，只有1个系统管理员、2个承包商。IP配置方案将会把所有的普通职工放入一个IP地址池中，然后为系统管理员和承包商分配固定的IP地址。</p><p>注意：本例的前提条件之一就是有一个运行于OpenVPN服务器所在计算机上的软件防火墙，并具备自定义防火墙规则的能力。这里假定防火墙是Linux系统的iptables。</p><p>首先，根据用户级别创建一个虚拟IP地址映射：</p><table><thead><tr><th>Class</th><th>Virtual IP Range</th><th>Allowed LAN Access</th><th>Common Names</th></tr></thead><tbody><tr><td>普通职工</td><td>10.8.0.0/24</td><td>Samba/Email服务器为10.66.4.4</td><td>[数量众多]</td></tr><tr><td>系统管理员</td><td>10.8.1.0/24</td><td>10.66.4.0/24整个网段</td><td>sysadmin1</td></tr><tr><td>承包商</td><td>10.8.2.0/24</td><td>承包商服务器为10.66.4.12</td><td>contractor1, contracter2</td></tr></tbody></table><p>下一步，将上述映射转换到OpenVPN服务器配置中。首先确保已经遵循了<a href="#19-服务器或客户端子网中的其他计算机互相访问">上述步骤</a>并将<code>10.66.4.0/24</code>网段分配给了所有的客户端（虽然配置允许客户端访问整个<code>10.66.4.0/24</code>网段，不过稍后将利用防火墙规则强制添加访问限制来实现上述表格中的访问策略）。</p><p>首先，为tun接口定义一个静态的单元编号，以便于稍后在防火墙规则中使用它：</p><pre><code class="shell">dev tun0</code></pre><p>在服务器配置文件中，定义普通职工的IP地址池：</p><pre><code class="shell">server 10.8.0.0 255.255.255.0</code></pre><p>为系统管理员和承包商的IP范围添加路由：</p><pre><code class="shell"># 管理员的IP范围route 10.8.1.0 255.255.255.0# 承包商的IP范围route 10.8.2.0 255.255.255.0</code></pre><p>因为要为指定的系统管理员和承包商分配固定的IP地址，将使用一个客户端配置文件：</p><pre><code class="shell">client-config-dir ccd</code></pre><p>在<code>ccd</code>子目录中放置专用的配置文件，为每个非普通职工的VPN客户端定义固定的IP地址。</p><p>文件<code>ccd/sysadmin1</code>：</p><pre><code class="shell">ifconfig-push 10.8.1.1 10.8.1.2</code></pre><p>文件<code>ccd/contractor1</code>：</p><pre><code class="shell">ifconfig-push 10.8.2.1 10.8.2.2</code></pre><p>文件<code>ccd/contractor2</code>：</p><pre><code class="shell">ifconfig-push 10.8.2.5 10.8.2.6</code></pre><p><code>ifconfig-push</code>中的每一对IP地址表示虚拟客户端和服务器的IP端点。它们必须从连续的<code>/30</code>子网网段中获取（这里是<code>/30</code>表示<code>xxx.xxx.xxx.xxx/30</code>，即子网掩码位数为30），以便于与Windows客户端和TAP-Windows驱动兼容。明确地说，每个端点的IP地址对的最后8位字节必须取自下面的集合：</p><pre><code class="shell">[  1,  2] [  5,  6] [  9, 10] [ 13, 14] [ 17, 18][ 21, 22] [ 25, 26] [ 29, 30] [ 33, 34] [ 37, 38][ 41, 42] [ 45, 46] [ 49, 50] [ 53, 54] [ 57, 58][ 61, 62] [ 65, 66] [ 69, 70] [ 73, 74] [ 77, 78][ 81, 82] [ 85, 86] [ 89, 90] [ 93, 94] [ 97, 98][101,102] [105,106] [109,110] [113,114] [117,118][121,122] [125,126] [129,130] [133,134] [137,138][141,142] [145,146] [149,150] [153,154] [157,158][161,162] [165,166] [169,170] [173,174] [177,178][181,182] [185,186] [189,190] [193,194] [197,198][201,202] [205,206] [209,210] [213,214] [217,218][221,222] [225,226] [229,230] [233,234] [237,238][241,242] [245,246] [249,250] [253,254]</code></pre><p>完成了OpenVPN的配置，最后一步是添加防火墙规则来完成访问策略。下例使用Linux系统iptables语法的防火墙规则：</p><pre><code class="shell"># 普通职工规则iptables -A FORWARD -i tun0 -s 10.8.0.0/24 -d 10.66.4.4 -j ACCEPT# 系统管理员规则iptables -A FORWARD -i tun0 -s 10.8.1.0/24 -d 10.66.4.0/24 -j ACCEPT# 承包商规则iptables -A FORWARD -i tun0 -s 10.8.2.0/24 -d 10.66.4.12 -j ACCEPT</code></pre><h2 id="1-12-使用其他身份验证方式"><a href="#1-12-使用其他身份验证方式" class="headerlink" title="1.12. 使用其他身份验证方式"></a>1.12. 使用其他身份验证方式</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#auth" target="_blank" rel="noopener">英文原文</a></p><p>OpenVPN 2.0及以上版本支持OpenVPN服务器安全地从客户端获取用户名和密码，并以该信息作为客户端身份验证的基础。</p><p>使用该身份验证方式，先在客户端配置中添加<code>auth-user-pass</code>指令。这使得OpenVPN客户端直接向用户询问用户名/密码，并通过安全的TLS隧道将其传递到服务器。</p><p>下一步，配置服务器以使用一个身份验证插件，该插件可以是一个脚本、共享的对象或者DLL文件。在每次客户端尝试连接时，OpenVPN服务器就会调用该插件，并将客户端输入的用户名/密码传递给它。身份验证插件通过返回一个表示失败(1)或成功(0)的值，从而控制OpenVPN是否允许该客户端连接。</p><p><strong>使用脚本插件</strong></p><p>通过在服务器端配置文件中添加<code>auth-user-pass-verify</code>指令，可以使用脚本插件。例如：</p><pre><code class="shell">auth-user-pass-verify auth-pam.pl via-file</code></pre><p>将使用名为<code>auth-pam.pl</code>的perl脚本来验证正在连接的客户端的用户名/密码。详情请查看<a href="https://openvpn.net/index.php/open-source/documentation/manuals/65-openvpn-20x-manpage.html" target="_blank" rel="noopener">手册页面</a>中关于<code>auth-user-pass-verify</code>的相关描述。</p><p><code>auth-pam.pl</code>脚本文件位于OpenVPN源代码发行版的<code>sample-scripts</code>子目录中。在Linux服务器上，它将使用PAM认证模块对用户进行身份验证，从而实现shadow密码、RADIUS（远程用户拨入验证服务）或者LDAP（轻量级目录访问协议）验证。<code>auth-pam.pl</code>主要用于演示目的。对于实际的PAM验证，请使用下面描述的<code>openvpn-auth-pam</code>共享对象插件。</p><p><strong>使用共享对象或DLL插件</strong></p><p>共享对象或DLL插件通常是一个经过编译的C模块，它能够在运行时被OpenVPN服务器加载。如果在Linux系统中使用基于RPM的OpenVPN，<code>openvpn-auth-pam</code>插件应该已经创建好了。为了使用该插件，在服务器端配置文件中添加如下语句：</p><pre><code class="shell">plugin /usr/share/openvpn/plugin/lib/openvpn-auth-pam.so login</code></pre><p>这将告诉OpenVPN服务器使用login PAM模块来校验客户端输入的用户名/密码。</p><p>对于实际生产环境中，最好使用<code>openvpn-auth-pam</code>插件，因为相对使用<code>auth-pam.pl</code>脚本而言，它具有以下几个优点：</p><ul><li>共享对象<code>openvpn-auth-pam</code>插件采用更加安全的拆分权限执行模式。这意味着OpenVPN服务器可以运行在使用<code>user nobody</code>、<code>group nobody</code>和<code>chroot</code>等指令来降低权限的情况下，并且能够进行身份验证，而不依赖于只有root用户才能读取的shadow密码文件。</li><li>OpenVPN可以通过虚拟内存将用户名/密码传递给插件，而不是通过一个文件或环境变量，对于服务器计算机而言，具有更好的本地安全性。</li></ul><p>如果想了解更多关于开发自己的插件以便与OpenVPN一起使用的信息，请参阅OpenVPN源代码发行版<code>plugin</code>子目录中的<code>README</code>文件。</p><p>在Linux中，为了构建<code>openvpn-auth-pam</code>插件，请转到OpenVPN源代码发行版的<code>plugin/auth-pam</code>目录，并运行<code>make</code>。</p><p><strong>使用用户名/密码认证作为唯一的客户端认证形式</strong></p><p>默认情况下，在服务器上使用<code>auth-user-pass-verify</code>或者用户名/密码验证插件将会启用双重身份验证，这使得待验证客户端的客户端证书和用户名/密码验证都必须通过。</p><p>也可以禁用客户端证书，而强制只使用用户名/密码验证（从安全角度来说，不鼓励这样做）。在服务器端加入：</p><pre><code class="shell">client-cert-not-required</code></pre><p>通常还需要这样设置：</p><pre><code class="shell">username-as-common-name</code></pre><p>这将告诉服务器优先使用用户名，就像它使用那些通过客户端证书认证的客户端的Common Name一样(也就是说，使用username作为Common Name，用法与之前使用Common Name时相同)。</p><p>注意：<code>client-cert-not-required</code>并不排除对服务器证书的需要，所以一个客户端连接到使用了<code>client-cert-not-required</code>指令的服务器，可以删除客户端配置文件中的<code>cert</code>和<code>key</code>指令，但不能删除<code>ca</code>指令，因为它对于客户端验证服务器端证书来说是必需的。</p><h2 id="1-13-使用客户端的智能卡实现双重认证"><a href="#1-13-使用客户端的智能卡实现双重认证" class="headerlink" title="1.13. 使用客户端的智能卡实现双重认证"></a>1.13. 使用客户端的智能卡实现双重认证</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#pkcs11" target="_blank" rel="noopener">英文原文</a></p><h2 id="1-14-路由所有客户端流量通过VPN"><a href="#1-14-路由所有客户端流量通过VPN" class="headerlink" title="1.14. 路由所有客户端流量通过VPN"></a>1.14. 路由所有客户端流量通过VPN</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#redirect" target="_blank" rel="noopener">英文原文</a></p><p><strong>概述</strong></p><p>默认情况下，当一个OpenVPN客户端处于活动状态时，只有往返于OpenVPN服务器的网络流量才会通过VPN。如一般的网页浏览操作，将绕过VPN，直接连接来完成。</p><p>在某些情况下，可能想让VPN客户端所有的网络流量均通过VPN，也包括一般的网络流量。虽然客户端的这种VPN配置将会耗费一些性能，但在客户端同时连接公共网络和VPN时，它给VPN管理员在安全策略上更多的控制能力。</p><p><strong>实施</strong></p><p>在服务器配置文件中添加如下指令：</p><pre><code class="shell">push &quot;redirect-gateway def1&quot;</code></pre><p>如果VPN安装在无线网络上，并且OpenVPN服务器和客户端均处于同一个无线子网中，请添加<code>local</code>标记：</p><pre><code class="shell">push &quot;redirect-gateway local def1&quot;</code></pre><p>推送<code>redirect-gateway</code>选项命令到客户端，将会导致源自客户端计算机的所有IP网络流量通过OpenVPN服务器。服务器需要进行配置，从而以某种方式处理这些流量，例如：通过NAT转化流量到internet，或者路由通过服务器所在网络场所的HTTP代理。在Linux系统中，你可以使用如下命令将VPN客户端的流量NAT转化到internet：</p><pre><code class="shell">iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE</code></pre><p>该命令假定VPN子网网段为<code>10.8.0.0/24</code>（取自OpenVPN服务器配置的server指令），本地以太网接口为eth0。</p><p>当启用了<code>redirect-gateway</code>指令，OpenVPN客户端将路由所有的DNS查询经过VPN，VPN服务器需要处理掉这些查询。在VPN活动期间，我们可以通过推送DNS服务器地址到正在连接的客户端上来完成该操作，从而代替常规的DNS服务器设置：</p><pre><code class="shell">push &quot;dhcp-option DNS 10.8.0.1&quot;</code></pre><p>这将配置Windows客户端（或带有额外的服务器端脚本的非Windows客户端）使用<code>10.8.0.1</code>作为它们的DNS服务器。任何客户端能够到达的地址都可能作为DNS服务器。</p><p><strong>注意事项</strong></p><p>通过VPN重定向所有网络流量并不是完全没有问题的提议。以下是一些典型的疑难问题：</p><ul><li>多数连接internet的OpenVPN客户端计算机会定期与DHCP服务器进行交互，并更新它们的IP地址租约。<code>redirect-gateway</code>选项命令可能会阻止客户端连接到本地DHCP服务器（因为DHCP信息会被路由通过VPN），从而导致丢失IP地址租约。</li><li>关于推送DNS地址到Windows客户端<a href="https://community.openvpn.net/openvpn/wiki/FAQ#dhcpcaveats" target="_blank" rel="noopener">存在一些问题</a>。</li><li>客户端的Web浏览性能将会明显降低。</li></ul><p>关于<code>redirect-gateway</code>指令的更多信息，请参考<a href="https://openvpn.net/index.php/open-source/documentation/manuals/65-openvpn-20x-manpage.html" target="_blank" rel="noopener">手册页面</a>。</p><h2 id="1-15-在动态IP地址上运行OpenVPN服务器"><a href="#1-15-在动态IP地址上运行OpenVPN服务器" class="headerlink" title="1.15. 在动态IP地址上运行OpenVPN服务器"></a>1.15. 在动态IP地址上运行OpenVPN服务器</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#dynamic" target="_blank" rel="noopener">英文原文</a></p><p>总结一句就是使用动态域名解析</p><h2 id="1-16-通过HTTP代理连接OpenVPN服务器"><a href="#1-16-通过HTTP代理连接OpenVPN服务器" class="headerlink" title="1.16. 通过HTTP代理连接OpenVPN服务器"></a>1.16. 通过HTTP代理连接OpenVPN服务器</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#http" target="_blank" rel="noopener">英文原文</a></p><p>OpenVPN支持以下列身份认证方式通过HTTP代理进行连接：</p><ul><li>无需代理身份认证</li><li>基本(Basic)代理身份认证</li><li>NTLM代理身份认证</li></ul><p>首先，HTTP代理的用法要求你必须使用TCP协议作为隧道载体。所以，在客户端和服务器配置中均添加如下语句：</p><pre><code class="shell">proto tcp</code></pre><p>确保删除（或注释）配置文件中的所有<code>proto udp</code>指令行。</p><p>下一步，在客户端配置文件中添加<code>http-proxy</code>指令（请查看<a href="http://openvpn.net/man.html" target="_blank" rel="noopener">手册页面</a>了解该指令的详细描述信息）。</p><p>例如，假设客户端局域网有一台<code>192.168.4.1</code>的HTTP代理服务器，并监听在<code>1080</code>端口。在客户端配置中添加如下语句：</p><p>假设HTTP代理要求基本的身份认证：</p><pre><code class="shell">http-proxy 192.168.4.1 1080 stdin basic</code></pre><p>假设HTTP代理要求NTLM身份认证：</p><pre><code class="shell">http-proxy 192.168.4.1 1080 stdin ntlm</code></pre><p>上面的两个身份认证示例将会使OpenVPN提示从标准输入界面输入用户名/密码。如果希望将这些用户凭据放入一个文件中来代替上述输入操作，使用一个文件名来替换语句中的stdin，该文件的第1行应该放用户名，第2行放密码。</p><h2 id="1-17-通过OpenVPN连接Samba网络共享服务器"><a href="#1-17-通过OpenVPN连接Samba网络共享服务器" class="headerlink" title="1.17. 通过OpenVPN连接Samba网络共享服务器"></a>1.17. 通过OpenVPN连接Samba网络共享服务器</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#samba" target="_blank" rel="noopener">英文原文</a></p><p>本示例演示OpenVPN是如何通过基于路由的<code>dev tun</code>隧道连接到一个Samba共享服务器的。如果使用的是以太网桥接模式(<code>dev tap</code>)，你可能不需要遵循下列操作，因为OpenVPN客户端可以在网络邻居中看到服务器端局域网中的计算机。</p><p>在本例中假设：</p><ul><li>服务器端局域网使用子网网段<code>10.66.0.0/24</code></li><li>VPN IP地址池使用<code>10.8.0.0/24</code>（作为OpenVPN服务器配置文件中的server指令参数）</li><li>Samba服务器的IP地址为<code>10.66.0.4</code></li><li>Samba服务器已进行配置，从本地局域网能够正常访问</li></ul><p>如果Samba和OpenVPN服务器运行于不同的计算机，请确保已经遵循并实现了<a href="#19-服务器或客户端子网中的其他计算机互相访问">扩大OpenVPN使用范围，包含服务器或客户端子网中的其他计算机</a>。</p><p>下一步，编辑Samba配置文件(<code>smb.conf</code>)。确保<code>hosts allow</code>指令允许来自<code>10.8.0.0/24</code>网段的OpenVPN客户端进行连接。例如：</p><pre><code class="shell">hosts allow = 10.66.0.0/24 10.8.0.0/24 127.0.0.1</code></pre><p>如果Samba和OpenVPN服务器运行于同一台计算机，可以编辑<code>smb.conf</code>文件中的<code>interfaces</code>指令，也监听TUN接口网段<code>10.8.0.0/24</code>：</p><pre><code class="shell">interfaces  = 10.66.0.0/24 10.8.0.0/24</code></pre><p>如果Samba和OpenVPN服务器运行于同一台计算机，使用文件夹名称：</p><pre><code class="shell">\\10.8.0.1\\sharename</code></pre><p>如果Samba和OpenVPN服务器位于不同的计算机，使用文件夹名称：</p><pre><code class="shell">\\10.66.0.4\sharename</code></pre><p>例如，从命令提示符窗口中运行：</p><pre><code class="shell">net use z: \\10.66.0.4\sharename /USER:myusername</code></pre><h2 id="1-18-实现负载均衡-故障转移的配置"><a href="#1-18-实现负载均衡-故障转移的配置" class="headerlink" title="1.18. 实现负载均衡/故障转移的配置"></a>1.18. 实现负载均衡/故障转移的配置</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#loadbalance" target="_blank" rel="noopener">英文原文</a></p><p><strong>客户端配置</strong></p><p>OpenVPN客户端配置可以用于实现负载均衡和故障转移功能的多台服务器。例如：</p><pre><code class="shell">remote server1.mydomainremote server2.mydomainremote server3.mydomain</code></pre><p>这将指示OpenVPN客户端按照顺序尝试与server1、server2、server3进行连接。如果现有的连接被中断，OpenVPN客户端将会重新尝试连接最近连接过的服务器；如果连接失败，客户端将会尝试与列表中的下一个服务器进行连接（测试大致会尝试半分钟至1分钟左右后，连接下一个服务器）。也可以指示OpenVPN客户端在启动时随机连接列表中的一个服务器，以便于客户端负载能够均等概率地覆盖服务器池。</p><pre><code class="shell">remote-random</code></pre><p>如果也希望在DNS解析失败时，让OpenVPN客户端移至列表中的下一个服务器，添加如下命令：</p><pre><code class="shell">resolv-retry 60</code></pre><p>参数<code>60</code>告诉OpenVPN客户端，在移至下一个服务器之前，尝试解析每个<code>remote</code>的DNS名称60秒（即60秒内都无法解析成功，就移至下一个服务器）。</p><p>服务器列表还可以引用运行于同一计算机上的多个OpenVPN服务器进程（每个进程监听不同的端口），例如：</p><pre><code class="shell">remote smp-server1.mydomain 8000remote smp-server1.mydomain 8001remote smp-server2.mydomain 8000remote smp-server2.mydomain 8001</code></pre><p>如果服务器有多个处理器，每台计算机运行多个OpenVPN后台进程有利于提高性能表现。</p><p>OpenVPN也支持<code>remote</code>指令引用在域名配置中拥有多个A记录的DNS名称。在这种情况下，在每次域名被解析时，OpenVPN客户端将会随机选择一个A记录。</p><p><strong>服务器端配置</strong></p><p>除了每个服务器使用不同的虚拟IP地址池之外，为集群中的每个服务器使用相同的配置文件，是在服务器端实现负载均衡/故障转移配置的最简单方法。例如：</p><p>server1：</p><pre><code class="shell">server 10.8.0.0 255.255.255.0</code></pre><p>server2：</p><pre><code class="shell">server 10.8.1.0 255.255.255.0</code></pre><p>server3：</p><pre><code class="shell">server 10.8.2.0 255.255.255.0</code></pre><h2 id="1-19-增强OpenVPN的安全性"><a href="#1-19-增强OpenVPN的安全性" class="headerlink" title="1.19. 增强OpenVPN的安全性"></a>1.19. 增强OpenVPN的安全性</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#security" target="_blank" rel="noopener">英文原文</a></p><p>一个经常被重复提及的网络安全准则就是：不要过分相信一个单一的安全组件，否则它的失败将导致灾难性的安全漏洞。OpenVPN提供多种机制来添加额外的安全层，以避免这样的结果。</p><p><strong>tls-auth</strong></p><p><code>tls-auth</code>指令为所有的SSL/TLS握手数据包添加一个额外的HMAC签名，以验证数据的完整性。无需进一步处理，没有正确的HMAC签名的任何UDP数据包将会被丢弃。<code>tls-auth</code> HMAC签名提供了上面所说的额外安全级别，而不是通过SSL/TLS来提供。它可以防御：</p><ul><li>Dos攻击或者UDP端口淹没攻击。</li><li>确定服务器UDP端口监听状态的端口扫描。</li><li>SSL/TLS实现的缓冲区溢出漏洞。</li><li>启动来自未经授权机器的SSL/TLS握手（虽然这样的握手最终会验证失败，但<code>tls-auth</code>可以更早地断开）。</li></ul><p>除了使用标准的RSA证书/密钥之外，使用<code>tls-auth</code>还需要生成一个共享的密钥：</p><pre><code class="shell">openvpn --genkey --secret ta.key</code></pre><p>该命令将生成一个OpenVPN静态密钥，并将其写入到<code>ta.key</code>文件中。该密钥应该通过已有的安全通道拷贝到服务器和所有的客户端。它应该与RSA的<code>.key</code>和<code>.crt</code>文件放在同一目录。</p><p>在服务器配置中，添加：</p><pre><code class="shell">tls-auth ta.key 0</code></pre><p>在客户端配置中，添加：</p><pre><code class="shell">tls-auth ta.key 1</code></pre><p><strong>proto udp</strong></p><p>虽然OpenVPN允许使用TCP或者UDP协议作为VPN的连接载体，但UDP协议能够比TCP提供更好的Dos攻击和端口扫描防护：</p><pre><code class="shell">proto udp</code></pre><p><strong>user/group（仅限于非Windows系统）</strong></p><p>OpenVPN经过非常仔细的设计，以允许在初始化后丢弃掉root权限，该特性可以在Linux/BSD/Solaris系统中一直使用。</p><p>对于攻击者而言，没有root权限，运行中的OpenVPN服务器进程就不是一个有吸引力的目标。</p><pre><code class="shell">user nobodygroup nobody</code></pre><p><strong>非特权模式（仅限于Linux系统）</strong></p><p>在Linux系统中，OpenVPN可以完全没有特权地正常运行。虽然配置上会稍稍麻烦一点，但却能带来最佳的安全性。</p><p>为了使用这种配置来运行，OpenVPN必须配置为使用<code>iproute</code>接口，这可以通过为<code>configure</code>脚本指定<code>--enable-iproute2</code>参数来完成。系统也需要有<code>sudo</code>软件包。</p><p>该配置使用Linux自身的能力来更改tun设备的权限，以便于非特权的用户也可以访问它。为了执行<code>iproute</code>，也需要使用<code>sudo</code>，从而使得接口属性和路由表可以被修改。</p><p>OpenVPN配置：</p><ul><li>重写并覆盖位于<code>/usr/local/sbin/unpriv-ip</code>的以下脚本文件：</li></ul><pre><code class="shell">#!/bin/shsudo /sbin/ip $*</code></pre><ul><li>执行<code>visudo</code>，添加如下命令以允许用户”user1”执行<code>/sbin/ip</code>：</li></ul><pre><code class="shell">user1 ALL=(ALL)  NOPASSWD: /sbin/ip</code></pre><p>也可以通过如下命令启用一个用户组：</p><pre><code class="shell">%users ALL=(ALL)  NOPASSWD: /sbin/ip</code></pre><ul><li>在OpenVPN配置中添加如下语句：</li></ul><pre><code class="shell">dev tunX/tapXiproute /usr/local/sbin/unpriv-ip</code></pre><p>注意：必须选择常量X（一般用数字标记，例如：tunX实际为tun0），并且不能同时指定tun或tap。</p><ul><li>使用root添加持久化接口，允许用户或用户组来管理它，下面的命令会创建<code>tunX</code>，并且允许user1和用户组访问它：</li></ul><pre><code class="shell">openvpn --mktun --dev tunX --type tun --user user1 --group users</code></pre><ul><li>在非特权用户的上下文环境中运行OpenVPN。</li></ul><p>可以通过核查脚本文件<code>/usr/local/sbin/unpriv-ip</code>的参数来添加进一步的安全约束。</p><p><strong>chroot（仅限于非Windows系统）</strong></p><p><code>chroot</code>指令允许将OpenVPN后台进程锁定到所谓的<code>chroot jail</code>（chroot监狱）中，除了该指令参数给出的指定目录外，<code>chroot jail</code>中的进程无法访问主机系统的文件系统的任何部分。例如：</p><pre><code class="shell">chroot jail</code></pre><p>将导致OpenVPN进程在初始化时转到jail子目录，然后将它的根文件系统调整为该目录，进程将无法访问jail和它的子目录树以外的任何文件。从安全角度来说，这很重要，因为即使攻击者能够使用代码插入攻击入侵服务器，攻击也会被锁定在服务器的大部分文件系统之外。</p><p>注意事项：由于chroot调整了文件系统（仅从后台进程的角度来看），因此有必要将OpenVPN初始化后可能用到的文件放入jail目录中，例如：</p><ul><li>文件<code>crl-verify</code></li><li>或者目录<code>client-config-dir</code></li></ul><p><strong>更大的RSA密钥</strong></p><p>我们可以通过文件<code>easy-rsa/vars</code>中的<code>KEY_SIZE</code>变量来控制RSA密钥的大小，该变量必须在所有密钥生成之前进行设置。如果默认设置为<code>1024</code>，可以合理地提高到<code>2048</code>，这对VPN隧道的性能没有什么负面影响，除了稍稍减缓每个客户端每小时一次的SSL/TLS重新协商握手速度，和大幅减慢使用脚本<code>easy-rsa/build-dh</code>生成迪菲赫尔曼参数的一次性过程之外。</p><p><strong>更大的对象密钥</strong></p><p>默认情况下，OpenVPN使用128位对称加密算法<code>Blowfish</code>。</p><p>OpenVPN自动支持OpenSSL库支持的任何加密算法，同样支持使用更大密钥长度的加密算法。例如，通过在服务器和客户端配置文件中均添加如下语句来使用256位版本的AES（Advanced Encryption Standard，高级加密标准）：</p><pre><code class="shell">cipher AES-256-CBC</code></pre><p><strong>将根密钥（<code>ca.key</code>）保留在一台没有网络连接的计算机上</strong></p><p>使用X509 PKI（OpenVPN也使用）的安全好处之一就是，根CA密钥（<code>ca.key</code>）不需要放在当前OpenVPN服务器所在计算机上。在一个高度安全的环境中，可以特别指定一台计算机用于密钥签名，让该计算机受到良好的保护，并断开所有的网络。必要时，可以使用软盘（这个可能已经绝迹了吧）来回移动该密钥文件。这些措施使得攻击者想要窃取根密钥变得非常困难（对于密钥签名计算机的物理盗窃除外）。</p><h2 id="1-20-撤销证书"><a href="#1-20-撤销证书" class="headerlink" title="1.20. 撤销证书"></a>1.20. 撤销证书</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#revoke" target="_blank" rel="noopener">英文原文</a></p><p><strong>撤销一个证书</strong>就是让一个已签名的证书作废，以便其无法再用于身份认证。</p><p>想要撤销一个证书的典型原因包括：</p><ul><li>与证书关联的私钥被泄露或被窃取。</li><li>加密私钥的用户忘记了密码。</li><li>你想要终止某个VPN用户的访问。</li></ul><p>例如撤销证书<code>client2</code>，该证书是前面的操作指南的“<a href="#14-创建证书">生成密钥</a>”部分生成的。</p><p>首先，打开shell或命令提示符窗口，转到之前“生成密钥”部分操作过的<code>easy-rsa</code>目录。在Linux/BSD/Unix系统中：</p><pre><code class="shell">. ./vars./revoke-full client2</code></pre><p>在Windows系统中：</p><pre><code class="shell">varsrevoke-full client2</code></pre><p>可以看到类似这样的输出：</p><pre><code class="shell">Using configuration from /root/openvpn/20/openvpn/tmp/easy-rsa/openssl.cnfDEBUG[load_index]: unique_subject = &quot;yes&quot;Revoking Certificate 04.Data Base UpdatedUsing configuration from /root/openvpn/20/openvpn/tmp/easy-rsa/openssl.cnfDEBUG[load_index]: unique_subject = &quot;yes&quot;client2.crt: /C=KG/ST=NA/O=OpenVPN-TEST/CN=client2/emailAddress=me@myhost.mydomainerror 23 at 0 depth lookup:certificate revoked</code></pre><p>注意最后一行的<code>error 23</code>表明已被撤销的证书的证书校验失败（即撤销成功）。</p><p><code>revoke-full</code>脚本将会在<code>keys</code>子目录中生成一个叫做<code>crl.pem</code>的CRL（证书撤销列表）文件。该文件应该被复制到一个OpenVPN服务器可以访问的目录，然后在服务器配置中启用CRL验证：</p><pre><code class="shell">crl-verify crl.pem</code></pre><p>现在，所有正在连接的客户端的证书会与CRL进行比对校验，任何正匹配都将导致该连接被丢失。</p><p><strong>CRL注意事项</strong></p><ul><li><p>当OpenVPN使用<code>crl-verify</code>选项命令后，任何新的客户端连接或者现有客户端重新建立SSL/TLS连接（默认每小时一次）都将使得CRL文件被重新读取。这意味着，即使OpenVPN服务器后台进程正在运行，你也可以更新你的CRL文件，新的CRL文件将会对新连接的客户端直接生效。如果一个刚刚撤销了证书的客户端早已经连接到服务器，你可以通过一个信号（SIGUSR1或者SIGHUP）来重启服务器，并刷新所有的客户端，或者你可以远程登录<a href="https://openvpn.net/management.html" target="_blank" rel="noopener">管理接口</a>，明确杀掉服务器上指定的客户端实例对象，而不干扰其他客户端。</p></li><li><p>虽然OpenVPN服务器和客户端都可以使用<code>crl-verify</code>指令，但通常不必将CRL文件分发到客户端，除非服务器证书已被撤销。客户端不需要知道其他哪些客户端的证书已被撤销，因为<a href="#121-关于中间人攻击的重要注意事项">客户端不应该直接接受来自其他客户端的连接</a>。</p></li><li><p>CRL文件无需保密，并且应该设为所有用户可读，以便于OpenVPN进程在没有root权限的情况下能够读取该文件。</p></li><li><p>如果使用<code>chroot</code>指令，请确保在<code>chroot</code>目录放置一份CRL文件的拷贝，因为不像OpenVPN读取的其他大多数文件，CRL将会在执行<code>chroot</code>调用之后被读取，而不是在此之前。</p></li><li><p>需要撤销证书的一个常见原因是，用户使用密码加密了自己的私钥，然后忘记了密码。通过撤销原来的证书，用户也可以使用原来的<code>Common Name</code>来生成新的证书/密钥对。</p></li></ul><h2 id="1-21-关于中间人攻击的重要注意事项"><a href="#1-21-关于中间人攻击的重要注意事项" class="headerlink" title="1.21. 关于中间人攻击的重要注意事项"></a>1.21. 关于中间人攻击的重要注意事项</h2><p><a href="https://openvpn.net/index.php/open-source/documentation/howto.html#secnotes" target="_blank" rel="noopener">英文原文</a></p><p>如果客户端不验证他们正在连接的服务器的证书，可能的“中间人”攻击。</p><p>为了避免授权客户端通过冒充的服务器尝试连接到另一个客户端的可能的中间人攻击，务必强制客户端进行某种类型的服务器证书验证。目前有五种不同的方式来完成这一点，按优先顺序排列：</p><ul><li><strong>OpenVPN 2.1 及以上版本</strong>使用指定的密钥用法和扩展密钥用法来创建服务器证书。RFC3280确定了应该为TLS连接提供下列属性：</li></ul><table><thead><tr><th>模式</th><th>密钥用法</th><th>扩展密钥用法</th></tr></thead><tbody><tr><td>客户端</td><td>数字签名</td><td>TLS Web客户端认证</td></tr><tr><td>客户端</td><td>密钥协议</td><td>TLS Web客户端认证</td></tr><tr><td>客户端</td><td>数字签名，密钥协议</td><td>TLS Web客户端认证</td></tr><tr><td>服务器</td><td>数字签名，密钥加密</td><td>TLS Web服务器认证</td></tr><tr><td>服务器</td><td>数字签名，密钥协议</td><td>TLS Web服务器认证</td></tr></tbody></table><p>可以使用<code>build-key-server</code>脚本来创建服务器证书（详情请查看<a href="https://openvpn.net/easyrsa.html" target="_blank" rel="noopener">easy-rsa</a>文档）。通过设置正确的属性，指定证书作为一个服务器端证书。在客户端配置中添加如下语句：</p><pre><code class="shell">remote-cert-tls server</code></pre><ul><li><strong>OpenVPN 2.0 及以下版本</strong>使用<code>build-key-server</code>脚本来创建服务器证书（详情请查看<a href="https://openvpn.net/easyrsa.html" target="_blank" rel="noopener">easy-rsa</a>文档）。通过设置<code>nsCertType=server</code>，指定该证书作为服务器端证书。在客户端配置中添加如下语句： </li></ul><pre><code class="shell">ns-cert-type server</code></pre><p>这将阻止客户端连接任何没有在证书中指定<code>nsCertType=server</code>的服务器，即使该证书已经通过OpenVPN配置文件中的<code>ca</code>文件进行了签名。</p><ul><li><p>在客户端使用<code>tls-remote</code>指令，根据服务器证书的<code>Common Name</code>来判断接受或拒绝该服务器连接。</p></li><li><p>使用<code>tls-verify</code>脚本或插件，根据服务器证书的嵌入式X509附属条目中的自定义测试来判断接受/拒绝该服务器连接。</p></li><li><p>使用一个CA给服务器证书签名，使用另一个不同的CA给客户端证书签名。客户端配置的ca指令应该引用为服务器签名的CA文件，而服务器配置的ca指令应该引用为客户端签名的CA文件。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> OpenVPN篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenVPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VSCode 图标在 Windows 10 系统开始菜单里的背景色为黑色问题的解决</title>
      <link href="/2020/05/02/VSCode-Win10-IconStyle/"/>
      <url>/2020/05/02/VSCode-Win10-IconStyle/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>安装好 CODE 后， 将快捷方式固定到开始菜单， 发现图标的背景色为黑色，和其他图标一比较，显得格格不入</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>由于 VSCODE 是 electron 开发的， 通过GitHub 查看源码，发现配置文件位于： <code>https://github.com/Microsoft/vscode/blob/master/resources/win32/VisualElementsManifest.xml</code></p><p>那么安装好之后的该配置文件位于安装路径的根目录下：<code>Code.VisualElementsManifest.xml</code></p><p>修改 BackgroundColor 为透明色 rgba(0, 0, 0, 0) 即可：</p><pre><code class="xml">    &lt;Application xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;            &lt;VisualElements                    BackgroundColor=&quot;rgba(0, 0, 0, 0)&quot;                    ShowNameOnSquare150x150Logo=&quot;on&quot;                    Square150x150Logo=&quot;resources\app\resources\win32\code_150x150.png&quot;                    Square70x70Logo=&quot;resources\app\resources\win32\code_70x70.png&quot;                    ForegroundText=&quot;light&quot; /&gt;    &lt;/Application&gt;</code></pre><p>重新创建快捷方式， 再固定到开始菜单上即可看到效果。</p>]]></content>
      
      
      <categories>
          
          <category> VSCode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VSCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 安装 Clash 并对外提供代理服务</title>
      <link href="/2020/05/02/Clash-Docker/"/>
      <url>/2020/05/02/Clash-Docker/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol><li>端口: <code>port: 7890 ; socks-port: 7891</code></li><li>运行局域网访问: <code>allow-lan: true</code></li><li>对外提供 rest 接口: <code>external-controller: 0.0.0.0:8080</code></li><li>dashboard 路径: <code>external-ui: /ui</code></li><li>配置文件 yaml, 挂载到: <code>/root/.config/clash/config.yaml</code></li></ol><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><pre><code class="bash">    docker run -d --name clash-client --restart always -p 7890:7890 -p 7891:7891 -p 8080:8080 -v /path/config.yaml:/root/.config/clash/config.yaml -v /path/ui:/ui dreamacro/clash</code></pre><h3 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h3><ol><li>使用官方的 Dashboard : <a href="https://github.com/Dreamacro/clash-dashboard/tree/gh-pages" target="_blank" rel="noopener">https://github.com/Dreamacro/clash-dashboard/tree/gh-pages</a></li><li>使用另一个第三方看起来很炫酷的 Dashboard: <a href="https://github.com/haishanh/yacd/tree/gh-pages" target="_blank" rel="noopener">https://github.com/haishanh/yacd/tree/gh-pages</a></li></ol><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>既然对外提供服务, 最好加密, 包括 Dashboard 加密和 http, socks 代理加用户名密码认证</p><pre><code class="yaml">    port: 7890    socks-port: 7891    allow-lan: true    mode: Rule    log-level: info    external-controller: &#39;0.0.0.0:9090&#39;    secret: &#39;passwd&#39;    external-ui: /ui    authentication:      - &quot;user:passwd&quot;    Proxy:    Proxy Group:    Rule:</code></pre><p>启动之后,便可以使用 Dashboard 来操作 Clash 了.</p>]]></content>
      
      
      <categories>
          
          <category> Clash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Clash </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Clash 基本配置记录</title>
      <link href="/2020/05/01/Clash-Config/"/>
      <url>/2020/05/01/Clash-Config/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="规则解释"><a href="#规则解释" class="headerlink" title="规则解释"></a>规则解释</h3><ul><li>DOMAIN-SUFFIX：域名后缀匹配</li><li>DOMAIN：域名匹配</li><li>DOMAIN-KEYWORD：域名关键字匹配</li><li>IP-CIDR：IP段匹配</li><li>SRC-IP-CIDR：源IP段匹配</li><li>GEOIP：GEOIP数据库（国家代码）匹配</li><li>DST-PORT：目标端口匹配</li><li>SRC-PORT：源端口匹配</li><li>MATCH：全匹配（一般放在最后）</li></ul><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><pre><code class="yaml">   port: 7890   socks-port: 7891   allow-lan: false   mode: Rule   log-level: info   external-controller: 127.0.0.1:9090   Proxy:   Proxy Group:   Rule:   - DOMAIN-SUFFIX,google.com,DIRECT   - DOMAIN-KEYWORD,google,DIRECT   - DOMAIN,google.com,DIRECT   - DOMAIN-SUFFIX,ad.com,REJECT   - GEOIP,CN,DIRECT   - MATCH,DIRECT</code></pre><p>额外支持特定的字段：</p><ul><li>cfw-latency-timeout：延迟测试超时时间（毫秒），默认3000</li><li>cfw-latency-url：延迟测试URL，默认<a href="http://www.gstatic.com/generate_204" target="_blank" rel="noopener">http://www.gstatic.com/generate_204</a></li><li>cfw-bypass：系统代理绕过域名或地址，参考 绕过系统代理</li><li>cfw-conn-break-strategy: 切换节点后或切换配置文件后打断连接</li><li>cfw-profiles-path: 自定义 profiles 目录路径 (beta)</li></ul><blockquote><p>这些配置关乎Clash核心是否能正常启动，如非必要，请勿更改</p></blockquote><h3 id="完全配置记录"><a href="#完全配置记录" class="headerlink" title="完全配置记录"></a>完全配置记录</h3><pre><code class="yaml">    #---------------------------------------------------#    ## 配置文件需要放置在 $HOME/.config/clash/config.yml    ##     ## 如果您不知道如何操作，请参阅 SS-Rule-Snippet 的 Wiki：    ## https://github.com/Hackl0us/SS-Rule-Snippet/wiki/clash(X)    #---------------------------------------------------#    # HTTP 代理端口    port: 7890    # SOCKS5 代理端口    socks-port: 7891    # Linux 和 macOS 的 redir 代理端口 (如需使用此功能，请取消注释)    # redir-port: 7892    # 允许局域网的连接（可用来共享代理）    allow-lan: false    # bind-address: &quot;*&quot;    # 此功能仅在 allow-lan 设置为 true 时生效，支持三种参数：    # &quot;*&quot;                           绑定所有的 IP 地址    # 192.168.122.11                绑定一个的 IPv4 地址    # &quot;[aaaa::a8aa:ff:fe09:57d8]&quot;   绑定一个 IPv6 地址    # 规则模式：Rule（规则） / Global（全局代理）/ Direct（全局直连）    mode: Rule    # 设置日志输出级别 (默认级别：silent，即不输出任何内容，以避免因日志内容过大而导致程序内存溢出）。    # 5 个级别：silent / info / warning / error / debug。级别越高日志输出量越大，越倾向于调试，若需要请自行开启。    log-level: silent    # clash 的 RESTful API    external-controller: 127.0.0.1:9090    # 您可以将静态网页资源（如 clash-dashboard）放置在一个目录中，clash 将会服务于 `${API}/ui`    # 参数应填写配置目录的相对路径或绝对路径。    # external-ui: folder    # RESTful API 的口令 (可选)    # secret: &quot;&quot;    # 实验性功能    experimental:      ignore-resolve-fail: true # 忽略 DNS 解析失败，默认值为 true    # 本地 SOCKS5 / HTTP(S) 服务认证    # authentication:    #  - &quot;user1:pass1&quot;    #  - &quot;user2:pass2&quot;    # # 实验性功能 hosts, 支持通配符 (例如 *.clash.dev 甚至 *.foo.*.example.com)    # # 静态的域名 比 通配域名 具有更高的优先级 (foo.example.com 优先于 *.example.com)    # # 注意: hosts 在 fake-ip 模式下不生效    # hosts:    #   &#39;*.clash.dev&#39;: 127.0.0.1    #   &#39;alpha.clash.dev&#39;: &#39;::1&#39;    dns:      enable: true      ipv6: false      # listen: 0.0.0.0:53      # enhanced-mode: redir-host # 或 fake-ip      # # fake-ip-range: 198.18.0.1/16 # 如果你不知道这个参数的作用，请勿修改      # fake-ip-filter: # fake-ip 白名单列表      #   - &#39;*.lan&#39;      #   - localhost.ptlogin2.qq.com      nameserver:        - 1.2.4.8        - 114.114.114.114        - 223.5.5.5        - tls://13800000000.rubyfish.cn:853        #- https://13800000000.rubyfish.cn/      fallback: # 与 nameserver 内的服务器列表同时发起请求，当规则符合 GEOIP 在 CN 以外时，fallback 列表内的域名服务器生效。        - tls://13800000000.rubyfish.cn:853        - tls://1.0.0.1:853        - tls://dns.google:853        #- https://13800000000.rubyfish.cn/        #- https://cloudflare-dns.com/dns-query        #- https://dns.google/dns-query      fallback-filter:        geoip: true # 默认        ipcidr: # 在这个网段内的 IP 地址会被考虑为被污染的 IP          - 240.0.0.0/4    # 1. clash DNS 请求逻辑：    #   (1) 当访问一个域名时， nameserver 与 fallback 列表内的所有服务器并发请求，得到域名对应的 IP 地址。    #   (2) clash 将选取 nameserver 列表内，解析最快的结果。    #   (3) 若解析结果中，IP 地址属于 国外，那么 clash 将选择 fallback 列表内，解析最快的结果。    #    #   因此，我在 nameserver 和 fallback 内都放置了无污染、解析速度较快的国内 DNS 服务器，以达到最快的解析速度。    #   但是 fallback 列表内服务器会用在解析境外网站，为了结果绝对无污染，我仅保留了支持 DoT/DoH 的两个服务器。    #     # 2. clash DNS 配置注意事项：    #   (1) 如果您为了确保 DNS 解析结果无污染，请仅保留列表内以 tls:// 或 https:// 开头的 DNS 服务器，但是通常对于国内域名没有必要。    #   (2) 如果您不在乎可能解析到污染的结果，更加追求速度。请将 nameserver 列表的服务器插入至 fallback 列表内，并移除重复项。    #     # 3. 关于 DNS over HTTPS (DoH) 和 DNS over TLS (DoT) 的选择：    #   对于两项技术双方各执一词，而且会无休止的争论，各有利弊。各位请根据具体需求自行选择，但是配置文件内默认启用 DoT，因为目前国内没有封锁或管制。    #   DoH: 以 https:// 开头的 DNS 服务器。拥有更好的伪装性，且几乎不可能被运营商或网络管理封锁，但查询效率和安全性可能略低。    #   DoT: 以 tls:// 开头的 DNS 服务器。拥有更高的安全性和查询效率，但端口有可能被管制或封锁。    #   若要了解更多关于 DoH/DoT 相关技术，请自行查阅规范文档。    Proxy:    # shadowsocks    # 所支持的加密方式与 go-shadowsocks2 保持一致    # 支持加密方式：     #   aes-128-gcm aes-192-gcm aes-256-gcm    #   aes-128-cfb aes-192-cfb aes-256-cfb    #   aes-128-ctr aes-192-ctr aes-256-ctr    #   rc4-md5 chacha20 chacha20-ietf xchacha20    #   chacha20-ietf-poly1305 xchacha20-ietf-poly1305      - name: &quot;ss1&quot;        type: ss        server: server        port: 443        cipher: chacha20-ietf-poly1305        password: &quot;password&quot;        # udp: true        - name: &quot;ss2&quot;        type: ss        server: server        port: 443        cipher: AEAD_CHACHA20_POLY1305        password: &quot;password&quot;        plugin: obfs        plugin-opts:          mode: tls # 混淆模式，可以选择 http 或 tls          host: bing.com # 混淆域名，需要和服务器配置保持一致      - name: &quot;ss3&quot;        type: ss        server: server        port: 443        cipher: AEAD_CHACHA20_POLY1305        password: &quot;password&quot;        plugin: v2ray-plugin        plugin-opts:          mode: websocket # 暂时不支持 QUIC 协议          # tls: true # wss          # skip-cert-verify: true          # host: bing.com          # path: &quot;/&quot;          # headers:          #   custom: value    # vmess    # 支持加密方式：auto / aes-128-gcm / chacha20-poly1305 / none      - name: &quot;vmess&quot;        type: vmess        server: server        port: 443        uuid: uuid        alterId: 32        cipher: auto        # udp: true        # tls: true        # skip-cert-verify: true        # network: ws        # ws-path: /path        # ws-headers:        #   Host: v2ray.com      # socks5      - name: &quot;socks&quot;        type: socks5        server: server        port: 443        # username: username        # password: password        # tls: true        # skip-cert-verify: true        # udp: true      # http      - name: &quot;http&quot;        type: http        server: server        port: 443        # username: username        # password: password        # tls: true # https        # skip-cert-verify: true      # snell      - name: &quot;snell&quot;        type: snell        server: server        port: 44046        psk: yourpsk        # obfs-opts:          # mode: http # 或 tls          # host: bing.com    Proxy Group:    # url-test 可以自动选择与指定 URL 测速后，延迟最短的服务器      - name: &quot;auto&quot;        type: url-test        proxies:          - ss1          - ss2          - vmess1        url: &#39;http://www.gstatic.com/generate_204&#39;        interval: 300    # fallback 可以尽量按照用户书写的服务器顺序，在确保服务器可用的情况下，自动选择服务器      - name: &quot;fallback-auto&quot;        type: fallback        proxies:          - ss1          - ss2          - vmess1        url: &#39;http://www.gstatic.com/generate_204&#39;        interval: 300    # load-balance 可以使相同 eTLD 请求在同一条代理线路上      - name: &quot;load-balance&quot;        type: load-balance        proxies:          - ss1          - ss2          - vmess1        url: &#39;http://www.gstatic.com/generate_204&#39;        interval: 300    # select 用来允许用户手动选择 代理服务器 或 服务器组    # 您也可以使用 RESTful API 去切换服务器，这种方式推荐在 GUI 中使用      - name: Proxy        type: select        proxies:          - ss1          - ss2          - vmess1          - auto    Rule:    # 抗 DNS 污染       - DOMAIN-KEYWORD,amazon,Proxy      - DOMAIN-KEYWORD,google,Proxy      - DOMAIN-KEYWORD,gmail,Proxy      - DOMAIN-KEYWORD,youtube,Proxy      - DOMAIN-KEYWORD,facebook,Proxy      - DOMAIN-SUFFIX,fb.me,Proxy      - DOMAIN-SUFFIX,fbcdn.net,Proxy      - DOMAIN-KEYWORD,twitter,Proxy      - DOMAIN-KEYWORD,instagram,Proxy      - DOMAIN-KEYWORD,dropbox,Proxy      - DOMAIN-SUFFIX,twimg.com,Proxy      - DOMAIN-KEYWORD,blogspot,Proxy      - DOMAIN-SUFFIX,youtu.be,Proxy      - DOMAIN-KEYWORD,whatsapp,Proxy    # 常见广告域名屏蔽      - DOMAIN-KEYWORD,admarvel,REJECT      - DOMAIN-KEYWORD,admaster,REJECT      - DOMAIN-KEYWORD,adsage,REJECT      - DOMAIN-KEYWORD,adsmogo,REJECT      - DOMAIN-KEYWORD,adsrvmedia,REJECT      - DOMAIN-KEYWORD,adwords,REJECT      - DOMAIN-KEYWORD,adservice,REJECT      - DOMAIN-KEYWORD,domob,REJECT      - DOMAIN-KEYWORD,duomeng,REJECT      - DOMAIN-KEYWORD,dwtrack,REJECT      - DOMAIN-KEYWORD,guanggao,REJECT      - DOMAIN-KEYWORD,lianmeng,REJECT      - DOMAIN-SUFFIX,mmstat.com,REJECT      - DOMAIN-KEYWORD,omgmta,REJECT      - DOMAIN-KEYWORD,openx,REJECT      - DOMAIN-KEYWORD,partnerad,REJECT      - DOMAIN-KEYWORD,pingfore,REJECT      - DOMAIN-KEYWORD,supersonicads,REJECT      - DOMAIN-KEYWORD,uedas,REJECT      - DOMAIN-KEYWORD,umeng,REJECT      - DOMAIN-KEYWORD,usage,REJECT      - DOMAIN-KEYWORD,wlmonitor,REJECT      - DOMAIN-KEYWORD,zjtoolbar,REJECT    # LAN      - DOMAIN-SUFFIX,local,DIRECT      - IP-CIDR,127.0.0.0/8,DIRECT      - IP-CIDR,172.16.0.0/12,DIRECT      - IP-CIDR,192.168.0.0/16,DIRECT      - IP-CIDR,10.0.0.0/8,DIRECT      - IP-CIDR,17.0.0.0/8,DIRECT      - IP-CIDR,100.64.0.0/10,DIRECT    # 最终规则      - GEOIP,CN,DIRECT      - MATCH,Proxy</code></pre><h3 id="绕过系统代理"><a href="#绕过系统代理" class="headerlink" title="绕过系统代理"></a>绕过系统代理</h3><p>Clash for Windows在v 0.4.5 版本后可以自定义系统代理需要绕过的域名或IP</p><p>部分应用检测到系统代理会拒绝响应（例如网易云音乐uwp），此功能用于解决此类问题</p><p>设置方式<br>config.yaml</p><pre><code class="yaml">    port: 8888    socks-port: 8889    redir-port: 0    allow-lan: true    mode: Rule    log-level: info    external-controller: &#39;0.0.0.0:6170&#39;    secret: &#39;&#39;    Proxy:      ...    Proxy Group:      ...    Rule:      ...    cfw-bypass:      ... # 原有字段不用删除      - &#39;music.163.com&#39; # 网易云域名1      - &#39;*.music.126.net&#39; # 网易云域名2</code></pre><p>cfw-bypass类型为数组，item为需要绕过的域名或节点，支持通配符*</p><blockquote><p>最后一行对应系统中“请勿将代理服务器用于本地(Intranet)地址”选项，请确保此项在最底部</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Clash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Clash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 使用 rest-high-level-client 连接 Elasticsearch</title>
      <link href="/2020/04/29/SpringBoot-Elasticsearch-RestHighLevelClient/"/>
      <url>/2020/04/29/SpringBoot-Elasticsearch-RestHighLevelClient/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="版本环境"><a href="#版本环境" class="headerlink" title="版本环境"></a>版本环境</h3><ol><li>Elasticsearch 6.4.3</li><li>SpringBoot 2.1.2.RELEASE</li></ol><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code class="groovy">    compile group: &#39;org.elasticsearch.client&#39;, name: &#39;elasticsearch-rest-high-level-client&#39;, version: &#39;6.4.3&#39;</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>其实引入这依赖后, <code>spring-boot-autoconfigure-2.1.2.RELEASE.jar</code> 这个依赖你会为你自动配置 <code>RestHighLevelClient</code>, 而不需要手动创建 <code>RestHighLevelClient</code></p><p>代码具体位置:</p><p>org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration</p><pre><code class="java">    /*     * Copyright 2012-2018 the original author or authors.     *     * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);     * you may not use this file except in compliance with the License.     * You may obtain a copy of the License at     *     *      http://www.apache.org/licenses/LICENSE-2.0     *     * Unless required by applicable law or agreed to in writing, software     * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.     * See the License for the specific language governing permissions and     * limitations under the License.     */    package org.springframework.boot.autoconfigure.elasticsearch.rest;    import org.apache.http.HttpHost;    import org.apache.http.auth.AuthScope;    import org.apache.http.auth.Credentials;    import org.apache.http.auth.UsernamePasswordCredentials;    import org.apache.http.client.CredentialsProvider;    import org.apache.http.impl.client.BasicCredentialsProvider;    import org.elasticsearch.client.RestClient;    import org.elasticsearch.client.RestClientBuilder;    import org.elasticsearch.client.RestHighLevelClient;    import org.springframework.beans.factory.ObjectProvider;    import org.springframework.boot.autoconfigure.EnableAutoConfiguration;    import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;    import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;    import org.springframework.boot.context.properties.EnableConfigurationProperties;    import org.springframework.boot.context.properties.PropertyMapper;    import org.springframework.context.annotation.Bean;    import org.springframework.context.annotation.Configuration;    /**     * {@link EnableAutoConfiguration Auto-configuration} for Elasticsearch REST clients.     *     * @author Brian Clozel     * @since 2.1.0     */    @Configuration    @ConditionalOnClass(RestClient.class)    @EnableConfigurationProperties(RestClientProperties.class)    public class RestClientAutoConfiguration {        private final RestClientProperties properties;        private final ObjectProvider&lt;RestClientBuilderCustomizer&gt; builderCustomizers;        public RestClientAutoConfiguration(RestClientProperties properties,                ObjectProvider&lt;RestClientBuilderCustomizer&gt; builderCustomizers) {            this.properties = properties;            this.builderCustomizers = builderCustomizers;        }        @Bean        @ConditionalOnMissingBean        public RestClient restClient(RestClientBuilder builder) {            return builder.build();        }        @Bean        @ConditionalOnMissingBean        public RestClientBuilder restClientBuilder() {            HttpHost[] hosts = this.properties.getUris().stream().map(HttpHost::create)                    .toArray(HttpHost[]::new);            RestClientBuilder builder = RestClient.builder(hosts);            PropertyMapper map = PropertyMapper.get();            map.from(this.properties::getUsername).whenHasText().to((username) -&gt; {                CredentialsProvider credentialsProvider = new BasicCredentialsProvider();                Credentials credentials = new UsernamePasswordCredentials(                        this.properties.getUsername(), this.properties.getPassword());                credentialsProvider.setCredentials(AuthScope.ANY, credentials);                builder.setHttpClientConfigCallback((httpClientBuilder) -&gt; httpClientBuilder                        .setDefaultCredentialsProvider(credentialsProvider));            });            this.builderCustomizers.orderedStream()                    .forEach((customizer) -&gt; customizer.customize(builder));            return builder;        }        @Configuration        @ConditionalOnClass(RestHighLevelClient.class)        public static class RestHighLevelClientConfiguration {            @Bean            @ConditionalOnMissingBean            public RestHighLevelClient restHighLevelClient(                    RestClientBuilder restClientBuilder) {                return new RestHighLevelClient(restClientBuilder);            }        }    }</code></pre><p>不过需要先配置 spring.elasticsearch.rest 配置</p><pre><code class="yaml">    spring:      elasticsearch:        rest:          uris:           username:           password: </code></pre><p>默认只配置了 hosts 和 username password, 如果要加更多配置的话, 建议重新添加 <code>RestClientBuilder</code> 的配置</p><p>当然也可以全部手动配置, 我这里给一个参考:</p><pre><code class="java">    package cn.joylau.code.config.elasticsearch.highLevelClient;    import org.apache.http.HttpHost;    import org.elasticsearch.client.RestClient;    import org.elasticsearch.client.RestClientBuilder;    import org.elasticsearch.client.RestHighLevelClient;    import org.springframework.beans.factory.annotation.Value;    import org.springframework.context.annotation.Bean;    import org.springframework.context.annotation.Configuration;    import java.util.ArrayList;    import java.util.List;    /**     * Created by joylau on 2020/4/27.     * cn.joylau.code.config.elasticsearch.highLevelClient     * 2587038142.liu@gmail.com     */    @Configuration    public class ElasticSearchClient {        /** 协议 */        @Value(&quot;${elasticsearch.schema:http}&quot;)        private String schema;        /** 集群地址，如果有多个用“,”隔开 */        @Value(&quot;${elasticsearch.address}&quot;)        private String address;        /** 连接超时时间 */        @Value(&quot;${elasticsearch.connectTimeout:5000}&quot;)        private int connectTimeout;        /** Socket 连接超时时间 */        @Value(&quot;${elasticsearch.socketTimeout:10000}&quot;)        private int socketTimeout;        /** 获取连接的超时时间 */        @Value(&quot;${elasticsearch.connectionRequestTimeout:5000}&quot;)        private int connectionRequestTimeout;        /** 最大连接数 */        @Value(&quot;${elasticsearch.maxConnectNum:100}&quot;)        private int maxConnectNum;        /** 最大路由连接数 */        @Value(&quot;${elasticsearch.maxConnectPerRoute:100}&quot;)        private int maxConnectPerRoute;        @Bean        public RestHighLevelClient restHighLevelClient() {            // 拆分地址            List&lt;HttpHost&gt; hostLists = new ArrayList&lt;&gt;();            String[] hostList = address.split(&quot;,&quot;);            for (String addr : hostList) {                String host = addr.split(&quot;:&quot;)[0];                String port = addr.split(&quot;:&quot;)[1];                hostLists.add(new HttpHost(host, Integer.parseInt(port), schema));            }            // 转换成 HttpHost 数组            HttpHost[] httpHost = hostLists.toArray(new HttpHost[]{});            // 构建连接对象            RestClientBuilder builder = RestClient.builder(httpHost);            // 异步连接延时配置            builder.setRequestConfigCallback(requestConfigBuilder -&gt; {                requestConfigBuilder.setConnectTimeout(connectTimeout);                requestConfigBuilder.setSocketTimeout(socketTimeout);                requestConfigBuilder.setConnectionRequestTimeout(connectionRequestTimeout);                return requestConfigBuilder;            });            // 异步连接数配置            builder.setHttpClientConfigCallback(httpClientBuilder -&gt; {                httpClientBuilder.setMaxConnTotal(maxConnectNum);                httpClientBuilder.setMaxConnPerRoute(maxConnectPerRoute);                return httpClientBuilder;            });            return new RestHighLevelClient(builder);        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ClashX 在英文 Mac 系统中切换界面语言</title>
      <link href="/2020/04/28/Clash-Mac-Language/"/>
      <url>/2020/04/28/Clash-Mac-Language/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在网络上搜索关于 ClashX 的教程, 看到的截图都是中文的界面, 而我安装后的界面语言却是英文的, 就想着怎么能够切换下<br>在软件的设置里, 没有找到设置语言的选项</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>去作者的 Github 去看了下代码, 发现是有中英文的配置的<br>那么既然作者做了语言环境适配, 那么在安装包里肯定有语言文件</p><ol><li>在 <code>Applications</code> 右键 <code>ClashX</code> ,显示包内容</li><li>进入 <code>Resources</code> 目录, 看到 <code>en.lproj</code> 和 <code>zh-Hans.lproj</code></li><li>将 <code>zh-Hans.lproj</code> 目录里的文件拷贝并覆盖掉 <code>en.lproj</code> 里的文件</li><li>重启软件即可</li></ol>]]></content>
      
      
      <categories>
          
          <category> Clash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ClashX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PowerDesigner 数据库逆向生成物理模型并显示 Comment 注释</title>
      <link href="/2020/04/27/Tools-PowerDesigner/"/>
      <url>/2020/04/27/Tools-PowerDesigner/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h3><ol><li>PowerDesigner 16.5</li></ol><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>使用 PowerDesigner 的原生方式连接各种数据库我遇到很多问题, 于是,这里我都是使用的 JDBC 的方式连接</p><p>使用 JDBC 方式连接需要注意一下几点</p><ol><li>JDK 的版本必须是 32 位的</li><li>需要 JDBC 的驱动 jar 包</li><li>需要新建 <strong>CLASSPATH</strong> 环境变量, 并且将驱动 jar 包的路径配置到 <code>CLASSPATH</code> 中, 否则的话会导致无法加载驱动类</li></ol><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>File -&gt; New Module, 选择 <code>Physical Diagram</code>, DBMS 选择实际的数据库类型</li><li>选择 Database -&gt; Configure Connections… -&gt; Connection Profiles , 选择 第二个图标, <code>add data source</code></li><li>Connections Type 现在 JDBC, 然后根据实际情况填写, 注意最后一项的 <code>JDBC driver jar files</code> 的文件需要配置的 CLASSPATH 环境变量中去, 如果已经配置了, 则此项都可以不用选择,亲测</li><li>点击测试,没有问题,保存即可</li><li>选择 Database -&gt; Update Model from Database , 选择需要的表</li><li>此时双击表,可能没有注释, 需要双击表，弹出表属性对话框，切到 ColumnTab ，默认是没显示 Comment 的，此时点击漏斗状的按钮 <code>Customize Columns and Filter</code>, 勾选 <code>Comment</code></li></ol><h3 id="设置物理模型显示注释"><a href="#设置物理模型显示注释" class="headerlink" title="设置物理模型显示注释"></a>设置物理模型显示注释</h3><ol><li>Tools&gt;Display Perferences..</li><li>进入 Table, 先勾选 Comment</li><li>再点击 Advanced -&gt; Columns , 点击 List columns 右边的按钮 <code>select</code> , 选择上 code, 并将位置调的最上方, 点击确定</li><li>Tools&gt;Execute Commands&gt;Edit/Run Script.., 执行下面的脚本, 脚本的作用是将 NAME 替换成 COMMENT</li></ol><pre><code class="bash">    Option   Explicit           ValidationMode   =   True           InteractiveMode   =   im_Batch        Dim blankStr        blankStr   =   Space(1)        Dim   mdl   &#39;   the   current   model          &#39;   get   the   current   active   model           Set   mdl   =   ActiveModel           If   (mdl   Is   Nothing)   Then                 MsgBox   &quot;There   is   no   current   Model &quot;           ElseIf   Not   mdl.IsKindOf(PdPDM.cls_Model)   Then                 MsgBox   &quot;The   current   model   is   not   an   Physical   Data   model. &quot;           Else                 ProcessFolder   mdl           End   If          Private   sub   ProcessFolder(folder)           On Error Resume Next                Dim   Tab   &#39;running     table                 for   each   Tab   in   folder.tables                       if   not   tab.isShortcut   then                             tab.name   =   tab.comment                            Dim   col   &#39;   running   column                             for   each   col   in   tab.columns                             if col.comment = &quot;&quot; or replace(col.comment,&quot; &quot;, &quot;&quot;)=&quot;&quot; Then                                col.name = blankStr                                blankStr = blankStr &amp; Space(1)                          else                                  col.name = col.comment                             end if                            next                       end   if                 next                Dim   view   &#39;running   view                 for   each   view   in   folder.Views                       if   not   view.isShortcut   then                             view.name   =   view.comment                       end   if                 next                &#39;   go   into   the   sub-packages                 Dim   f   &#39;   running   folder                 For   Each   f   In   folder.Packages                       if   not   f.IsShortcut   then                             ProcessFolder   f                       end   if                 Next           end   sub  </code></pre>]]></content>
      
      
      <categories>
          
          <category> Tools篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PowerDesigner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- 自制像素时钟, 不输 LaMeetric Time</title>
      <link href="/2020/04/23/Daily-Pixel-Clock/"/>
      <url>/2020/04/23/Daily-Pixel-Clock/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>之前看到一个像素时钟 LaMeetric Time, 感觉很漂亮, 但是太贵,淘宝上要卖到 2000 块左右<br>后来又看到一个项目 AWTRIX : <a href="https://awtrixdocs.blueforcer.de/#/en-en/" target="_blank" rel="noopener">https://awtrixdocs.blueforcer.de/#/en-en/</a><br>作者在他的网站上介绍了如何制作一个像素时钟<br>于是,我就跟着他的文档后面做了起来</p><h3 id="这玩意是什么"><a href="#这玩意是什么" class="headerlink" title="这玩意是什么??"></a>这玩意是什么??</h3><ol><li>首先它是一个时钟</li><li>其次,他能够通过 WIFI 连接到一个服务端, 服务端有 AppStore 能装很多 app 实现很多效果</li><li>我想用它来实时显示我博客的访客数, 当然,这需要我后期自己编码</li><li>好玩</li></ol><h3 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h3><h4 id="必须材料"><a href="#必须材料" class="headerlink" title="必须材料"></a>必须材料</h4><ol><li>WS2812B 可编程像素软屏</li><li>Wemos D1 mini ESP 8266 mini WIFI 开发板</li><li>杜邦连接线,公对母</li></ol><p>如何你想要制作成我的这种效果, 你还需要</p><ol><li>10V 1000uF 电容</li><li>电烙铁家用一套</li><li>5v 4A 2.5mm 电源</li><li>2.5mm 直流电源插头</li><li>手动修改官方 3D 打印图纸, 这是我修改好的图纸,其中前面板的高度调高了 3 mm : <a href="http://image.joylau.cn//blog/awtrix2/3d打印图纸.zip" target="_blank" rel="noopener">http://image.joylau.cn//blog/awtrix2/3d打印图纸.zip</a></li><li>手摇自喷漆一罐</li><li>定制黑色半透明亚克力板一块,尺寸 335mm * 95mm * 3mm</li><li>通用超 520 粘胶一小瓶</li></ol><h3 id="服务端部署"><a href="#服务端部署" class="headerlink" title="服务端部署"></a>服务端部署</h3><p>这里最方便的莫过于 docker 部署</p><pre><code class="bash">    docker run -d --name awtrix2 -p 7000:7000 -p 7001:7001 --restart always -e TZ=Asia/Shanghai -v /path:/data whyet/awtrix2:latest</code></pre><p>注意: 这里需要挂载容器里的目录 data, 否则重启后,安装的软件会丢失不见</p><h3 id="客户端烧录"><a href="#客户端烧录" class="headerlink" title="客户端烧录"></a>客户端烧录</h3><p>最简单的方式是使用 Windows 机器</p><ol><li>下载烧录工具: <a href="https://blueforcer.de/downloads/ESP8266Flasher.exe" target="_blank" rel="noopener">https://blueforcer.de/downloads/ESP8266Flasher.exe</a></li><li>下载最新固件: <a href="https://blueforcer.de/awtrix/stable/firmware.bin" target="_blank" rel="noopener">https://blueforcer.de/awtrix/stable/firmware.bin</a></li><li>启动 ESP8266Flasher.exe 并在 “ Config” 选项卡中打开固件（单击齿轮选择固件）</li><li>返回到 “操作” 选项卡，如果未自动检测到正确的串口，则需要手动设置它</li><li>单击“ Flash”，然后等待该过程完成，在左下角会显示一个绿色的复选标记。</li><li>重新启动控制器</li></ol><h3 id="连接-WiFi"><a href="#连接-WiFi" class="headerlink" title="连接 WiFi"></a>连接 WiFi</h3><ol><li>启动控制器</li><li>手机连接 SSID 为 “ AWTRIX Controller ” 的 WiFi, 密码是: <strong>awtrixxx</strong></li><li>如果网页没有自动跳出，则可以使用任何浏览器将设置页面导航到 IP “ 172.217.28.1 ”</li><li>点击“配置WiFi”，进入实际设置页面,配置家里的 WLAN 的 SSID 和密码</li><li>主机 IP 则设置为之前 docker 部署的服务端的 IP, 注意不需要加端口号</li><li>如果你的像素屏不是 32* 8 ,则需要配置 MatrixType2, 这个不需要配置</li></ol><h3 id="如何重置控制器"><a href="#如何重置控制器" class="headerlink" title="如何重置控制器???"></a>如何重置控制器???</h3><ol><li>按住控制器的 reset 键 3-4 秒</li><li>等待重启</li><li>再按住 reset 键 3-4 秒</li><li>等待重启</li><li>此时如何屏上显示 <strong>RESET</strong> ,则重置成功</li></ol><h3 id="接线图"><a href="#接线图" class="headerlink" title="接线图"></a>接线图</h3><p><img src="//image.joylau.cn/blog/awtrix2/AWTRIX_Core_Steckplatine.jpg" alt="1"></p><h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_1.jpg" alt="2">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_2.jpg" alt="3">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_3.jpg" alt="4">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_4.jpg" alt="5">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_5.jpg" alt="6">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_6.jpg" alt="7">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_7.jpg" alt="8">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_8.jpg" alt="9">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_9.jpg" alt="10">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_10.jpg" alt="11">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_11.jpg" alt="12">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_12.jpg" alt="13">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_13.jpg" alt="14">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_14.jpg" alt="15">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_15.jpg" alt="16">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_16.jpg" alt="17">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_17.jpg" alt="18">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_18.jpg" alt="19">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_19.jpg" alt="20">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_20.jpg" alt="21">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_21.jpg" alt="22">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_22.jpg" alt="23">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_23.jpg" alt="24">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_24.jpg" alt="25">  </p><p><img src="//image.joylau.cn/blog/awtrix2/server-page-1.png" alt="26">  </p><p><img src="//image.joylau.cn/blog/awtrix2/server-page-2.png" alt="27">  </p><center><video src="//image.joylau.cn/blog/awtrix2/awtrix2_video1.mp4" muted loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center>  <center><video src="//image.joylau.cn/blog/awtrix2/awtrix2_video2.mp4" muted loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center>  <h3 id="Siri-语音控制"><a href="#Siri-语音控制" class="headerlink" title="Siri 语音控制"></a>Siri 语音控制</h3><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_siri-1.PNG" alt="28">  </p><p><img src="//image.joylau.cn/blog/awtrix2/awtrix2_siri-2.PNG" alt="29"></p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker ENTRYPOINT 和 CMD 组合使用</title>
      <link href="/2020/04/22/Docker-ENTRYPOINT-CMD/"/>
      <url>/2020/04/22/Docker-ENTRYPOINT-CMD/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><ol><li>清楚 ENTRYPOINT 和 CMD 的 shell 和 exec 的 2 种写法</li><li>定义多个 CMD, 只有最后一个 CMD 生效</li><li>同时定义 ENTRYPOINT 和 CMD, 那么 ENTRYPOINT 会覆盖 CMD</li></ol><h3 id="总结的结论"><a href="#总结的结论" class="headerlink" title="总结的结论"></a>总结的结论</h3><ol><li>ENTRYPOINT 使用了 shell 模式，CMD 指令会被忽略</li><li>ENTRYPOINT 使用了 exec 模式，CMD 指定的内容被追加为 ENTRYPOINT 指定命令的参数</li><li>ENTRYPOINT 使用了 exec 模式，CMD 也应该使用 exec 模式</li><li>Dockerfile 里至少定义一个 ENTRYPOINT 或者 CMD</li></ol><p>下面是官方文档里 2 种组合情况</p><table><thead><tr><th></th><th>No ENTRYPOINT</th><th>ENTRYPOINT exec_entry p1_entry</th><th>ENTRYPOINT [“exec_entry”, “p1_entry”]</th></tr></thead><tbody><tr><td>No CMD</td><td>error, not allowed</td><td>/bin/sh -c exec_entry p1_entry</td><td>exec_entry p1_entry</td></tr><tr><td>CMD [“exec_cmd”, “p1_cmd”]</td><td>exec_cmd p1_cmd</td><td>/bin/sh -c exec_entry p1_entry</td><td>exec_entry p1_entry exec_cmd p1_cmd</td></tr><tr><td>CMD [“p1_cmd”, “p2_cmd”]</td><td>p1_cmd p2_cmd</td><td>/bin/sh -c exec_entry p1_entry</td><td>exec_entry p1_entry p1_cmd p2_cmd</td></tr><tr><td>CMD exec_cmd p1_cmd</td><td>/bin/sh -c exec_cmd p1_cmd</td><td>/bin/sh -c exec_entry p1_entry</td><td>exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd</td></tr></tbody></table><h3 id="docker-entrypoint-sh-的使用"><a href="#docker-entrypoint-sh-的使用" class="headerlink" title="docker-entrypoint.sh 的使用"></a>docker-entrypoint.sh 的使用</h3><p>参照我 blog 的 Dockerfile 的 docker-entrypoint.sh</p><h4 id="set-e"><a href="#set-e" class="headerlink" title="set -e"></a>set -e</h4><p>文件开头加上set -e, 这句语句告诉bash如果任何语句的执行结果不是true则应该退出</p><h4 id="exec-gosu-www-data-“-0”-“-”"><a href="#exec-gosu-www-data-“-0”-“-”" class="headerlink" title="exec gosu www-data “$0” “$@”"></a>exec gosu www-data “$0” “$@”</h4><p>使用 gosu 来切换身份,而不是 su<br>$0 代表当前的 shell 脚本名, $@ 代表 CMD 的第一个参数</p><h4 id="exec-“-”"><a href="#exec-“-”" class="headerlink" title="exec “$@”"></a>exec “$@”</h4><p>当在 docker-entrypoint.sh 执行了一些需要初始化的事情后,边去执行 CMD 定义的脚本</p><h4 id="综合"><a href="#综合" class="headerlink" title="综合"></a>综合</h4><pre><code class="bash">    #!/bin/bash    set -e    if [ &quot;$1&quot; = &#39;/my-blog/bash/init.sh&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then        service nginx start        service fcgiwrap start        echo &quot;☆☆☆☆☆ base service has started. ☆☆☆☆☆&quot;        exec gosu www-data &quot;$0&quot; &quot;$@&quot;    fi    exec &quot;$@&quot;</code></pre><p>解释: 如果 CMD 的第一个参数是 <code>/my-blog/bash/init.sh</code>,并且 当前用户是 root 的话, 那么启动 <code>nginx</code> 和 <code>fcgiwrap</code> 服务,并切换到 <code>www-data</code> 的身份,带上参数 <code>/my-blog/bash/init.sh</code>, 再次运行 <code>docker-entrypoint.sh</code></p><p>当再次执行该脚本时由于已经不是 root 用户了, 会直接执行 <code>exec &quot;$@&quot;</code>,  于是直接执行带的参数,即 CMD 定义的脚本.</p><p>很多 Dockerfile 都是这样的做法,比如 MySQL , Redis </p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- iPhone 7 更换电池,缝缝补补又三年</title>
      <link href="/2020/04/21/Daily-iPhone7-Replace-Battery/"/>
      <url>/2020/04/21/Daily-iPhone7-Replace-Battery/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>有台老 iPhone 7,电池峰值只有 66%, 家人一直在用,想着买块电池换上,缝缝补补又三年….</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li>使用 0.8mm 五角螺丝刀拆下充电口 2 边的螺丝</li><li>吹风机均匀加热手机 5 分钟, 使手机的边框的防水胶变软</li><li>使用吸盘吸住屏幕,并使用拆机片沿手机尾部慢慢切入,并沿着四周慢慢划开</li><li>注意手机的右侧,有屏幕和指纹的排线,切入右侧的时候需要小心</li><li>打开手机屏幕,将手机绑到一个瓶子上固定住</li></ol><p><img src="//image.joylau.cn/blog/iPhone7/1.jpeg" alt="1"></p><p><img src="//image.joylau.cn/blog/iPhone7/2.jpeg" alt="2"></p><ol start="6"><li>卸下下图位置的挡板,先断开电池的排线, 在断开指纹和屏幕的排线</li></ol><p><img src="//image.joylau.cn/blog/iPhone7/4.jpeg" alt="4"></p><p><img src="//image.joylau.cn/blog/iPhone7/3.jpeg" alt="3"></p><ol start="7"><li>断开电池尾部震动马达的排线和手机上面的排线接口</li></ol><p><img src="//image.joylau.cn/blog/iPhone7/5.jpeg" alt="5"></p><ol start="8"><li>拿下屏幕,使用镊子挑开屏幕尾部的易拉胶,再慢慢抽出来, 我这里抽断了,再次使用吹风机在背部加热三分钟,然后在使用拆机片沿底部慢慢切入划开,注意不要硬撬,有风险</li></ol><p><img src="//image.joylau.cn/blog/iPhone7/6.jpeg" alt="6"></p><p>花了不少时间,电池都形变了</p><p><img src="//image.joylau.cn/blog/iPhone7/7.jpeg" alt="7"></p><p><img src="//image.joylau.cn/blog/iPhone7/8.jpeg" alt="8"></p><ol start="9"><li>卸下的螺丝按位置摆放好</li></ol><p><img src="//image.joylau.cn/blog/iPhone7/9.jpeg" alt="9"></p><ol start="10"><li><p>换上新电池,注意先扣上排线接口,再放入电池</p></li><li><p>依次接好之前挑开的排线,开机测试,查看电池容量, 测试电池充放电是否正常..</p></li><li><p>没有问题,再次关机, 在电池背部贴上易拉胶,上好之前卸下的螺丝,扣上屏幕</p></li><li><p>满血复活</p></li></ol><p><img src="//image.joylau.cn/blog/iPhone7/10.jpeg" alt="10"></p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- Filebeat 实时收集 SpringBoot 日志</title>
      <link href="/2020/04/18/SpringBoot-FileBeat/"/>
      <url>/2020/04/18/SpringBoot-FileBeat/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li>Filebeat 版本为 6.4.3</li></ol><h3 id="logback-配置"><a href="#logback-配置" class="headerlink" title="logback 配置"></a>logback 配置</h3><pre><code class="yaml">    logging:      config: classpath:logback-config.xml</code></pre><pre><code class="xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;      &lt;configuration scan=&quot;true&quot;&gt;          &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;              &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;                  &lt;pattern&gt;%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%exception}                  &lt;/pattern&gt;              &lt;/encoder&gt;          &lt;/appender&gt;          &lt;appender name=&quot;CONSOLE-FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;              &lt;file&gt;                  /Users/joylau/docker-data/logs/es-doc-office-service/es-doc-office-service-console.log              &lt;/file&gt;              &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;                  &lt;fileNamePattern&gt;                      /Users/joylau/docker-data/logs/es-doc-office-service/es-doc-office-service-console-%d{yyyy-MM-dd}.log.gz                  &lt;/fileNamePattern&gt;                  &lt;!--最大保留时间为 7 天--&gt;                  &lt;maxHistory&gt;7&lt;/maxHistory&gt;              &lt;/rollingPolicy&gt;              &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;                  &lt;pattern&gt;%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%exception}                  &lt;/pattern&gt;              &lt;/encoder&gt;          &lt;/appender&gt;          &lt;appender name=&quot;JSON-FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;              &lt;file&gt;                  /Users/joylau/docker-data/logs/es-doc-office-service/es-doc-office-service-json.log              &lt;/file&gt;              &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;                  &lt;fileNamePattern&gt;                      /Users/joylau/docker-data/logs/es-doc-office-service/es-doc-office-service-json-%d{yyyy-MM-dd}.log.gz                  &lt;/fileNamePattern&gt;                  &lt;maxHistory&gt;7&lt;/maxHistory&gt;              &lt;/rollingPolicy&gt;              &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;                  &lt;!--            json 日志美化--&gt;                  &lt;!--            &lt;jsonGeneratorDecorator class=&quot;net.logstash.logback.decorate.PrettyPrintingJsonGeneratorDecorator&quot;/&gt;--&gt;                  &lt;jsonGeneratorDecorator class=&quot;net.logstash.logback.decorate.FeatureJsonGeneratorDecorator&quot;/&gt;                  &lt;providers&gt;                      &lt;pattern&gt;                          &lt;pattern&gt;                              {                              &quot;date&quot;: &quot;%date{yyyy-MM-dd HH:mm:ss}&quot;,                              &quot;level&quot;: &quot;%level&quot;,                              &quot;thread&quot;: &quot;%thread&quot;,                              &quot;class&quot;: &quot;%logger{500}&quot;,                              &quot;msg&quot;: &quot;%msg&quot;,                              &quot;stack_trace&quot;: &quot;%exception{2000}&quot;                              }                          &lt;/pattern&gt;                      &lt;/pattern&gt;                  &lt;/providers&gt;              &lt;/encoder&gt;          &lt;/appender&gt;          &lt;root level=&quot;INFO&quot;&gt;              &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;              &lt;appender-ref ref=&quot;CONSOLE-FILE&quot;/&gt;              &lt;appender-ref ref=&quot;JSON-FILE&quot;/&gt;          &lt;/root&gt;          &lt;!--打印 mysql 日志--&gt;          &lt;logger name=&quot;cn.joylau.code.mapper&quot; level=&quot;DEBUG&quot;&gt;              &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;              &lt;appender-ref ref=&quot;CONSOLE-FILE&quot;/&gt;              &lt;appender-ref ref=&quot;JSON-FILE&quot;/&gt;          &lt;/logger&gt;      &lt;/configuration&gt;</code></pre><p>我这里记录了 2 份文件日志是因为我想在日志端点监控中(/actuator/logfile)直接访问控制台日志<br>需要配置 </p><pre><code class="yaml">    logging:      file: /path/es-doc-office-service-console.log</code></pre><p>这里简单记录下 logback 配置文件:</p><p>logback的主要组成部分</p><ul><li>appender，是用来定义一个写日志记录的组件，常用的appender类有ConsoleAppender和RollingFileAppender，前者个是用来在控制台上打印日志，后者是将日志输出到文件中。</li><li>layout，是指定日志的布局方式，这个基本都不会去特殊的指定，可以忽略，知道有这个东西即可。</li><li>encoder，负责把事件转换成字节数组并把字节数组写到合适的输出流。encoder可以指定属性值class，这里对应的类只有一个PatternLayoutEncoder，也是默认值，可以不去指定。</li><li>filter，过滤器分为三种，logback-classic提供的是两种，分别是常规的过滤器和Turbo过滤器。常用的过滤器就是按照日志级别来控制，将不同级别的日志输出到不同文件中，便于查看日志。如：错误日志输出到xxx-error.log，info日志输出到xxx-info.log中。</li><li>rollingPolicy，用来设置日志的滚动策略，当达到条件后会自动将条件前的日志生成一个备份日志文件，条件后的日志输出到最新的日志文件中。常用的是按照时间来滚动（使用的类TimeBaseRollingPolicy）,还有一种就是基于索引来实现（使用的类FixedWindowRollingPolicy）。rolling policies有 TimeBasedRollingPolicy，SizeAndTimeBasedRollingPolicy,FixedWindowRollingPolicy三种策略</li><li>triggeringPolicy，日志触发器策略，常用的是日志的大小的控制，当日志达到对应的大小的时候，就会触发。生成新的日志文件。日志大小的控制配合rollingPlicy使用的时候，不同的rollingPolicy会有所不同。</li></ul><h3 id="springboot-日志输出格式"><a href="#springboot-日志输出格式" class="headerlink" title="springboot 日志输出格式"></a>springboot 日志输出格式</h3><pre><code class="json">    {&quot;date&quot;:&quot;2020-04-18 09:18:56&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;cn.joylau.code.EsDocOfficeApplication&quot;,&quot;msg&quot;:&quot;Starting EsDocOfficeApplication on JoyLaudeMacBook-Pro.local with PID 21663 (/Users/joylau/dev/idea-project/dev-app/es-doc-office/es-doc-office-service/build/classes/java/main started by joylau in /Users/joylau/dev/idea-project/es-doc-office)&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:56&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;cn.joylau.code.EsDocOfficeApplication&quot;,&quot;msg&quot;:&quot;The following profiles are active: db,dev&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:58&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;org.springframework.data.repository.config.RepositoryConfigurationDelegate&quot;,&quot;msg&quot;:&quot;Bootstrapping Spring Data repositories in DEFAULT mode.&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:58&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;org.springframework.data.repository.config.RepositoryConfigurationDelegate&quot;,&quot;msg&quot;:&quot;Finished Spring Data repository scanning in 86ms. Found 3 repository interfaces.&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:58&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker&quot;,&quot;msg&quot;:&quot;Bean &#39;org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration&#39; of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a477e06a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:59&quot;,&quot;level&quot;:&quot;WARN&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;io.undertow.websockets.jsr&quot;,&quot;msg&quot;:&quot;UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:59&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;io.undertow.servlet&quot;,&quot;msg&quot;:&quot;Initializing Spring embedded WebApplicationContext&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:59&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;org.springframework.web.context.ContextLoader&quot;,&quot;msg&quot;:&quot;Root WebApplicationContext: initialization completed in 2231 ms&quot;,&quot;stack_trace&quot;:&quot;&quot;}    {&quot;date&quot;:&quot;2020-04-18 09:18:59&quot;,&quot;level&quot;:&quot;INFO&quot;,&quot;thread&quot;:&quot;main&quot;,&quot;class&quot;:&quot;com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure&quot;,&quot;msg&quot;:&quot;Init DruidDataSource&quot;,&quot;stack_trace&quot;:&quot;&quot;}</code></pre><h3 id="filebeat-配置"><a href="#filebeat-配置" class="headerlink" title="filebeat 配置"></a>filebeat 配置</h3><pre><code class="yaml">    #=========================== Configure logging ================================    logging.level: warning    #=========================== Filebeat prospectors =============================    filebeat.inputs:      - type: log        # Paths that should be crawled and fetched. Glob based paths.        paths:          - /var/log/read-log/*.log        json.keys_under_root: true        json.overwrite_keys: true    #-------------------------- Elasticsearch output ------------------------------    output.elasticsearch:      # Array of hosts to connect to.      hosts: [&quot;http://ip:9200&quot;]      index: &quot;service-runtime-log_%{+YYYY-MM-dd}&quot;      username: &quot;username&quot;      password: &quot;password&quot;    setup:template.enabled: true    setup.template.overwrite: true    setup.template.name: &quot;service-log-filebeat-template&quot;    setup.template.pattern: &quot;service-runtime-log_*&quot;    setup.template.json.enabled: true    setup.template.json.path: &quot;/usr/share/filebeat/filebeat.template.json&quot;    setup.template.json.name: &quot;service-log-filebeat-template&quot;</code></pre><p>注意这里我使用了自定义模板 <code>filebeat.template.json</code>, 因为我需要处理一下特殊字段, 比如 date 字段需要设置为日期类型, <code>msg</code> 和 <code>stack_trace</code> 设置为 text 以供分词和全文检索,<br>默认处理使用的字段在配置文件 <code>fields.yml</code> 里,见下面附录<br>可以使用 </p><pre><code class="bash">    filebeat export template &gt; /var/log/read-log/filebeat.template.json</code></pre><p>导出模板,详细配置见下面的附录</p><h3 id="模板配置"><a href="#模板配置" class="headerlink" title="模板配置"></a>模板配置</h3><pre><code class="json">    {      &quot;index_patterns&quot;: [        &quot;service-runtime-log_*&quot;      ],      &quot;mappings&quot;: {        &quot;doc&quot;: {          &quot;_meta&quot;: {            &quot;version&quot;: &quot;6.4.3&quot;          },          &quot;date_detection&quot;: false,          &quot;dynamic_templates&quot;: [            {              &quot;fields&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;fields.*&quot;              }            },            {              &quot;docker.container.labels&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;docker.container.labels.*&quot;              }            },            {              &quot;kibana.log.meta&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;kibana.log.meta.*&quot;              }            },            {              &quot;strings_as_keyword&quot;: {                &quot;mapping&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;              }            }          ],          &quot;properties&quot;: {            &quot;@timestamp&quot;: {              &quot;type&quot;: &quot;date&quot;            },            &quot;beat&quot;: {              &quot;properties&quot;: {                &quot;hostname&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;name&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;timezone&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;version&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;offset&quot;: {              &quot;type&quot;: &quot;long&quot;            },            &quot;source&quot;: {              &quot;ignore_above&quot;: 1024,              &quot;type&quot;: &quot;keyword&quot;            },            &quot;date&quot;: {              &quot;type&quot;: &quot;date&quot;,              &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;            },            &quot;stack_trace&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;msg&quot;: {              &quot;type&quot;: &quot;text&quot;            }          }        }      },      &quot;order&quot;: 1,      &quot;settings&quot;: {        &quot;index&quot;: {          &quot;mapping&quot;: {            &quot;total_fields&quot;: {              &quot;limit&quot;: 10000            }          },          &quot;number_of_routing_shards&quot;: 30,          &quot;refresh_interval&quot;: &quot;5s&quot;        }      },      &quot;aliases&quot;: {        &quot;service-runtime-log&quot;: {}      }    }</code></pre><h3 id="docker-运行"><a href="#docker-运行" class="headerlink" title="docker 运行"></a>docker 运行</h3><pre><code class="bash">    docker run --rm --name filebeat --mount type=bind,source=&quot;$(pwd)&quot;/filebeat.yml,target=/usr/share/filebeat/filebeat.yml --mount type=bind,source=&quot;$(pwd)&quot;/filebeat.template.json,target=/usr/share/filebeat/filebeat.template.json -v /Users/joylau/docker-data/logs/es-doc-office-service:/var/log/read-log docker.elastic.co/beats/filebeat:6.4.3</code></pre><h3 id="自定义-docker-容器"><a href="#自定义-docker-容器" class="headerlink" title="自定义 docker 容器"></a>自定义 docker 容器</h3><pre><code class="dockerfile">    FROM docker.elastic.co/beats/filebeat:6.4.3    MAINTAINER liufa &quot;2587038142.liu@gmail.com&quot;    LABEL Descripttion=&quot;This image use custom configuration filebeat in Docker.&quot;    COPY filebeat.yml /usr/share/filebeat/filebeat.yml    COPY filebeat.template.json /usr/share/filebeat/filebeat.template.json    USER root    RUN chown root:filebeat /usr/share/filebeat/filebeat.yml /usr/share/filebeat/filebeat.template.json    USER filebeat</code></pre><h3 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h3><pre><code class="json">    {      &quot;_index&quot;: &quot;service-runtime-log_2020-04-18&quot;,      &quot;_type&quot;: &quot;doc&quot;,      &quot;_id&quot;: &quot;PiQoi3EBOwES5EhZK7lp&quot;,      &quot;_version&quot;: 1,      &quot;_score&quot;: 1,      &quot;_source&quot;: {        &quot;@timestamp&quot;: &quot;2020-04-18T02:39:56.273Z&quot;,        &quot;thread&quot;: &quot;main&quot;,        &quot;source&quot;: &quot;/var/log/read-log/es-doc-office-service-2020-04-18.log&quot;,        &quot;offset&quot;: 2145,        &quot;input&quot;: {          &quot;type&quot;: &quot;log&quot;        },        &quot;beat&quot;: {          &quot;name&quot;: &quot;032aebe1f6bc&quot;,          &quot;hostname&quot;: &quot;032aebe1f6bc&quot;,          &quot;version&quot;: &quot;6.4.3&quot;        },        &quot;host&quot;: {          &quot;name&quot;: &quot;032aebe1f6bc&quot;        },        &quot;msg&quot;: &quot;Init DruidDataSource&quot;,        &quot;date&quot;: &quot;2020-04-18 09:18:59&quot;,        &quot;class&quot;: &quot;com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure&quot;,        &quot;prospector&quot;: {          &quot;type&quot;: &quot;log&quot;        },        &quot;stack_trace&quot;: &quot;&quot;,        &quot;level&quot;: &quot;INFO&quot;      }    }</code></pre><h3 id="处理-timestamp-时区问题"><a href="#处理-timestamp-时区问题" class="headerlink" title="处理 timestamp 时区问题"></a>处理 timestamp 时区问题</h3><p>使用 filebeat 处理数据可以利用 elasticsearch 的 pipline</p><p>PUT /_ingest/pipeline/process_data</p><pre><code class="json">    {      &quot;description&quot; : &quot;process timestamp field to &quot;,      &quot;processors&quot; : [        {          &quot;date&quot; : {            &quot;field&quot; : &quot;@timestamp&quot;,            &quot;formats&quot; : [&quot;ISO8601&quot;],            &quot;target_field&quot; : &quot;@timestamp&quot;,            &quot;timezone&quot; : &quot;Asia/Shanghai&quot;          }        }      ]    }</code></pre><h3 id="附录一-filebeat-template-all-json"><a href="#附录一-filebeat-template-all-json" class="headerlink" title="附录一(filebeat.template-all.json)"></a>附录一(filebeat.template-all.json)</h3><pre><code class="json">    {      &quot;index_patterns&quot;: [        &quot;filebeat_log_*&quot;      ],      &quot;mappings&quot;: {        &quot;doc&quot;: {          &quot;_meta&quot;: {            &quot;version&quot;: &quot;6.4.3&quot;          },          &quot;date_detection&quot;: false,          &quot;dynamic_templates&quot;: [            {              &quot;fields&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;fields.*&quot;              }            },            {              &quot;docker.container.labels&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;docker.container.labels.*&quot;              }            },            {              &quot;kibana.log.meta&quot;: {                &quot;mapping&quot;: {                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;,                &quot;path_match&quot;: &quot;kibana.log.meta.*&quot;              }            },            {              &quot;strings_as_keyword&quot;: {                &quot;mapping&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;match_mapping_type&quot;: &quot;string&quot;              }            }          ],          &quot;properties&quot;: {            &quot;@timestamp&quot;: {              &quot;type&quot;: &quot;date&quot;            },            &quot;apache2&quot;: {              &quot;properties&quot;: {                &quot;access&quot;: {                  &quot;properties&quot;: {                    &quot;agent&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;body_sent&quot;: {                      &quot;properties&quot;: {                        &quot;bytes&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;http_version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;referrer&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;response_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;url&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user_agent&quot;: {                      &quot;properties&quot;: {                        &quot;device&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os_major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;patch&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;user_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;error&quot;: {                  &quot;properties&quot;: {                    &quot;client&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;module&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;pid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;tid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;auditd&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;a0&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;acct&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;item&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;items&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;new_auid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;new_ses&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;old_auid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;old_ses&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;pid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;ppid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;record_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;res&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;sequence&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;beat&quot;: {              &quot;properties&quot;: {                &quot;hostname&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;name&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;timezone&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;version&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;docker&quot;: {              &quot;properties&quot;: {                &quot;container&quot;: {                  &quot;properties&quot;: {                    &quot;id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;image&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;labels&quot;: {                      &quot;type&quot;: &quot;object&quot;                    },                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;elasticsearch&quot;: {              &quot;properties&quot;: {                &quot;audit&quot;: {                  &quot;properties&quot;: {                    &quot;action&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;event_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;layer&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;origin_address&quot;: {                      &quot;type&quot;: &quot;ip&quot;                    },                    &quot;origin_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;principal&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;request&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;request_body&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;uri&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;deprecation&quot;: {                  &quot;properties&quot;: {}                },                &quot;gc&quot;: {                  &quot;properties&quot;: {                    &quot;heap&quot;: {                      &quot;properties&quot;: {                        &quot;size_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;used_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;jvm_runtime_sec&quot;: {                      &quot;type&quot;: &quot;float&quot;                    },                    &quot;old_gen&quot;: {                      &quot;properties&quot;: {                        &quot;size_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;used_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;phase&quot;: {                      &quot;properties&quot;: {                        &quot;class_unload_time_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        },                        &quot;cpu_time&quot;: {                          &quot;properties&quot;: {                            &quot;real_sec&quot;: {                              &quot;type&quot;: &quot;float&quot;                            },                            &quot;sys_sec&quot;: {                              &quot;type&quot;: &quot;float&quot;                            },                            &quot;user_sec&quot;: {                              &quot;type&quot;: &quot;float&quot;                            }                          }                        },                        &quot;duration_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;parallel_rescan_time_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        },                        &quot;scrub_string_table_time_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        },                        &quot;scrub_symbol_table_time_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        },                        &quot;weak_refs_processing_time_sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        }                      }                    },                    &quot;stopping_threads_time_sec&quot;: {                      &quot;type&quot;: &quot;float&quot;                    },                    &quot;tags&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;threads_total_stop_time_sec&quot;: {                      &quot;type&quot;: &quot;float&quot;                    },                    &quot;young_gen&quot;: {                      &quot;properties&quot;: {                        &quot;size_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;used_kb&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    }                  }                },                &quot;index&quot;: {                  &quot;properties&quot;: {                    &quot;id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;node&quot;: {                  &quot;properties&quot;: {                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;server&quot;: {                  &quot;properties&quot;: {                    &quot;component&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;gc&quot;: {                      &quot;properties&quot;: {                        &quot;young&quot;: {                          &quot;properties&quot;: {                            &quot;one&quot;: {                              &quot;type&quot;: &quot;long&quot;                            },                            &quot;two&quot;: {                              &quot;type&quot;: &quot;long&quot;                            }                          }                        }                      }                    },                    &quot;gc_overhead&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                },                &quot;shard&quot;: {                  &quot;properties&quot;: {                    &quot;id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;slowlog&quot;: {                  &quot;properties&quot;: {                    &quot;extra_source&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;logger&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;routing&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;search_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;source_query&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;stats&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;took&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;took_millis&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;total_hits&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;total_shards&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;types&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;error&quot;: {              &quot;properties&quot;: {                &quot;code&quot;: {                  &quot;type&quot;: &quot;long&quot;                },                &quot;message&quot;: {                  &quot;norms&quot;: false,                  &quot;type&quot;: &quot;text&quot;                },                &quot;type&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;event&quot;: {              &quot;properties&quot;: {                &quot;created&quot;: {                  &quot;type&quot;: &quot;date&quot;                },                &quot;severity&quot;: {                  &quot;type&quot;: &quot;long&quot;                }              }            },            &quot;fields&quot;: {              &quot;type&quot;: &quot;object&quot;            },            &quot;fileset&quot;: {              &quot;properties&quot;: {                &quot;module&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;name&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;host&quot;: {              &quot;properties&quot;: {                &quot;architecture&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;id&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;ip&quot;: {                  &quot;type&quot;: &quot;ip&quot;                },                &quot;mac&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;name&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;os&quot;: {                  &quot;properties&quot;: {                    &quot;family&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;platform&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;http&quot;: {              &quot;properties&quot;: {                &quot;request&quot;: {                  &quot;properties&quot;: {                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;response&quot;: {                  &quot;properties&quot;: {                    &quot;content_length&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;elapsed_time&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;status_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;icinga&quot;: {              &quot;properties&quot;: {                &quot;debug&quot;: {                  &quot;properties&quot;: {                    &quot;facility&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;severity&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;main&quot;: {                  &quot;properties&quot;: {                    &quot;facility&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;severity&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;startup&quot;: {                  &quot;properties&quot;: {                    &quot;facility&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;severity&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;iis&quot;: {              &quot;properties&quot;: {                &quot;access&quot;: {                  &quot;properties&quot;: {                    &quot;agent&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;body_received&quot;: {                      &quot;properties&quot;: {                        &quot;bytes&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;body_sent&quot;: {                      &quot;properties&quot;: {                        &quot;bytes&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;cookie&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;hostname&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;http_version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;port&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;query_string&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;referrer&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;request_time_ms&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;response_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;server_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;server_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;site_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;sub_status&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;url&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user_agent&quot;: {                      &quot;properties&quot;: {                        &quot;device&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os_major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;patch&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;user_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;win32_status&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                },                &quot;error&quot;: {                  &quot;properties&quot;: {                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;http_version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;queue_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;reason_phrase&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_port&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;response_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;server_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;server_port&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;url&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;input&quot;: {              &quot;properties&quot;: {                &quot;type&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;kafka&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;class&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;component&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;timestamp&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;trace&quot;: {                      &quot;properties&quot;: {                        &quot;class&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;full&quot;: {                          &quot;norms&quot;: false,                          &quot;type&quot;: &quot;text&quot;                        },                        &quot;message&quot;: {                          &quot;norms&quot;: false,                          &quot;type&quot;: &quot;text&quot;                        }                      }                    }                  }                }              }            },            &quot;kibana&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;meta&quot;: {                      &quot;type&quot;: &quot;object&quot;                    },                    &quot;state&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;tags&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;kubernetes&quot;: {              &quot;properties&quot;: {                &quot;annotations&quot;: {                  &quot;type&quot;: &quot;object&quot;                },                &quot;container&quot;: {                  &quot;properties&quot;: {                    &quot;image&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;labels&quot;: {                  &quot;type&quot;: &quot;object&quot;                },                &quot;namespace&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;node&quot;: {                  &quot;properties&quot;: {                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;pod&quot;: {                  &quot;properties&quot;: {                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;uid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;log&quot;: {              &quot;properties&quot;: {                &quot;level&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;logstash&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;log_event&quot;: {                      &quot;type&quot;: &quot;object&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;module&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;thread&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    }                  }                },                &quot;slowlog&quot;: {                  &quot;properties&quot;: {                    &quot;event&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;module&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;plugin_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;plugin_params&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;plugin_params_object&quot;: {                      &quot;type&quot;: &quot;object&quot;                    },                    &quot;plugin_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;thread&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;took_in_millis&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;took_in_nanos&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;message&quot;: {              &quot;norms&quot;: false,              &quot;type&quot;: &quot;text&quot;            },            &quot;meta&quot;: {              &quot;properties&quot;: {                &quot;cloud&quot;: {                  &quot;properties&quot;: {                    &quot;availability_zone&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;instance_id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;instance_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;machine_type&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;project_id&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;provider&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;region&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;mongodb&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;component&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;context&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;severity&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;mysql&quot;: {              &quot;properties&quot;: {                &quot;error&quot;: {                  &quot;properties&quot;: {                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;thread_id&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;timestamp&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;slowlog&quot;: {                  &quot;properties&quot;: {                    &quot;host&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;id&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;lock_time&quot;: {                      &quot;properties&quot;: {                        &quot;sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        }                      }                    },                    &quot;query&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;query_time&quot;: {                      &quot;properties&quot;: {                        &quot;sec&quot;: {                          &quot;type&quot;: &quot;float&quot;                        }                      }                    },                    &quot;rows_examined&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;rows_sent&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;timestamp&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;user&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;nginx&quot;: {              &quot;properties&quot;: {                &quot;access&quot;: {                  &quot;properties&quot;: {                    &quot;agent&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;body_sent&quot;: {                      &quot;properties&quot;: {                        &quot;bytes&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;http_version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;referrer&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;response_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;url&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user_agent&quot;: {                      &quot;properties&quot;: {                        &quot;device&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os_major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;patch&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;user_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;error&quot;: {                  &quot;properties&quot;: {                    &quot;connection_id&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;pid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;tid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;offset&quot;: {              &quot;type&quot;: &quot;long&quot;            },            &quot;osquery&quot;: {              &quot;properties&quot;: {                &quot;result&quot;: {                  &quot;properties&quot;: {                    &quot;action&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;calendar_time&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;host_identifier&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;unix_time&quot;: {                      &quot;type&quot;: &quot;long&quot;                    }                  }                }              }            },            &quot;postgresql&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;database&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;duration&quot;: {                      &quot;type&quot;: &quot;float&quot;                    },                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;query&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;thread_id&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;timestamp&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;timezone&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;process&quot;: {              &quot;properties&quot;: {                &quot;pid&quot;: {                  &quot;type&quot;: &quot;long&quot;                },                &quot;program&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;prospector&quot;: {              &quot;properties&quot;: {                &quot;type&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;read_timestamp&quot;: {              &quot;ignore_above&quot;: 1024,              &quot;type&quot;: &quot;keyword&quot;            },            &quot;redis&quot;: {              &quot;properties&quot;: {                &quot;log&quot;: {                  &quot;properties&quot;: {                    &quot;level&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;pid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;role&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                },                &quot;slowlog&quot;: {                  &quot;properties&quot;: {                    &quot;args&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;cmd&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;duration&quot;: {                      &quot;properties&quot;: {                        &quot;us&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;id&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;key&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;service&quot;: {              &quot;properties&quot;: {                &quot;name&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;source&quot;: {              &quot;ignore_above&quot;: 1024,              &quot;type&quot;: &quot;keyword&quot;            },            &quot;stream&quot;: {              &quot;ignore_above&quot;: 1024,              &quot;type&quot;: &quot;keyword&quot;            },            &quot;syslog&quot;: {              &quot;properties&quot;: {                &quot;facility&quot;: {                  &quot;type&quot;: &quot;long&quot;                },                &quot;facility_label&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                },                &quot;priority&quot;: {                  &quot;type&quot;: &quot;long&quot;                },                &quot;severity_label&quot;: {                  &quot;ignore_above&quot;: 1024,                  &quot;type&quot;: &quot;keyword&quot;                }              }            },            &quot;system&quot;: {              &quot;properties&quot;: {                &quot;auth&quot;: {                  &quot;properties&quot;: {                    &quot;groupadd&quot;: {                      &quot;properties&quot;: {                        &quot;gid&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;hostname&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;pid&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;program&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;ssh&quot;: {                      &quot;properties&quot;: {                        &quot;dropped_ip&quot;: {                          &quot;type&quot;: &quot;ip&quot;                        },                        &quot;event&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;geoip&quot;: {                          &quot;properties&quot;: {                            &quot;city_name&quot;: {                              &quot;ignore_above&quot;: 1024,                              &quot;type&quot;: &quot;keyword&quot;                            },                            &quot;continent_name&quot;: {                              &quot;ignore_above&quot;: 1024,                              &quot;type&quot;: &quot;keyword&quot;                            },                            &quot;country_iso_code&quot;: {                              &quot;ignore_above&quot;: 1024,                              &quot;type&quot;: &quot;keyword&quot;                            },                            &quot;location&quot;: {                              &quot;type&quot;: &quot;geo_point&quot;                            },                            &quot;region_iso_code&quot;: {                              &quot;ignore_above&quot;: 1024,                              &quot;type&quot;: &quot;keyword&quot;                            },                            &quot;region_name&quot;: {                              &quot;ignore_above&quot;: 1024,                              &quot;type&quot;: &quot;keyword&quot;                            }                          }                        },                        &quot;ip&quot;: {                          &quot;type&quot;: &quot;ip&quot;                        },                        &quot;method&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;port&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;signature&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;sudo&quot;: {                      &quot;properties&quot;: {                        &quot;command&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;error&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;pwd&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;tty&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;user&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;timestamp&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;useradd&quot;: {                      &quot;properties&quot;: {                        &quot;gid&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;home&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;shell&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;uid&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    }                  }                },                &quot;syslog&quot;: {                  &quot;properties&quot;: {                    &quot;hostname&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;message&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;pid&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;program&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;timestamp&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            },            &quot;tags&quot;: {              &quot;ignore_above&quot;: 1024,              &quot;type&quot;: &quot;keyword&quot;            },            &quot;traefik&quot;: {              &quot;properties&quot;: {                &quot;access&quot;: {                  &quot;properties&quot;: {                    &quot;agent&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;backend_url&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;body_sent&quot;: {                      &quot;properties&quot;: {                        &quot;bytes&quot;: {                          &quot;type&quot;: &quot;long&quot;                        }                      }                    },                    &quot;frontend_name&quot;: {                      &quot;norms&quot;: false,                      &quot;type&quot;: &quot;text&quot;                    },                    &quot;geoip&quot;: {                      &quot;properties&quot;: {                        &quot;city_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;continent_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;country_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;location&quot;: {                          &quot;type&quot;: &quot;geo_point&quot;                        },                        &quot;region_iso_code&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;region_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;http_version&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;method&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;referrer&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;remote_ip&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;request_count&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;response_code&quot;: {                      &quot;type&quot;: &quot;long&quot;                    },                    &quot;url&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    },                    &quot;user_agent&quot;: {                      &quot;properties&quot;: {                        &quot;device&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;os_major&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_minor&quot;: {                          &quot;type&quot;: &quot;long&quot;                        },                        &quot;os_name&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        },                        &quot;patch&quot;: {                          &quot;ignore_above&quot;: 1024,                          &quot;type&quot;: &quot;keyword&quot;                        }                      }                    },                    &quot;user_name&quot;: {                      &quot;ignore_above&quot;: 1024,                      &quot;type&quot;: &quot;keyword&quot;                    }                  }                }              }            }          }        }      },      &quot;order&quot;: 1,      &quot;settings&quot;: {        &quot;index&quot;: {          &quot;mapping&quot;: {            &quot;total_fields&quot;: {              &quot;limit&quot;: 10000            }          },          &quot;number_of_routing_shards&quot;: 30,          &quot;refresh_interval&quot;: &quot;5s&quot;        }      }    }</code></pre><h3 id="附录二-fields-all-yml"><a href="#附录二-fields-all-yml" class="headerlink" title="附录二(fields-all.yml)"></a>附录二(fields-all.yml)</h3><pre><code class="yaml">    - key: log      title: Log file content      description: &gt;        Contains log file lines.      fields:        - name: source          type: keyword          required: true          description: &gt;            The file from which the line was read. This field contains the absolute path to the file.            For example: `/var/log/system.log`.        - name: offset          type: long          required: false          description: &gt;            The file offset the reported line starts at.        - name: message          type: text          ignore_above: 0          required: true          description: &gt;            The content of the line read from the log file.        - name: stream          type: keyword          required: false          description: &gt;            Log stream when reading container logs, can be &#39;stdout&#39; or &#39;stderr&#39;        - name: prospector.type          required: true          description: &gt;            The input type from which the event was generated. This field is set to the value specified            for the `type` option in the input section of the Filebeat config file. (DEPRECATED: see `input.type`)        - name: input.type          required: true          description: &gt;            The input type from which the event was generated. This field is set to the value specified            for the `type` option in the input section of the Filebeat config file.        - name: read_timestamp          description: &gt;            In case the ingest pipeline parses the timestamp from the log contents, it stores            the original `@timestamp` (representing the time when the log line was read) in this            field.        - name: fileset.module          description: &gt;            The Filebeat module that generated this event.        - name: fileset.name          description: &gt;            The Filebeat fileset that generated this event.        - name: syslog.facility          type: long          required: false          description: &gt;            The facility extracted from the priority.        - name: syslog.priority          type: long          required: false          description: &gt;            The priority of the syslog event.        - name: syslog.severity_label          type: keyword          required: false          description: &gt;            The human readable severity.        - name: syslog.facility_label          type: keyword          required: false          description: &gt;            The human readable facility.        - name: process.program          type: keyword          required: false          description: &gt;            The name of the program.        - name: process.pid          type: long          required: false          description: &gt;            The pid of the process.        - name: event.severity          type: long          required: false          description: &gt;            The severity of the event.        - name: service.name          type: keyword          description: &gt;            Service name.        - name: log.level          type: keyword          description: &gt;            Logging level.        - name: event.created          type: date          description: &gt;            event.created contains the date on which the event was created. In case of            log events this is when the log line was read by Filebeat. In comparison            @timestamp is the processed timestamp from the log line. If both are identical            only @timestamp should be used.        - name: http.response.status_code          type: long          description: &gt;            HTTP response status_code.          example: 404        - name: http.response.elapsed_time          type: long          description: &gt;            Elapsed time between request and response in milli seconds.        - name: http.response.content_length          type: long          description: &gt;            Content length of the HTTP response body.        - name: http.request.method          type: keyword          description: &gt;            Request method.    - key: beat      title: Beat      description: &gt;        Contains common beat fields available in all event types.      fields:        - name: beat.name          description: &gt;            The name of the Beat sending the log messages. If the Beat name is            set in the configuration file, then that value is used. If it is not            set, the hostname is used. To set the Beat name, use the `name`            option in the configuration file.        - name: beat.hostname          description: &gt;            The hostname as returned by the operating system on which the Beat is            running.        - name: beat.timezone          description: &gt;            The timezone as returned by the operating system on which the Beat is            running.        - name: beat.version          description: &gt;            The version of the beat that generated this event.        - name: &quot;@timestamp&quot;          type: date          required: true          format: date          example: August 26th 2016, 12:35:53.332          description: &gt;            The timestamp when the event log record was generated.        - name: tags          description: &gt;            Arbitrary tags that can be set per Beat and per transaction            type.        - name: fields          type: object          object_type: keyword          description: &gt;            Contains user configurable fields.        - name: error          type: group          description: &gt;            Error fields containing additional info in case of errors.          fields:            - name: message              type: text              description: &gt;                Error message.            - name: code              type: long              description: &gt;                Error code.            - name: type              type: keyword              description: &gt;                Error type.    - key: cloud      title: Cloud provider metadata      description: &gt;        Metadata from cloud providers added by the add_cloud_metadata processor.      fields:        - name: meta.cloud.provider          example: ec2          description: &gt;            Name of the cloud provider. Possible values are ec2, gce, or digitalocean.        - name: meta.cloud.instance_id          description: &gt;            Instance ID of the host machine.        - name: meta.cloud.instance_name          description: &gt;            Instance name of the host machine.        - name: meta.cloud.machine_type          example: t2.medium          description: &gt;            Machine type of the host machine.        - name: meta.cloud.availability_zone          example: us-east-1c          description: &gt;            Availability zone in which this host is running.        - name: meta.cloud.project_id          example: project-x          description: &gt;            Name of the project in Google Cloud.        - name: meta.cloud.region          description: &gt;            Region in which this host is running.    - key: docker      title: Docker      description: &gt;        Docker stats collected from Docker.      short_config: false      anchor: docker-processor      fields:        - name: docker          type: group          fields:            - name: container.id              type: keyword              description: &gt;                Unique container id.            - name: container.image              type: keyword              description: &gt;                Name of the image the container was built on.            - name: container.name              type: keyword              description: &gt;                Container name.            - name: container.labels              type: object              object_type: keyword              description: &gt;                Image labels.    - key: host      title: Host      description: &gt;        Info collected for the host machine.      anchor: host-processor      fields:        - name: host          type: group          fields:            - name: name              type: keyword              description: &gt;                Hostname.            - name: id              type: keyword              description: &gt;                Unique host id.            - name: architecture              type: keyword              description: &gt;                Host architecture (e.g. x86_64, arm, ppc, mips).            - name: os.platform              type: keyword              description: &gt;                OS platform (e.g. centos, ubuntu, windows).            - name: os.version              type: keyword              description: &gt;                OS version.            - name: os.family              type: keyword              description: &gt;                OS family (e.g. redhat, debian, freebsd, windows).            - name: ip              type: ip              description: &gt;                List of IP-addresses.            - name: mac              type: keyword              description: &gt;                List of hardware-addresses, usually MAC-addresses.    - key: kubernetes      title: Kubernetes      description: &gt;        Kubernetes metadata added by the kubernetes processor      short_config: false      anchor: kubernetes-processor      fields:        - name: kubernetes          type: group          fields:            - name: pod.name              type: keyword              description: &gt;                Kubernetes pod name            - name: pod.uid              type: keyword              description: &gt;                Kubernetes Pod UID            - name: namespace              type: keyword              description: &gt;                Kubernetes namespace            - name: node.name              type: keyword              description: &gt;                Kubernetes node name            - name: labels              type: object              description: &gt;                Kubernetes labels map            - name: annotations              type: object              description: &gt;                Kubernetes annotations map            - name: container.name              type: keyword              description: &gt;                Kubernetes container name            - name: container.image              type: keyword              description: &gt;                Kubernetes container image    - key: apache2      title: &quot;Apache2&quot;      description: &gt;        Apache2 Module      short_config: true      fields:        - name: apache2          type: group          description: &gt;            Apache2 fields.          fields:            - name: access              type: group              description: &gt;                Contains fields for the Apache2 HTTPD access logs.              fields:                - name: remote_ip                  type: keyword                  description: &gt;                    Client IP address.                - name: user_name                  type: keyword                  description: &gt;                    The user name used when basic authentication is used.                - name: method                  type: keyword                  example: GET                  description: &gt;                    The request HTTP method.                - name: url                  type: keyword                  description: &gt;                    The request HTTP URL.                - name: http_version                  type: keyword                  description: &gt;                    The HTTP version.                - name: response_code                  type: long                  description: &gt;                    The HTTP response code.                - name: body_sent.bytes                  type: long                  format: bytes                  description: &gt;                    The number of bytes of the server response body.                - name: referrer                  type: keyword                  description: &gt;                    The HTTP referrer.                - name: agent                  type: text                  description: &gt;                    Contains the un-parsed user agent string. Only present if the user                    agent Elasticsearch plugin is not available or not used.                - name: user_agent                  type: group                  description: &gt;                    Contains the parsed User agent field. Only present if the user                    agent Elasticsearch plugin is available and used.                  fields:                    - name: device                      type: keyword                      description: &gt;                        The name of the physical device.                    - name: major                      type: long                      description: &gt;                        The major version of the user agent.                    - name: minor                      type: long                      description: &gt;                        The minor version of the user agent.                    - name: patch                      type: keyword                      description: &gt;                        The patch version of the user agent.                    - name: name                      type: keyword                      example: Chrome                      description: &gt;                        The name of the user agent.                    - name: os                      type: keyword                      description: &gt;                        The name of the operating system.                    - name: os_major                      type: long                      description: &gt;                        The major version of the operating system.                    - name: os_minor                      type: long                      description: &gt;                        The minor version of the operating system.                    - name: os_name                      type: keyword                      description: &gt;                        The name of the operating system.                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the remote_ip field.                    Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_name                      type: keyword                      description: &gt;                        The region name.                    - name: city_name                      type: keyword                      description: &gt;                        The city name.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.            - name: error              type: group              description: &gt;                Fields from the Apache error logs.              fields:                - name: level                  type: keyword                  description: &gt;                    The severity level of the message.                - name: client                  type: keyword                  description: &gt;                    The IP address of the client that generated the error.                - name: message                  type: text                  description: &gt;                    The logged message.                - name: pid                  type: long                  description: &gt;                    The process ID.                - name: tid                  type: long                  description: &gt;                    The thread ID.                - name: module                  type: keyword                  description: &gt;                    The module producing the logged message.    - key: auditd      title: &quot;Auditd&quot;      description: &gt;        Module for parsing auditd logs.      short_config: true      fields:        - name: auditd          type: group          description: &gt;            Fields from the auditd logs.          fields:            - name: log              type: group              description: &gt;                Fields from the Linux audit log. Not all fields are documented here because                they are dynamic and vary by audit event type.              fields:                - name: record_type                  description: &gt;                    The audit event type.                - name: old_auid                  description: &gt;                    For login events this is the old audit ID used for the user prior to                    this login.                - name: new_auid                  description: &gt;                    For login events this is the new audit ID. The audit ID can be used to                    trace future events to the user even if their identity changes (like                    becoming root).                - name: old_ses                  description: &gt;                    For login events this is the old session ID used for the user prior to                    this login.                - name: new_ses                  description: &gt;                    For login events this is the new session ID. It can be used to tie a                    user to future events by session ID.                - name: sequence                  type: long                  description: &gt;                    The audit event sequence number.                - name: acct                  description: &gt;                    The user account name associated with the event.                - name: pid                  description: &gt;                    The ID of the process.                - name: ppid                  description: &gt;                    The ID of the process.                - name: items                  description: &gt;                    The number of items in an event.                - name: item                  description: &gt;                    The item field indicates which item out of the total number of items.                    This number is zero-based; a value of 0 means it is the first item.                - name: a0                  description: &gt;                    The first argument to the system call.                - name: res                  description: &gt;                    The result of the system call (success or failure).                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the `auditd.log.addr`                    field. Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: city_name                      type: keyword                      description: &gt;                        The name of the city.                    - name: region_name                      type: keyword                      description: &gt;                        The name of the region.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.    - key: elasticsearch      title: &quot;elasticsearch&quot;      description: &gt;        elasticsearch Module      fields:        - name: elasticsearch          type: group          description: &gt;          fields:            - name: node.name              description: &quot;Name of the node&quot;              example: &quot;vWNJsZ3&quot;              type: keyword            - name: index.name              description: &quot;Index name&quot;              example: &quot;filebeat-test-input&quot;              type: keyword            - name: index.id              description: &quot;Index id&quot;              example: &quot;aOGgDwbURfCV57AScqbCgw&quot;              type: keyword            - name: shard.id              description: &quot;Id of the shard&quot;              example: &quot;0&quot;              type: keyword            - name: audit              type: group              description: &gt;              fields:                - name: layer                  description: &quot;The layer from which this event originated: rest, transport or ip_filter&quot;                  example: &quot;rest&quot;                  type: keyword                - name: event_type                  description: &quot;The type of event that occurred: anonymous_access_denied, authentication_failed, access_denied, access_granted, connection_granted, connection_denied, tampered_request, run_as_granted, run_as_denied&quot;                  example: &quot;access_granted&quot;                  type: keyword                - name: origin_type                  description: &quot;Where the request originated: rest (request originated from a REST API request), transport (request was received on the transport channel), local_node (the local node issued the request)&quot;                  example: &quot;local_node&quot;                  type: keyword                - name: origin_address                  description: &quot;The IP address from which the request originated&quot;                  example: &quot;192.168.1.42&quot;                  type: ip                - name: principal                  description: &quot;The principal (username) that failed authentication&quot;                  example: &quot;_anonymous&quot;                  type: keyword                - name: action                  description: &quot;The name of the action that was executed&quot;                  example: &quot;cluster:monitor/main&quot;                  type: keyword                - name: uri                  description: &quot;The REST endpoint URI&quot;                  example: /_xpack/security/_authenticate                  type: keyword                - name: request                  description: &quot;The type of request that was executed&quot;                  example: &quot;ClearScrollRequest&quot;                  type: keyword                - name: request_body                  description: &quot;The body of the request, if enabled&quot;                  example: &quot;body&quot;                  type: text            - name: deprecation              type: group              description: &gt;              fields:            - name: gc              type: group              description: &gt;                GC fileset fields.              fields:                - name: phase                  type: group                  description: &gt;                    Fields specific to GC phase.                  fields:                    - name: name                      type: keyword                      description: &gt;                        Name of the GC collection phase.                    - name: duration_sec                      type: float                      description: &gt;                        Collection phase duration according to the Java virtual machine.                    - name: scrub_symbol_table_time_sec                      type: float                      description: &gt;                         Pause time in seconds cleaning up symbol tables.                    - name: scrub_string_table_time_sec                      type: float                      description: &gt;                        Pause time in seconds cleaning up string tables.                    - name: weak_refs_processing_time_sec                      type: float                      description: &gt;                        Time spent processing weak references in seconds.                    - name: parallel_rescan_time_sec                      type: float                      description: &gt;                        Time spent in seconds marking live objects while application is stopped.                    - name: class_unload_time_sec                      type: float                      description: &gt;                        Time spent unloading unused classes in seconds.                    - name: cpu_time                      type: group                      description: &gt;                        Process CPU time spent performing collections.                      fields:                        - name: user_sec                          type: float                          description: &gt;                            CPU time spent outside the kernel.                        - name: sys_sec                          type: float                          description: &gt;                            CPU time spent inside the kernel.                         - name: real_sec                          type: float                          description: &gt;                            Total elapsed CPU time spent to complete the collection from start to finish.                - name: jvm_runtime_sec                  type: float                  description: &gt;                    The time from JVM start up in seconds, as a floating point number.                - name: threads_total_stop_time_sec                  type: float                  description: &gt;                    Garbage collection threads total stop time seconds.                - name: stopping_threads_time_sec                  type: float                  description: &gt;                    Time took to stop threads seconds.                - name: tags                  type: keyword                  description: &gt;                    GC logging tags.                - name: heap                  type: group                  description: &gt;                    Heap allocation and total size.                  fields:                    - name: size_kb                      type: integer                      description: &gt;                        Total heap size in kilobytes.                    - name: used_kb                      type: integer                      description: &gt;                        Used heap in kilobytes.                - name: old_gen                  type: group                  description: &gt;                    Old generation occupancy and total size.                  fields:                    - name: size_kb                      type: integer                      description: &gt;                        Total size of old generation in kilobytes.                    - name: used_kb                      type: integer                      description: &gt;                        Old generation occupancy in kilobytes.                - name: young_gen                  type: group                  description: &gt;                    Young generation occupancy and total size.                  fields:                    - name: size_kb                      type: integer                      description: &gt;                        Total size of young generation in kilobytes.                    - name: used_kb                      type: integer                      description: &gt;                        Young generation occupancy in kilobytes.            - name: server              description: &quot;Server log file&quot;              type: group              fields:              - name: component                description: &quot;Log component&quot;                example: &quot;o.e.c.m.MetaDataCreateIndexService&quot;                type: keyword              - name: gc                description: &quot;GC log&quot;                type: group                fields:                - name: young                  description: &quot;Young GC&quot;                  example: &quot;&quot;                  type: group                  fields:                  - name: one                    description: &quot;&quot;                    example: &quot;&quot;                    type: long                  - name: two                    description: &quot;&quot;                    example: &quot;&quot;                    type: long              - name: gc_overhead                description: &quot;&quot;                example: &quot;&quot;                type: long            - name: slowlog              description: &quot;Slowlog events from Elasticsearch&quot;              example: &quot;[2018-06-29T10:06:14,933][INFO ][index.search.slowlog.query] [v_VJhjV] [metricbeat-6.3.0-2018.06.26][0] took[4.5ms], took_millis[4], total_hits[19435], types[], stats[], search_type[QUERY_THEN_FETCH], total_shards[1], source[{\&quot;query\&quot;:{\&quot;match_all\&quot;:{\&quot;boost\&quot;:1.0}}}],&quot;              type: group              fields:              - name: logger                description: &quot;Logger name&quot;                example: &quot;index.search.slowlog.fetch&quot;                type: keyword              - name: took                description: &quot;Time it took to execute the query&quot;                example: &quot;300ms&quot;                type: text              - name: types                description: &quot;Types&quot;                example: &quot;&quot;                type: keyword              - name: stats                description: &quot;Statistics&quot;                example: &quot;&quot;                type: text              - name: search_type                description: &quot;Search type&quot;                example: &quot;QUERY_THEN_FETCH&quot;                type: keyword              - name: source_query                description: &quot;Slow query&quot;                example: &quot;{\&quot;query\&quot;:{\&quot;match_all\&quot;:{\&quot;boost\&quot;:1.0}}}&quot;                type: text              - name: extra_source                description: &quot;Extra source information&quot;                example: &quot;&quot;                type: text              - name: took_millis                description: &quot;Time took in milliseconds&quot;                example: 42                type: keyword              - name: total_hits                description: &quot;Total hits&quot;                example: 42                type: keyword              - name: total_shards                description: &quot;Total queried shards&quot;                example: 22                type: keyword              - name: routing                description: &quot;Routing&quot;                example: &quot;s01HZ2QBk9jw4gtgaFtn&quot;                type: keyword              - name: id                description: Id                example: &quot;&quot;                type: keyword              - name: type                description: &quot;Type&quot;                example: &quot;doc&quot;                type: keyword    - key: icinga      title: &quot;Icinga&quot;      description: &gt;        Icinga Module      fields:        - name: icinga          type: group          description: &gt;          fields:            - name: debug              type: group              description: &gt;                Contains fields for the Icinga debug logs.              fields:                - name: facility                  type: keyword                  description: &gt;                    Specifies what component of Icinga logged the message.                - name: severity                  type: keyword                  description: &gt;                    Possible values are &quot;debug&quot;, &quot;notice&quot;, &quot;information&quot;, &quot;warning&quot; or                    &quot;critical&quot;.                - name: message                  type: text                  description: &gt;                    The logged message.            - name: main              type: group              description: &gt;                Contains fields for the Icinga main logs.              fields:                - name: facility                  type: keyword                  description: &gt;                    Specifies what component of Icinga logged the message.                - name: severity                  type: keyword                  description: &gt;                    Possible values are &quot;debug&quot;, &quot;notice&quot;, &quot;information&quot;, &quot;warning&quot; or                    &quot;critical&quot;.                - name: message                  type: text                  description: &gt;                    The logged message.            - name: startup              type: group              description: &gt;                Contains fields for the Icinga startup logs.              fields:                - name: facility                  type: keyword                  description: &gt;                    Specifies what component of Icinga logged the message.                - name: severity                  type: keyword                  description: &gt;                    Possible values are &quot;debug&quot;, &quot;notice&quot;, &quot;information&quot;, &quot;warning&quot; or                    &quot;critical&quot;.                - name: message                  type: text                  description: &gt;                    The logged message.    - key: iis      title: &quot;IIS&quot;      description: &gt;        Module for parsing IIS log files.      fields:        - name: iis          type: group          description: &gt;            Fields from IIS log files.          fields:            - name: access              type: group              description: &gt;                Contains fields for IIS access logs.              fields:                - name: server_ip                  type: keyword                  description: &gt;                    The server IP address.                - name: method                  type: keyword                  example: GET                  description: &gt;                    The request HTTP method.                - name: url                  type: keyword                  description: &gt;                    The request HTTP URL.                - name: query_string                  type: keyword                  description: &gt;                    The request query string, if any.                - name: port                  type: long                  description: &gt;                    The request port number.                - name: user_name                  type: keyword                  description: &gt;                    The user name used when basic authentication is used.                - name: remote_ip                  type: keyword                  description: &gt;                    The client IP address.                - name: referrer                  type: keyword                  description: &gt;                    The HTTP referrer.                - name: response_code                  type: long                  description: &gt;                    The HTTP response code.                - name: sub_status                  type: long                  description: &gt;                    The HTTP substatus code.                - name: win32_status                  type: long                  description: &gt;                    The Windows status code.                - name: request_time_ms                  type: long                  description: &gt;                    The request time in milliseconds.                - name: site_name                  type: keyword                  description: &gt;                    The site name and instance number.                - name: server_name                  type: keyword                  description: &gt;                    The name of the server on which the log file entry was generated.                - name: http_version                  type: keyword                  description: &gt;                    The HTTP version.                - name: cookie                  type: keyword                  description: &gt;                    The content of the cookie sent or received, if any.                - name: hostname                  type: keyword                  description: &gt;                    The host header name, if any.                - name: body_sent.bytes                  type: long                  format: bytes                  description: &gt;                    The number of bytes of the server response body.                - name: body_received.bytes                  type: long                  format: bytes                  description: &gt;                    The number of bytes of the server request body.                - name: agent                  type: text                  description: &gt;                    Contains the un-parsed user agent string. Only present if the user                    agent Elasticsearch plugin is not available or not used.                - name: user_agent                  type: group                  description: &gt;                    Contains the parsed user agent field. Only present if the user                    agent Elasticsearch plugin is available and used.                  fields:                    - name: device                      type: keyword                      description: &gt;                        The name of the physical device.                    - name: major                      type: long                      description: &gt;                        The major version of the user agent.                    - name: minor                      type: long                      description: &gt;                        The minor version of the user agent.                    - name: patch                      type: keyword                      description: &gt;                        The patch version of the user agent.                    - name: name                      type: keyword                      example: Chrome                      description: &gt;                        The name of the user agent.                    - name: os                      type: keyword                      description: &gt;                        The name of the operating system.                    - name: os_major                      type: long                      description: &gt;                        The major version of the operating system.                    - name: os_minor                      type: long                      description: &gt;                        The minor version of the operating system.                    - name: os_name                      type: keyword                      description: &gt;                        The name of the operating system.                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the remote_ip field.                    Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_name                      type: keyword                      description: &gt;                        The region name.                    - name: city_name                      type: keyword                      description: &gt;                        The city name.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.            - name: error              type: group              description: &gt;                Contains fields for IIS error logs.              fields:                - name: remote_ip                  type: keyword                  description: &gt;                    The client IP address.                - name: remote_port                  type: long                  description: &gt;                    The client port number.                - name: server_ip                  type: keyword                  description: &gt;                    The server IP address.                - name: server_port                  type: long                  description: &gt;                    The server port number.                - name: http_version                  type: keyword                  description: &gt;                    The HTTP version.                - name: method                  type: keyword                  example: GET                  description: &gt;                    The request HTTP method.                - name: url                  type: keyword                  description: &gt;                    The request HTTP URL.                - name: response_code                  type: long                  description: &gt;                    The HTTP response code.                - name: reason_phrase                  type: keyword                  description: &gt;                    The HTTP reason phrase.                - name: queue_name                  type: keyword                  description: &gt;                    The IIS application pool name.                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the remote_ip field.                    Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_name                      type: keyword                      description: &gt;                        The region name.                    - name: city_name                      type: keyword                      description: &gt;                        The city name.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.    - key: kafka      title: &quot;Kafka&quot;      description: &gt;        Kafka module      fields:        - name: kafka          type: group          description: &gt;          fields:            - name: log              type: group              description: &gt;                Kafka log lines.              fields:                - name: timestamp                  description: &gt;                    The timestamp from the log line.                - name: level                  example: &quot;WARN&quot;                  description: &gt;                    The log level.                - name: message                  type: text                  description: &gt;                    The logged message.                - name: component                  type: keyword                  description: &gt;                    Component the log is coming from.                - name: class                  type: text                  description: &gt;                    Java class the log is coming from.                - name: trace                  type: group                  description: &gt;                      Trace in the log line.                  fields:                    - name: class                      type: keyword                      description: &gt;                        Java class the trace is coming from.                    - name: message                      type: text                      description: &gt;                          Message part of the trace.                    - name: full                      type: text                      description: &gt;                          The full trace in the log line.    - key: kibana      title: &quot;kibana&quot;      description: &gt;        kibana Module      fields:        - name: kibana          type: group          description: &gt;          fields:            - name: log              type: group              description: &gt;                Kafka log lines.              fields:                - name: tags                  type: keyword                  description: &gt;                    Kibana logging tags.                - name: state                  type: keyword                  description: &gt;                    Current state of Kibana.                - name: meta                  type: object                  object_type: keyword    - key: logstash      title: &quot;logstash&quot;      description: &gt;        logstash Module      fields:        - name: logstash          type: group          description: &gt;          fields:            - name: log              title: &quot;Logstash&quot;              type: group              description: &gt;                Fields from the Logstash logs.              fields:                - name: message                  type: text                  description: &gt;                    Contains the un-parsed log message                - name: level                  type: keyword                  description: &gt;                    The log level of the message, this correspond to Log4j levels.                - name: module                  type: keyword                  description: &gt;                    The module or class where the event originate.                - name: thread                  type: text                  description: &gt;                    Information about the running thread where the log originate.                - name: log_event                  type: object                  description: &gt;                    key and value debugging information.            - name: slowlog              type: group              description: &gt;                slowlog              fields:                - name: message                  type: text                  description: &gt;                    Contains the un-parsed log message                - name: level                  type: keyword                  description: &gt;                    The log level of the message, this correspond to Log4j levels.                - name: module                  type: keyword                  description: &gt;                    The module or class where the event originate.                - name: thread                  type: text                  description: &gt;                    Information about the running thread where the log originate.                - name: event                  type: text                  description: &gt;                    Raw dump of the original event                - name: plugin_name                  type: keyword                  description: &gt;                    Name of the plugin                - name: plugin_type                  type: keyword                  description: &gt;                    Type of the plugin: Inputs, Filters, Outputs or Codecs.                - name: took_in_millis                  type: long                  description: &gt;                    Execution time for the plugin in milliseconds.                - name: took_in_nanos                  type: long                  description: &gt;                    Execution time for the plugin in nanoseconds.                - name: plugin_params                  type: text                  description: &gt;                    String value of the plugin configuration                - name: plugin_params_object                  type: object                  description: &gt;                    key -&gt; value of the configuration used by the plugin.    - key: mongodb      title: &quot;mongodb&quot;      description: &gt;        Module for parsing MongoDB log files.      fields:        - name: mongodb          type: group          description: &gt;              Fields from MongoDB logs.          fields:            - name: log              type: group              description: &gt;                  Contains fields from MongoDB logs.              fields:              - name: severity                description: &gt;                    Severity level of message                example: I                type: keyword              - name: component                description: &gt;                    Functional categorization of message                example: COMMAND                type: keyword              - name: context                description: &gt;                    Context of message                example: initandlisten                type: keyword              - name: message                description: &gt;                    The message in the log line.                type: text    - key: mysql      title: &quot;MySQL&quot;      description: &gt;        Module for parsing the MySQL log files.      short_config: true      fields:        - name: mysql          type: group          description: &gt;            Fields from the MySQL log files.          fields:            - name: error              type: group              description: &gt;                Contains fields from the MySQL error logs.              fields:                - name: timestamp                  description: &gt;                    The timestamp from the log line.                - name: thread_id                  type: long                  description: &gt;                    As of MySQL 5.7.2, this is the thread id. For MySQL versions prior to 5.7.2, this                    field contains the process id.                - name: level                  example: &quot;Warning&quot;                  description:                    The log level.                - name: message                  type: text                  description: &gt;                    The logged message.            - name: slowlog              type: group              description: &gt;                Contains fields from the MySQL slow logs.              fields:                - name: user                  description: &gt;                    The MySQL user that created the query.                - name: host                  description: &gt;                    The host from where the user that created the query logged in.                - name: ip                  description: &gt;                    The IP address from where the user that created the query logged in.                - name: query_time.sec                  type: float                  description: &gt;                    The total time the query took, in seconds, as a floating point number.                - name: lock_time.sec                  type: float                  description: &gt;                    The amount of time the query waited for the lock to be available. The                    value is in seconds, as a floating point number.                - name: rows_sent                  type: long                  description: &gt;                    The number of rows returned by the query.                - name: rows_examined                  type: long                  description: &gt;                    The number of rows scanned by the query.                - name: timestamp                  type: long                  description: &gt;                    The unix timestamp taken from the `SET timestamp` query.                - name: query                  description: &gt;                    The slow query.                - name: id                  type: long                  description: &gt;                    The connection ID for the query.    - key: nginx      title: &quot;Nginx&quot;      description: &gt;        Module for parsing the Nginx log files.      short_config: true      fields:        - name: nginx          type: group          description: &gt;            Fields from the Nginx log files.          fields:            - name: access              type: group              description: &gt;                Contains fields for the Nginx access logs.              fields:                - name: remote_ip_list                  type: array                  description: &gt;                    An array of remote IP addresses. It is a list because it is common to include, besides the client                    IP address, IP addresses from headers like `X-Forwarded-For`. See also the `remote_ip` field.                - name: remote_ip                  type: keyword                  description: &gt;                    Client IP address. The first public IP address from the `remote_ip_list` array. If no public IP                    addresses are present, this field contains the first private IP address from the `remote_ip_list`                    array.                - name: user_name                  type: keyword                  description: &gt;                    The user name used when basic authentication is used.                - name: method                  type: keyword                  example: GET                  description: &gt;                    The request HTTP method.                - name: url                  type: keyword                  description: &gt;                    The request HTTP URL.                - name: http_version                  type: keyword                  description: &gt;                    The HTTP version.                - name: response_code                  type: long                  description: &gt;                    The HTTP response code.                - name: body_sent.bytes                  type: long                  format: bytes                  description: &gt;                    The number of bytes of the server response body.                - name: referrer                  type: keyword                  description: &gt;                    The HTTP referrer.                - name: agent                  type: text                  description: &gt;                    Contains the un-parsed user agent string. Only present if the user                    agent Elasticsearch plugin is not available or not used.                - name: user_agent                  type: group                  description: &gt;                    Contains the parsed User agent field. Only present if the user                    agent Elasticsearch plugin is available and used.                  fields:                    - name: device                      type: keyword                      description: &gt;                        The name of the physical device.                    - name: major                      type: long                      description: &gt;                        The major version of the user agent.                    - name: minor                      type: long                      description: &gt;                        The minor version of the user agent.                    - name: patch                      type: keyword                      description: &gt;                        The patch version of the user agent.                    - name: name                      type: keyword                      example: Chrome                      description: &gt;                        The name of the user agent.                    - name: os                      type: keyword                      description: &gt;                        The name of the operating system.                    - name: os_major                      type: long                      description: &gt;                        The major version of the operating system.                    - name: os_minor                      type: long                      description: &gt;                        The minor version of the operating system.                    - name: os_name                      type: keyword                      description: &gt;                        The name of the operating system.                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the remote_ip field.                    Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_name                      type: keyword                      description: &gt;                        The region name.                    - name: city_name                      type: keyword                      description: &gt;                        The city name.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.            - name: error              type: group              description: &gt;                Contains fields for the Nginx error logs.              fields:                - name: level                  type: keyword                  description: &gt;                    Error level (e.g. error, critical).                - name: pid                  type: long                  description: &gt;                    Process identifier (PID).                - name: tid                  type: long                  description: &gt;                    Thread identifier.                - name: connection_id                  type: long                  description: &gt;                    Connection identifier.                - name: message                  type: text                  description: &gt;                    The error message    - key: osquery      title: &quot;Osquery&quot;      description: &gt;        Fields exported by the `osquery` module      fields:        - name: osquery          type: group          description: &gt;          fields:            - name: result              type: group              description: &gt;                Common fields exported by the result metricset.              fields:                - name: name                  type: keyword                  description: &gt;                    The name of the query that generated this event.                - name: action                  type: keyword                  description: &gt;                    For incremental data, marks whether the entry was added                    or removed. It can be one of &quot;added&quot;, &quot;removed&quot;, or &quot;snapshot&quot;.                - name: host_identifier                  type: keyword                  description: &gt;                    The identifier for the host on which the osquery agent is running.                    Normally the hostname.                - name: unix_time                  type: long                  description: &gt;                    Unix timestamp of the event, in seconds since the epoch. Used for computing the `@timestamp` column.                - name: calendar_time                  tupe: keyword                  description: &gt;                    String representation of the collection time, as formatted by osquery.    - key: postgresql      title: &quot;PostgreSQL&quot;      description: &gt;        Module for parsing the PostgreSQL log files.      short_config: true      fields:        - name: postgresql          type: group          description: &gt;              Fields from PostgreSQL logs.          fields:            - name: log              type: group              description: &gt;                Fields from the PostgreSQL log files.              fields:                - name: timestamp                  description: &gt;                    The timestamp from the log line.                - name: timezone                  description: &gt;                    The timezone of timestamp.                - name: thread_id                  type: long                  description: &gt;                      Process id                - name: user                  example: &quot;admin&quot;                  description:                    Name of user                - name: database                  example: &quot;mydb&quot;                  description:                    Name of database                - name: level                  example: &quot;FATAL&quot;                  description:                    The log level.                - name: duration                  type: float                  example: &quot;30.0&quot;                  description:                    Duration of a query.                - name: query                  example: &quot;SELECT * FROM users;&quot;                  description:                    Query statement.                - name: message                  type: text                  description: &gt;                    The logged message.    - key: redis      title: &quot;Redis&quot;      description: &gt;        Redis Module      fields:        - name: redis          type: group          description: &gt;          fields:            - name: log              type: group              description: &gt;                Redis log files              fields:                - name: pid                  type: long                  description: &gt;                    The process ID of the Redis server.                - name: role                  type: keyword                  description: &gt;                    The role of the Redis instance. Can be one of `master`, `slave`, `child` (for RDF/AOF writing child),                    or `sentinel`.                - name: level                  type: keyword                  description: &gt;                    The log level. Can be one of `debug`, `verbose`, `notice`, or `warning`.                - name: message                  type: text                  description: &gt;                    The log message            - name: slowlog              type: group              description: &gt;                Slow logs are retrieved from Redis via a network connection.              fields:                - name: cmd                  type: keyword                  description: &gt;                    The command executed.                - name: duration.us                  type: long                  description: &gt;                    How long it took to execute the command in microseconds.                - name: id                  type: long                  description: &gt;                    The ID of the query.                - name: key                  type: keyword                  description: &gt;                    The key on which the command was executed.                - name: args                  type: keyword                  description: &gt;                    The arguments with which the command was called.    - key: system      title: &quot;System&quot;      description: &gt;        Module for parsing system log files.      short_config: true      fields:        - name: system          type: group          description: &gt;            Fields from the system log files.          fields:            - name: auth              type: group              description: &gt;                Fields from the Linux authorization logs.              fields:                - name: timestamp                  description: &gt;                    The timestamp as read from the auth message.                - name: hostname                  description: &gt;                    The hostname as read from the auth message.                - name: program                  description: &gt;                    The process name as read from the auth message.                - name: pid                  type: long                  description: &gt;                    The PID of the process that sent the auth message.                - name: message                  type: text                  description: &gt;                    The message in the log line.                - name: user                  description: &gt;                    The Unix user that this event refers to.                - name: ssh                  type: group                  description: &gt;                    Fields specific to SSH login events.                  fields:                  - name: event                    description: &gt;                      The SSH login event. Can be one of &quot;Accepted&quot;, &quot;Failed&quot;, or &quot;Invalid&quot;. &quot;Accepted&quot;                      means a successful login. &quot;Invalid&quot; means that the user is not configured on the                      system. &quot;Failed&quot; means that the SSH login attempt has failed.                  - name: method                    description: &gt;                      The SSH authentication method. Can be one of &quot;password&quot; or &quot;publickey&quot;.                  - name: ip                    type: ip                    description: &gt;                      The client IP from where the login attempt was made.                  - name: dropped_ip                    type: ip                    description: &gt;                      The client IP from SSH connections that are open and immediately dropped.                  - name: port                    type: long                    description: &gt;                      The client port from where the login attempt was made.                  - name: signature                    description: &gt;                      The signature of the client public key.                  - name: geoip                    type: group                    description: &gt;                      Contains GeoIP information gathered based on the `system.auth.ip` field.                      Only present if the GeoIP Elasticsearch plugin is available and                      used.                    fields:                      - name: continent_name                        type: keyword                        description: &gt;                          The name of the continent.                      - name: city_name                        type: keyword                        description: &gt;                          The name of the city.                      - name: region_name                        type: keyword                        description: &gt;                          The name of the region.                      - name: country_iso_code                        type: keyword                        description: &gt;                          Country ISO code.                      - name: location                        type: geo_point                        description: &gt;                          The longitude and latitude.                      - name: region_iso_code                        type: keyword                        description: &gt;                          Region ISO code.                - name: sudo                  type: group                  description: &gt;                    Fields specific to events created by the `sudo` command.                  fields:                  - name: error                    example: user NOT in sudoers                    description: &gt;                      The error message in case the sudo command failed.                  - name: tty                    description: &gt;                      The TTY where the sudo command is executed.                  - name: pwd                    description: &gt;                      The current directory where the sudo command is executed.                  - name: user                    example: root                    description: &gt;                      The target user to which the sudo command is switching.                  - name: command                    description: &gt;                      The command executed via sudo.                - name: useradd                  type: group                  description: &gt;                    Fields specific to events created by the `useradd` command.                  fields:                  - name: name                    description: &gt;                      The user name being added.                  - name: uid                    type: long                    description:                      The user ID.                  - name: gid                    type: long                    description:                      The group ID.                  - name: home                    description:                      The home folder for the new user.                  - name: shell                    description:                      The default shell for the new user.                - name: groupadd                  type: group                  description: &gt;                    Fields specific to events created by the `groupadd` command.                  fields:                  - name: name                    description: &gt;                      The name of the new group.                  - name: gid                    type: long                    description: &gt;                      The ID of the new group.            - name: syslog              type: group              description: &gt;                Contains fields from the syslog system logs.              fields:                - name: timestamp                  description: &gt;                    The timestamp as read from the syslog message.                - name: hostname                  description: &gt;                    The hostname as read from the syslog message.                - name: program                  description: &gt;                    The process name as read from the syslog message.                - name: pid                  description: &gt;                    The PID of the process that sent the syslog message.                - name: message                  type: text                  description: &gt;                    The message in the log line.    - key: traefik      title: &quot;Traefik&quot;      description: &gt;        Module for parsing the Traefik log files.      fields:        - name: traefik          type: group          description: &gt;            Fields from the Traefik log files.          fields:            - name: access              type: group              description: &gt;                Contains fields for the Traefik access logs.              fields:                - name: remote_ip                  type: keyword                  description: &gt;                    Client IP address.                - name: user_name                  type: keyword                  description: &gt;                    The user name used when basic authentication is used.                - name: method                  type: keyword                  example: GET                  description: &gt;                    The request HTTP method.                - name: url                  type: keyword                  description: &gt;                    The request HTTP URL.                - name: http_version                  type: keyword                  description: &gt;                    The HTTP version.                - name: response_code                  type: long                  description: &gt;                    The HTTP response code.                - name: body_sent.bytes                  type: long                  format: bytes                  description: &gt;                    The number of bytes of the server response body.                - name: referrer                  type: keyword                  description: &gt;                    The HTTP referrer.                - name: agent                  type: text                  description: &gt;                    Contains the un-parsed user agent string. Only present if the user                    agent Elasticsearch plugin is not available or not used.                - name: user_agent                  type: group                  description: &gt;                    Contains the parsed User agent field. Only present if the user                    agent Elasticsearch plugin is available and used.                  fields:                    - name: device                      type: keyword                      description: &gt;                        The name of the physical device.                    - name: major                      type: long                      description: &gt;                        The major version of the user agent.                    - name: minor                      type: long                      description: &gt;                        The minor version of the user agent.                    - name: patch                      type: keyword                      description: &gt;                        The patch version of the user agent.                    - name: name                      type: keyword                      example: Chrome                      description: &gt;                        The name of the user agent.                    - name: os                      type: keyword                      description: &gt;                        The name of the operating system.                    - name: os_major                      type: long                      description: &gt;                        The major version of the operating system.                    - name: os_minor                      type: long                      description: &gt;                        The minor version of the operating system.                    - name: os_name                      type: keyword                      description: &gt;                        The name of the operating system.                - name: geoip                  type: group                  description: &gt;                    Contains GeoIP information gathered based on the remote_ip field.                    Only present if the GeoIP Elasticsearch plugin is available and                    used.                  fields:                    - name: continent_name                      type: keyword                      description: &gt;                        The name of the continent.                    - name: country_iso_code                      type: keyword                      description: &gt;                        Country ISO code.                    - name: location                      type: geo_point                      description: &gt;                        The longitude and latitude.                    - name: region_name                      type: keyword                      description: &gt;                        The region name.                    - name: city_name                      type: keyword                      description: &gt;                        The city name.                    - name: region_iso_code                      type: keyword                      description: &gt;                        Region ISO code.                - name: request_count                  type: long                  description: &gt;                    The number of requests                - name: frontend_name                  type: text                  description: &gt;                    The name of the frontend used                - name: backend_url                  type: text                  description:                    The url of the backend where request is forwarded</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tunnelblick The tmp system folder (/tmp) is not secure. 问题解决记录</title>
      <link href="/2020/04/15/MacOS-Tunnelblick/"/>
      <url>/2020/04/15/MacOS-Tunnelblick/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h3><p>MacOS 升级到 10.15 后,每次打开 Tunnelblick 都会提示 The tmp system folder (/tmp) is not secure<br>虽然点继续可以使用,但是无法打开软件的配置界面, 会直接闪退<br>于是就想着修复这个问题<br>可是过程并没有那么顺利</p><ol><li>首先查看官方文档</li></ol><p><a href="https://tunnelblick.net/cSystemFolderNotSecure.html" target="_blank" rel="noopener">https://tunnelblick.net/cSystemFolderNotSecure.html</a></p><p>根据文档提示执行操作:</p><pre><code class="bash">    sudo chown root:admin /tmp; sudo chmod 0755 /tmp    sudo chown root:wheel /private/tmp; sudo chmod 01777 /private/tmp</code></pre><p>重启,问题继续…..</p><ol start="2"><li><p>升级最新版本<br>通过查看官方文档, 了解到官方在 Tunnelblick 3.8.0+ 版本后修复这一问题<br>于是想着升级就可以了<br>首先升级到最新版本 <code>Tunnelblick 3.8.2 (build 5480)</code><br>可是,问题继续…..</p></li><li><p>完全卸载<br>于是继续查看官方文档,发现官方有个卸载程序: <code>Tunnelblick Uninstaller 1.12</code><br>于是下载下来完全卸载程序<br>之后重装,问题继续……</p></li><li><p>再读文档</p></li></ol><blockquote><p>Disconnect all configurations and quit Tunnelblick*<br>Control-click the “Uninstaller” and click “Open”<br>Click on “Test” or “Uninstall”<br>When the uninstall is complete, restart your computer.</p></blockquote><p><strong>restart your computer.</strong></p><p>我忽略了这个问题</p><p>于是完全卸载完后重启, 重启之后再重装, 问题继续……</p><p>但是这次提示不太一样, 错误信息: </p><blockquote><p>The installation or repair took too long or failed. Try again?</p></blockquote><ol start="5"><li>再次执行第一步的命令<br>重启软件,解决!!!</li></ol><p>备注: </p><p>For OS X 10.11 and higher (including all versions of macOS):</p><table><thead><tr><th>Folder</th><th>Owner</th><th>Group</th><th>Permissions</th><th>Octal</th><th>Terminal command to repair</th></tr></thead><tbody><tr><td>/Applications</td><td>root</td><td>admin</td><td>rwxrwxr-x</td><td>0775</td><td>sudo chown root:admin /Applications; sudo chmod 0775 /Applications</td></tr><tr><td>/Library</td><td>root</td><td>wheel</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:wheel /Library; sudo chmod 0755 /Library</td></tr><tr><td>/Library/Application Support</td><td>root</td><td>admin</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:admin /Library/Application\ Support; sudo chmod 0755 /Library/Application\ Support</td></tr><tr><td>/tmp (10.11 - 10.14)</td><td>root</td><td>wheel</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:wheel /tmp; sudo chmod 0755 /tmp</td></tr><tr><td>/tmp (10.15+)</td><td>root</td><td>admin</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:admin /tmp; sudo chmod 0755 /tmp</td></tr><tr><td>/private</td><td>root</td><td>wheel</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:wheel /private; sudo chmod 0755 /private</td></tr><tr><td>/private/tmp</td><td>root</td><td>wheel</td><td>rwxrwxrwt</td><td>1777</td><td>sudo chown root:wheel /private/tmp; sudo chmod 01777 /private/tmp</td></tr><tr><td>/Users</td><td>root</td><td>admin</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:admin /Users; sudo chmod 0755 /Users</td></tr><tr><td>/usr</td><td>root</td><td>wheel</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:wheel /usr; sudo chmod 0755 /usr</td></tr><tr><td>/usr/bin</td><td>root</td><td>wheel</td><td>rwxr-xr-x</td><td>0755</td><td>sudo chown root:wheel /usr; sudo chmod 0755 /usr/bin</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tunnelblick </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾之 KVR 漫游(二) --- 利用新路由 3 (Newifi D2) 组 KVR Wi-Fi 漫游</title>
      <link href="/2020/04/14/Daily-KVR-NewifiD2-JiKe/"/>
      <url>/2020/04/14/Daily-KVR-NewifiD2-JiKe/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>继续上篇文章来写, 本次基于 Breed 系统刷入集客 AP 系统, 来完成 KVR 漫游配置</p><h2 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h2><ol><li>集客 AP 固件 GECOOS_AP243P_mt7621_LLELL_5.8_2020013000.bin : <a href="http://file.cnrouter.com/index.php/Index/index.html?model_id=40&amp;device_type_id=6" target="_blank" rel="noopener">http://file.cnrouter.com/index.php/Index/index.html?model_id=40&amp;device_type_id=6</a></li></ol><p>我目前为止下载的版本为: 5.8_2020013000</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li>打开 Breed 管理界面: <a href="http://192.168.1.1" target="_blank" rel="noopener">http://192.168.1.1</a></li><li>选择固件,上传</li><li>耐心等待重启</li><li>由于 AP 没有 DHCP 功能, 没有自动分配 IP, 我们需要手动将 ip 设置为 6.6.6.x 网段, 子网掩码: 255.255.255.0, 网关不填</li><li>浏览器访问: <a href="http://6.6.6.6" target="_blank" rel="noopener">http://6.6.6.6</a>, 默认密码为 admin</li></ol><p>这时前期工作已经完成, 可以把路由器接入家里的主路由了</p><h2 id="配置-AP"><a href="#配置-AP" class="headerlink" title="配置 AP"></a>配置 AP</h2><ol><li>首先进入系统管理设置设备名称和重新修改密码</li><li>进入无线管理-&gt;SSID 设置WIFI 信息, 只要设置一台即可,下面通过克隆的方式来配置其他的 AP</li><li>进入微AC-&gt;AP列表</li></ol><p><img src="//image.joylau.cn/blog/Daily-KVR-NewifiD2-JiKe.png" alt="配置信息如下"></p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol><li><p>我三台 新路由 3,其中有一台是 1.1 版本的,无法开启 5G WIFI<br>新路由 3 版本识别:<br>查询路由器底部 SN 前三位:<br>PND: 1.1<br>MND: 1.1+<br>HND: 1.2</p></li><li><p>注意 WIFI 切换不同的信道,防止互相干扰</p></li></ol><p><img src="//image.joylau.cn/blog/Daily-KVR-NewifiD2-JiKe-2.png" alt="信道切换"></p><p>之后可以使用 WIFI 魔盒对家里的各个地方进行网速和稳定性及漫游的测试了✿✿ヽ(°▽°)ノ✿</p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾之 KVR 漫游(一) --- 新路由 3 (Newifi D2) 刷入 Breed (刷不死)固件</title>
      <link href="/2020/04/13/Daily-KVR-NewifiD2-Breed/"/>
      <url>/2020/04/13/Daily-KVR-NewifiD2-Breed/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>目前想要组 WIFI 漫游可选的方案有 AC + AP 或者 mesh 组网, 可这些的价格都不便宜, 而我选择用 2 台之前很火的矿机新路由 3 (Newifi D2) 来组 AP 实现 KVR 漫游<br>想要组 KVR 漫游, 2 台路由必须刷入集客 AP 固件, 而刷入集客 AP 固件前必须先刷入 Breed 固件<br>本篇介绍新路由 3 如何刷入该固件 </p><h2 id="我的新路由-3"><a href="#我的新路由-3" class="headerlink" title="我的新路由 3"></a>我的新路由 3</h2><p>一次性搞了 3 台</p><p><img src="//image.joylau.cn/blog/Daily-KVR-NewifiD2-Breed.jpeg" alt="新路由 3"></p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><h3 id="802-11k"><a href="#802-11k" class="headerlink" title="802.11k"></a>802.11k</h3><p>通过创建优化的频道列表，802.11k 标准可帮助设备快速搜索附近可作为漫游目标的 AP。如果当前接入点的信号强度变弱，您的设备将进行扫描来确定是否有此列表中的目标接入点。</p><h3 id="802-11v"><a href="#802-11v" class="headerlink" title="802.11v"></a>802.11v</h3><p>具备“即将解除关联”功能的 BSS 转换管理可向网络的控制层提供附近接入点的负载信息，从而影响客户端漫游行为。设备在确定可能的漫游目标时会考量这些信息。</p><p>DMS 可优化无线网络上的多播流量传输。设备会利用这些信息来增强多播通信，并保持电池续航能力。</p><p>BSS 最大空闲服务有助于客户端和接入点在没有流量传输时，高效地决定保持关联的时长。设备会利用这些信息来保持电池续航能力。</p><h3 id="802-11r"><a href="#802-11r" class="headerlink" title="802.11r"></a>802.11r</h3><p>当您的设备在同一网络中从一个 AP 漫游到另一个 AP 时，802.11r 会使用一项名为“快速基本服务集转换”(FT) 的功能更快地进行认证。FT 适用于预共享密钥 (PSK) 和 802.1X 鉴定方法。</p><p>以上来自苹果官网对于 KVR 的介绍: <a href="https://support.apple.com/zh-cn/HT202628" target="_blank" rel="noopener">https://support.apple.com/zh-cn/HT202628</a></p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="材料准备"><a href="#材料准备" class="headerlink" title="材料准备"></a>材料准备</h3><ol><li><a href="//image.joylau.cn/blog/newifi-d2-jail-break.ko" target="_blank" rel="noopener">newifi-d2-jail-break.ko</a></li></ol><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><ol><li>重置现有路由器系统: 开机状态下按住 reset 键 5 秒,等待重启</li><li>进入 <a href="http://192.168.99.1" target="_blank" rel="noopener">http://192.168.99.1</a> 初始化路由器,设置好 WIFI 和密码</li><li>浏览器访问 <a href="http://192.168.99.1/newifi/ifiwen_hss.html" target="_blank" rel="noopener">http://192.168.99.1/newifi/ifiwen_hss.html</a> 开启路由器的 ssh 登录, 用户名为 root ,密码为刚才设置的密码</li><li>使用 scp 命令拷贝 newifi-d2-jail-break.ko 到 tmp 目录下: scp ./newifi-d2-jail-break.ko <a href="mailto:root@192.168.99.1">root@192.168.99.1</a>:/tmp</li><li>刷入系统: insmod /tmp/newifi-d2-jail-break.ko </li><li>等待 30 秒左右, 断电, 再按住 reset 键通电</li><li>此时路由器分配的网段为 192.168.1.0</li><li>访问 <a href="http://192.168.1.1" target="_blank" rel="noopener">http://192.168.1.1</a> 进行设置</li></ol><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol><li>newifi-d2-jail-break.ko 是恩山论坛上一个大神破解的,如果在 Breed 官网(<a href="https://breed.hackpascal.net/)下载固件" target="_blank" rel="noopener">https://breed.hackpascal.net/)下载固件</a> <code>breed-mt7621-newifi-d2.bin</code>,是无法通过自身恢复模式刷入固件的,别问我怎么知道的</li></ol>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker Jib 插件使用问题记录</title>
      <link href="/2020/04/12/Docker-Jib/"/>
      <url>/2020/04/12/Docker-Jib/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h3><pre><code class="text">    Failed to execute goal com.google.cloud.tools:jib-maven-plugin:1.1.2:dockerBuild (default-cli) on project xxxxx: Build to Docker daemon failed, perhaps you should use a registry that supports HTTPS so credentials can be sent safely, or set the &#39;sendCredentialsOverHttp&#39; system property to true</code></pre><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>这是由于 from image 配置的基础镜像需要认证信息</p><p>提示你指定 sendCredentialsOverHttp 参数为 true 即可</p><p>于是可以在命令行手动执行:</p><pre><code class="bash">    mvn compile com.google.cloud.tools:jib-maven-plugin:1.1.2:dockerBuild -DsendCredentialsOverHttp=true</code></pre><p>注意是 DsendCredentialsOverHttp</p><p>每次去手动执行就很烦</p><p>在 idea 里配置如下, 以后双击即可构建</p><p><img src="//image.joylau.cn/blog/docker-jib-sendCredentialsOverHttp.png" alt="Docker-Jib-SendCredentialsOverHttp"></p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker LibreOffice Online Requesting address is denied&amp;#58; &amp;#58;&amp;#58; ffff&amp;#58;172.xx.xx.xx 错误解决记录</title>
      <link href="/2020/04/12/Docker-LibreOffice-Online/"/>
      <url>/2020/04/12/Docker-LibreOffice-Online/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>这是容器内使用 ipv6 造成的<br>解决方式:<br>添加参数</p><pre><code class="text">    - e &#39;extra_params=--o:ssl.enable=false --o:net.post_allow.host[0]=.\{1,99\}&#39;</code></pre><p>使用正则匹配所有 ip , 注意使用单引号, 否则反斜杠需要转义</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>各种代理设置汇总记录</title>
      <link href="/2020/04/01/Daily-Various-Proxy-Setting/"/>
      <url>/2020/04/01/Daily-Various-Proxy-Setting/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>以前博客多多少少写个一些常用工具的代理设置,这里做一个汇总, 以后有更多工具使用代理直接在此处记录了</p><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>如果代理有用户名密码的话, 使用</p><pre><code class="bash">    http://username:password@127.0.0.1:1087    # 或者    sockts5://username:password@127.0.0.1:1087</code></pre><h3 id="Mac-终端代理设置"><a href="#Mac-终端代理设置" class="headerlink" title="Mac 终端代理设置"></a>Mac 终端代理设置</h3><p><code>export HTTP_PROXY=http://127.0.0.1:1087</code></p><p><code>export SOCKS5_PROXY=socks5://127.0.0.1:1086</code></p><p><code>export ALL_PROXY=socks5://127.0.0.1:1086</code></p><p>我一般直接使用最后一种方式,简单粗暴</p><h3 id="HomeBrew-代理设置"><a href="#HomeBrew-代理设置" class="headerlink" title="HomeBrew 代理设置"></a>HomeBrew 代理设置</h3><p>同上, 因为 brew 走的 curl,代理设置通用</p><h3 id="Git-代理配置"><a href="#Git-代理配置" class="headerlink" title="Git 代理配置"></a>Git 代理配置</h3><p>需要全局 git 都走代理</p><p><code>git config --global http.proxy &#39;socks5://127.0.0.1:1080&#39;</code><br><code>git config --global https.proxy &#39;socks5://127.0.0.1:1080&#39;</code></p><p>取消</p><p><code>git config --global --unset http.proxy</code><br><code>git config --global --unset https.proxy</code></p><p>但是有时候我们并不需要所有的 git 仓库都走代理,可以去掉上述的命令中的 –global,然后到你需要走代理的那个 git 仓库下执行命令,或者添加配置:</p><p>单独配置 git 走代理<br>在 .git =&gt; config 文件中加入配置</p><pre><code class="bash">    [https]        proxy = socks5://127.0.0.1:1080    [http]        proxy = socks5://127.0.0.1:1080</code></pre><h3 id="Linux-终端代理"><a href="#Linux-终端代理" class="headerlink" title="Linux 终端代理"></a>Linux 终端代理</h3><p>同 <strong>Mac 终端代理设置</strong></p><h3 id="Ubuntu-桌面版使用全局代理"><a href="#Ubuntu-桌面版使用全局代理" class="headerlink" title="Ubuntu 桌面版使用全局代理"></a>Ubuntu 桌面版使用全局代理</h3><p>以前我使用的是: <a href="http://blog.joylau.cn/2018/08/08/Git-Proxy-And-Ubuntu-Global-Proxy/">http://blog.joylau.cn/2018/08/08/Git-Proxy-And-Ubuntu-Global-Proxy/</a><br>现在我使用的是: Clash</p><h3 id="Gradle-配置代理"><a href="#Gradle-配置代理" class="headerlink" title="Gradle 配置代理"></a>Gradle 配置代理</h3><p>配置 gradle.properties</p><pre><code class="properties">    ## http    systemProp.http.proxyHost=www.somehost.org    systemProp.http.proxyPort=8080    systemProp.http.proxyUser=userid    systemProp.http.proxyPassword=password    systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost    ## https    systemProp.https.proxyHost=www.somehost.org    systemProp.https.proxyPort=8080    systemProp.https.proxyUser=userid    systemProp.https.proxyPassword=password    systemProp.https.nonProxyHosts=*.nonproxyrepos.com|localhost</code></pre><h3 id="Docker-配置代理"><a href="#Docker-配置代理" class="headerlink" title="Docker 配置代理"></a>Docker 配置代理</h3><p>在命令行使用 export HTTP_PROXY=xxxx:xx , 命令行里绝大部分命令都可以使用此代理联网,但是安装的 docker 不行,无法 pull 下来镜像文件,想要 pull 使用代理的话,需要添加代理的变量<br>vim /usr/lib/systemd/system/docker.service<br>添加</p><p><code>Environment=HTTP_PROXY=http://xxxx:xxx</code><br><code>Environment=HTTPS_PROXY=http://xxxx:xxx</code></p><p>保存</p><p><code>systemctl deamon-reload</code><br><code>systemctl restart docker</code></p><h3 id="npm-使用代理"><a href="#npm-使用代理" class="headerlink" title="npm 使用代理"></a>npm 使用代理</h3><p>npm 支持 http 代理，但是不支持 socks 代理</p><pre><code class="bash">    npm config set proxy &quot;http://localhost:1087&quot;    npm config set https-proxy &quot;http://localhost:1087&quot;</code></pre><p>该设置方式是永久的，全局的，想要取消的话，使用</p><p>删除代理</p><pre><code class="bash">    npm config delete proxy    npm config delete https-proxy</code></pre><h3 id="apt-get-使用代理"><a href="#apt-get-使用代理" class="headerlink" title="apt-get 使用代理"></a>apt-get 使用代理</h3><p>使用参数 <code>-o Acquire</code></p><pre><code class="bash">    sudo apt-get -o Acquire::http::proxy=&quot;http://host:port&quot; update/install ...</code></pre><p>该代理是一次性的，关闭 shell 即失效</p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Proxy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>真·Docker 自动部署个人博客</title>
      <link href="/2020/03/18/Docker-Auto-Publish-Blog/"/>
      <url>/2020/03/18/Docker-Auto-Publish-Blog/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="何为-真"><a href="#何为-真" class="headerlink" title="何为 真"></a>何为 <code>真</code></h3><p>以前我都是服务器上执行定时任务,在凌晨的时候 pull 博客仓库在 hexo 编译, 在上传到 github 静态资源库, 在 pull 静态资源库到 nginx 目录下,这样实现个人博客的发布</p><p>真: 放弃定时任务, 采用 github 的钩子, 在博客仓库有 push 行为时,立马执行上述操作, 以前直接在服务器上写的脚本来执行,这次决定将这些操作打包成一个 docker 镜像, 随时随地可部署</p><p>避免了部署还需要配置定时任务和写一批脚本的问题.</p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ol><li>以 Ubuntu 18.04 为基础镜像,进行镜像的制作</li><li>docker run -it -name blog-auto-publish ubuntu:18.04 /bin/bash</li><li>apt update</li><li>apt install git</li><li>apt install vim</li><li>rm -rf /etc/apt/sources.list</li><li>vim /etc/apt/sources.list</li></ol><pre><code class="shell">    deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse    deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse    deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse    deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse    deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse    deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse    deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse    deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse    deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse    deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</code></pre><ol start="8"><li>apt update</li><li>apt install curl</li><li>curl -sL <a href="https://deb.nodesource.com/setup_13.x" target="_blank" rel="noopener">https://deb.nodesource.com/setup_13.x</a> | bash </li><li>apt-get install -y nodejs</li><li>npm install hexo -g</li><li>apt install nginx</li><li>apt install fcgiwrap</li></ol><h3 id="新建目录"><a href="#新建目录" class="headerlink" title="新建目录"></a>新建目录</h3><p>mkdir /my-blog<br>mkdir -p /my-blog/bash<br>mkdir -p /my-blog/logs</p><h3 id="克隆仓库"><a href="#克隆仓库" class="headerlink" title="克隆仓库"></a>克隆仓库</h3><p>git clone <a href="https://github.com/JoyLau/blog.git" target="_blank" rel="noopener">https://github.com/JoyLau/blog.git</a></p><p>cd blog</p><p>npm install</p><h3 id="建立命令"><a href="#建立命令" class="headerlink" title="建立命令"></a>建立命令</h3><p>vim /my-blog/bash/init.sh</p><p>vim init.sh</p><pre><code class="bash">    #!/usr/bin/env bash    chown -R www-data:www-data /my-blog/* &amp;&amp; service fcgiwrap start &amp;&amp; service nginx start &amp;&amp; tail -f -n 500 /my-blog/logs/publish.log</code></pre><p>vim /my-blog/bash/pull-deploy.sh</p><pre><code class="bash">    #! /usr/bin/env bash    cd /my-blog/blog &amp;&amp; \    ## git checkout -- _config.yml &amp;&amp; \    git pull &amp;&amp; \    echo `pwd` &amp;&amp; \    ## update config    ## sed -i &quot;s/https:\/\/name:password@github.com\/JoyLau\/blog-public.git/https:\/\/$GITHUB_REPO_USERNAME:$GITHUB_REPO_PASSWORD@github.com\/$GITHUB_REPO_USERNAME\/$GITHUB_REPO_NAME.git/g&quot; _config.yml &amp;&amp; \    ## hexo clean &amp;&amp; \    hexo g    ## hexo d</code></pre><p>vim /my-blog/bash/publish.sh</p><pre><code class="bash">    #!/bin/bash    echo &quot;Content-Type:text/html&quot;    echo &quot;&quot;    echo &quot;ok&quot;    /my-blog/bash/pull-deploy.sh&gt;/my-blog/logs/publish.log</code></pre><p>注意: 前 2 行是必须的.这样发出请求会有返回</p><h3 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h3><p>vim /etc/nginx/sites-available/default </p><pre><code class="nginx">    server {        listen 80 default_server;        listen [::]:80 default_server;        index index.html index.htm index.nginx-debian.html;        server_name _;        location / {                # First attempt to serve request as file, then                # as directory, then fall back to displaying a 404.                try_files $uri $uri/ =404;        }    }    server {            listen 8080 default_server;            listen [::]:8080 default_server;            root /my-blog/bash;            server_name _;            location ~ ^/.*\.sh  {              gzip off;              fastcgi_pass  unix:/var/run/fcgiwrap.socket;              include fastcgi_params;              fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;            }    }</code></pre><p>nginx -t 检查错误</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol><li>fcgiwrap 不能以 root 组或者 root 用户运行, 这点在配置文件 /etc/init.d/fcgiwrap 可以配置,默认为 www-data, 因此 nginx 的用户也设置为 www-data,同时设置 /my-blog 目录下所属者为 www-data</li></ol><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><pre><code class="text">    FROM nas.joylau.cn:5007/joy/blog.joylau.cn:1.0    LABEL maintainer=&quot;blog.joylau.cn&quot;    ENV GITHUB_REPO_USERNAME &quot;&quot;    ENV GITHUB_REPO_PASSWORD &quot;&quot;    ENV GITHUB_REPO_NAME &quot;&quot;    ENV REPO_INFO &quot;&quot;    EXPOSE 80    EXPOSE 8080    CMD [&quot;sh&quot;, &quot;/my-blog/bash/init.sh&quot;]</code></pre><p>打包镜像:<br>docker build -t nas.joylau.cn:5007/joy/blog.joylau.cn:1.0 .</p><p>打包后镜像大小为: 294 MB</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>docker run -p 8081:80 -p 8082:8080 -d –name blog.joylau.cn nas.joylau.cn:5007/joy/blog.joylau.cn:1.0</p><h3 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h3><ol><li>80 端口提供的服务为 blog 页面</li><li>8080 端口提供的服务为执行 shell 命令</li><li>提供 webhook 为 <a href="http://host:port/publish.sh">http://host:port/publish.sh</a> ,通过请求这个请求来更新博客</li><li>查看日志文件有 /my-blog/logs/publish.log 和 nginx 的日志文件 /var/log/nginx/error.log</li></ol><h3 id="后续优化备忘"><a href="#后续优化备忘" class="headerlink" title="后续优化备忘"></a>后续优化备忘</h3><ol><li>删除原来的 /var/log/nginx/error.log 日志里的错误信息，现有的错误信息是是测试使用产生的</li><li>在镜像里就执行一遍 chown -R www-data:www-data /my-blog/* , 否则的话容器刚启动的时候会很慢， 可以不执行 hexo g ,使用 hexo g –watch 实时监听文件变化，也不需要 nginx 了，直接使用 hexo-server ,开启 –debug 参数打印详细日志信息 </li><li>考虑将 publish.sh 的最后一行命令不等待执行完就返回，现在的情况是部署到配置较低的机器上执行很慢，会导致请求超时，虽然不影响执行结果</li><li>配置好容器内的时区，使得日志的时间戳更明显</li></ol><h3 id="优化更新记录-2020-04-01"><a href="#优化更新记录-2020-04-01" class="headerlink" title="优化更新记录 [2020-04-01]"></a>优化更新记录 [2020-04-01]</h3><ol><li>设置时区:</li></ol><pre><code class="bash">    apt-get install tzdata    然后依次选择 6 , 70 即可    使用 dpkg-reconfigure tzdata 来重写选择</code></pre><ol start="2"><li>清空 nginx 日志文件</li></ol><pre><code class="bash">    echo &quot;&quot; &gt; /var/log/nginx/error.log     echo &quot;&quot; &gt; /var/log/nginx/access.log </code></pre><ol start="3"><li>webhooks 不等待执行完就返回<br>vim /my-blog/bash/publish.sh</li></ol><pre><code class="bash">    #!/bin/bash    echo &quot;Content-Type:text/html&quot;    echo &quot;&quot;    echo &quot;ok&quot;    /my-blog/bash/pull-deploy.sh&gt;/my-blog/logs/publish.log 2&gt;&amp;1 &amp;</code></pre><ol start="4"><li>实时监听文件变化<br>vim /my-bog/bash/init.sh</li></ol><pre><code class="bash">    #!/usr/bin/env bash    service fcgiwrap start    service nginx start    cd /my-blog/blog/ &amp;&amp; nohup hexo g --watch &gt;/my-blog/logs/hexo-generate.log 2&gt;&amp;1 &amp;    tail -f -n 500 /my-blog/logs/publish.log /my-blog/logs/hexo-generate.log /var/log/nginx/error.log /var/log/nginx/access.log </code></pre><ol start="5"><li>不使用 dockerfile 来构建,直接使用 docker commit</li></ol><pre><code class="bash">    docker commit -c &#39;CMD [&quot;sh&quot;, &quot;/my-blog/bash/init.sh&quot;]&#39; -c &quot;EXPOSE 80&quot; -c &quot;EXPOSE 8080&quot; -a &quot;JoyLau&quot; -m &quot;JoyLau&#39;s Blog Docker Image&quot;  blog nas.joylau.cn:5007/joy/blog.joylau.cn:2.1</code></pre><h3 id="优化更新记录-2020-04-02"><a href="#优化更新记录-2020-04-02" class="headerlink" title="优化更新记录 [2020-04-02]"></a>优化更新记录 [2020-04-02]</h3><p>更新脚本:</p><ol><li>init.sh</li></ol><pre><code class="bash">    #!/usr/bin/env bash    echo &quot;Hello! log file in /my-blog/logs/publish.log&quot;    service fcgiwrap start    service nginx start    su - www-data -c &quot;cd /my-blog/blog/ &amp;&amp; git pull&quot;    cd /my-blog/blog/    hexo g --watch | tee -a /my-blog/logs/publish.log</code></pre><ol start="2"><li>publish.sh</li></ol><pre><code class="bash">    #!/bin/bash    echo &quot;Content-Type:text/html&quot;    echo &quot;&quot;    echo &quot;ok\r\n&quot;    /my-blog/bash/pull-deploy.sh | tee -a /my-blog/logs/publish.log</code></pre><ol start="3"><li>pull-deploy.sh</li></ol><pre><code class="bash">    #! /usr/bin/env bash    echo &quot;Prepare to update Blog Posts.....&quot;    cd /my-blog/blog/    git pull</code></pre><h3 id="优化更新记录-2020-04-07"><a href="#优化更新记录-2020-04-07" class="headerlink" title="优化更新记录 [2020-04-07]"></a>优化更新记录 [2020-04-07]</h3><p>新增 republish.sh</p><pre><code class="bash">    #!/usr/bin/env bash    echo &quot;prepare republish......&quot;    cd /my-blog/blog/    hexo clean &amp;&amp; hexo g</code></pre><p>修改 init.sh</p><pre><code class="bash">    #!/usr/bin/env bash    echo &quot;Hello! log file in /my-blog/logs/publish.log&quot;    service fcgiwrap start    service nginx start    su - www-data -c &quot;cd /my-blog/blog/ &amp;&amp; git pull &amp;&amp; hexo g --watch | tee -a /my-blog/logs/publish.log&quot;</code></pre><h3 id="使用-Dockerfile-构建-2020-04-21-更新"><a href="#使用-Dockerfile-构建-2020-04-21-更新" class="headerlink" title="使用 Dockerfile 构建 [2020-04-21 更新]"></a>使用 Dockerfile 构建 [2020-04-21 更新]</h3><p>在容器里各种操作是在是太黑箱了,日后极难维护,这里我编写 Dockerfile 来构建镜像</p><h4 id="Dockerfile-1"><a href="#Dockerfile-1" class="headerlink" title="Dockerfile"></a>Dockerfile</h4><pre><code class="dockerfile">    FROM node:latest    MAINTAINER joylau 2587038142.liu@gmail.com    LABEL Descripttion=&quot;This image is JoyLau&#39;s Bolg&quot;    ENV GIT_REPO=&quot;https://github.com/JoyLau/blog.git&quot;    ENV BRANCH master    EXPOSE 80 8081    ADD sources.list /etc/apt/sources.list    RUN apt-get update &amp;&amp;\        apt-get install -y gosu nginx git fcgiwrap &amp;&amp;\        npm install hexo -g &amp;&amp;\        npm install -g cnpm --registry=https://registry.npm.taobao.org    COPY nginx.default.conf /etc/nginx/sites-available/default    RUN mkdir -p /my-blog/bash /my-blog/logs    COPY *.sh /my-blog/bash/    RUN chown -R www-data:www-data /my-blog &amp;&amp;\        chmod -R 777 /var/www &amp;&amp;\        chmod +x /my-blog/bash/*.sh    ENTRYPOINT [&quot;/my-blog/bash/docker-entrypoint.sh&quot;]    CMD [&quot;/my-blog/bash/init.sh&quot;]</code></pre><h4 id="docker-entrypoint-sh"><a href="#docker-entrypoint-sh" class="headerlink" title="docker-entrypoint.sh"></a>docker-entrypoint.sh</h4><pre><code class="bash">    #!/bin/bash    set -e    if [ &quot;$1&quot; = &#39;/my-blog/bash/init.sh&#39; -a &quot;$(id -u)&quot; = &#39;0&#39; ]; then        service nginx start        service fcgiwrap start        echo &quot;☆☆☆☆☆ base service has started. ☆☆☆☆☆&quot;        exec gosu www-data &quot;$0&quot; &quot;$@&quot;    fi    exec &quot;$@&quot;</code></pre><h4 id="init-sh"><a href="#init-sh" class="headerlink" title="init.sh"></a>init.sh</h4><pre><code class="bash">    #! /bin/bash    cd /my-blog    echo &quot;☆☆☆☆☆ your git repo is [$GIT_REPO] ; branch is [$BRANCH]. ☆☆☆☆☆&quot;    git clone -b $BRANCH --progress $GIT_REPO blog    cd blog    cnpm install -d    hexo g --watch --debug | tee -a /my-blog/logs/genrate.log</code></pre><h4 id="nginx-default-conf"><a href="#nginx-default-conf" class="headerlink" title="nginx.default.conf"></a>nginx.default.conf</h4><pre><code class="config">    server {        listen 80 default_server;        listen [::]:80 default_server;        index index.html index.htm index.nginx-debian.html;        server_name _;        root /my-blog/blog/public;        location / {                # First attempt to serve request as file, then                # as directory, then fall back to displaying a 404.                try_files $uri $uri/ =404;        }    }    server {            listen 8081 default_server;            listen [::]:8080 default_server;            root /my-blog/bash;            server_name _;            location ~ ^/.*\.sh  {              gzip off;              fastcgi_pass  unix:/var/run/fcgiwrap.socket;              include fastcgi_params;              fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;            }    }</code></pre><h4 id="publish-sh"><a href="#publish-sh" class="headerlink" title="publish.sh"></a>publish.sh</h4><pre><code class="bash">    #!/bin/bash    echo &quot;Content-Type:text/html&quot;    echo &quot;&quot;    echo &quot;&lt;h1&gt;ok&lt;/h1&gt;&quot;    echo &quot;&lt;h3&gt;Prepare to update Blog Posts.....&lt;/h3&gt;&quot;    cd /my-blog/blog/    git pull</code></pre><h4 id="republish-sh"><a href="#republish-sh" class="headerlink" title="republish.sh"></a>republish.sh</h4><pre><code class="bash">    #!/bin/bash    echo &quot;Content-Type:text/html&quot;    echo &quot;&quot;    echo &quot;&lt;h1&gt;ok&lt;/h1&gt;&quot;    echo &quot;&lt;h3&gt;republish blog.....&lt;/h3&gt;&quot;    cd /my-blog/blog    hexo g --force</code></pre><h4 id="sources-list"><a href="#sources-list" class="headerlink" title="sources.list"></a>sources.list</h4><pre><code class="text">    deb http://mirrors.163.com/debian/ stretch main non-free contrib    deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib    deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib    deb-src http://mirrors.163.com/debian/ stretch main non-free contrib    deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib    deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib    deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib    deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib</code></pre><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><pre><code class="bash">    docker run -d --restart always --name blog -p 8001:80 -p 8002:8081 nas.joylau.cn:5007/joy/blog.joylau.cn:3.0</code></pre><h3 id="加入代理-2020-04-28更新"><a href="#加入代理-2020-04-28更新" class="headerlink" title="加入代理 [2020-04-28更新]"></a>加入代理 [2020-04-28更新]</h3><p>遇到初始化容器很慢的情况, 原因是 git clone 很慢<br>本次在 init.sh 脚本里加入了 git 代理设置, 有代理的条件的可以设置代理<br>快速启动容器</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS HomeBrew 更新遇到的问题解决</title>
      <link href="/2020/03/18/MacOS-Homebrew-Question/"/>
      <url>/2020/03/18/MacOS-Homebrew-Question/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>brew update 遇到错误, 错误信息如下:</p><pre><code class="shell">   Updating Homebrew...   Warning: You are using macOS 10.15.   We do not provide support for this pre-release version.   You will encounter build failures with some formulae.   Please create pull requests instead of asking for help on Homebrew&#39;s GitHub,   Discourse, Twitter or IRC. You are responsible for resolving any issues you   experience, as you are running this pre-release version.</code></pre><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><ol><li>brew doctor</li></ol><p>运行后发现源为科大的源, 于是切换回原来的官方的 brew 源</p><pre><code class="shell">   cd &quot;$(brew --repo)&quot;   git remote set-url origin https://github.com/Homebrew/brew.git</code></pre><p>有其他问题,建议按照提示一一解决掉  </p><ol start="2"><li>brew update</li></ol><p>更新成功</p><ol start="3"><li>brew config</li></ol><p>查看配置</p>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> brew </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS 10.15 版本里 Quick Look 插件无法使用的解决办法</title>
      <link href="/2020/03/18/MacOS-Quick-Look/"/>
      <url>/2020/03/18/MacOS-Quick-Look/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>MacOS 升级到 10.15 版本时,预览文件出现下面的提示</p><center><img src='//image.joylau.cn/blog/qlPlugin-not-work.png' alt='qlPlugin-not-work'></center><h2 id="解决方式-1"><a href="#解决方式-1" class="headerlink" title="解决方式 1"></a>解决方式 1</h2><p>删除 ~/Library/QuickLook 目录下的隔离属性 (quarantine attribute) </p><p>运行下面命令查看属性:</p><pre><code class="shell">    xattr -r ~/Library/QuickLook</code></pre><p>运行下列命令移除这些属性:</p><pre><code class="shell">    xattr -d -r com.apple.quarantine ~/Library/QuickLook</code></pre><h2 id="解决方式-2"><a href="#解决方式-2" class="headerlink" title="解决方式 2"></a>解决方式 2</h2><ol><li>空格预览文件出现下列提示,点击 取消</li></ol><center><img src='//image.joylau.cn/blog/qlPlugin-not-work.png' alt='qlPlugin-not-work'></center><ol start="2"><li>转到系统设置里</li></ol><center><img src='//image.joylau.cn/blog/qlPlugin-solution-1.png' alt='qlPlugin-solution-1'></center><p>点击 “Allow Anyway”</p><ol start="3"><li>使用下列命令打开刚才需要预览的文件</li></ol><pre><code class="shell">    qlmanage -p /path/to/any/file.js</code></pre><ol start="4"><li>此时弹出提示,点击 “open”</li></ol><center><img src='//image.joylau.cn/blog/qlPlugin-solution-2.png' alt='qlPlugin-solution-2'></center><ol start="5"><li>然后就可以预览该后缀名的所有文件了</li></ol><center><img src='//image.joylau.cn/blog/qlPlugin-solution-3.png' alt='qlPlugin-solution-3'></center><ol start="6"><li>如果需要预览其他类型的文件,则将上述步骤重新操作一遍, 换个后缀名即可</li></ol><h3 id="最后推荐"><a href="#最后推荐" class="headerlink" title="最后推荐"></a>最后推荐</h3><p>推荐下自己使用的预览插件</p><pre><code class="shell">    brew cask reinstall qlcolorcode qlstephen qlmarkdown quicklook-json qlimagesize suspicious-package quicklookase qlvideo</code></pre><p>需要注意的是 <code>qlcolorcode</code> 需要 <code>highlight</code> 库来显示高亮效果, 需要安装:  <code>brew install highlight</code></p>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 容器内 Java 应用发生 OutOfMemoryError 堆内存空间不足时, 容器无法重启应用</title>
      <link href="/2020/03/12/Docker-Java-OOM/"/>
      <url>/2020/03/12/Docker-Java-OOM/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在一次生产环境部署 elasticsearch 节点时 docker 容器设置了 –restart always,<br>此时 elasticsearch 的一个节点发生了 java.lang.OutOfMemoryError: Java heap space<br>容器并没有重启</p><p>elasticsearch 已经设置了 -Xms -Xmx</p><h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>JVM堆内存超出xmx限制，并抛java.lang.OutOfMemoryError: Java heap space异常。堆内存爆了之后，JVM和java进程会继续运行，并不会crash</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>当JVM出现 OutOfMemoryError，要让 JVM 自行退出, 这样容器就会触发重启</p><p>添加新的 jvm 配置: ExitOnOutOfMemoryError and CrashOnOutOfMemoryError</p><p>该配置支持 jdk8u92 版本及其之后的版本</p><p>地址: <a href="https://www.oracle.com/technetwork/java/javase/8u92-relnotes-2949471.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/8u92-relnotes-2949471.html</a></p><p>oracle 官网的原话: </p><p>New JVM Options added: ExitOnOutOfMemoryError and CrashOnOutOfMemoryError<br>Two new JVM flags have been added:</p><p>ExitOnOutOfMemoryError - When you enable this option, the JVM exits on the first occurrence of an out-of-memory error. It can be used if you prefer restarting an instance of the JVM rather than handling out of memory errors.</p><p>CrashOnOutOfMemoryError - If this option is enabled, when an out-of-memory error occurs, the JVM crashes and produces text and binary crash files (if core files are enabled).</p><p>ExitOnOutOfMemoryError: 启用此选项时，JVM在第一次出现内存不足错误时退出。如果您希望重新启动JVM实例而不是处理内存不足错误，则可以使用它。<br>CrashOnOutOfMemoryError: 如果启用此选项，则在发生内存不足错误时，JVM崩溃并生成文本和二进制崩溃文件（如果启用了核心文件）。</p><p>加上配置</p><blockquote><p>ES_JAVA_OPTS = “-XX:+ExitOnOutOfMemoryError”</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 知识点小记</title>
      <link href="/2020/02/18/Git-Knowledges/"/>
      <url>/2020/02/18/Git-Knowledges/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="文件回滚"><a href="#文件回滚" class="headerlink" title="文件回滚"></a>文件回滚</h2><ol><li>工作区尚未暂存的文件: git checkout – 文件名</li><li>已添加到暂存区: git reset HEAD 文件名 &amp;&amp; git checkout – 文件名</li><li>已提交到本地库, 想要撤销提交,并恢复到之前的文件内容: git reset –hard HEAD^</li></ol><p>其中:<br>git reset 有三种参数:</p><ul><li>Soft：这个模式仅仅撤销 commit 记录而已，不影响本地的任何文件，即本地修改的文件内容还会存在,也不影响（index）缓存区的任何文件。</li><li>Hard：不仅撤销 commit 记录，还将本地的文件指向 commit 前的版本，同时 index 也会指向 commit 前的版本。</li><li>Mixed：回滚 index ，其余的保持不变。</li></ul><p>另外 HEAD 后面加上 <code>~1</code> 代表回滚一次 commit 记录, <code>HEAD^</code> 代表全部 commit 记录</p><h2 id="git-fetch-和-git-pull"><a href="#git-fetch-和-git-pull" class="headerlink" title="git fetch 和 git pull"></a>git fetch 和 git pull</h2><ol><li>git fetch : 将本地仓库指向的 remote 提交记录更新为和远端一致,即最新,其他的不做任何改变</li><li>git pull : 将本地仓库和将本地仓库指向的 remote 都更新为最新, 相当于 fetch + merge</li></ol><p>参看: <a href="https://blog.csdn.net/qq_37420939/article/details/89736567" target="_blank" rel="noopener">https://blog.csdn.net/qq_37420939/article/details/89736567</a></p><h2 id="git-merge-和-git-rebase"><a href="#git-merge-和-git-rebase" class="headerlink" title="git merge 和 git rebase"></a>git merge 和 git rebase</h2><p>merge 和 rebase 都是 git pull 时的策略</p><p>git rebase 有以下几种使用场景:</p><ol><li>合并本地的多次提交记录</li></ol><p>合并最近的 4 次提交纪录</p><pre><code class="bash">    git rebase -i HEAD~4</code></pre><p>在 idea 中可以在 Version Control 中选择最早时间的提交记录, 然后选择 <code>Interactively Rebase from Here</code><br>然后除了第一个为pick外，其他选择squash，点击start rebasing，接着输入提交信息就可以把多次commit合并为一次了</p><ol start="2"><li>分支合并,可以把本地未push的分叉提交历史整理成直线</li></ol>]]></content>
      
      
      <categories>
          
          <category> Git篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React WebSocket 的一些配置</title>
      <link href="/2020/01/15/React-WebSocket/"/>
      <url>/2020/01/15/React-WebSocket/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="spring-boot-后台的配置"><a href="#spring-boot-后台的配置" class="headerlink" title="spring boot 后台的配置"></a>spring boot 后台的配置</h3><p>这里记录一些坑<br>使用 gradle 配置, 其中移除了 Tomcat , 使用的是 Undertow<br>先引入依赖</p><p><code>implementation (&#39;org.springframework.boot:spring-boot-starter-websocket&#39;)</code></p><p>提示报错 web 容器没有实现 JSR356<br>undertow 肯定是实现了 JSR356, 在 undertow-websockets-jsr 这个依赖里<br>判断肯定是由于移除 Tomcat 的问题,查看依赖发现 <code>spring-boot-starter-websocket</code> 依赖了 web , 而 web 默认使用的就是 Tomcat<br>于是移除 web 依赖即可</p><pre><code class="groovy">    implementation (&#39;org.springframework.boot:spring-boot-starter-websocket&#39;){         exclude group: &#39;org.springframework.boot&#39;, module: &#39;spring-boot-starter-web&#39;    }</code></pre><p>代码部分:</p><pre><code class="java">    @Configuration    public class WebSocketConfig implements WebSocketMessageBrokerConfigurer {        @Override        public void configureMessageBroker(MessageBrokerRegistry config) {    //        config.enableSimpleBroker(&quot;/topic&quot;);        }        @Override        public void registerStompEndpoints(StompEndpointRegistry registry) {            registry.addEndpoint(&quot;/ws&quot;)                    .setAllowedOrigins(&quot;*&quot;)                    .withSockJS();        }    }</code></pre><p>注意在启动类上加入: <code>@EnableWebSocketMessageBroker</code></p><p>这里使用的是 stomp 协议, 于是也要前端使用 stomp 配合</p><p>发送消息可以加入 @SendTo 注解, 还有一种方式, 就是使用 SimpMessagingTemplate</p><pre><code class="java">    @RestController    @RequestMapping(&quot;ws&quot;)    public class PushMessage {        private final SimpMessagingTemplate template;        public PushMessage(SimpMessagingTemplate template) {            this.template = template;        }        @GetMapping(&quot;/config&quot;)        public void configMessage() {            template.convertAndSend(&quot;/topic/public&quot;, MessageBody.success());        }    }</code></pre><h3 id="React-配置"><a href="#React-配置" class="headerlink" title="React 配置"></a>React 配置</h3><p>安装组件 npm install react-stomp<br>自行封装一个组件,如下:</p><pre><code class="js">    import React, {Component} from &#39;react&#39;;    import SockJsClient from &quot;react-stomp&quot;;    import {message} from &quot;antd&quot;;    class Websocket extends Component {        render() {            return (                &lt;div&gt;                    &lt;SockJsClient                        url={&#39;ws&#39;}                        topics={[]}                        onMessage={(payload) =&gt; {                            console.info(payload)                        }}                        onConnect={() =&gt; {                            console.info(&quot;websocket connect success&quot;)                        }}                        onConnectFailure={() =&gt; {                            message.error(&quot;websocket 连接失败!&quot;)                        }}                        onDisconnect={() =&gt; {                            console.info(&quot;websocket disconnect&quot;)                        }}                        debug={false}                        {...this.props}                    /&gt;                &lt;/div&gt;            );        }    }    export default Websocket;</code></pre><p>子组件使用: </p><pre><code class="js">    &lt;Websocket        topics={[&#39;/topic/public&#39;]}        debug={false}        onMessage={(payload) =&gt; {            // do somthing        }}    /&gt;</code></pre><h3 id="遇坑解决"><a href="#遇坑解决" class="headerlink" title="遇坑解决"></a>遇坑解决</h3><p>以上方式看起来使用没有问题,但是现实情况往往开发时前后端分离,请求后端接口往往在 node 项目里配置代理, 这里涉及到 websocket 的代理</p><p>之前的配置都是在 package.json 配置, 比如: </p><pre><code class="json">    &quot;proxy&quot;: &quot;http://localhost:8098&quot;</code></pre><p>但是这种方式对 websocket 的代理失败,会发现 websocket 连接不上</p><p>解决方式:<br>在新版的 customize-cra 的使用方式里:<br>先安装 http-proxy-middleware : npm install http-proxy-middleware<br>在 src 目录下新建文件 setupProxy.js, 名字不可改,一定要是这个文件名</p><pre><code class="js">    const proxy = require(&quot;http-proxy-middleware&quot;);    const pck = require(&#39;../package&#39;);    module.exports = app =&gt; {        app.use(            proxy(&quot;/ws&quot;,                {                    target: pck.proxy,                    ws: true                })        )    };</code></pre><p>这里开启 ws: true 即可完成 websocket 的代理.</p>]]></content>
      
      
      <categories>
          
          <category> React篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> react </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React-App-Rewired 的一些配置</title>
      <link href="/2019/12/26/React-App-Rewired/"/>
      <url>/2019/12/26/React-App-Rewired/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="添加多页面配置"><a href="#添加多页面配置" class="headerlink" title="添加多页面配置"></a>添加多页面配置</h3><p>之前写过一篇 npm eject 之后的多页面配置,可以往前翻阅 , 现在不想 eject, 该怎么配置多页面?</p><ol><li><p>npm install react-app-rewire-multiple-entry –save-dev</p></li><li><p>在 config-overrides.js 中添加配置<br>现在 public 里复制一个 html 页面, 在 src 目录下再新增一个目录,里面的文件拷贝 index 的稍微改动下,<br>大致目录如下:</p></li></ol><p>-serviceWorker.js<br>-metadata.js<br>-metadata.css<br>-logo.svg<br>-App.test.js<br>-App.js<br>-App.css</p><p>基本使用:</p><pre><code class="js">    const multipleEntry = require(&#39;react-app-rewire-multiple-entry&#39;)([{        entry: &#39;src/metadata/metadata.js&#39;,        template: &#39;public/metadata.html&#39;,        outPath: &#39;/metadata&#39;,    }]);    module.exports = {      webpack: function(config, env) {        multipleEntry.addMultiEntry(config);        return config;      }    };</code></pre><p>在 customize-cra 使用</p><pre><code class="js">    const multipleEntry = require(&#39;react-app-rewire-multiple-entry&#39;)([      {        entry: &#39;src/entry/landing.js&#39;,        template: &#39;public/landing.html&#39;,        outPath: &#39;/landing.html&#39;      }    ]);    const {      override,      overrideDevServer    } = require(&#39;customize-cra&#39;);    module.exports = {      webpack: override(        multipleEntry.addMultiEntry      )    };</code></pre><p>结合 ant-design 使用</p><pre><code class="js">    const {override, fixBabelImports, addLessLoader} = require(&#39;customize-cra&#39;);    const multipleEntry = require(&#39;react-app-rewire-multiple-entry&#39;)([{        entry: &#39;src/metadata/metadata.js&#39;,        template: &#39;public/metadata.html&#39;,        outPath: &#39;/metadata&#39;,    }]);    module.exports = override(        multipleEntry.addMultiEntry,        fixBabelImports(&#39;import&#39;, {            libraryName: &#39;antd&#39;,            libraryDirectory: &#39;es&#39;,            style: true,        }),        addLessLoader({            javascriptEnabled: true,            modifyVars: { &#39;@primary-color&#39;: &#39;#1890ff&#39; },        }),    );</code></pre><blockquote><p>注意,这样配置的话, 请求的 uri 是 /metadata, 在 build 后会生成 metadata 文件, 将打包后的文件拷贝到服务器上运行效果不好<br>一般我都注释掉 template, 再将 outPath 写成 /metadata.html</p></blockquote><h3 id="打包不生成-source-map-文件"><a href="#打包不生成-source-map-文件" class="headerlink" title="打包不生成 source-map 文件"></a>打包不生成 source-map 文件</h3><p>在 配置文件 config-overrides.js 添加 <code>process.env.GENERATE_SOURCEMAP = &quot;false&quot;;</code><br>或者  </p><p>在项目更目录下创建文件 .env, 写入: GENERATE_SOURCEMAP=false 即可.</p>]]></content>
      
      
      <categories>
          
          <category> React篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> react </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch Nested 类型动态数据的组合查询</title>
      <link href="/2019/12/23/Elasticsearch-Multi-NestedQuery/"/>
      <url>/2019/12/23/Elasticsearch-Multi-NestedQuery/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Nested 类型的数据不多说了,<br>先看 mapping:</p><pre><code class="json">    &quot;metaArray&quot;: {        &quot;type&quot;: &quot;nested&quot;,        &quot;properties&quot;: {          &quot;key&quot;: {            &quot;type&quot;: &quot;text&quot;,            &quot;analyzer&quot;: &quot;ik_max_word&quot;,            &quot;fields&quot;: {              &quot;full&quot;: {                &quot;type&quot;: &quot;keyword&quot;              }            }          },          &quot;value&quot;: {            &quot;type&quot;: &quot;text&quot;,            &quot;analyzer&quot;: &quot;ik_max_word&quot;,            &quot;fields&quot;: {              &quot;full&quot;: {                &quot;type&quot;: &quot;keyword&quot;              }            }          }        }      },</code></pre><p>再看数据:</p><pre><code class="json">    {        &quot;_index&quot;:&quot;category_libs_v1.x&quot;,        &quot;_type&quot;:&quot;category_info&quot;,        &quot;_id&quot;:&quot;526&quot;,        &quot;_version&quot;:1,        &quot;_score&quot;:1,        &quot;_source&quot;:{            &quot;categoryName&quot;:&quot;投标文件&quot;,            &quot;createTime&quot;:&quot;2019-12-23 00:07:15&quot;,            &quot;id&quot;:&quot;526&quot;,            &quot;metaArray&quot;:[                {                    &quot;value&quot;:&quot;Joy&quot;,                    &quot;key&quot;:&quot;作者&quot;                },                {                    &quot;value&quot;:&quot;txt&quot;,                    &quot;key&quot;:&quot;文件类型&quot;                }            ],            &quot;pathName&quot;:&quot;企业空间导航/业务条块&quot;,            &quot;pids&quot;:&quot;|1|525|&quot;,            &quot;status&quot;:0,            &quot;updateTime&quot;:&quot;2019-12-23 00:07:15&quot;        }    }</code></pre><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>想查作者是 Joy 并且文件类型是 txt 的记录</p><h3 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h3><p>使用 nestedQuery + queryStringQuery</p><p>语句:</p><pre><code class="json">    {        &quot;from&quot;:0,        &quot;size&quot;:10,        &quot;query&quot;:{            &quot;bool&quot;:{                &quot;must&quot;:[                    {                        &quot;nested&quot;:{                            &quot;query&quot;:{                                &quot;query_string&quot;:{                                    &quot;query&quot;:&quot;metaArray.key.full:作者 AND metaArray.value.full:Joy&quot;                                }                            },                            &quot;path&quot;:&quot;metaArray&quot;,                            &quot;score_mode&quot;:&quot;max&quot;                        }                    },                    {                        &quot;nested&quot;:{                            &quot;query&quot;:{                                &quot;query_string&quot;:{                                    &quot;query&quot;:&quot;metaArray.key.full:文件类型 AND metaArray.value.full:txt&quot;                                }                            },                            &quot;path&quot;:&quot;metaArray&quot;,                            &quot;score_mode&quot;:&quot;max&quot;                        }                    }                ]            }        }    }</code></pre><p>代码:</p><pre><code class="java">    String key = xxxx    String value = xxxx    nestedQuery(&quot;metaArray&quot;, queryStringQuery(&quot;metaArray.key.full:&quot; + key + &quot; AND metaArray.value.full:&quot; + value), ScoreMode.Max);</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开源项目申请 JetBrains 家族系列软件的 License</title>
      <link href="/2019/11/29/IntelliJIDEA-JetBrains-License/"/>
      <url>/2019/11/29/IntelliJIDEA-JetBrains-License/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>之前一直用我弟弟的学生证申请的 license,可惜今年毕业了,无法在续费申请了<br>早期已经听说 JetBrains 可以使用自己的开源项目进行申请免费的 license<br>正好使用我的这个博客来申请一波</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>前往 JetBrains 官方提供的申请链接 (<a href="https://www.jetbrains.com/shop/eform/opensource?product=ALL" target="_blank" rel="noopener">https://www.jetbrains.com/shop/eform/opensource?product=ALL</a>)</li><li>填写资料,其中注意,需要在项目的根目录下创建 License 文件,类型没有差别,我使用的是 MIT LICENSE,还有就是邮箱地址和 github profile 页面的邮箱地址一致</li><li>等待了 2 天,收到了 JetBrains 工作人员的回复</li><li>点击邮件中的 <code>Take me to my license(s)</code></li><li>使用申请的邮箱地址登录已有的账号或者创建新的账号</li><li>登录成功后点击 license tab 页面,会看到你填的项目名</li><li>点击 <code>Active subscriptions</code>, 激活,在点击 <code>Assign</code>分配使用</li><li>看到一些提示成功信息,就说明没有问题了,直接在 IDEA 的激活页面登录账户使用即可</li></ol><h3 id="小插曲"><a href="#小插曲" class="headerlink" title="小插曲"></a>小插曲</h3><p>我这里因为之前使用 QQ 邮箱创建过 JetBrains 的账号,这次不想使用新的邮箱再次创建账号<br>于是在第四步点击 <code>Take me to my license(s)</code> 后,我选择授权其他邮箱,填写邮箱地址,之后你的邮箱会收到邮件,点击接受授权的链接<br>之后的操作都一致了,成功使用我原来的邮箱获取到了 license.</p>]]></content>
      
      
      <categories>
          
          <category> IntelliJ IDEA篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IntelliJ IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring EL 表达式 ${} 和</title>
      <link href="/2019/11/20/SpringBoot-Spel/"/>
      <url>/2019/11/20/SpringBoot-Spel/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p>个人理解:<br><code>${}</code> : 用于加载外部文件中指定key的值<br><code>#{}</code> : 功能更强大的SpEl表达式，将内容赋值给属性<br><code>#{…}</code> 和 <code>${…}</code> 可以混合使用，但是必须<code>#{}</code>外面，${}在里面,#{ ‘${}’ } ，注意单引号，注意不能反过来</p><h3 id="功能"><a href="#功能" class="headerlink" title="#{} 功能"></a><strong>#{}</strong> 功能</h3><ol><li>直接量表达式: “#{‘Hello World’}”</li><li>使用java代码new/instance of: 此方法只能是java.lang 下的类才可以省略包名 #{“new Spring(‘Hello World’)”}</li><li>使用T(Type): 使用“T(Type)”来表示java.lang.Class实例，同样，只有java.lang 下的类才可以省略包名。此方法一般用来引用常量或静态方法 ,#{“T(Integer).MAX_VALUE”}</li><li>变量: 使用“#bean_id”来获取,#{“beanId.field”}</li><li>方法调用: #{“#abc.substring(0,1)”}</li><li>运算符表达式: 算数表达式,比较表达式,逻辑表达式,赋值表达式,三目表达式,正则表达式</li><li>判断空: #{“name?:’other’”}</li></ol><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>springboot 和 elasticsearch 的整合包里有一个注解<br>@Document(indexName = “”, type = “”)<br>indexName 和 type 都是字符串<br>这个注解写在实体类上,代表该实体类是一个索引<br>现在, indexName 和 type 不能为固定写死,需要从配置文件读取,<br>于是想到了 spring  的 el 表达式<br>使用<br>@Document(indexName = “${xxxx}”, type = “${xxxx}”)<br>启动后<br>无效,spring 直接将其解析成了字符串<br>于是,查看 @Document 这个注解实现的源码<br>在这个包中 org.springframework.data.elasticsearch.core.mapping 找到了实现类 SimpleElasticsearchPersistentEntity<br>其中</p><pre><code class="java">    public SimpleElasticsearchPersistentEntity(TypeInformation&lt;T&gt; typeInformation) {        super(typeInformation);        this.context = new StandardEvaluationContext();        this.parser = new SpelExpressionParser();        Class&lt;T&gt; clazz = typeInformation.getType();        if (clazz.isAnnotationPresent(Document.class)) {            Document document = clazz.getAnnotation(Document.class);            Assert.hasText(document.indexName(),                    &quot; Unknown indexName. Make sure the indexName is defined. e.g @Document(indexName=\&quot;foo\&quot;)&quot;);            this.indexName = document.indexName();            this.indexType = hasText(document.type()) ? document.type() : clazz.getSimpleName().toLowerCase(Locale.ENGLISH);            this.useServerConfiguration = document.useServerConfiguration();            this.shards = document.shards();            this.replicas = document.replicas();            this.refreshInterval = document.refreshInterval();            this.indexStoreType = document.indexStoreType();            this.createIndexAndMapping = document.createIndex();        }        if (clazz.isAnnotationPresent(Setting.class)) {            this.settingPath = typeInformation.getType().getAnnotation(Setting.class).settingPath();        }    }    @Override    public String getIndexName() {        Expression expression = parser.parseExpression(indexName, ParserContext.TEMPLATE_EXPRESSION);        return expression.getValue(context, String.class);    }    @Override    public String getIndexType() {        Expression expression = parser.parseExpression(indexType, ParserContext.TEMPLATE_EXPRESSION);        return expression.getValue(context, String.class);    }</code></pre><p>我们看到了 <code>SpelExpressionParser</code> 和 <code>ParserContext.TEMPLATE_EXPRESSION</code><br>那么这里就很肯定 indexName 和 type 是支持 spel 的写法了,只是怎么写,暂时不知道<br>再看<br>ParserContext.TEMPLATE_EXPRESSION 的源码是</p><pre><code class="java">    /**     * The default ParserContext implementation that enables template expression     * parsing mode. The expression prefix is &quot;#{&quot; and the expression suffix is &quot;}&quot;.     * @see #isTemplate()     */    ParserContext TEMPLATE_EXPRESSION = new ParserContext() {        @Override        public boolean isTemplate() {            return true;        }        @Override        public String getExpressionPrefix() {            return &quot;#{&quot;;        }        @Override        public String getExpressionSuffix() {            return &quot;}&quot;;        }    };</code></pre><p>看到上面的注释,知道是使用 #{}<br>接着<br>新建一个类,使用 @Configuration 和 @ConfigurationProperties(prefix = “xxx”) 注册一个 bean<br>再在实体类上加上注解 @Component 也注册一个bean<br>之后就可以使用 #{bean.indexName} 来读取到配置属性了</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 日志信息</title>
      <link href="/2019/11/19/Docker-Logs/"/>
      <url>/2019/11/19/Docker-Logs/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>docker 容器启动, 通过 docker logs -f container 可以实时查看日志</p><p>但是控制台输出的日志太多,会怎么样,容器里控制台输出的日志在宿主机什么位置?</p><p>有时容器输出太多,运行时间长了后,会把磁盘撑满…</p><h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>docker 里容器的日志都属于标准输出（stdout）<br>每个 container 都是一个特殊的进程，由 docker daemon 创建并启动,docker daemon 来守护和管理</p><p>docker daemon 有一个默认的日志驱动程序，默认为json-file<br>json-file 会把所有容器的标准输出和标准错误以json格式写入文件中，这个文件每行记录一个标准输出或标准错误并用时间戳注释</p><h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><ol><li><p>vim /etc/docker/daemon.json</p></li><li><p>增加一条：{“log-driver”: “none”} （也可以添加{“log-opts”: {“max-size”: “10m” }} 来控制log文件的大小）</p></li><li><p>重新加载配置文件并重启docker服务: systemctl daemon-reload</p></li></ol><h2 id="docker-compose-配置"><a href="#docker-compose-配置" class="headerlink" title="docker-compose 配置"></a>docker-compose 配置</h2><pre><code class="yaml">    logging: #        driver: &quot;json-file&quot;        options:           max-size: &quot;1g&quot;</code></pre><p>这样就不需要修改 daemon.json 配置文件了</p><h2 id="查看日志位置"><a href="#查看日志位置" class="headerlink" title="查看日志位置"></a>查看日志位置</h2><ol><li>docker inspect container_id | grep log</li><li>进入上述目录</li><li>du -sh *</li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gradle No cached version available for offline mode</title>
      <link href="/2019/11/13/Gradle-Offline-Mode/"/>
      <url>/2019/11/13/Gradle-Offline-Mode/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>在 idea 以前的版本里,在 Preferences | Build, Execution, Deployment | Gradle 去掉勾选 Offline work 即可</p><p>但是在最新版 2019.2 里,需要点击 gradle 面板里最上面一排小扳手左边一个图标,取消离线模式 </p>]]></content>
      
      
      <categories>
          
          <category> Gradle篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PM2 集群模式使用 ES6 语法</title>
      <link href="/2019/10/27/PM2-Cluster-ES6/"/>
      <url>/2019/10/27/PM2-Cluster-ES6/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li>fork 模式下</li></ol><ul><li>使用命令参数 <code>pm2 start app.js --node-args=&quot;--harmony&quot;</code></li><li>json 文件添加配置: <code>&quot;node_args&quot; : &quot;--harmony&quot;</code></li></ul><ol start="2"><li>cluster 模式下<br>使用上一篇的方法 <code>require(&quot;babel-register&quot;);</code><br>在更改配置:</li></ol><pre><code class="json">    {      &quot;apps&quot;: [        {          &quot;name&quot;: &quot;my_name&quot;,          &quot;cwd&quot;: &quot;./&quot;,          &quot;script&quot;: &quot;bin/start&quot;,          &quot;instances&quot; : &quot;max&quot;,          &quot;exec_mode&quot; : &quot;cluster&quot;,          &quot;log_date_format&quot;: &quot;YYYY-MM-DD HH:mm Z&quot;,          &quot;error_file&quot;: &quot;./logs/error.log&quot;,          &quot;watch&quot;: [&quot;routes&quot;]        }      ]    }</code></pre><p>这里需要注意:</p><ol><li>exec_mode 要改为 <code>cluster</code>, instances 为实例数, max 为 CPU 的核心数,</li><li>script 里配置的直接就是 js 文件,不需要加 node 命令(如 “script”: “node bin/start”) ,否则启动会报错,我踩过这个坑</li></ol>]]></content>
      
      
      <categories>
          
          <category> PM2篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NodeJs 使用 ES6 语法</title>
      <link href="/2019/10/26/Node-Use-ES6/"/>
      <url>/2019/10/26/Node-Use-ES6/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li>package.json 添加 </li></ol><pre><code class="json">    &quot;babel&quot;: {        &quot;presets&quot;: [          &quot;es2015&quot;        ]      },    &quot;devDependencies&quot;: {        &quot;babel-cli&quot;: &quot;^6.26.0&quot;,        &quot;babel-preset-es2015&quot;: &quot;^6.24.1&quot;,        &quot;babel-register&quot;: &quot;^6.26.0&quot;      }</code></pre><ol start="2"><li><p>npm install</p></li><li><p>有 2 种方法可配置</p></li></ol><ul><li>第一种: 启动命令改为: <code>./node_modules/.bin/babel-node app.js</code></li><li>第二种: 在 app.js 头部里添加 <code>require(&quot;babel-register&quot;);</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> Node篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle 升级到 5.x+ 之后遇到的问题记录</title>
      <link href="/2019/09/28/Gradle-Update-5-Questions/"/>
      <url>/2019/09/28/Gradle-Update-5-Questions/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="lombok-依赖编译报错"><a href="#lombok-依赖编译报错" class="headerlink" title="lombok 依赖编译报错"></a>lombok 依赖编译报错</h3><p>在gradle4.7以后对于加入依赖lombok方式发生变化，gradle4.7版本以前，可以直接如下引用：</p><pre><code class="groovy">    compile(&quot;org.projectlombok:lombok:1.18.2&quot;)或者compileOnly(&quot;org.projectlombok:lombok:1.18.2&quot;)</code></pre><p>在gradle5.0这种方式会产生警告,在gradle5.0里面会直接报编译错误</p><p>有 2 中解决方式:</p><ol><li>官方推荐</li></ol><p>开发依赖：</p><pre><code class="groovy">    annotationProcessor &#39;org.projectlombok:lombok:1.18.2&#39;    compileOnly &#39;org.projectlombok:lombok:1.18.2&#39;               </code></pre><p>测试依赖:</p><pre><code class="groovy">    testAnnotationProcessor &#39;org.projectlombok:lombok:1.18.2&#39;    testCompileOnly &#39;org.projectlombok:lombok:1.18.2&#39;</code></pre><ol start="2"><li>gradle-lombok插件方式</li></ol><pre><code class="groovy">    repositories {                       mavenCentral()              }    plugins {        id &#39;net.ltgt.apt&#39; version &#39;0.10&#39;     }    dependencies {            compileOnly &#39;org.projectlombok:lombok:1.18.2&#39;            apt &quot;org.projectlombok:lombok:1.18.2&quot;    }</code></pre><h3 id="log4j-报错"><a href="#log4j-报错" class="headerlink" title="log4j 报错"></a>log4j 报错</h3><p>错误信息:</p><pre><code class="bash">    Errors occurred while build effective model from /Users/joylau/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.16/88efb1b8d3d993fe339e9e2b201c75eed57d4c65/log4j-1.2.16.pom:    &#39;build.plugins.plugin[io.spring.gradle.dependencymanagement.org.apache.maven.plugins:maven-antrun-plugin].dependencies.dependency.scope&#39; for junit:junit:jar must be one of [compile, runtime, system] but is &#39;test&#39;. in log4j:log4j:1.2.16</code></pre><p>这是因为 Log4J 1.2.16 的 pom 中存在一个Bug。1.2.16 已经在 2010 年停止更新了<br>可以通过声明对 log4j：log4j：1.2.17 的显式依赖<br>或通过依赖关系管理确保使用 1.2.17 来解决</p><pre><code class="groovy">    implementation(&quot;log4j:log4j:1.2.17&quot;)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Gradle篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker --- Maridb 容器启动时初始化数据库</title>
      <link href="/2019/09/23/Docker-Mariadb-InitDB/"/>
      <url>/2019/09/23/Docker-Mariadb-InitDB/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="容器启动时初始化数据的方法"><a href="#容器启动时初始化数据的方法" class="headerlink" title="容器启动时初始化数据的方法"></a>容器启动时初始化数据的方法</h3><ol><li>编写好脚本,支持 .sql;.sh;.sql.gz</li><li>容器启动时, 将脚本挂载到容器的 <code>/docker-entrypoint-initdb.d</code> 目录下即可</li></ol><p>可就是这么简单的操作,我却没有成功…</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>该方法只在初始化数据库的时候起作用,意思是,当你想把 mariadb 的数据目录 <code>/var/lib/mysql</code> 挂载到本地盘上,那么 该目下有文件时,放置的脚本将不会执行</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> mariaDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- 关于自动更新的一系列折腾</title>
      <link href="/2019/09/16/Electron-AutoUpdater/"/>
      <url>/2019/09/16/Electron-AutoUpdater/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Electron-自动更新的方法"><a href="#Electron-自动更新的方法" class="headerlink" title="Electron 自动更新的方法"></a>Electron 自动更新的方法</h3><ol><li>使用 Electron 自己提供的 autoUpdater 模块</li><li>使用更新服务器</li><li>自己实现自动更新逻辑</li></ol><p>为什么说经过了一系列的折腾呢, 因为前 2 中方式都没有解决我的问题,最后我是自己实现了自动更新的逻辑<br>没有解决我的问题是因为我需要兼顾到 mac 平台和 Windows 平台,然而 mac 平台比较麻烦,代码需要签名<br>我自己亲测方式一和方式二在 mac 平台上都需要代码签名, 而签名代码需要注册苹果开发者账号,需要付年费<br>于是这 2 条路就走不通了  </p><p>最后我决定自己实现更新的逻辑</p><h3 id="更新逻辑分析"><a href="#更新逻辑分析" class="headerlink" title="更新逻辑分析"></a>更新逻辑分析</h3><ol><li>自动触发或手动触发软件更新检查</li><li>服务器版本号大于本地版本才出现更新提示</li><li>对于更新,无非就是卸载之前的版本,安装新下载的安装包</li><li>软件的打包我选择的是 Electron Builder, 分别打成 dmg , setup.exe , app.zip</li><li>更新的时候先从服务器下载新版本</li><li>下载完成后对于安装包的安装分平台来说</li></ol><h3 id="Windows-下的更新"><a href="#Windows-下的更新" class="headerlink" title="Windows 下的更新"></a>Windows 下的更新</h3><ol><li>Windows 下的安装包是 exe 可执行文件,安装包本身是有处理逻辑在里面的</li><li>于是我们只需要将安装包下载到临时目录,然后再软件里打开它,再退出软件,剩下的安装步骤交给用户</li><li>有一点需要注意的是,NSIS 的新安装包在安装前会自动卸载掉之前的版本,不过不会提示用户,我们可以在 nsis 脚本里加一个提示</li></ol><h3 id="MacOS-下的更新"><a href="#MacOS-下的更新" class="headerlink" title="MacOS 下的更新"></a>MacOS 下的更新</h3><ol><li>相比于 Windows 下的安装包, macOS 下的 dmg 安装包就没有什么逻辑了,直接打开,然后将 app 文件拖到 Applications 目录中即可完成安装</li><li>于是有 2 中方法可选</li><li>一. 挂载 dmg, 找到挂载目录,在 mac 下是 /Volumes 目录下; 删除 /Applications 下的 app, 将 /Volumes 下的 app 拷贝到 /Applications 目录下; 再卸载 dmg; 重启应用即可,该方法可实现类似无缝更新的效果</li><li>二. 和方法一一个道理,只不过不是挂载 dmg 来查找 app, 直接解压 app.zip 压缩文件即可得到 app ,在使用相同的方式覆盖即可.</li></ol><h3 id="软件的版本控制"><a href="#软件的版本控制" class="headerlink" title="软件的版本控制"></a>软件的版本控制</h3><p>可以采取一个 json 文件来记录个版本的更新记录, 这里给个参考:</p><pre><code class="json">    [      {        &quot;version&quot;: &quot;1.1.0&quot;,        &quot;force&quot;: false,        &quot;time&quot;: &quot;2019-09-14&quot;,        &quot;download&quot;: {          &quot;winSetup&quot;: &quot;&quot;,          &quot;dmg&quot;: &quot;&quot;,          &quot;appZip&quot;: &quot;&quot;        },        &quot;description&quot;: [          &quot;1. 修复若干 BUG,稳定性提升&quot;        ]      },      {        &quot;version&quot;: &quot;1.0.0&quot;,        &quot;force&quot;: false,        &quot;time&quot;: &quot;2019-09-01&quot;,        &quot;download&quot;: {          &quot;winSetup&quot;: &quot;&quot;,          &quot;dmg&quot;: &quot;&quot;,          &quot;appZip&quot;: &quot;&quot;        },        &quot;description&quot;: [          &quot;1. 全新界面,主体功能完成&quot;        ]      }    ]</code></pre><h3 id="代码参考"><a href="#代码参考" class="headerlink" title="代码参考"></a>代码参考</h3><pre><code class="js">    import $ from &#39;jquery&#39;;    import semver from &#39;semver&#39;;    import request from &#39;request&#39;;    import progress from &#39;request-progress&#39;;    //global.fs = require(&#39;fs&#39;);    //global.cp = require(&#39;child_process&#39;);    const fs = window.fs;    const cp = window.cp;    const electron = window.electron;    const {app, shell} = electron.remote;    state = {        check: true,        latest: {},        // wait,download,install,error        update: &#39;wait&#39;,        downloadState: {}    };    // 检查更新    $.ajax({        url: appConfig.updateCheckURL,        timeout: 10000,        type: &#39;GET&#39;,        cache:false,        success: function (data) {            let latest = data[0];            if(semver.satisfies(latest.version, &#39;&gt;&#39; + app.getVersion())){                if (latest.force) {                    that.updateVersion();                }            }        },        complete: function (XMLHttpRequest, status) {            that.setState({                check: false            })        }    });    updateVersion(){        let that = this;        const platform = osInfo.platform();        try {            const downloadUrl = platform === &#39;darwin&#39; ? this.state.latest.download.dmg : platform === &#39;win32&#39; ? this.state.latest.download.winSetup : &#39;&#39;;            if (downloadUrl === &#39;&#39;) return;            const downloadUrlArr = downloadUrl.split(&quot;/&quot;);            const filename = downloadUrlArr[downloadUrlArr.length-1];            const savePath = osInfo.tmpdir() + &#39;/&#39; + filename;            const _request = request(downloadUrl);            progress(_request, {                // throttle: 2000,                    // Throttle the progress event to 2000ms, defaults to 1000ms                // delay: 1000,                       // Only start to emit after 1000ms delay, defaults to 0ms                // lengthHeader: &#39;x-transfer-length&#39;  // Length header to use, defaults to content-length            })                .on(&#39;progress&#39;, function (state) {                    // The state is an object that looks like this:                    // {                    //     percent: 0.5,               // Overall percent (between 0 to 1)                    //     speed: 554732,              // The download speed in bytes/sec                    //     size: {                    //         total: 90044871,        // The total payload size in bytes                    //         transferred: 27610959   // The transferred payload size in bytes                    //     },                    //     time: {                    //         elapsed: 36.235,        // The total elapsed seconds since the start (3 decimals)                    //         remaining: 81.403       // The remaining seconds to finish (3 decimals)                    //     }                    // }                    that.setState({downloadState: state})                })                .on(&#39;error&#39;, function (err) {                    that.setState({                        downloadState:{                            error: true                        }                    })                })                .on(&#39;end&#39;, function () {                    if (that.state.update === &#39;error&#39;) return;                    that.setState({                        update: &#39;install&#39;,                    });                    setTimeout(function () {                        if (platform === &#39;darwin&#39;){                            const appName = pjson.build.productName;                            const appVersion = app.getVersion();                            console.info(appName,appVersion);                            // 挂载                            cp.execSync(`hdiutil attach &#39;${savePath}&#39; -nobrowse`, {                                stdio: [&#39;ignore&#39;, &#39;ignore&#39;, &#39;ignore&#39;]                            });                            // 覆盖原 app                            cp.execSync(`rm -rf &#39;/Applications/${appName}.app&#39; &amp;&amp; cp -R &#39;/Volumes/${appName} ${appVersion}/${appName}.app&#39; &#39;/Applications/${appName}.app&#39;`);                            // 卸载挂载的 dmg                            cp.execSync(`hdiutil eject &#39;/Volumes/${appName} ${appVersion}&#39;`, {                                stdio: [&#39;ignore&#39;, &#39;ignore&#39;, &#39;ignore&#39;]                            });                            // 重启                            app.relaunch();                            app.quit();                        }                        if (platform === &#39;win32&#39;) {                            shell.openItem(savePath);                            setTimeout(function () {                                app.quit();                            },1500)                        }                    },2000)                })                .pipe(fs.createWriteStream(savePath));            that.setState({update:&#39;download&#39;});        } catch (e) {            console.info(e);            that.setState({                update: &#39;error&#39;,            });        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- Electron-Builder 打包的各种配置</title>
      <link href="/2019/09/14/Electron-Electron-Builder/"/>
      <url>/2019/09/14/Electron-Electron-Builder/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="打包的资源无法包含-build-目录"><a href="#打包的资源无法包含-build-目录" class="headerlink" title="打包的资源无法包含 build 目录"></a>打包的资源无法包含 build 目录</h3><pre><code class="json">    &quot;files&quot;: [          &quot;**/*&quot;,          &quot;build/&quot;,          &quot;!build/static/js/*.js.map&quot;,          &quot;!src/&quot;        ],</code></pre><p>同时该配置也可防止源码被打包进去,</p><h3 id="查看打包后的目录结构"><a href="#查看打包后的目录结构" class="headerlink" title="查看打包后的目录结构"></a>查看打包后的目录结构</h3><p><code>&quot;asar&quot;: false,</code> </p><h3 id="引入外部文件"><a href="#引入外部文件" class="headerlink" title="引入外部文件"></a>引入外部文件</h3><pre><code class="json">    &quot;extraResources&quot;: [          {            &quot;from&quot;: &quot;./LICENSE&quot;,            &quot;to&quot;: &quot;./../LICENSE.txt&quot;          }        ],</code></pre><h3 id="定义安装包输出目录"><a href="#定义安装包输出目录" class="headerlink" title="定义安装包输出目录"></a>定义安装包输出目录</h3><pre><code class="json">    &quot;directories&quot;: {      &quot;output&quot;: &quot;dist&quot;    },</code></pre><h3 id="Windows-环境下打出-32-位和-64-位二合一包"><a href="#Windows-环境下打出-32-位和-64-位二合一包" class="headerlink" title="Windows 环境下打出 32 位和 64 位二合一包"></a>Windows 环境下打出 32 位和 64 位二合一包</h3><pre><code class="json">    &quot;win&quot;: {      &quot;target&quot;: [        {          &quot;target&quot;: &quot;nsis&quot;,          &quot;arch&quot;: [            &quot;ia32&quot;,            &quot;x64&quot;          ]        }      ]    },</code></pre><h3 id="打出的-mac-包写入数据到-Info-plist-文件"><a href="#打出的-mac-包写入数据到-Info-plist-文件" class="headerlink" title="打出的 mac 包写入数据到 Info.plist 文件"></a>打出的 mac 包写入数据到 Info.plist 文件</h3><pre><code class="json">   &quot;mac&quot;: {     &quot;extendInfo&quot;: {       &quot;URL types&quot;: [         {           &quot;URL identifier&quot;: &quot;Joy Security&quot;,           &quot;URL Schemes&quot;: [             &quot;joy-security&quot;           ]         }       ]     }   },</code></pre><h3 id="NSIS-配置"><a href="#NSIS-配置" class="headerlink" title="NSIS 配置"></a>NSIS 配置</h3><pre><code class="json">    &quot;nsis&quot;: {      &quot;oneClick&quot;: false, // 一键安装      &quot;perMachine&quot;: true, // 为所有用户安装      &quot;allowElevation&quot;: true, // 允许权限提升, 设置 false 的话需要重新允许安装程序      &quot;allowToChangeInstallationDirectory&quot;: true, // 允许更改安装目录      &quot;installerIcon&quot;: &quot;./public/icons/win.ico&quot;,      &quot;uninstallerIcon&quot;: &quot;./public/icons/win_uninstall.ico&quot;,      &quot;installerHeaderIcon&quot;: &quot;./public/icons/win.ico&quot;,      &quot;createDesktopShortcut&quot;: true,      &quot;createStartMenuShortcut&quot;: true,      &quot;shortcutName&quot;: &quot;Joy Security&quot;,      &quot;license&quot;: &quot;./LICENSE&quot;,      &quot;include&quot;: &quot;./public/nsis/installer.nsh&quot; // 包含的脚本    }</code></pre><h3 id="NSIS-脚本"><a href="#NSIS-脚本" class="headerlink" title="NSIS 脚本"></a>NSIS 脚本</h3><pre><code class="nsh">    !macro customHeader    !macroend    !macro preInit    !macroend    !macro customInit            # guid=7e51495b-3f4d-5235-aadd-5636863064f0            ReadRegStr $0 HKLM &quot;SOFTWARE\Microsoft\Windows\CurrentVersion\Uninstall\{7e51495b-3f4d-5235-aadd-5636863064f0}&quot; &quot;UninstallString&quot;            ${If} $0 != &quot;&quot;                MessageBox MB_ICONINFORMATION|MB_TOPMOST  &quot;检测到系统中已安装本程序，将卸载旧版本&quot; IDOK                # ExecWait $0 $1            ${EndIf}    !macroend    !macro customInstall    !macroend    !macro customInstallMode      # set $isForceMachineInstall or $isForceCurrentInstall      # to enforce one or the other modes.      #set $isForceMachineInstall    !macroend</code></pre><h3 id="NSIS-引入-license-文件包含中文的问题"><a href="#NSIS-引入-license-文件包含中文的问题" class="headerlink" title="NSIS 引入 license 文件包含中文的问题"></a>NSIS 引入 license 文件包含中文的问题</h3><p>当引入的 license 文件里有中文时, 在 Windows (中文操作系统) 平台下打包需要 GBK 编码, 在 macOS 下,GBK 编码会直接报错,需要修改为 UTF-8 编码</p>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- Windows 和 MacOS 套娃图标的制作</title>
      <link href="/2019/09/13/Electron-Icon-Icns/"/>
      <url>/2019/09/13/Electron-Icon-Icns/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="什么是套娃图标"><a href="#什么是套娃图标" class="headerlink" title="什么是套娃图标"></a>什么是套娃图标</h3><p>可能见过一种套娃的玩具,就是一个大的套着一个小的,每一个玩具的形状颜色都一样,只是大小比例不一样,套娃图标也是这个意思</p><h3 id="什么工具"><a href="#什么工具" class="headerlink" title="什么工具"></a>什么工具</h3><p>需要这么一个工具, IconFX : <a href="http://nas.joylau.cn:5000/sharing/Y3xyQ0OJV" target="_blank" rel="noopener">下载</a></p><p><img src="http://image.joylau.cn/blog/Electron-icon-icns-iconfx.png.png" alt="IconFX"></p><p>制做一组至少有 256<em>256 (此外还有 128</em>128 , 96<em>96, 64</em>64, 48<em>48,32</em>32,16*16)的一套图标, Windows 下格式为 icon, Mac 下格式为 icns</p><h3 id="怎么制作"><a href="#怎么制作" class="headerlink" title="怎么制作"></a>怎么制作</h3><p>使用 PS 制作一张图片或者下载一张图片,按照下面的步骤完成所有大小的图标创建,之后保存.</p><p>图像 — 从图像创建 Windows 图标</p><p><img src="http://image.joylau.cn/blog/Electron-icon-icns-iconfx-make.png" alt="IconFX-make"></p><p>MacOS 也是同样的道理</p>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- 在 Windows 下和在 MacOS 下 Scheme 协议的使用</title>
      <link href="/2019/09/12/Electron-URL-Scheme/"/>
      <url>/2019/09/12/Electron-URL-Scheme/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="什么是-URL-Scheme-协议"><a href="#什么是-URL-Scheme-协议" class="headerlink" title="什么是 URL Scheme 协议"></a>什么是 URL Scheme 协议</h3><p>个人理解为注册一种协议来实现应用间的跳转</p><h3 id="Windows-上的实现"><a href="#Windows-上的实现" class="headerlink" title="Windows 上的实现"></a>Windows 上的实现</h3><p>Windows 上是通过注册表实现的</p><p>通过在 HKCR (HKEY_CALSSES_ROOT) 添加一条注册表记录</p><p><img src="http://image.joylau.cn/blog/Electron-URL-Scheme-win.png" alt="Win Registry"></p><p>其中 command 的命令即为要执行的命令,注意后面要加一个参数 <code>&quot;%1&quot;</code></p><h3 id="Mac-上的实现"><a href="#Mac-上的实现" class="headerlink" title="Mac 上的实现"></a>Mac 上的实现</h3><p>在应用里显示包内容,使用 xcode 查看 Info.plist 找到 URL types – URL Schemes 里添加一项</p><p><img src="http://image.joylau.cn/blog/Electron-URL-Scheme-mac.png" alt="Mac Info.plist"></p><h3 id="Electron-的实现"><a href="#Electron-的实现" class="headerlink" title="Electron 的实现"></a>Electron 的实现</h3><pre><code class="js">   app.setAsDefaultProtocolClient(PROTOCOL, process.execPath, [`${__dirname}`]);</code></pre><p>这一句话即可完成 Windows 下和 macOS 下的协议注册,只不过需要应用启动后才可注册成功,就是说如果安装过后不打开的话,无法通过协议来唤醒应用,解决方式我们后面再讲</p><p>第一个参数为协议的名称, 第二个参数为执行的命令,第三个参数为所传字符串参数数组</p><p>在 Windows 环境下最后一项需要带上当前的项目路径,否则的话在开发模式下会打不开 electron 应用,打包完成后不会存在这个问题, mac 上也不会存在这个问题</p><h3 id="Electron-上协议参数的处理"><a href="#Electron-上协议参数的处理" class="headerlink" title="Electron 上协议参数的处理"></a>Electron 上协议参数的处理</h3><p>参数的处理分 2 中情况</p><ol><li>新打开的窗口</li><li>打开的第二个实例</li></ol><p>对于新打开的窗口:<br>使用 <code>let argv = process.argv;</code> 来获取进程参数,得到的是一个数组,如果做够一项包含我们的协议,则需要根据自己的字符串规则来进行处理</p><pre><code class="js">    let argv = process.argv;    if (argv[argv.length - 1].indexOf(PROTOCOL + &quot;://&quot;) &gt; -1) {        //.....    }</code></pre><p>对于打开的第二个实例:<br>windows 上监听的事件是 <code>second-instance</code>, mac 上监听的事件是 <code>open-url</code>, 2 个事件传入参数还不一样, Windows 下传入的参数是字符串数组,mac 传入的参数是字符串,都包含了协议名称</p><pre><code class="js">    app.on(&#39;second-instance&#39;, (event, commandLine, workingDirectory) =&gt; {        // 当运行第二个实例时,主动对焦        if (win) {            if (win.isMinimized()) win.restore();            win.focus();            win.show();            let message = handleArgv(commandLine);            processSend(message);        }    });    // macOS    app.on(&#39;open-url&#39;, (event, urlStr) =&gt; {        if (win) {            win.showInactive();            let message = handleArgv(urlStr);            processSend(message);        } else {            global.shareObject.message = handleArgv(urlStr);            global.shareObject.isSend = true;        }    });    function processSend(message) {        global.shareObject.message = message;        win.webContents.send(&#39;ch-1&#39;, &#39;send&#39;);    }    function handleArgv(argv) {        let urlObj = [];        if (Array.isArray(argv)) {            urlObj = argv[argv.length - 1].replace(PROTOCOL + &quot;://&quot;, &quot;&quot;).split(&quot;_&quot;);        } else {            urlObj = argv.replace(PROTOCOL + &quot;://&quot;, &quot;&quot;).split(&quot;_&quot;);        }        return urlObj.length &gt;= 2 ? {sessionId: urlObj[0], url: urlObj[1], macInfo: os.networkInterfaces()} : {};    }</code></pre><h3 id="浏览器判断-scheme-协议是否存在"><a href="#浏览器判断-scheme-协议是否存在" class="headerlink" title="浏览器判断 scheme 协议是否存在"></a>浏览器判断 scheme 协议是否存在</h3><p>使用 setTimeout, 如果超时未打开的话则说明协议不存在 </p><pre><code class="js">    let downloadURL = &quot;http://xxxx&quot;;    window.location = &quot;joy-security://xxxxxx_xxxxxxx&quot;;    setTimeout(function() {      window.location = downloadURL;    },1000)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- 知识点小记</title>
      <link href="/2019/09/11/Electron-Questions/"/>
      <url>/2019/09/11/Electron-Questions/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Electron-只启动一个实例"><a href="#Electron-只启动一个实例" class="headerlink" title="Electron 只启动一个实例"></a>Electron 只启动一个实例</h3><p>使用 app.requestSingleInstanceLock()</p><pre><code class="js">    const gotTheLock = app.requestSingleInstanceLock();    if (!gotTheLock) {        app.quit()    } else {        app.on(&#39;ready&#39;, createWindow);        app.on(&#39;window-all-closed&#39;, () =&gt; {            app.quit();        });        app.on(&#39;activate&#39;, () =&gt; {            if (win == null) {                createWindow();            }        });    }</code></pre><h3 id="Electron-不显示菜单栏"><a href="#Electron-不显示菜单栏" class="headerlink" title="Electron 不显示菜单栏"></a>Electron 不显示菜单栏</h3><p>经过实测<br><code>Menu.setApplicationMenu(null);</code><br>在 Windows 环境下没有菜单栏, 在 MAC 系统上开发模式下有菜单栏</p><p>正确的解决方式是<br><code>Menu.setApplicationMenu(Menu.buildFromTemplate([]));</code></p><h3 id="注册快捷键"><a href="#注册快捷键" class="headerlink" title="注册快捷键"></a>注册快捷键</h3><p>electron 自带的注册快捷键的功能函数是 globalShortcut, 这个是全局的快捷键,就是说焦点不在当前程序上也能触发快捷键<br>我这里使用的是一个第三方的组件 electron-localshortcut</p><pre><code class="js">    electronLocalshortcut.register(win, &#39;F12&#39;, function () {        win.webContents.isDevToolsOpened() ? win.webContents.closeDevTools() : win.webContents.openDevTools();    });    electronLocalshortcut.register(win, &#39;F5&#39;, function () {        win.reload();    });</code></pre><h3 id="主线程和渲染线程之间的通信"><a href="#主线程和渲染线程之间的通信" class="headerlink" title="主线程和渲染线程之间的通信"></a>主线程和渲染线程之间的通信</h3><p>这里使用的是 ipcMain 和 ipcRenderer<br>渲染进程使用ipcRenderer.send发送异步消息，然后使用on事件监控主进程的返回值。主进程使用on事件监听消息，使用event.sender.send返回数据</p><p>App.js:</p><pre><code class="js">    const {ipcRenderer} = require(&#39;electron&#39;)    ipcRenderer.send(&#39;asynchronous-message&#39;, &#39;ping&#39;)    ipcRenderer.on(&#39;asynchronous-reply&#39;, (event, arg) =&gt; {         console.log(arg) // prints &quot;pong&quot;    })</code></pre><p>main.js</p><pre><code class="js">    const {ipcMain} = require(&#39;electron&#39;)    ipcMain.on(&#39;asynchronous-message&#39;, (event, arg) =&gt; {      console.log(arg)  // prints &quot;ping&quot;      event.sender.send(&#39;asynchronous-reply&#39;, &#39;pong&#39;)    });</code></pre><p>渲染进程使用ipcRenderer.sendSync发送同步消息。主进程使用on事件监控消息，使用event.returnValue返回数据给渲染进程。返回值在渲染进程中，就直接体现为ipcRenderer.sendSync的函数返回值</p><h3 id="主线程如何给渲染线程发送消息"><a href="#主线程如何给渲染线程发送消息" class="headerlink" title="主线程如何给渲染线程发送消息"></a>主线程如何给渲染线程发送消息</h3><p>上面的示例没有说主线程如何对小渲染线程发送消息,应该这样做:</p><pre><code class="js">    win.webContents.send(&#39;ch-1&#39;, &#39;send&#39;);</code></pre><h3 id="渲染进程和渲染进程如何互发消息"><a href="#渲染进程和渲染进程如何互发消息" class="headerlink" title="渲染进程和渲染进程如何互发消息"></a>渲染进程和渲染进程如何互发消息</h3><ol><li>渲染进程的页面自己处理</li><li>通过主线程进行中间转换</li></ol><h3 id="渲染线程如何使用-electron-的功能"><a href="#渲染线程如何使用-electron-的功能" class="headerlink" title="渲染线程如何使用 electron 的功能"></a>渲染线程如何使用 electron 的功能</h3><p>渲染窗口添加配置:</p><pre><code class="js">    webPreferences: {        nodeIntegration: true, // 开启 node 功能        preload: path.join(__dirname, &#39;./public/renderer.js&#39;)    }</code></pre><p>添加 renderer.js</p><pre><code class="js">    global.electron = require(&#39;electron&#39;)</code></pre><p>渲染进程的页面使用:</p><pre><code class="js">    const electron = window.electron;    electron.xxxx</code></pre><h3 id="主线程和渲染进程如何共享对象"><a href="#主线程和渲染进程如何共享对象" class="headerlink" title="主线程和渲染进程如何共享对象"></a>主线程和渲染进程如何共享对象</h3><p>不需要引入任何包,直接在主线程使用 global</p><pre><code class="js">    // 共享对象    global.shareObject = {        osInfo: os    };</code></pre><p>渲染进程获取信息: let osInfo = electron.remote.getGlobal(‘shareObject’).osInfo;</p><p>主线程修改对象: global.shareObject.osInfo = message;</p><p>渲染线程修改对象: electron.remote.getGlobal(‘shareObject’).osInfo = null;</p><h3 id="区分开发模式还是生产模式"><a href="#区分开发模式还是生产模式" class="headerlink" title="区分开发模式还是生产模式"></a>区分开发模式还是生产模式</h3><p>建议使用 <code>app.isPackaged</code></p><h3 id="通过协议打开第二个实例的情况下触发的事件"><a href="#通过协议打开第二个实例的情况下触发的事件" class="headerlink" title="通过协议打开第二个实例的情况下触发的事件"></a>通过协议打开第二个实例的情况下触发的事件</h3><p>Windows 环境下:</p><pre><code class="js">    app.on(&#39;second-instance&#39;, (event, commandLine, workingDirectory) =&gt; {        // 当运行第二个实例时,主动对焦        if (win) {            if (win.isMinimized()) win.restore();            win.focus();            win.show();        }    });</code></pre><p>Mac 环境下:</p><pre><code class="js">    // macOS    app.on(&#39;open-url&#39;, (event, urlStr) =&gt; {        if (win) {            win.showInactive();        }    });</code></pre><h3 id="开发环境和生成环境加载不同的页面"><a href="#开发环境和生成环境加载不同的页面" class="headerlink" title="开发环境和生成环境加载不同的页面"></a>开发环境和生成环境加载不同的页面</h3><pre><code class="js">     if (app.isPackaged) {        win.loadURL(`file://${__dirname}/build/index.html`);    } else {        win.loadURL(&#39;http://localhost:3000&#39;);    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Create-React-App 的一些配置</title>
      <link href="/2019/09/10/React-Create-React-App/"/>
      <url>/2019/09/10/React-Create-React-App/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="添加多页面配置"><a href="#添加多页面配置" class="headerlink" title="添加多页面配置"></a>添加多页面配置</h3><ol><li><code>npm run eject</code></li><li>修改 webpack.config.js</li></ol><p>entry 修改:<br>这里我加了一个 update.html 页面</p><pre><code class="js">    entry: {      index: [        // Include an alternative client for WebpackDevServer. A client&#39;s job is to        // connect to WebpackDevServer by a socket and get notified about changes.        // When you save a file, the client will either apply hot updates (in case        // of CSS changes), or refresh the page (in case of JS changes). When you        // make a syntax error, this client will display a syntax error overlay.        // Note: instead of the default WebpackDevServer client, we use a custom one        // to bring better experience for Create React App users. You can replace        // the line below with these two lines if you prefer the stock client:        // require.resolve(&#39;webpack-dev-server/client&#39;) + &#39;?/&#39;,        // require.resolve(&#39;webpack/hot/dev-server&#39;),        isEnvDevelopment &amp;&amp;        require.resolve(&#39;react-dev-utils/webpackHotDevClient&#39;),        // Finally, this is your app&#39;s code:        paths.appIndexJs,        // We include the app code last so that if there is a runtime error during        // initialization, it doesn&#39;t blow up the WebpackDevServer client, and        // changing JS code would still trigger a refresh.      ].filter(Boolean),      update: [        isEnvDevelopment &amp;&amp;        require.resolve(&#39;react-dev-utils/webpackHotDevClient&#39;),        paths.appSrc + &#39;/update.js&#39;,      ].filter(Boolean),    },</code></pre><p>output 修改</p><pre><code class="js">    output: {          // The build folder.          path: isEnvProduction ? paths.appBuild : undefined,          // Add /* filename */ comments to generated require()s in the output.          pathinfo: isEnvDevelopment,          // There will be one main bundle, and one file per asynchronous chunk.          // In development, it does not produce real files.          filename: isEnvProduction            ? &#39;static/js/[name].[contenthash:8].js&#39;            : isEnvDevelopment &amp;&amp; &#39;static/js/[name]bundle.js&#39;,          // There are also additional JS chunk files if you use code splitting.          chunkFilename: isEnvProduction            ? &#39;static/js/[name].[contenthash:8].chunk.js&#39;            : isEnvDevelopment &amp;&amp; &#39;static/js/[name].chunk.js&#39;,          // We inferred the &quot;public path&quot; (such as / or /my-project) from homepage.          // We use &quot;/&quot; in development.          publicPath: publicPath,          // Point sourcemap entries to original disk location (format as URL on Windows)          devtoolModuleFilenameTemplate: isEnvProduction            ? info =&gt;                path                  .relative(paths.appSrc, info.absoluteResourcePath)                  .replace(/\\/g, &#39;/&#39;)            : isEnvDevelopment &amp;&amp;              (info =&gt; path.resolve(info.absoluteResourcePath).replace(/\\/g, &#39;/&#39;)),        },</code></pre><p>注意修改其中的 filename</p><p>HtmlWebpackPlugin 修改:<br>新增一个 HtmlWebpackPlugin </p><pre><code class="js">    new HtmlWebpackPlugin(            Object.assign(              {},              {                inject: true,                template: paths.appHtml,                chunks: [&quot;index&quot;]              },              isEnvProduction                ? {                    minify: {                      removeComments: true,                      collapseWhitespace: true,                      removeRedundantAttributes: true,                      useShortDoctype: true,                      removeEmptyAttributes: true,                      removeStyleLinkTypeAttributes: true,                      keepClosingSlash: true,                      minifyJS: true,                      minifyCSS: true,                      minifyURLs: true,                    },                  }                : undefined            )          ),          new HtmlWebpackPlugin(              Object.assign(                  {},                  {                    inject: true,                    template: paths.appHtml,                    chunks: [&quot;update&quot;],                    filename: &quot;update.html&quot;                  },                  isEnvProduction                      ? {                        minify: {                          removeComments: true,                          collapseWhitespace: true,                          removeRedundantAttributes: true,                          useShortDoctype: true,                          removeEmptyAttributes: true,                          removeStyleLinkTypeAttributes: true,                          keepClosingSlash: true,                          minifyJS: true,                          minifyCSS: true,                          minifyURLs: true,                        },                      }                      : undefined              )          ),</code></pre><p>在 public 目录里添加 update.html, 内容照抄 index.html 文件即可;<br>在 src 目录下添加 update.js 文件:</p><pre><code class="js">    import React from &#39;react&#39;;    import ReactDOM from &#39;react-dom&#39;;    import &#39;./index.css&#39;;    import Update from &#39;./page/Update&#39;;    import * as serviceWorker from &#39;./serviceWorker&#39;;    ReactDOM.render(&lt;Update /&gt;, document.getElementById(&#39;root&#39;));    serviceWorker.register();</code></pre><p>之后, <a href="http://localhost:3000/update.html" target="_blank" rel="noopener">http://localhost:3000/update.html</a> 即可访问; 如果想加个路径,直接修改 HtmlWebpackPlugin 里的 filename, 例如 <code>filename: &quot;index/update.html&quot;</code><br>就可以 使用 <a href="http://localhost:3000/index/update.html" target="_blank" rel="noopener">http://localhost:3000/index/update.html</a> 来访问</p><h3 id="引入-src-目录以外的文件报错"><a href="#引入-src-目录以外的文件报错" class="headerlink" title="引入 src 目录以外的文件报错"></a>引入 src 目录以外的文件报错</h3><p>例如需要引入 public 目录下的图片,就会报错,此时,注释掉</p><pre><code class="js">    // new ModuleScopePlugin(paths.appSrc, [paths.appPackageJson]),</code></pre><p>这一行,重启即可.</p>]]></content>
      
      
      <categories>
          
          <category> React篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> react </tag>
            
            <tag> webpack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Electron --- Create-React-App + Antd + Electron 的搭建</title>
      <link href="/2019/09/10/Electron-Create-React-App/"/>
      <url>/2019/09/10/Electron-Create-React-App/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="创建-create-react-app-antd-项目"><a href="#创建-create-react-app-antd-项目" class="headerlink" title="创建 create-react-app-antd 项目"></a>创建 create-react-app-antd 项目</h3><ol><li>git clone <a href="https://github.com/ant-design/create-react-app-antd" target="_blank" rel="noopener">https://github.com/ant-design/create-react-app-antd</a></li><li>npm install</li><li>将 webpack 所有内建的配置暴露出来, <code>npm run eject</code>, 如果发现错误,看下 package.json 里 eject 的脚本是不是为 <code>react-scripts eject</code></li><li>修改 config-overrides.js</li></ol><pre><code class="js">    module.exports = function override(config, env) {        return config;    };</code></pre><ol start="5"><li><p>修改 webpack.config.js 里的 <code>module.rules.oneOf</code> 支持 css 和 less, 添加</p><pre><code class="js"> {   test: /\.(css|less)$/,   use: [     require.resolve(&#39;style-loader&#39;),     {       loader: require.resolve(&#39;css-loader&#39;),       options: {         importLoaders: 1,       },     },     {       loader: require.resolve(&#39;postcss-loader&#39;),       options: {         // Necessary for external CSS imports to work         // https://github.com/facebookincubator/create-react-app/issues/2677         ident: &#39;postcss&#39;,         plugins: () =&gt; [           require(&#39;postcss-flexbugs-fixes&#39;),           autoprefixer({             browsers: [               &#39;&gt;1%&#39;,               &#39;last 4 versions&#39;,               &#39;Firefox ESR&#39;,               &#39;not ie &lt; 9&#39;, // React doesn&#39;t support IE8 anyway             ],             flexbox: &#39;no-2009&#39;,           }),         ],       },     },     {       loader: require.resolve(&#39;less-loader&#39;),       options: { javascriptEnabled: true }     },   ], }</code></pre></li><li><p>修改 start.js 注释掉下面代码关闭项目启动自动打开浏览器</p></li></ol><pre><code class="js">    // openBrowser(urls.localUrlForBrowser);</code></pre><ol start="7"><li><p>package.json 添加 <code>&quot;homepage&quot;: &quot;.&quot;</code> ,防止打包后的静态文件 index.html 引入 css 和 js 的路径错误</p></li><li><p>App.less 修改为 <code>@import &#39;~antd/dist/antd.less&#39;;</code></p></li></ol><h3 id="添加-electron"><a href="#添加-electron" class="headerlink" title="添加 electron"></a>添加 electron</h3><ol><li>package.json 添加 <code>&quot;main&quot;: &quot;main.js&quot;,</code> 和 electron 依赖</li></ol><pre><code class="json">    {        &quot;main&quot;: &quot;main.js&quot;,        &quot;devDependencies&quot;: {            &quot;electron&quot;: &quot;^6.0.7&quot;         }     }</code></pre><ol start="2"><li>创建 main.js,添加以下代码</li></ol><pre><code class="js">    const {app, BrowserWindow, Menu} = require(&#39;electron&#39;);    let win;    let windowConfig = {        width: 800,        height: 600,        title: &quot;Joy Security&quot;,    };    let menuTemplate = [{        label: &#39;Joy Security&#39;,        submenu: [{            label: &#39;退出&#39;,            role: &#39;quit&#39;        }, {            label: `关于 ${windowConfig.title}`,            role: &#39;about&#39;        }]    }];    app.on(&#39;ready&#39;, createWindow);    app.on(&#39;window-all-closed&#39;, () =&gt; {        app.quit();    });    app.on(&#39;activate&#39;, () =&gt; {        if (win == null) {            createWindow();        }    });    function createWindow() {        // 隐藏菜单栏,兼容 MAC        Menu.setApplicationMenu(Menu.buildFromTemplate([]));        win = new BrowserWindow(windowConfig);        win.loadURL(&#39;http://localhost:3000&#39;);        win.on(&#39;close&#39;, () =&gt; {            //回收BrowserWindow对象            win = null;        });        win.on(&#39;resize&#39;, () =&gt; {            // win.reload();        });    }</code></pre><ol start="3"><li>package.json 更改脚本</li></ol><pre><code class="json">    {    &quot;scripts&quot;: {        &quot;react-start&quot;: &quot;node scripts/start.js&quot;,        &quot;eletron-start&quot;: &quot;electron .&quot;,        &quot;react-build&quot;: &quot;node scripts/build.js&quot;,      }    }</code></pre><ol start="4"><li>启动时先 react-start 再 eletron-start 即可看到效果</li></ol>]]></content>
      
      
      <categories>
          
          <category> Electron篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Electron </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖系列 --- 添加私有仓库无法下载镜像问题的解决</title>
      <link href="/2019/09/09/Synology-Docker-Insecure/"/>
      <url>/2019/09/09/Synology-Docker-Insecure/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在群晖的 Docker 组件里添加了个人的私有仓库,发现却无法下载镜像….</p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>在 Docker 组件里添加新的仓库,并设置为使用仓库,发现在仓库里下载镜像总是失败,状态栏提示查看日志,可是在日志里总看不到东西</p><p>想了想,可能是新添加的 docker 私服是 http 的服务,而不是 https</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ol><li>于是我使用 GateOne 组件进入 shell </li><li>使用命令 docker pull xxx:xxx, 发现报错 <code>Get https://172.18.18.90:5000/v2/: http: server gave HTTP response to HTTPS client</code> , 果然是这个问题</li><li>于是找到 Docker 组件的配置文件目录,在 <code>/var/packages/Docker/etc</code> 目录下,添加配置文件 daemon.json </li></ol><pre><code class="json">    {    &quot;insecure-registries&quot;: [&quot;domain:5000&quot;]    }</code></pre><ol start="4"><li>重启 Docker 组件, 发现不起作用,在命令行下 pull 依然报错,可想配置文件错了</li><li>转眼看到一个可疑的配置文件 <code>dockerd.json</code>, 里面已经有一些配置了,于是就把配置写到这个里面</li><li>再重启,问题解决.可见群晖对于 docker 是做了一些改变的.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 群晖篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoSetup --- 使用心得记录</title>
      <link href="/2019/09/04/InnoSetup-Experience/"/>
      <url>/2019/09/04/InnoSetup-Experience/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="添加环境变量【Registry】"><a href="#添加环境变量【Registry】" class="headerlink" title="添加环境变量【Registry】"></a>添加环境变量【Registry】</h2><pre><code class="text">   [Registry]   Root: HKCR; Subkey: &quot;JOY-SECURITY&quot;; ValueType: string; ValueData: &quot;URL:JOY-SECURITY Protocol Handler&quot;; Flags: uninsdeletekey</code></pre><h3 id="Root-必需的"><a href="#Root-必需的" class="headerlink" title="Root  (必需的)"></a>Root  (必需的)</h3><p>根键。必须是下列值中的一个:</p><p>HKCR  (HKEY_CLASSES_ROOT)<br>HKCU  (HKEY_CURRENT_USER)<br>HKLM  (HKEY_LOCAL_MACHINE)<br>HKU  (HKEY_USERS)<br>HKCC  (HKEY_CURRENT_CONFIG) </p><h3 id="Subkey-必需的"><a href="#Subkey-必需的" class="headerlink" title="Subkey  (必需的)"></a>Subkey  (必需的)</h3><p>子键名，可以包含常量。</p><h3 id="ValueType"><a href="#ValueType" class="headerlink" title="ValueType"></a>ValueType</h3><p>值的数据类型。必须是下面中的一个:</p><p>none<br>string<br>expandsz<br>multisz<br>dword<br>qword<br>binary </p><p>如果指定了 none (默认设置)，安装程序将创建一个没有键值的键，在这种情况下，ValueData 参数将被忽略。<br>如果指定了 string，安装程序将创建一个字符串 (REG_SZ) 值。<br>如果指定了 expandsz，安装程序将创建一个扩展字符串 (REG_EXPAND_SZ) 值。<br>如果指定了 multisz，安装程序将创建一个多行文本 (REG_MULTI_SZ) 值。<br>如果指定了 dword，安装程序将创建一个32位整数 (REG_DWORD) 值。<br>如果指定了 qdword，安装程序将创建一个64位整数 (REG_QDWORD) 值。<br>如果指定了 binary，安装程序将创建一个二进制 (REG_BINARY) 值。</p><h3 id="Flags"><a href="#Flags" class="headerlink" title="Flags"></a>Flags</h3><p>这个参数是额外选项设置。多个选项可以使用空格隔开。支持下面的选项:</p><p>createvalueifdoesntexist<br>当指定了这个标记，安装程序只在如果没有相同名字的值存在时创建值。如果值类型是 none，或如果你指定了 deletevalue 标记，这个标记无效。</p><p>deletekey<br>当指定了这个标记，安装程序在如果条目存在的情况下，先将尝试删除它，包括其中的所有值和子键。如果 ValueType 不是 none，那么它将创建一个新的键和值。</p><p>要防止意外，如果 Subkey 是空白的或只包含反斜框符号，安装时这个标记被忽略。</p><p>deletevalue<br>当指定了这个标记，安装程序在如果值存在的情况下，先将尝试删除值，如果 ValueType 是 none，那么在键不存在的情况下，它将创建键以及新值。</p><p>dontcreatekey<br>当指定了这个标记，如果键已经在用户系统中不存在，安装程序将不尝试创建键或值。如果键不存在，不显示错误消息。</p><p>一般来说，这个键与 uninsdeletekey 标记组合使用，在卸载时删除键，但安装时不创建键。</p><p>noerror<br>如果安装程序因任何原因创建键或值失败，不显示错误消息。</p><p>preservestringtype<br>这只在当 ValueType 参数是 string 或 expandsz 时适用。当指定这个标记，并且值不存在或现有的值不是 string 类型 (REG_SZ 或 REG_EXPAND_SZ)，它将用 ValueType 指定的类型创建。如果值存在，并且是 string 类型，它将用先存在值的相同值类型替换。</p><p>uninsclearvalue<br>当卸载程序时，设置值数据为空字符 (类型 REG_SZ)。这个标记不能与 uninsdeletekey 标记组合使用。</p><p>uninsdeletekey<br>当卸载程序时，删除整个键，包含其中的所有值和子键。这对于 Windows 自身使用的键明显不是一个好方法。你只能用于你的应用程序特有的键中。</p><p>为防止意外，安装期间如果 Subkey 空白或只包含反斜框符号，这个标记被忽略。</p><p>uninsdeletekeyifempty<br>当程序卸载时，如果这个键的内部没有值或子键，则删除这个键。这个标记可以与 uninsdeletevalue 组合使用</p><p>为防止意外，安装期间如果 Subkey 空白或只包含反斜框符号，这个标记被忽略。</p><p>uninsdeletevalue<br>当程序卸载时删除该值。这个标记不能与 uninsdeletekeyifempty 组合使用</p><p>注意: 在早于 1.1 的 Inno Setup 版本中，你可以使用这个标记连同数据类型 none，那么它的功能与“如果空则删除键”标记一样。这个方法已经不支持了。你必须使用 uninsdeletekeyifempty 标记实现。</p><h2 id="添加环境变量【Code】"><a href="#添加环境变量【Code】" class="headerlink" title="添加环境变量【Code】"></a>添加环境变量【Code】</h2><pre><code class="pascal">    //添加环境变量    procedure CurStepChanged(CurStep: TSetupStep);    var    oldpath:    String;    newpath:    String;    ErrorCode: Integer;    begin    if CurStep = ssPostInstall then    begin       RegQueryStringValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;Path&#39;, oldPath);       newPath := oldPath + &#39;;%JAVA_HOME%\bin\;&#39;;       RegWriteStringValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;PATH&#39;, newPath);       RegWriteStringValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;JAVA_HOME&#39;, ExpandConstant(&#39;{app}\java\jdk1.8.0_45&#39;));    end;    end; </code></pre><p>添加环境变量后记得在 setup 中配置 <code>ChangesEnvironment=yes</code> 通知其他应用程序从注册表重新获取环境变量</p><h2 id="删除环境变量【Code】"><a href="#删除环境变量【Code】" class="headerlink" title="删除环境变量【Code】"></a>删除环境变量【Code】</h2><pre><code class="pascal">    procedure CurUninstallStepChanged(CurUninstallStep: TUninstallStep);    var    oldpath:    String;    newpath:    String;    begin    if CurUninstallStep = usDone then       RegDeleteValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;JAVA_HOME&#39;);       RegQueryStringValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;Path&#39;, oldPath);       StringChangeEx(oldPath, &#39;;%JAVA_HOME%\bin\;&#39;, &#39;&#39;, True);       newPath := oldPath;       RegWriteStringValue(HKEY_LOCAL_MACHINE, &#39;SYSTEM\CurrentControlSet\Control\Session Manager\Environment&#39;, &#39;PATH&#39;, newPath);    end;</code></pre><h2 id="安装完成后执行脚本"><a href="#安装完成后执行脚本" class="headerlink" title="安装完成后执行脚本"></a>安装完成后执行脚本</h2><pre><code class="text">    [Run]    Filename: &quot;{app}\service-install.bat&quot;; Description: &quot;{cm:LaunchProgram,{#StringChange(&#39;SERVICE_INSTALL&#39;, &#39;&amp;&#39;, &#39;&amp;&amp;&#39;)}}&quot;; Flags: shellexec postinstall waituntilterminated runascurrentuser</code></pre><h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><p>程序的可选命令行参数，可以包含常量。</p><h3 id="Flags-1"><a href="#Flags-1" class="headerlink" title="Flags"></a>Flags</h3><p>这个参数是额外选项设置。多个选项可以使用空格隔开。支持下面的选项:</p><p>32bit<br>Causes the {sys} constant to map to the 32-bit System directory when used in the Filename and WorkingDir parameters. This is the default behavior in a 32-bit mode install。</p><p>这个标记不能与 shellexec 组合使用。</p><p>64bit<br>Causes the {sys} constant to map to the 64-bit System directory when used in the Filename and WorkingDir parameters. This is the default behavior in a 64-bit mode install。</p><p>This flag can only be used when Setup is running on 64-bit Windows, otherwise an error will occur. On an installation supporting both 32- and 64-bit architectures, it is possible to avoid the error by adding a Check: IsWin64 parameter, which will cause the entry to be silently skipped when running on 32-bit Windows。</p><p>这个标记不能与 shellexec 组合使用。</p><p>hidewizard<br>如果指定了这个标记，向导将在程序运行期间隐藏。</p><p>nowait<br>如果指定了这个标记，它将在处理下一个 [Run] 条目前或完成安装前不等待进程执行完成。不能与 waituntilidle 或 waituntilterminated 组合使用。</p><p>postinstall<br>仅在 [Run] 段有效。告诉安装程序在安装完成向导页创建一个选择框，用户可以选中或不选中这个选择框从而决定是否处理这个条目。以前这个标记调用 showcheckbox。</p><p>如果安装程序已经重新启动了用户的电脑 (安装了一个带 restartreplace 标记的文件或如果 [Setup] 段的 AlwaysRestart 指令是 yes 引起的)，选择框没有机会出现，因此这些条目不会被处理。</p><p>[Files] 段条目中的 isreadme 标记现在已被废弃。如果编译器带 isreadme 标记的条目，它将从 [Files] 段条目中忽略这个标记，并在 [Run] 段条目列表的开头插入一个生成的 [Run] 条目。这相生成的 [Run] 段条目运行自述文件，并带有 shellexec，skipifdoesntexist，postinstall 和 skipifsilent 标记。</p><p>runascurrentuser<br>如果指定了这个标记，the spawned process will inherit Setup/Uninstall’s user credentials (typically, full administrative privileges)。</p><p>This is the default behavior when the postinstall flag is not used。</p><p>这个标记不能与 runasoriginaluser 组合使用。</p><p>runasoriginaluser<br>仅在 [Run] 段有效。If this flag is specified and the system is running Windows Vista or later, the spawned process will execute with the (normally non-elevated) credentials of the user that started Setup initially (i.e., the “pre-UAC dialog” credentials)。</p><p>This is the default behavior when the postinstall flag is used。</p><p>If a user launches Setup by right-clicking its EXE file and selecting “Run as administrator”, then this flag, unfortunately, will have no effect, because Setup has no opportunity to run any code with the original user credentials. The same is true if Setup is launched from an already-elevated process. Note, however, that this is not an Inno Setup-specific limitation; Windows Installer-based installers cannot return to the original user credentials either in such cases。</p><p>这个标记不能与 runascurrentuser 组合使用。</p><p>runhidden<br>如果指定了这个标记，它将在隐藏窗口中运行程序。请在执行一个要提示用户输入的程序中不要使用这个标记。</p><p>runmaximized<br>如果指定了这个标记，将在最大化窗口运行程序或文档。</p><p>runminimized<br>如果指定了这个标记，将在最小化窗口运行程序或文档。</p><p>shellexec<br>如果 Filename 不是一个直接可执行文件 (.exe 或 .com 文件)，这个标记是必需的。当设置这个标记时，Filename 可以是一个文件夹或任何已注册的文件类型 – 包括 .hlp，.doc 等。该文件将用用户系统中与这个文件类型关联的应用程序打开，与在资源管理器双击文件的方法是相同的。</p><p>按默认，当使用 shellexec 标记时，将不等待，直到生成的进程终止。<br>如果你需要，你必须添加标记 waituntilterminated。注意，如果新进程未生成，它不能执行也将不等待 – 例如，文件指定指定为一个文件夹。</p><p>skipifdoesntexist<br>如果这个标记在 [Run] 段中指定，如果 Filename 不存在，安装程序不显示错误消息。</p><p>如果这个标记在 [UninstallRun] 段中指定，如果 Filename 不存在，卸载程序不显示“一些元素不能删除”的警告。</p><p>在使用这个标记时， Filename 必须是一个绝对路径。</p><p>skipifnotsilent<br>仅在 [Run] 段有效。告诉安装程序如果安装程序未在后台运行则跳过这个条目。</p><p>skipifsilent<br>仅在 [Run] 段有效。告诉安装程序如果安装程序在后台运行则跳过这个条目。</p><p>unchecked<br>仅在 [Run] 段有效。告诉安装程序初始为不选中选择框。如果用户希望处理这个条目，可以通过选取选择框执行。如果 postinstall 标记未同时指定，这个标记被忽略。</p><p>waituntilidle<br>如果指定了这个标记，它将在未输入期间等待，直到进程等待用户输入，而不是等待进程终止。(调用 WaitForInputIdle Win32 函数。) 不能与 nowait 或 waituntilterminated 组合使用。</p><p>waituntilterminated<br>如果指定这个标记，将等待到进程完全终止。注意这是一个默认动作 (也就是你不需要指定这个标记)，除非你使用了 shellexec 标记，在这种情况下，如果你要等待，需要指定这个标记。不能与 nowait 或 waituntilidle 组合使用。</p><h2 id="安装前卸载旧版本"><a href="#安装前卸载旧版本" class="headerlink" title="安装前卸载旧版本"></a>安装前卸载旧版本</h2><pre><code class="pascal">    function InitializeSetup(): boolean;    var    bRes: Boolean;    ResultStr: String;    ResultCode: Integer;    begin    if RegQueryStringValue(HKLM, &#39;SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Uninstall\{4AA89D60-9EB2-4A69-B73E-67E3AC22CF8E}_is1&#39;, &#39;UninstallString&#39;, ResultStr) then      begin        MsgBox(&#39;检测到系统之前安装过本程序,即将卸载低版本！&#39;, mbInformation, MB_OK);        ResultStr := RemoveQuotes(ResultStr);        bRes := Exec(ResultStr, &#39;/silent&#39;, &#39;&#39;, SW_HIDE, ewWaitUntilTerminated, ResultCode);        if bRes and (ResultCode = 0) then begin          result := true;          Exit;        end else          MsgBox(&#39;卸载低版本失败！&#39;, mbInformation, MB_OK);          result:= false;          Exit;      end;      result := true;    end;</code></pre><h2 id="检测服务是否存在并删除"><a href="#检测服务是否存在并删除" class="headerlink" title="检测服务是否存在并删除"></a>检测服务是否存在并删除</h2><pre><code class="pascal">    function DeleteService(strExeName: String): Boolean;    var    ErrorCode: Integer;    bRes: Boolean;    strCmdFind: String;    strCmdDelete: String;    begin      strCmdFind := Format(&#39;/c sc query &quot;%s&quot;&#39;, [strExeName]);      strCmdDelete := Format(&#39;/c sc stop &quot;%s&quot; &amp; sc delete &quot;%s&quot;&#39;, [strExeName, strExeName]);      bRes := ShellExec(&#39;open&#39;, ExpandConstant(&#39;{cmd}&#39;), strCmdFind, &#39;&#39;, SW_HIDE, ewWaitUntilTerminated, ErrorCode);      if bRes and (ErrorCode = 0) then begin          if MsgBox(&#39;检测到 &#39; + strExeName + &#39; 服务存在，需要删除，是否继续？&#39;, mbConfirmation, MB_YESNO) = IDYES then begin              bRes := ShellExec(&#39;open&#39;, ExpandConstant(&#39;{cmd}&#39;), strCmdDelete, &#39;&#39;, SW_HIDE, ewWaitUntilTerminated, ErrorCode);              if bRes and (ErrorCode = 0) then begin                 MsgBox(&#39;服务 &#39;+strExeName+&#39; 删除成功！&#39;, mbInformation, MB_OK);                 result := true;                 Exit;              end else                 MsgBox(&#39;删除失败，请手动删除服务 &#39; + strExeName, mbError, MB_OK);                 result := false;                 Exit;          end else          result := false;          Exit;      end;      MsgBox(&#39;服务 &#39;+strExeName+&#39; 不存在！&#39;, mbInformation, MB_OK);      result := true;    end;</code></pre>]]></content>
      
      
      <categories>
          
          <category> InnoSetup篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InnoSetup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git pull 和 git push 记住用户名密码</title>
      <link href="/2019/09/03/Git-RememberMe/"/>
      <url>/2019/09/03/Git-RememberMe/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h2><p>执行 <code>git config credential.helper store</code></p><p>或者在 .gitconfig 添加</p><pre><code class="text">    [credential]    helper = store</code></pre>]]></content>
      
      
      <categories>
          
          <category> Git篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 开启子线程执行其他操作，并获取结果</title>
      <link href="/2019/08/23/Java-Future/"/>
      <url>/2019/08/23/Java-Future/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>示例代码，10后抛出超时错误，并且取消子线程任务的执行</p><pre><code class="java">    ExecutorService executorService = Executors.newSingleThreadExecutor();    Future&lt;String&gt; future = executorService.submit(() -&gt; {                ....            }    );    try {        return future.get(10, TimeUnit.SECONDS);    } catch (Exception e) {        future.cancel(true);        executorService.shutdown();        return new ArrayList&lt;&gt;();    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Java篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Security 禁用匿名用户（anonymous().disable()）后无限重定向到登录页的问题解决</title>
      <link href="/2019/08/19/SpringBoot-SpringSecurity-Anonymous/"/>
      <url>/2019/08/19/SpringBoot-SpringSecurity-Anonymous/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近做了一个小 demo，需要使用到 spring security，于是就把以前写过的 spring security 的代码直接 copy 过来用了，没想到却出现了问题…..</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>小 demo 直接使用 spring boot 构建，前后端不分离，于是自己写的登录界面，在 spring security 里配置好 loginPage 后，发现只要打开登录页就会无限重定向到登录页，其他任何请求都是如此</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><pre><code class="java">    @Configuration    @EnableWebSecurity    public class WebSecurityConfig extends WebSecurityConfigurerAdapter {        @Override        protected void configure(HttpSecurity http) throws Exception {            http                    .anonymous().disable()                    .csrf().disable()                    .authorizeRequests()                    .antMatchers(&quot;/&quot;).permitAll()                    .anyRequest().authenticated()//其他请求必须授权后访问                    .and()                    .formLogin()                    .loginPage(&quot;/&quot;)                    .loginProcessingUrl(&quot;/login&quot;)                    .permitAll();//登录请求可以直接访问        }        @Override        public void configure(AuthenticationManagerBuilder auth) throws Exception {            auth.inMemoryAuthentication().passwordEncoder(passwordEncoder()).withUser(&quot;admin&quot;).password(passwordEncoder().encode(&quot;123456&quot;)).roles(&quot;ADMIN&quot;);        }        @Bean        public SessionRegistry sessionRegistry(){            return new SessionRegistryImpl();        }        @Bean        public BCryptPasswordEncoder passwordEncoder() {            return new BCryptPasswordEncoder();        }        @Bean        public AuthenticationSuccess authenticationSuccessHandler(){            return new AuthenticationSuccess();        }        @Bean        public AuthenticationFailureHandler authenticationFailureHandler(){            return new AuthenticationFailure();        }    }</code></pre><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>一开始的直觉告诉我，登录页的请求 <strong>“/“</strong> 没有认证，而没有认证的请求会重定向到登录页，也就还是 <strong>“/“</strong>,于是就造成了重定向</p><p>于是我先添加请求 <strong>“/“</strong>, 不进行认证即可访问，也就是上面配置的 <code>.antMatchers(&quot;/&quot;).permitAll()</code></p><p>重启后发现不起作用，依旧无限重定向</p><p>然而可怕的是控制台没有打印任何日志….</p><p>一下子懵逼了，不知如何解决….</p><p>冷静下来分析后—</p><p>我是这样解决的</p><h3 id="打开-debug-日志"><a href="#打开-debug-日志" class="headerlink" title="打开 debug 日志"></a>打开 debug 日志</h3><p>配置 spring security 的日志级别</p><pre><code class="yaml">    logging:      level:        org.springframework.security: debug</code></pre><p>启动时看到日志截取如下</p><pre><code class="text">    2019-08-19 15:19:06.628 DEBUG 19133 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression &#39;permitAll&#39;, for ExactUrl [processUrl=&#39;/?error&#39;]    2019-08-19 15:19:06.631 DEBUG 19133 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression &#39;permitAll&#39;, for ExactUrl [processUrl=&#39;/login&#39;]    2019-08-19 15:19:06.631 DEBUG 19133 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression &#39;permitAll&#39;, for ExactUrl [processUrl=&#39;/&#39;]    2019-08-19 15:19:06.631 DEBUG 19133 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression &#39;permitAll&#39;, for Ant [pattern=&#39;/&#39;]    2019-08-19 15:19:06.632 DEBUG 19133 --- [           main] edFilterInvocationSecurityMetadataSource : Adding web access control expression &#39;authenticated&#39;, for any request    2019-08-19 15:19:06.646 DEBUG 19133 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes    2019-08-19 15:19:06.648 DEBUG 19133 --- [           main] o.s.s.w.a.i.FilterSecurityInterceptor    : Validated configuration attributes    2019-08-19 15:34:24.451  INFO 22575 --- [           main] o.s.s.web.DefaultSecurityFilterChain     : Creating filter chain: any request, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@32c6d164, org.springframework.security.web.context.SecurityContextPersistenceFilter@390a7532, org.springframework.security.web.header.HeaderWriterFilter@5ebf776c, org.springframework.security.web.authentication.logout.LogoutFilter@523ade68, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@652f26da, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7d49a1a0, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@3a12f3e7, org.springframework.security.web.session.SessionManagementFilter@54ae1240, org.springframework.security.web.access.ExceptionTranslationFilter@3c62f69a, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@2b3242a5]</code></pre><p>可以看到 <strong>“/“</strong> 添加成功了，可是为什么好像没有生效呢？</p><h3 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h3><p>继续往下走，刷新登录页，发现控制台打印了错误信息如下“</p><pre><code class="text">    2019-08-19 15:21:16.813 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 1 of 10 in additional filter chain; firing Filter: &#39;WebAsyncManagerIntegrationFilter&#39;    2019-08-19 15:21:16.815 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 2 of 10 in additional filter chain; firing Filter: &#39;SecurityContextPersistenceFilter&#39;    2019-08-19 15:21:16.816 DEBUG 19133 --- [nio-8080-exec-2] w.c.HttpSessionSecurityContextRepository : No HttpSession currently exists    2019-08-19 15:21:16.817 DEBUG 19133 --- [nio-8080-exec-2] w.c.HttpSessionSecurityContextRepository : No SecurityContext was available from the HttpSession: null. A new one will be created.    2019-08-19 15:21:16.822 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 3 of 10 in additional filter chain; firing Filter: &#39;HeaderWriterFilter&#39;    2019-08-19 15:21:16.825 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 4 of 10 in additional filter chain; firing Filter: &#39;LogoutFilter&#39;    2019-08-19 15:21:16.825 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern=&#39;/logout&#39;, GET]    2019-08-19 15:21:16.825 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Checking match of request : &#39;/&#39;; against &#39;/logout&#39;    2019-08-19 15:21:16.826 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern=&#39;/logout&#39;, POST]    2019-08-19 15:21:16.826 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request &#39;GET /&#39; doesn&#39;t match &#39;POST /logout&#39;    2019-08-19 15:21:16.826 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern=&#39;/logout&#39;, PUT]    2019-08-19 15:21:16.826 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request &#39;GET /&#39; doesn&#39;t match &#39;PUT /logout&#39;    2019-08-19 15:21:16.826 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : Trying to match using Ant [pattern=&#39;/logout&#39;, DELETE]    2019-08-19 15:21:16.827 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request &#39;GET /&#39; doesn&#39;t match &#39;DELETE /logout&#39;    2019-08-19 15:21:16.827 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.web.util.matcher.OrRequestMatcher  : No matches found    2019-08-19 15:21:16.827 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 5 of 10 in additional filter chain; firing Filter: &#39;UsernamePasswordAuthenticationFilter&#39;    2019-08-19 15:21:16.827 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.u.matcher.AntPathRequestMatcher  : Request &#39;GET /&#39; doesn&#39;t match &#39;POST /login&#39;    2019-08-19 15:21:16.828 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 6 of 10 in additional filter chain; firing Filter: &#39;RequestCacheAwareFilter&#39;    2019-08-19 15:21:16.828 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.s.HttpSessionRequestCache        : saved request doesn&#39;t match    2019-08-19 15:21:16.829 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 7 of 10 in additional filter chain; firing Filter: &#39;SecurityContextHolderAwareRequestFilter&#39;    2019-08-19 15:21:16.832 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 8 of 10 in additional filter chain; firing Filter: &#39;SessionManagementFilter&#39;    2019-08-19 15:21:16.833 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 9 of 10 in additional filter chain; firing Filter: &#39;ExceptionTranslationFilter&#39;    2019-08-19 15:21:21.085 DEBUG 19133 --- [nio-8080-exec-2] o.s.security.web.FilterChainProxy        : / at position 10 of 10 in additional filter chain; firing Filter: &#39;FilterSecurityInterceptor&#39;    2019-08-19 15:21:21.440 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.a.i.FilterSecurityInterceptor    : Secure object: FilterInvocation: URL: /; Attributes: [permitAll]    2019-08-19 15:21:21.450 DEBUG 19133 --- [nio-8080-exec-2] o.s.s.w.a.ExceptionTranslationFilter     : Authentication exception occurred; redirecting to authentication entry point    org.springframework.security.authentication.AuthenticationCredentialsNotFoundException: An Authentication object was not found in the SecurityContext        at org.springframework.security.access.intercept.AbstractSecurityInterceptor.credentialsNotFound(AbstractSecurityInterceptor.java:379) ~[spring-security-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.access.intercept.AbstractSecurityInterceptor.beforeInvocation(AbstractSecurityInterceptor.java:223) ~[spring-security-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:124) ~[spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) ~[spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) ~[spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:74) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) [spring-security-web-5.1.6.RELEASE.jar:5.1.6.RELEASE]        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) [spring-web-5.1.9.RELEASE.jar:5.1.9.RELEASE]        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:41002) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:853) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1587) [tomcat-embed-core-9.0.22.jar:9.0.22]        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.22.jar:9.0.22]        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135) [na:na]        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [na:na]        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.22.jar:9.0.22]        at java.base/java.lang.Thread.run(Thread.java:844) [na:na]</code></pre><p>看到2个关键的错误信息：</p><ol><li><strong>Authentication exception occurred; redirecting to authentication entry point</strong></li><li><strong>An Authentication object was not found in the SecurityContext</strong></li></ol><p>意思是认证异常，重定向到认证入口点，异常的原因是在 SecurityContext 没有找到认证信息对象</p><h3 id="排查"><a href="#排查" class="headerlink" title="排查"></a>排查</h3><p>根据错误信息，我先到 <code>ExceptionTranslationFilter</code> 类中去查看问题出在什么地方</p><pre><code class="java">   public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)               throws IOException, ServletException {           HttpServletRequest request = (HttpServletRequest) req;           HttpServletResponse response = (HttpServletResponse) res;           try {               chain.doFilter(request, response);               logger.debug(&quot;Chain processed normally&quot;);           }           catch (IOException ex) {               throw ex;           }           catch (Exception ex) {               // Try to extract a SpringSecurityException from the stacktrace               Throwable[] causeChain = throwableAnalyzer.determineCauseChain(ex);               RuntimeException ase = (AuthenticationException) throwableAnalyzer                       .getFirstThrowableOfType(AuthenticationException.class, causeChain);               if (ase == null) {                   ase = (AccessDeniedException) throwableAnalyzer.getFirstThrowableOfType(                           AccessDeniedException.class, causeChain);               }               if (ase != null) {                   if (response.isCommitted()) {                       throw new ServletException(&quot;Unable to handle the Spring Security Exception because the response is already committed.&quot;, ex);                   }                   handleSpringSecurityException(request, response, chain, ase);               }               else {                   // Rethrow ServletExceptions and RuntimeExceptions as-is                   if (ex instanceof ServletException) {                       throw (ServletException) ex;                   }                   else if (ex instanceof RuntimeException) {                       throw (RuntimeException) ex;                   }                   // Wrap other Exceptions. This shouldn&#39;t actually happen                   // as we&#39;ve already covered all the possibilities for doFilter                   throw new RuntimeException(ex);               }           }       } </code></pre><p>ExceptionTranslationFilter 没有什么逻辑，都是对异常的处理， 然后直接进入下一个过滤器了，</p><p>那么这时我们就需要了解 spring security 的过滤器链的顺序</p><p>我们来看最开始打印的 debug 的日志信息，我整理一下，有如下顺序：</p><p><strong>WebAsyncManagerIntegrationFilter</strong><br><strong>SecurityContextPersistenceFilter</strong><br><strong>HeaderWriterFilter</strong><br><strong>LogoutFilter</strong><br><strong>UsernamePasswordAuthenticationFilter</strong><br><strong>RequestCacheAwareFilter</strong><br><strong>SecurityContextHolderAwareRequestFilter</strong><br><strong>SessionManagementFilter</strong><br><strong>ExceptionTranslationFilter</strong><br><strong>FilterSecurityInterceptor</strong></p><p>这是spring security 的默认过滤器链，完整的过滤器链可以通过查看源码详细看到， 在类 FilterComparator 中：</p><pre><code class="java">    FilterComparator() {            Step order = new Step(INITIAL_ORDER, ORDER_STEP);            put(ChannelProcessingFilter.class, order.next());            put(ConcurrentSessionFilter.class, order.next());            put(WebAsyncManagerIntegrationFilter.class, order.next());            put(SecurityContextPersistenceFilter.class, order.next());            put(HeaderWriterFilter.class, order.next());            put(CorsFilter.class, order.next());            put(CsrfFilter.class, order.next());            put(LogoutFilter.class, order.next());            filterToOrder.put(                &quot;org.springframework.security.oauth2.client.web.OAuth2AuthorizationRequestRedirectFilter&quot;,                    order.next());            put(X509AuthenticationFilter.class, order.next());            put(AbstractPreAuthenticatedProcessingFilter.class, order.next());            filterToOrder.put(&quot;org.springframework.security.cas.web.CasAuthenticationFilter&quot;,                    order.next());            filterToOrder.put(                &quot;org.springframework.security.oauth2.client.web.OAuth2LoginAuthenticationFilter&quot;,                    order.next());            put(UsernamePasswordAuthenticationFilter.class, order.next());            put(ConcurrentSessionFilter.class, order.next());            filterToOrder.put(                    &quot;org.springframework.security.openid.OpenIDAuthenticationFilter&quot;, order.next());            put(DefaultLoginPageGeneratingFilter.class, order.next());            put(DefaultLogoutPageGeneratingFilter.class, order.next());            put(ConcurrentSessionFilter.class, order.next());            put(DigestAuthenticationFilter.class, order.next());            filterToOrder.put(                    &quot;org.springframework.security.oauth2.server.resource.web.BearerTokenAuthenticationFilter&quot;, order.next());            put(BasicAuthenticationFilter.class, order.next());            put(RequestCacheAwareFilter.class, order.next());            put(SecurityContextHolderAwareRequestFilter.class, order.next());            put(JaasApiIntegrationFilter.class, order.next());            put(RememberMeAuthenticationFilter.class, order.next());            put(AnonymousAuthenticationFilter.class, order.next());            filterToOrder.put(                &quot;org.springframework.security.oauth2.client.web.OAuth2AuthorizationCodeGrantFilter&quot;,                    order.next());            put(SessionManagementFilter.class, order.next());            put(ExceptionTranslationFilter.class, order.next());            put(FilterSecurityInterceptor.class, order.next());            put(SwitchUserFilter.class, order.next());        }</code></pre><p>回到原来的问题， <code>ExceptionTranslationFilter</code> 过滤器后是 <code>FilterSecurityInterceptor</code> 过滤器</p><p>再来看 <code>FilterSecurityInterceptor</code> 的源码</p><pre><code class="java">    public void doFilter(ServletRequest request, ServletResponse response,            FilterChain chain) throws IOException, ServletException {        FilterInvocation fi = new FilterInvocation(request, response, chain);        invoke(fi);    }    public void invoke(FilterInvocation fi) throws IOException, ServletException {            if ((fi.getRequest() != null)                    &amp;&amp; (fi.getRequest().getAttribute(FILTER_APPLIED) != null)                    &amp;&amp; observeOncePerRequest) {                // filter already applied to this request and user wants us to observe                // once-per-request handling, so don&#39;t re-do security checking                fi.getChain().doFilter(fi.getRequest(), fi.getResponse());            }            else {                // first time this request being called, so perform security checking                if (fi.getRequest() != null &amp;&amp; observeOncePerRequest) {                    fi.getRequest().setAttribute(FILTER_APPLIED, Boolean.TRUE);                }                InterceptorStatusToken token = super.beforeInvocation(fi);                try {                    fi.getChain().doFilter(fi.getRequest(), fi.getResponse());                }                finally {                    super.finallyInvocation(token);                }                super.afterInvocation(token, null);            }        }</code></pre><p>这里的看的主要方法是 <code>invoke（fi）</code></p><p>通过调试看到， 问题出在 beforeInvocation（fi） 方法里：</p><pre><code class="java">    protected InterceptorStatusToken beforeInvocation(Object object) {            Assert.notNull(object, &quot;Object was null&quot;);            final boolean debug = logger.isDebugEnabled();            if (!getSecureObjectClass().isAssignableFrom(object.getClass())) {                throw new IllegalArgumentException(                        &quot;Security invocation attempted for object &quot;                                + object.getClass().getName()                                + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot;                                + getSecureObjectClass());            }            Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource()                    .getAttributes(object);            if (attributes == null || attributes.isEmpty()) {                if (rejectPublicInvocations) {                    throw new IllegalArgumentException(                            &quot;Secure object invocation &quot;                                    + object                                    + &quot; was denied as public invocations are not allowed via this interceptor. &quot;                                    + &quot;This indicates a configuration error because the &quot;                                    + &quot;rejectPublicInvocations property is set to &#39;true&#39;&quot;);                }                if (debug) {                    logger.debug(&quot;Public object - authentication not attempted&quot;);                }                publishEvent(new PublicInvocationEvent(object));                return null; // no further work post-invocation            }            if (debug) {                logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes);            }            if (SecurityContextHolder.getContext().getAuthentication() == null) {                credentialsNotFound(messages.getMessage(                        &quot;AbstractSecurityInterceptor.authenticationNotFound&quot;,                        &quot;An Authentication object was not found in the SecurityContext&quot;),                        object, attributes);            }            Authentication authenticated = authenticateIfRequired();            // Attempt authorization            try {                this.accessDecisionManager.decide(authenticated, object, attributes);            }            catch (AccessDeniedException accessDeniedException) {                publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated,                        accessDeniedException));                throw accessDeniedException;            }            if (debug) {                logger.debug(&quot;Authorization successful&quot;);            }            if (publishAuthorizationSuccess) {                publishEvent(new AuthorizedEvent(object, attributes, authenticated));            }            // Attempt to run as a different user            Authentication runAs = this.runAsManager.buildRunAs(authenticated, object,                    attributes);            if (runAs == null) {                if (debug) {                    logger.debug(&quot;RunAsManager did not change Authentication object&quot;);                }                // no further work post-invocation                return new InterceptorStatusToken(SecurityContextHolder.getContext(), false,                        attributes, object);            }            else {                if (debug) {                    logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs);                }                SecurityContext origCtx = SecurityContextHolder.getContext();                SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext());                SecurityContextHolder.getContext().setAuthentication(runAs);                // need to revert to token.Authenticated post-invocation                return new InterceptorStatusToken(origCtx, true, attributes, object);            }        }</code></pre><p>继续调试，问题定位在了 <code>if (SecurityContextHolder.getContext().getAuthentication() == null)</code></p><p>也就打印出了日志 <code>An Authentication object was not found in the SecurityContext</code>，这也就对的上号了</p><p>继续分析</p><p>为什么 <code>SecurityContext</code> 里的 <code>Authentication</code> 会为空呢？</p><p>据官方文档解释 spring security 默认是会有匿名的 Authentication 的啊</p><p>一想到这里，马上看下配置，原来是我禁用了匿名用户， <code>.anonymous().disable()</code> 怪不得这样。。。。</p><p>可是一想，为什么以前项目这么配置就没有出现这个问题呢？？？</p><p>对比发现，以前的项目是前后端分离的，不需要配置 <code>loginPage</code>, 而且登录成功和登录失败都是返回状态码和错误信息的，和我的这个小 demo 不一样，这个是前后端不分离的，需要做页面的跳转</p><h3 id="为什么如此"><a href="#为什么如此" class="headerlink" title="为什么如此"></a>为什么如此</h3><p>这时搞清楚之后，我把 <code>.anonymous().disable()</code> 注释掉再重启，刷新下页面，果然登录页出来了，问题不再了</p><p>那么为什么会这样呢？？？</p><p>我仔细分析了一下， 看下注释掉配置会有说明不同</p><p>首先从过滤器链来看， 这里我不再贴日志信息了， 过滤器链整理如下：</p><p><strong>WebAsyncManagerIntegrationFilter</strong><br><strong>SecurityContextPersistenceFilter</strong><br><strong>HeaderWriterFilter</strong><br><strong>LogoutFilter</strong><br><strong>UsernamePasswordAuthenticationFilter</strong><br><strong>RequestCacheAwareFilter</strong><br><strong>SecurityContextHolderAwareRequestFilter</strong><br><code>AnonymousAuthenticationFilter</code><br><strong>SessionManagementFilter</strong><br><strong>ExceptionTranslationFilter</strong><br><strong>FilterSecurityInterceptor</strong></p><p>对比发现，过滤器链里多了一个过滤器 <code>AnonymousAuthenticationFilter</code>，来看看 <code>AnonymousAuthenticationFilter</code> 做了什么事情</p><pre><code class="java">        public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)                throws IOException, ServletException {            if (SecurityContextHolder.getContext().getAuthentication() == null) {                SecurityContextHolder.getContext().setAuthentication(                        createAuthentication((HttpServletRequest) req));                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Populated SecurityContextHolder with anonymous token: &#39;&quot;                            + SecurityContextHolder.getContext().getAuthentication() + &quot;&#39;&quot;);                }            }            else {                if (logger.isDebugEnabled()) {                    logger.debug(&quot;SecurityContextHolder not populated with anonymous token, as it already contained: &#39;&quot;                            + SecurityContextHolder.getContext().getAuthentication() + &quot;&#39;&quot;);                }            }            chain.doFilter(req, res);        }        protected Authentication createAuthentication(HttpServletRequest request) {            AnonymousAuthenticationToken auth = new AnonymousAuthenticationToken(key,                    principal, authorities);            auth.setDetails(authenticationDetailsSource.buildDetails(request));            return auth;        }</code></pre><p>看到了关键信息 <code>createAuthentication</code> 和 <code>setAuthentication</code>， 那么在后续的过滤器链中就有了认证信息，不再报错了</p><p>这也就是为什么解决了这个问题的原因所在</p><h3 id="重定向的原因"><a href="#重定向的原因" class="headerlink" title="重定向的原因"></a>重定向的原因</h3><p>至于为什么会无限的重定向到登录页，还得再回过头来看 <code>ExceptionTranslationFilter</code> 类，这里有个处理异常的方法</p><pre><code class="java">        private void handleSpringSecurityException(HttpServletRequest request,                HttpServletResponse response, FilterChain chain, RuntimeException exception)                throws IOException, ServletException {            if (exception instanceof AuthenticationException) {                logger.debug(                        &quot;Authentication exception occurred; redirecting to authentication entry point&quot;,                        exception);                sendStartAuthentication(request, response, chain,                        (AuthenticationException) exception);            }            else if (exception instanceof AccessDeniedException) {                Authentication authentication = SecurityContextHolder.getContext().getAuthentication();                if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) {                    logger.debug(                            &quot;Access is denied (user is &quot; + (authenticationTrustResolver.isAnonymous(authentication) ? &quot;anonymous&quot; : &quot;not fully authenticated&quot;) + &quot;); redirecting to authentication entry point&quot;,                            exception);                    sendStartAuthentication(                            request,                            response,                            chain,                            new InsufficientAuthenticationException(                                messages.getMessage(                                    &quot;ExceptionTranslationFilter.insufficientAuthentication&quot;,                                    &quot;Full authentication is required to access this resource&quot;)));                }                else {                    logger.debug(                            &quot;Access is denied (user is not anonymous); delegating to AccessDeniedHandler&quot;,                            exception);                    accessDeniedHandler.handle(request, response,                            (AccessDeniedException) exception);                }            }        }        protected void sendStartAuthentication(HttpServletRequest request,                HttpServletResponse response, FilterChain chain,                AuthenticationException reason) throws ServletException, IOException {            // SEC-112: Clear the SecurityContextHolder&#39;s Authentication, as the            // existing Authentication is no longer considered valid            SecurityContextHolder.getContext().setAuthentication(null);            requestCache.saveRequest(request, response);            logger.debug(&quot;Calling Authentication entry point.&quot;);            authenticationEntryPoint.commence(request, response, reason);        }</code></pre><p>通过调试， 发现进入了 <code>sendStartAuthentication</code> 方法，继续调试，进入 <code>authenticationEntryPoint.commence</code> 查看</p><p>实现类为 <code>LoginUrlAuthenticationEntryPoint</code></p><pre><code class="java">        public void commence(HttpServletRequest request, HttpServletResponse response,                AuthenticationException authException) throws IOException, ServletException {            String redirectUrl = null;            if (useForward) {                if (forceHttps &amp;&amp; &quot;http&quot;.equals(request.getScheme())) {                    // First redirect the current request to HTTPS.                    // When that request is received, the forward to the login page will be                    // used.                    redirectUrl = buildHttpsRedirectUrlForRequest(request);                }                if (redirectUrl == null) {                    String loginForm = determineUrlToUseForThisRequest(request, response,                            authException);                    if (logger.isDebugEnabled()) {                        logger.debug(&quot;Server side forward to: &quot; + loginForm);                    }                    RequestDispatcher dispatcher = request.getRequestDispatcher(loginForm);                    dispatcher.forward(request, response);                    return;                }            }            else {                // redirect to login page. Use https if forceHttps true                redirectUrl = buildRedirectUrlToLoginPage(request, response, authException);            }            redirectStrategy.sendRedirect(request, response, redirectUrl);        }</code></pre><p>这里的 <code>redirectUrl</code> 通过调试发现就是 <code>&quot;/&quot;</code></p><p>于是无限重定向的原因也清楚了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>解决方式有 2 种： </p><ol><li>上面所说的注释掉 <code>.anonymous().disable()</code></li><li>配置 <code>webSecurity.ignoring().antMatchers(&quot;/&quot;)</code></li></ol><pre><code class="java">    @Override    public void configure(WebSecurity web) {        web.ignoring().antMatchers(&quot;/&quot;);    }</code></pre><p>这种方法一般是配置系统静态资源用，配置的请求根本不会进入 spring security 的过滤器链，直接放行，<br>而 <code>.antMatchers(&quot;/&quot;).permitAll()</code> 是会进入 spring security 的过滤器链的，这是 2 者的主要区别<br>结合实际情况，第二种方式不是太好，建议第一种方式。</p>]]></content>
      
      
      <categories>
          
          <category> SpringSecurity篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> SpringSecurity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- 硕美科 E95x 耳机复活记</title>
      <link href="/2019/07/26/Daily-Somix-E95X/"/>
      <url>/2019/07/26/Daily-Somix-E95X/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我这款硕美科耳机是 2015 年入手的,到现在已经 4 年多了,日常使用中汗水已经腐蚀了耳机的皮套和头悬梁的皮套<br>但是耳机本身是没有任何问题的,只是用起来经常掉皮,我并不想重新再买一个<br>于是我决定在淘宝上买些配件<br>把原来腐蚀掉的皮套给换掉</p><h2 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h2><p>就下面 2 个皮套和一个头悬梁<br><img src="http://gd4.alicdn.com/imgextra/i4/1714578795/O1CN01IAg4JF2Eq9sEivlHX_!!1714578795.jpg_800x800.jpg" alt="材料"></p><h2 id="原来的模样"><a href="#原来的模样" class="headerlink" title="原来的模样"></a>原来的模样</h2><p>下面是我耳机没有更换前的模样,掉皮,平时我都是用纸巾包一层在戴到头上使用</p><p><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0534.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0535.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0536.JPG" alt="">  </p><h2 id="动手"><a href="#动手" class="headerlink" title="动手"></a>动手</h2><ol><li><p>先硬撕掉耳机保护套,撕不掉用剪子剪掉</p></li><li><p>撕掉之后使用扁平的螺丝刀沿着边缘将卡口翘出来,像下面这样<br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0537.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0538.JPG" alt=""></p></li><li><p>之后将皮套套到卡口的圈中,注意皮套上的一圈洞和卡口上的突起相对应<br><img src="!%5B%5D(http://image.joylau.cn/blog/Somix_E95x_IMG_0539.JPG)" alt=""></p></li><li><p>将套好的一只耳机沿着之前的翘起的卡口位置在按到耳机架上,另一只耳机也是这样操作</p></li><li><p>接下来就是头悬梁的皮套的安装了,这个比较麻烦<br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0545.JPG" alt=""></p></li><li><p>先用小号螺丝刀打开悬梁 2 边的塑料小盒,露出 2 边的钢丝</p></li><li><p>用剪刀剪断钢丝,再翘起钢丝边缘的卡扣,把钢丝取出来,另一边也是这样操作<br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0540.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0544.JPG" alt=""></p></li><li><p>把新的悬梁换上,把钢丝穿过悬梁的小盒子,在穿进耳机架里面</p></li><li><p>打开送的小袋子里面的四个铜帽,用钳子夹紧到耳机架边缘伸出来的钢丝末端<br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0541.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0542.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0543.JPG" alt=""></p></li><li><p>另一边也是相同的方式安装好</p></li></ol><h2 id="更换完成"><a href="#更换完成" class="headerlink" title="更换完成"></a>更换完成</h2><p>这是更换完成后的模样<br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0546.JPG" alt=""><br><img src="http://image.joylau.cn/blog/Somix_E95x_IMG_0547.JPG" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 强制设置分辨率</title>
      <link href="/2019/07/15/Ubuntu-Force-Resolution/"/>
      <url>/2019/07/15/Ubuntu-Force-Resolution/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一次系统重启后,Ubuntu 系统无法正确识别连接的显示器分辨率了,我连接的 2 个显示器,其中一个分辨率正确识别,另一个却无法识别,默认成 1024 的分辨率了</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>强制设置的分辨率起码显示器得支持</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li><code>xrandr</code> 查看当前显示器的设置信息, 记住当前显示接口的名称,我这里是 <code>VGA-1</code>, 而且支持的分辨率列表应该是没有你想要的分辨率,不然的话在设置里就能看到了</li><li>添加一个分辨率,我这里是 1920 * 1080 : <code>cvt 1920 1080</code>; 得到输出: <code>Modeline &quot;1920x1080_60.00&quot;  173.00  1920 2048 2248 2576  1080 1083 1088 1120 -hsync +vsync</code></li><li>将 cvt 得到的显示模式使用 xrandr 命令添加:<br> <code>sudo xrandr --newmode &quot;1920x1080_60.00&quot; 173.00  1920 2048 2248 2576  1080 1083 1088 1120 -hsync +vsync</code><br> <code>sudo xrandr --addmode VGA-1 &quot;1920x1080_60.00&quot;</code></li><li>这样设置重启会失效, 将脚本写到一个文件中,并授予执行权限</li></ol><pre><code class="bash">    !#/bin/bash    cvt 1920 1080    ## 如果登录用户不是 root ,则需要使用 sudo ,sudo 需要输入密码,可使用下面的方式解决    echo &quot;password&quot; | sudo -S xrandr --newmode &quot;1920x1080_60.00&quot; 173.00  1920 2048 2248 2576  1080 1083 1088 1120 -hsync +vsync    echo &quot;password&quot; | sudo -S xrandr --addmode VGA-1 &quot;1920x1080_60.00&quot;</code></pre><ol start="5"><li>在 Ubuntu 中搜索 <code>启动应用程序</code>, 将脚本添加进去,完成.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Ubuntu篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 基于 OpenCV 的百度路况研究记录 (五) 性能测试</title>
      <link href="/2019/07/04/OpenCV-Baidu-Traffic-5/"/>
      <url>/2019/07/04/OpenCV-Baidu-Traffic-5/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>基于百度地图的路况分析服务目前实现的功能有:</p><ol><li>根据给定的行政区划(省,市,区,县等)获取任一缩放等级下的瓦片</li><li>提取分析拥堵数据(拥堵等级,拥堵点集,拥堵空间数据,拥堵距离,道路代码,省,市,区县,镇,街区,道路名,道路车道数,拥堵方向,拥堵描述,拥堵趋势变化,拥堵时长)</li><li>分析性能监控,日志记录</li></ol><h4 id="特性"><a href="#特性" class="headerlink" title="特性:"></a>特性:</h4><ol><li>简单: 提供 web 界面,可支持在线查看,分析,调试路况信息</li><li>实时: 提供根据给定的区域范围 (矩形区域) 实时分析该区域拥堵数据的 API</li><li>弹性: 分布式计算分析,弹性增加或减少机器</li><li>易部署: 所有复杂的环境和依赖都已打包成镜像, 一条命令即可部署启动</li><li>少依赖: 服务的地理位置解析不依赖互联网接口及其他第三方接口,全部由分析服务自己解决</li></ol><h4 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h4><p>输入: 百度地图瓦片<br>输出: 拥堵数据</p><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p>合肥市(行政区划范围)第 17 等级下的全部地图瓦片, 共 <code>61172</code> 张瓦片,其中有道路信息(截止 2019-06-28) 的有 <code>18092</code> 张 </p><h4 id="环境依赖"><a href="#环境依赖" class="headerlink" title="环境依赖"></a>环境依赖</h4><ol start="0"><li>centOS : 7.5</li><li>openjdk : 12</li><li>openCV : 4.1.0</li><li>docker : 18.09</li><li>docker compose : 1.24.0</li><li>redis : 5.0.5</li><li>zookeeper : 3.5.5</li><li>rabbitMQ : 3.7.15-management</li><li>mariadb: 10.4.6</li><li>postgres : 11.4</li><li>node : 8.16.0</li><li>PostGIS : 2.5.0</li><li>PHP : 7.3.6 (PHP-pgsql, PHP-intl)</li><li>Apache : 2.4</li></ol><h4 id="测试机器配置"><a href="#测试机器配置" class="headerlink" title="测试机器配置"></a>测试机器配置</h4><p>暂时没有找到更合适的机器用来长时间运行测试,本次使用的是公司的机器,运行着几个服务,但对系统资源的占用都不大,可以忽略对本次性能测试的影响  </p><p>CPU : Intel(R) Core(TM) i7-4770 CPU @ 3.40GHz x64 / 单颗 / 8 核<br>GPU : Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor Integrated Graphics Controller / 核显<br>MEM : 组合内存, 4 个插槽, 共 24G<br>      1. 8G Kingston DDR3 1600MHz<br>      2. 8G Kingston DDR3 1600MHz<br>      3. 4G Samsung DDR3 1600MHz<br>      4. 4G Hynix/Hyundai DDR3 1600MHz<br>DISK : INTEL SSDSC2BW240H6 240G<br>NETWORK : Intel Corporation Ethernet Connection I217-LM 1000M</p><p>网络 : 中国电信 50M 对等宽带, PING 60ms, 抖动 28ms, 丢包 0% (公司网络正常使用情况下)<br>局域网 : 100M 局域网</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><h4 id="测试说明"><a href="#测试说明" class="headerlink" title="测试说明"></a>测试说明</h4><ol><li>服务部署在单台机器上, 线程跑满</li><li>目前已稳定运行一星期 (<strong>2019年06月28日 - 2019年07月05日</strong>)</li><li>从中抽取其中 1 天的分析数据 (<strong>2019年07月04日13:12:40 - 2019年07月05日13:12:40</strong>)</li><li>本次测试的功能包含了已经开发完成的全部功能</li></ol><h4 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h4><table><thead><tr><th>id</th><th>task_id</th><th>max_thread_size</th><th>start_time</th><th>end_time</th><th>total_time</th><th>network_time</th><th>all_count</th><th>error_count</th><th>congest_count</th></tr></thead><tbody><tr><td>102</td><td>1562217160232</td><td>8</td><td>2019-07-04 13:12:40</td><td>2019-07-04 13:14:16</td><td>95</td><td>84</td><td>18902</td><td>0</td><td>152</td></tr><tr><td>103</td><td>1562217280004</td><td>8</td><td>2019-07-04 13:14:40</td><td>2019-07-04 13:16:18</td><td>98</td><td>89</td><td>18902</td><td>0</td><td>153</td></tr><tr><td>104</td><td>1562217400004</td><td>8</td><td>2019-07-04 13:16:40</td><td>2019-07-04 13:18:14</td><td>94</td><td>85</td><td>18902</td><td>0</td><td>142</td></tr><tr><td>105</td><td>1562217520003</td><td>8</td><td>2019-07-04 13:18:40</td><td>2019-07-04 13:20:18</td><td>98</td><td>87</td><td>18902</td><td>0</td><td>151</td></tr><tr><td>106</td><td>1562217640004</td><td>8</td><td>2019-07-04 13:20:40</td><td>2019-07-04 13:22:21</td><td>101</td><td>90</td><td>18902</td><td>0</td><td>158</td></tr><tr><td>107</td><td>1562217760003</td><td>8</td><td>2019-07-04 13:22:40</td><td>2019-07-04 13:24:13</td><td>93</td><td>82</td><td>18902</td><td>0</td><td>166</td></tr><tr><td>108</td><td>1562217880004</td><td>8</td><td>2019-07-04 13:24:40</td><td>2019-07-04 13:26:16</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>165</td></tr><tr><td>109</td><td>1562218000003</td><td>8</td><td>2019-07-04 13:26:40</td><td>2019-07-04 13:28:17</td><td>97</td><td>87</td><td>18902</td><td>0</td><td>157</td></tr><tr><td>110</td><td>1562218120004</td><td>8</td><td>2019-07-04 13:28:40</td><td>2019-07-04 13:30:18</td><td>98</td><td>86</td><td>18902</td><td>0</td><td>171</td></tr><tr><td>111</td><td>1562218240003</td><td>8</td><td>2019-07-04 13:30:40</td><td>2019-07-04 13:32:16</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>164</td></tr><tr><td>112</td><td>1562218360003</td><td>8</td><td>2019-07-04 13:32:40</td><td>2019-07-04 13:34:29</td><td>109</td><td>97</td><td>18902</td><td>0</td><td>163</td></tr><tr><td>113</td><td>1562218480004</td><td>8</td><td>2019-07-04 13:34:40</td><td>2019-07-04 13:36:16</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>169</td></tr><tr><td>114</td><td>1562218600003</td><td>8</td><td>2019-07-04 13:36:40</td><td>2019-07-04 13:38:17</td><td>97</td><td>86</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>115</td><td>1562218720003</td><td>8</td><td>2019-07-04 13:38:40</td><td>2019-07-04 13:40:17</td><td>97</td><td>86</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>116</td><td>1562218840004</td><td>8</td><td>2019-07-04 13:40:40</td><td>2019-07-04 13:42:18</td><td>98</td><td>86</td><td>18902</td><td>0</td><td>201</td></tr><tr><td>117</td><td>1562218960004</td><td>8</td><td>2019-07-04 13:42:40</td><td>2019-07-04 13:44:19</td><td>99</td><td>88</td><td>18902</td><td>0</td><td>196</td></tr><tr><td>118</td><td>1562219080003</td><td>8</td><td>2019-07-04 13:44:40</td><td>2019-07-04 13:46:16</td><td>96</td><td>84</td><td>18902</td><td>0</td><td>188</td></tr><tr><td>119</td><td>1562219200003</td><td>8</td><td>2019-07-04 13:46:40</td><td>2019-07-04 13:48:15</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>174</td></tr><tr><td>120</td><td>1562219320003</td><td>8</td><td>2019-07-04 13:48:40</td><td>2019-07-04 13:50:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>176</td></tr><tr><td>121</td><td>1562219440003</td><td>8</td><td>2019-07-04 13:50:40</td><td>2019-07-04 13:52:19</td><td>99</td><td>86</td><td>18902</td><td>0</td><td>195</td></tr><tr><td>122</td><td>1562219560003</td><td>8</td><td>2019-07-04 13:52:40</td><td>2019-07-04 13:54:26</td><td>106</td><td>93</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>123</td><td>1562219680003</td><td>8</td><td>2019-07-04 13:54:40</td><td>2019-07-04 13:56:27</td><td>107</td><td>95</td><td>18902</td><td>0</td><td>185</td></tr><tr><td>124</td><td>1562219800003</td><td>8</td><td>2019-07-04 13:56:40</td><td>2019-07-04 13:58:19</td><td>99</td><td>89</td><td>18902</td><td>0</td><td>189</td></tr><tr><td>125</td><td>1562219920003</td><td>8</td><td>2019-07-04 13:58:40</td><td>2019-07-04 14:00:28</td><td>108</td><td>96</td><td>18902</td><td>0</td><td>195</td></tr><tr><td>126</td><td>1562220040003</td><td>8</td><td>2019-07-04 14:00:40</td><td>2019-07-04 14:02:25</td><td>105</td><td>93</td><td>18902</td><td>0</td><td>209</td></tr><tr><td>127</td><td>1562220160003</td><td>8</td><td>2019-07-04 14:02:40</td><td>2019-07-04 14:04:22</td><td>102</td><td>90</td><td>18902</td><td>0</td><td>205</td></tr><tr><td>128</td><td>1562220280003</td><td>8</td><td>2019-07-04 14:04:40</td><td>2019-07-04 14:06:18</td><td>98</td><td>87</td><td>18902</td><td>0</td><td>214</td></tr><tr><td>129</td><td>1562220400003</td><td>8</td><td>2019-07-04 14:06:40</td><td>2019-07-04 14:08:16</td><td>96</td><td>83</td><td>18901</td><td>1</td><td>219</td></tr><tr><td>130</td><td>1562220520003</td><td>8</td><td>2019-07-04 14:08:40</td><td>2019-07-04 14:10:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>226</td></tr><tr><td>131</td><td>1562220640003</td><td>8</td><td>2019-07-04 14:10:40</td><td>2019-07-04 14:12:19</td><td>99</td><td>88</td><td>18902</td><td>0</td><td>240</td></tr><tr><td>132</td><td>1562220760002</td><td>8</td><td>2019-07-04 14:12:40</td><td>2019-07-04 14:14:18</td><td>98</td><td>85</td><td>18902</td><td>0</td><td>228</td></tr><tr><td>133</td><td>1562220880003</td><td>8</td><td>2019-07-04 14:14:40</td><td>2019-07-04 14:16:22</td><td>102</td><td>89</td><td>18902</td><td>0</td><td>219</td></tr><tr><td>134</td><td>1562221000003</td><td>8</td><td>2019-07-04 14:16:40</td><td>2019-07-04 14:18:17</td><td>97</td><td>85</td><td>18902</td><td>0</td><td>230</td></tr><tr><td>135</td><td>1562221120003</td><td>8</td><td>2019-07-04 14:18:40</td><td>2019-07-04 14:20:20</td><td>100</td><td>88</td><td>18902</td><td>0</td><td>247</td></tr><tr><td>136</td><td>1562221240003</td><td>8</td><td>2019-07-04 14:20:40</td><td>2019-07-04 14:22:17</td><td>97</td><td>86</td><td>18902</td><td>0</td><td>218</td></tr><tr><td>137</td><td>1562221360003</td><td>8</td><td>2019-07-04 14:22:40</td><td>2019-07-04 14:24:18</td><td>98</td><td>85</td><td>18902</td><td>0</td><td>256</td></tr><tr><td>138</td><td>1562221480003</td><td>8</td><td>2019-07-04 14:24:40</td><td>2019-07-04 14:26:23</td><td>103</td><td>89</td><td>18902</td><td>0</td><td>233</td></tr><tr><td>139</td><td>1562221600003</td><td>8</td><td>2019-07-04 14:26:40</td><td>2019-07-04 14:28:23</td><td>103</td><td>89</td><td>18902</td><td>0</td><td>246</td></tr><tr><td>140</td><td>1562221720003</td><td>8</td><td>2019-07-04 14:28:40</td><td>2019-07-04 14:30:22</td><td>102</td><td>87</td><td>18902</td><td>0</td><td>241</td></tr><tr><td>141</td><td>1562221840003</td><td>8</td><td>2019-07-04 14:30:40</td><td>2019-07-04 14:32:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>231</td></tr><tr><td>142</td><td>1562221960004</td><td>8</td><td>2019-07-04 14:32:40</td><td>2019-07-04 14:34:17</td><td>97</td><td>83</td><td>18902</td><td>0</td><td>241</td></tr><tr><td>143</td><td>1562222080003</td><td>8</td><td>2019-07-04 14:34:40</td><td>2019-07-04 14:36:17</td><td>97</td><td>84</td><td>18902</td><td>0</td><td>241</td></tr><tr><td>144</td><td>1562222200002</td><td>8</td><td>2019-07-04 14:36:40</td><td>2019-07-04 14:38:52</td><td>132</td><td>120</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>145</td><td>1562222340003</td><td>8</td><td>2019-07-04 14:39:00</td><td>2019-07-04 14:40:37</td><td>97</td><td>82</td><td>18901</td><td>1</td><td>263</td></tr><tr><td>146</td><td>1562222500043</td><td>8</td><td>2019-07-04 14:41:40</td><td>2019-07-04 14:43:14</td><td>94</td><td>81</td><td>18902</td><td>0</td><td>219</td></tr><tr><td>147</td><td>1562222620004</td><td>8</td><td>2019-07-04 14:43:40</td><td>2019-07-04 14:45:29</td><td>109</td><td>97</td><td>18902</td><td>0</td><td>208</td></tr><tr><td>148</td><td>1562222740004</td><td>8</td><td>2019-07-04 14:45:40</td><td>2019-07-04 14:47:18</td><td>98</td><td>84</td><td>18902</td><td>0</td><td>219</td></tr><tr><td>149</td><td>1562222860004</td><td>8</td><td>2019-07-04 14:47:40</td><td>2019-07-04 14:49:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>237</td></tr><tr><td>150</td><td>1562222980003</td><td>8</td><td>2019-07-04 14:49:40</td><td>2019-07-04 14:51:12</td><td>92</td><td>79</td><td>18902</td><td>0</td><td>212</td></tr><tr><td>151</td><td>1562223100004</td><td>8</td><td>2019-07-04 14:51:40</td><td>2019-07-04 14:53:15</td><td>95</td><td>81</td><td>18902</td><td>0</td><td>248</td></tr><tr><td>152</td><td>1562223220003</td><td>8</td><td>2019-07-04 14:53:40</td><td>2019-07-04 14:55:22</td><td>102</td><td>89</td><td>18902</td><td>0</td><td>242</td></tr><tr><td>153</td><td>1562223340003</td><td>8</td><td>2019-07-04 14:55:40</td><td>2019-07-04 14:57:18</td><td>98</td><td>84</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>154</td><td>1562223460003</td><td>8</td><td>2019-07-04 14:57:40</td><td>2019-07-04 14:59:19</td><td>99</td><td>84</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>155</td><td>1562223580003</td><td>8</td><td>2019-07-04 14:59:40</td><td>2019-07-04 15:01:24</td><td>104</td><td>88</td><td>18900</td><td>2</td><td>270</td></tr><tr><td>156</td><td>1562223700003</td><td>8</td><td>2019-07-04 15:01:40</td><td>2019-07-04 15:03:18</td><td>98</td><td>85</td><td>18902</td><td>0</td><td>254</td></tr><tr><td>157</td><td>1562223820003</td><td>8</td><td>2019-07-04 15:03:40</td><td>2019-07-04 15:05:57</td><td>137</td><td>113</td><td>18902</td><td>0</td><td>253</td></tr><tr><td>158</td><td>1562223960003</td><td>8</td><td>2019-07-04 15:06:00</td><td>2019-07-04 15:07:50</td><td>110</td><td>97</td><td>18902</td><td>0</td><td>262</td></tr><tr><td>159</td><td>1562224080004</td><td>8</td><td>2019-07-04 15:08:00</td><td>2019-07-04 15:09:44</td><td>104</td><td>90</td><td>18902</td><td>0</td><td>250</td></tr><tr><td>160</td><td>1562224200003</td><td>8</td><td>2019-07-04 15:10:00</td><td>2019-07-04 15:11:44</td><td>104</td><td>92</td><td>18902</td><td>0</td><td>244</td></tr><tr><td>161</td><td>1562224320004</td><td>8</td><td>2019-07-04 15:12:00</td><td>2019-07-04 15:13:46</td><td>106</td><td>93</td><td>18902</td><td>0</td><td>259</td></tr><tr><td>162</td><td>1562224440003</td><td>8</td><td>2019-07-04 15:14:00</td><td>2019-07-04 15:15:42</td><td>102</td><td>88</td><td>18902</td><td>0</td><td>239</td></tr><tr><td>163</td><td>1562224560003</td><td>8</td><td>2019-07-04 15:16:00</td><td>2019-07-04 15:17:43</td><td>103</td><td>89</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>164</td><td>1562224680003</td><td>8</td><td>2019-07-04 15:18:00</td><td>2019-07-04 15:19:35</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>241</td></tr><tr><td>165</td><td>1562224780003</td><td>8</td><td>2019-07-04 15:19:40</td><td>2019-07-04 15:21:19</td><td>99</td><td>86</td><td>18902</td><td>0</td><td>254</td></tr><tr><td>166</td><td>1562224900003</td><td>8</td><td>2019-07-04 15:21:40</td><td>2019-07-04 15:23:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>262</td></tr><tr><td>167</td><td>1562225020003</td><td>8</td><td>2019-07-04 15:23:40</td><td>2019-07-04 15:25:16</td><td>96</td><td>82</td><td>18902</td><td>0</td><td>268</td></tr><tr><td>168</td><td>1562225140003</td><td>8</td><td>2019-07-04 15:25:40</td><td>2019-07-04 15:27:35</td><td>115</td><td>99</td><td>18900</td><td>2</td><td>254</td></tr><tr><td>169</td><td>1562225260003</td><td>8</td><td>2019-07-04 15:27:40</td><td>2019-07-04 15:29:52</td><td>132</td><td>118</td><td>18902</td><td>0</td><td>252</td></tr><tr><td>170</td><td>1562225400003</td><td>8</td><td>2019-07-04 15:30:00</td><td>2019-07-04 15:31:57</td><td>117</td><td>103</td><td>18902</td><td>0</td><td>240</td></tr><tr><td>171</td><td>1562225520003</td><td>8</td><td>2019-07-04 15:32:00</td><td>2019-07-04 15:33:44</td><td>104</td><td>88</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>172</td><td>1562225640003</td><td>8</td><td>2019-07-04 15:34:00</td><td>2019-07-04 15:35:42</td><td>102</td><td>88</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>173</td><td>1562225760003</td><td>8</td><td>2019-07-04 15:36:00</td><td>2019-07-04 15:37:41</td><td>101</td><td>86</td><td>18902</td><td>0</td><td>277</td></tr><tr><td>174</td><td>1562225880002</td><td>8</td><td>2019-07-04 15:38:00</td><td>2019-07-04 15:39:50</td><td>110</td><td>94</td><td>18900</td><td>2</td><td>275</td></tr><tr><td>175</td><td>1562226000003</td><td>8</td><td>2019-07-04 15:40:00</td><td>2019-07-04 15:41:39</td><td>99</td><td>84</td><td>18902</td><td>0</td><td>281</td></tr><tr><td>176</td><td>1562226100003</td><td>8</td><td>2019-07-04 15:41:40</td><td>2019-07-04 15:43:17</td><td>97</td><td>82</td><td>18902</td><td>0</td><td>304</td></tr><tr><td>177</td><td>1562226220004</td><td>8</td><td>2019-07-04 15:43:40</td><td>2019-07-04 15:45:21</td><td>101</td><td>87</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>178</td><td>1562226340002</td><td>8</td><td>2019-07-04 15:45:40</td><td>2019-07-04 15:47:24</td><td>104</td><td>89</td><td>18902</td><td>0</td><td>284</td></tr><tr><td>179</td><td>1562226460003</td><td>8</td><td>2019-07-04 15:47:40</td><td>2019-07-04 15:49:22</td><td>102</td><td>87</td><td>18902</td><td>0</td><td>290</td></tr><tr><td>180</td><td>1562226580003</td><td>8</td><td>2019-07-04 15:49:40</td><td>2019-07-04 15:51:23</td><td>103</td><td>89</td><td>18902</td><td>0</td><td>287</td></tr><tr><td>181</td><td>1562226700003</td><td>8</td><td>2019-07-04 15:51:40</td><td>2019-07-04 15:53:21</td><td>101</td><td>89</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>182</td><td>1562226820003</td><td>8</td><td>2019-07-04 15:53:40</td><td>2019-07-04 15:55:34</td><td>114</td><td>99</td><td>18902</td><td>0</td><td>276</td></tr><tr><td>183</td><td>1562226940004</td><td>8</td><td>2019-07-04 15:55:40</td><td>2019-07-04 15:57:50</td><td>130</td><td>113</td><td>18901</td><td>1</td><td>280</td></tr><tr><td>184</td><td>1562227080003</td><td>8</td><td>2019-07-04 15:58:00</td><td>2019-07-04 15:59:54</td><td>114</td><td>99</td><td>18902</td><td>0</td><td>259</td></tr><tr><td>185</td><td>1562227200003</td><td>8</td><td>2019-07-04 16:00:00</td><td>2019-07-04 16:01:43</td><td>103</td><td>89</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>186</td><td>1562227320003</td><td>8</td><td>2019-07-04 16:02:00</td><td>2019-07-04 16:03:48</td><td>108</td><td>94</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>187</td><td>1562227440002</td><td>8</td><td>2019-07-04 16:04:00</td><td>2019-07-04 16:05:39</td><td>99</td><td>86</td><td>18902</td><td>0</td><td>257</td></tr><tr><td>188</td><td>1562227540003</td><td>8</td><td>2019-07-04 16:05:40</td><td>2019-07-04 16:07:21</td><td>101</td><td>87</td><td>18901</td><td>1</td><td>251</td></tr><tr><td>189</td><td>1562227660003</td><td>8</td><td>2019-07-04 16:07:40</td><td>2019-07-04 16:09:20</td><td>100</td><td>85</td><td>18902</td><td>0</td><td>239</td></tr><tr><td>190</td><td>1562227780003</td><td>8</td><td>2019-07-04 16:09:40</td><td>2019-07-04 16:11:28</td><td>108</td><td>95</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>191</td><td>1562227900003</td><td>8</td><td>2019-07-04 16:11:40</td><td>2019-07-04 16:13:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>284</td></tr><tr><td>192</td><td>1562228020002</td><td>8</td><td>2019-07-04 16:13:40</td><td>2019-07-04 16:15:46</td><td>126</td><td>114</td><td>18902</td><td>0</td><td>247</td></tr><tr><td>193</td><td>1562228160003</td><td>8</td><td>2019-07-04 16:16:00</td><td>2019-07-04 16:17:39</td><td>99</td><td>86</td><td>18902</td><td>0</td><td>274</td></tr><tr><td>194</td><td>1562228260003</td><td>8</td><td>2019-07-04 16:17:40</td><td>2019-07-04 16:19:22</td><td>102</td><td>89</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>195</td><td>1562228380003</td><td>8</td><td>2019-07-04 16:19:40</td><td>2019-07-04 16:21:28</td><td>108</td><td>93</td><td>18901</td><td>1</td><td>252</td></tr><tr><td>196</td><td>1562228500004</td><td>8</td><td>2019-07-04 16:21:40</td><td>2019-07-04 16:23:33</td><td>113</td><td>97</td><td>18899</td><td>3</td><td>252</td></tr><tr><td>197</td><td>1562228620003</td><td>8</td><td>2019-07-04 16:23:40</td><td>2019-07-04 16:25:46</td><td>126</td><td>101</td><td>18898</td><td>4</td><td>269</td></tr><tr><td>198</td><td>1562228760002</td><td>8</td><td>2019-07-04 16:26:00</td><td>2019-07-04 16:27:51</td><td>111</td><td>93</td><td>18899</td><td>3</td><td>250</td></tr><tr><td>199</td><td>1562228880003</td><td>8</td><td>2019-07-04 16:28:00</td><td>2019-07-04 16:29:35</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>247</td></tr><tr><td>200</td><td>1562228980002</td><td>8</td><td>2019-07-04 16:29:40</td><td>2019-07-04 16:31:22</td><td>102</td><td>87</td><td>18902</td><td>0</td><td>252</td></tr><tr><td>201</td><td>1562229100003</td><td>8</td><td>2019-07-04 16:31:40</td><td>2019-07-04 16:33:21</td><td>101</td><td>89</td><td>18902</td><td>0</td><td>226</td></tr><tr><td>202</td><td>1562229220003</td><td>8</td><td>2019-07-04 16:33:40</td><td>2019-07-04 16:35:23</td><td>103</td><td>91</td><td>18902</td><td>0</td><td>241</td></tr><tr><td>203</td><td>1562229340002</td><td>8</td><td>2019-07-04 16:35:40</td><td>2019-07-04 16:37:28</td><td>108</td><td>91</td><td>18899</td><td>3</td><td>266</td></tr><tr><td>204</td><td>1562229460003</td><td>8</td><td>2019-07-04 16:37:40</td><td>2019-07-04 16:40:41</td><td>181</td><td>159</td><td>18901</td><td>1</td><td>264</td></tr><tr><td>205</td><td>1562229660003</td><td>8</td><td>2019-07-04 16:41:00</td><td>2019-07-04 16:42:42</td><td>102</td><td>87</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>206</td><td>1562229780002</td><td>8</td><td>2019-07-04 16:43:00</td><td>2019-07-04 16:44:36</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>240</td></tr><tr><td>207</td><td>1562229880003</td><td>8</td><td>2019-07-04 16:44:40</td><td>2019-07-04 16:46:20</td><td>100</td><td>85</td><td>18901</td><td>1</td><td>242</td></tr><tr><td>208</td><td>1562230000003</td><td>8</td><td>2019-07-04 16:46:40</td><td>2019-07-04 16:48:22</td><td>102</td><td>89</td><td>18902</td><td>0</td><td>243</td></tr><tr><td>209</td><td>1562230120002</td><td>8</td><td>2019-07-04 16:48:40</td><td>2019-07-04 16:50:33</td><td>113</td><td>88</td><td>18900</td><td>2</td><td>255</td></tr><tr><td>210</td><td>1562230240003</td><td>8</td><td>2019-07-04 16:50:40</td><td>2019-07-04 16:52:27</td><td>106</td><td>93</td><td>18902</td><td>0</td><td>244</td></tr><tr><td>211</td><td>1562230360003</td><td>8</td><td>2019-07-04 16:52:40</td><td>2019-07-04 16:54:21</td><td>101</td><td>88</td><td>18902</td><td>0</td><td>276</td></tr><tr><td>212</td><td>1562230480003</td><td>8</td><td>2019-07-04 16:54:40</td><td>2019-07-04 16:56:25</td><td>105</td><td>89</td><td>18900</td><td>2</td><td>284</td></tr><tr><td>213</td><td>1562230600003</td><td>8</td><td>2019-07-04 16:56:40</td><td>2019-07-04 16:58:19</td><td>99</td><td>83</td><td>18902</td><td>0</td><td>290</td></tr><tr><td>214</td><td>1562230720002</td><td>8</td><td>2019-07-04 16:58:40</td><td>2019-07-04 17:00:57</td><td>137</td><td>97</td><td>18894</td><td>8</td><td>282</td></tr><tr><td>215</td><td>1562230860003</td><td>8</td><td>2019-07-04 17:01:00</td><td>2019-07-04 17:02:40</td><td>100</td><td>85</td><td>18901</td><td>1</td><td>264</td></tr><tr><td>216</td><td>1562230980002</td><td>8</td><td>2019-07-04 17:03:00</td><td>2019-07-04 17:04:50</td><td>110</td><td>97</td><td>18902</td><td>0</td><td>296</td></tr><tr><td>217</td><td>1562231100003</td><td>8</td><td>2019-07-04 17:05:00</td><td>2019-07-04 17:06:58</td><td>118</td><td>102</td><td>18902</td><td>0</td><td>267</td></tr><tr><td>218</td><td>1562231220003</td><td>8</td><td>2019-07-04 17:07:00</td><td>2019-07-04 17:09:00</td><td>120</td><td>103</td><td>18902</td><td>0</td><td>289</td></tr><tr><td>219</td><td>1562231380003</td><td>8</td><td>2019-07-04 17:09:40</td><td>2019-07-04 17:11:37</td><td>117</td><td>101</td><td>18902</td><td>0</td><td>360</td></tr><tr><td>220</td><td>1562231500003</td><td>8</td><td>2019-07-04 17:11:40</td><td>2019-07-04 17:13:46</td><td>126</td><td>100</td><td>18901</td><td>1</td><td>347</td></tr><tr><td>221</td><td>1562231640003</td><td>8</td><td>2019-07-04 17:14:00</td><td>2019-07-04 17:16:21</td><td>141</td><td>122</td><td>18901</td><td>1</td><td>342</td></tr><tr><td>222</td><td>1562231800003</td><td>8</td><td>2019-07-04 17:16:40</td><td>2019-07-04 17:18:52</td><td>132</td><td>113</td><td>18902</td><td>0</td><td>354</td></tr><tr><td>223</td><td>1562231940003</td><td>8</td><td>2019-07-04 17:19:00</td><td>2019-07-04 17:20:56</td><td>116</td><td>97</td><td>18901</td><td>1</td><td>349</td></tr><tr><td>224</td><td>1562232060003</td><td>8</td><td>2019-07-04 17:21:00</td><td>2019-07-04 17:22:51</td><td>111</td><td>93</td><td>18902</td><td>0</td><td>352</td></tr><tr><td>225</td><td>1562232180003</td><td>8</td><td>2019-07-04 17:23:00</td><td>2019-07-04 17:24:44</td><td>104</td><td>87</td><td>18902</td><td>0</td><td>375</td></tr><tr><td>226</td><td>1562232300002</td><td>8</td><td>2019-07-04 17:25:00</td><td>2019-07-04 17:27:01</td><td>121</td><td>91</td><td>18899</td><td>3</td><td>385</td></tr><tr><td>227</td><td>1562232460002</td><td>8</td><td>2019-07-04 17:27:40</td><td>2019-07-04 17:29:30</td><td>110</td><td>91</td><td>18902</td><td>0</td><td>390</td></tr><tr><td>228</td><td>1562232580002</td><td>8</td><td>2019-07-04 17:29:40</td><td>2019-07-04 17:31:47</td><td>127</td><td>105</td><td>18900</td><td>2</td><td>407</td></tr><tr><td>229</td><td>1562232720003</td><td>8</td><td>2019-07-04 17:32:00</td><td>2019-07-04 17:33:46</td><td>105</td><td>86</td><td>18902</td><td>0</td><td>415</td></tr><tr><td>230</td><td>1562232840003</td><td>8</td><td>2019-07-04 17:34:00</td><td>2019-07-04 17:35:54</td><td>114</td><td>82</td><td>18901</td><td>1</td><td>431</td></tr><tr><td>231</td><td>1562232960003</td><td>8</td><td>2019-07-04 17:36:00</td><td>2019-07-04 17:37:56</td><td>116</td><td>93</td><td>18901</td><td>1</td><td>468</td></tr><tr><td>232</td><td>1562233080003</td><td>8</td><td>2019-07-04 17:38:00</td><td>2019-07-04 17:39:45</td><td>105</td><td>82</td><td>18902</td><td>0</td><td>499</td></tr><tr><td>233</td><td>1562233200003</td><td>8</td><td>2019-07-04 17:40:00</td><td>2019-07-04 17:41:47</td><td>107</td><td>85</td><td>18902</td><td>0</td><td>490</td></tr><tr><td>234</td><td>1562233320002</td><td>8</td><td>2019-07-04 17:42:00</td><td>2019-07-04 17:43:55</td><td>115</td><td>89</td><td>18902</td><td>0</td><td>499</td></tr><tr><td>235</td><td>1562233440002</td><td>8</td><td>2019-07-04 17:44:00</td><td>2019-07-04 17:45:42</td><td>102</td><td>78</td><td>18902</td><td>0</td><td>491</td></tr><tr><td>236</td><td>1562233560003</td><td>8</td><td>2019-07-04 17:46:00</td><td>2019-07-04 17:47:49</td><td>109</td><td>84</td><td>18902</td><td>0</td><td>506</td></tr><tr><td>237</td><td>1562233680002</td><td>8</td><td>2019-07-04 17:48:00</td><td>2019-07-04 17:49:46</td><td>106</td><td>80</td><td>18902</td><td>0</td><td>521</td></tr><tr><td>238</td><td>1562233800002</td><td>8</td><td>2019-07-04 17:50:00</td><td>2019-07-04 17:51:49</td><td>109</td><td>83</td><td>18902</td><td>0</td><td>547</td></tr><tr><td>239</td><td>1562233920003</td><td>8</td><td>2019-07-04 17:52:00</td><td>2019-07-04 17:53:48</td><td>108</td><td>81</td><td>18902</td><td>0</td><td>558</td></tr><tr><td>240</td><td>1562234040003</td><td>8</td><td>2019-07-04 17:54:00</td><td>2019-07-04 17:55:51</td><td>111</td><td>84</td><td>18902</td><td>0</td><td>557</td></tr><tr><td>241</td><td>1562234160002</td><td>8</td><td>2019-07-04 17:56:00</td><td>2019-07-04 17:57:51</td><td>111</td><td>82</td><td>18902</td><td>0</td><td>574</td></tr><tr><td>242</td><td>1562234280002</td><td>8</td><td>2019-07-04 17:58:00</td><td>2019-07-04 17:59:51</td><td>111</td><td>80</td><td>18902</td><td>0</td><td>613</td></tr><tr><td>243</td><td>1562234400003</td><td>8</td><td>2019-07-04 18:00:00</td><td>2019-07-04 18:01:58</td><td>118</td><td>84</td><td>18899</td><td>3</td><td>577</td></tr><tr><td>244</td><td>1562234520003</td><td>8</td><td>2019-07-04 18:02:00</td><td>2019-07-04 18:03:45</td><td>105</td><td>78</td><td>18902</td><td>0</td><td>568</td></tr><tr><td>245</td><td>1562234640003</td><td>8</td><td>2019-07-04 18:04:00</td><td>2019-07-04 18:05:47</td><td>107</td><td>78</td><td>18902</td><td>0</td><td>554</td></tr><tr><td>246</td><td>1562234760003</td><td>8</td><td>2019-07-04 18:06:00</td><td>2019-07-04 18:07:47</td><td>107</td><td>78</td><td>18902</td><td>0</td><td>561</td></tr><tr><td>247</td><td>1562234880002</td><td>8</td><td>2019-07-04 18:08:00</td><td>2019-07-04 18:09:46</td><td>106</td><td>81</td><td>18902</td><td>0</td><td>533</td></tr><tr><td>248</td><td>1562235000003</td><td>8</td><td>2019-07-04 18:10:00</td><td>2019-07-04 18:11:47</td><td>107</td><td>81</td><td>18902</td><td>0</td><td>530</td></tr><tr><td>249</td><td>1562235120002</td><td>8</td><td>2019-07-04 18:12:00</td><td>2019-07-04 18:13:48</td><td>108</td><td>80</td><td>18902</td><td>0</td><td>571</td></tr><tr><td>250</td><td>1562235240002</td><td>8</td><td>2019-07-04 18:14:00</td><td>2019-07-04 18:15:52</td><td>112</td><td>81</td><td>18902</td><td>0</td><td>582</td></tr><tr><td>251</td><td>1562235360003</td><td>8</td><td>2019-07-04 18:16:00</td><td>2019-07-04 18:17:50</td><td>110</td><td>81</td><td>18902</td><td>0</td><td>602</td></tr><tr><td>252</td><td>1562235480003</td><td>8</td><td>2019-07-04 18:18:00</td><td>2019-07-04 18:19:48</td><td>108</td><td>80</td><td>18902</td><td>0</td><td>571</td></tr><tr><td>253</td><td>1562235600002</td><td>8</td><td>2019-07-04 18:20:00</td><td>2019-07-04 18:21:52</td><td>112</td><td>81</td><td>18902</td><td>0</td><td>588</td></tr><tr><td>254</td><td>1562235720003</td><td>8</td><td>2019-07-04 18:22:00</td><td>2019-07-04 18:23:53</td><td>113</td><td>84</td><td>18902</td><td>0</td><td>588</td></tr><tr><td>255</td><td>1562235840003</td><td>8</td><td>2019-07-04 18:24:00</td><td>2019-07-04 18:25:48</td><td>108</td><td>79</td><td>18902</td><td>0</td><td>565</td></tr><tr><td>256</td><td>1562235960002</td><td>8</td><td>2019-07-04 18:26:00</td><td>2019-07-04 18:27:51</td><td>111</td><td>81</td><td>18902</td><td>0</td><td>577</td></tr><tr><td>257</td><td>1562236080003</td><td>8</td><td>2019-07-04 18:28:00</td><td>2019-07-04 18:29:48</td><td>108</td><td>81</td><td>18902</td><td>0</td><td>558</td></tr><tr><td>258</td><td>1562236200003</td><td>8</td><td>2019-07-04 18:30:00</td><td>2019-07-04 18:31:50</td><td>110</td><td>82</td><td>18902</td><td>0</td><td>555</td></tr><tr><td>259</td><td>1562236320002</td><td>8</td><td>2019-07-04 18:32:00</td><td>2019-07-04 18:33:50</td><td>110</td><td>82</td><td>18902</td><td>0</td><td>547</td></tr><tr><td>260</td><td>1562236440004</td><td>8</td><td>2019-07-04 18:34:00</td><td>2019-07-04 18:35:46</td><td>106</td><td>80</td><td>18902</td><td>0</td><td>546</td></tr><tr><td>261</td><td>1562236560003</td><td>8</td><td>2019-07-04 18:36:00</td><td>2019-07-04 18:37:51</td><td>111</td><td>84</td><td>18902</td><td>0</td><td>508</td></tr><tr><td>262</td><td>1562236680003</td><td>8</td><td>2019-07-04 18:38:00</td><td>2019-07-04 18:39:46</td><td>106</td><td>81</td><td>18902</td><td>0</td><td>509</td></tr><tr><td>263</td><td>1562236800003</td><td>8</td><td>2019-07-04 18:40:00</td><td>2019-07-04 18:41:54</td><td>114</td><td>83</td><td>18901</td><td>1</td><td>511</td></tr><tr><td>264</td><td>1562236920003</td><td>8</td><td>2019-07-04 18:42:00</td><td>2019-07-04 18:43:49</td><td>109</td><td>83</td><td>18902</td><td>0</td><td>517</td></tr><tr><td>265</td><td>1562237040003</td><td>8</td><td>2019-07-04 18:44:00</td><td>2019-07-04 18:45:45</td><td>105</td><td>81</td><td>18902</td><td>0</td><td>493</td></tr><tr><td>266</td><td>1562237160003</td><td>8</td><td>2019-07-04 18:46:00</td><td>2019-07-04 18:47:45</td><td>105</td><td>81</td><td>18902</td><td>0</td><td>498</td></tr><tr><td>267</td><td>1562237280003</td><td>8</td><td>2019-07-04 18:48:00</td><td>2019-07-04 18:49:47</td><td>107</td><td>82</td><td>18902</td><td>0</td><td>482</td></tr><tr><td>268</td><td>1562237400002</td><td>8</td><td>2019-07-04 18:50:00</td><td>2019-07-04 18:51:44</td><td>104</td><td>80</td><td>18902</td><td>0</td><td>466</td></tr><tr><td>269</td><td>1562237520003</td><td>8</td><td>2019-07-04 18:52:00</td><td>2019-07-04 18:53:44</td><td>104</td><td>81</td><td>18902</td><td>0</td><td>458</td></tr><tr><td>270</td><td>1562237640003</td><td>8</td><td>2019-07-04 18:54:00</td><td>2019-07-04 18:55:42</td><td>102</td><td>80</td><td>18902</td><td>0</td><td>458</td></tr><tr><td>271</td><td>1562237760002</td><td>8</td><td>2019-07-04 18:56:00</td><td>2019-07-04 18:57:42</td><td>102</td><td>80</td><td>18902</td><td>0</td><td>453</td></tr><tr><td>272</td><td>1562237880003</td><td>8</td><td>2019-07-04 18:58:00</td><td>2019-07-04 18:59:44</td><td>104</td><td>84</td><td>18902</td><td>0</td><td>440</td></tr><tr><td>273</td><td>1562238000002</td><td>8</td><td>2019-07-04 19:00:00</td><td>2019-07-04 19:01:41</td><td>101</td><td>81</td><td>18902</td><td>0</td><td>403</td></tr><tr><td>274</td><td>1562238120003</td><td>8</td><td>2019-07-04 19:02:00</td><td>2019-07-04 19:03:41</td><td>101</td><td>83</td><td>18902</td><td>0</td><td>381</td></tr><tr><td>275</td><td>1562238240002</td><td>8</td><td>2019-07-04 19:04:00</td><td>2019-07-04 19:05:41</td><td>101</td><td>84</td><td>18902</td><td>0</td><td>349</td></tr><tr><td>276</td><td>1562238360002</td><td>8</td><td>2019-07-04 19:06:00</td><td>2019-07-04 19:07:37</td><td>97</td><td>79</td><td>18902</td><td>0</td><td>352</td></tr><tr><td>277</td><td>1562238460003</td><td>8</td><td>2019-07-04 19:07:40</td><td>2019-07-04 19:09:16</td><td>96</td><td>79</td><td>18902</td><td>0</td><td>329</td></tr><tr><td>278</td><td>1562238580002</td><td>8</td><td>2019-07-04 19:09:40</td><td>2019-07-04 19:11:18</td><td>98</td><td>81</td><td>18902</td><td>0</td><td>354</td></tr><tr><td>279</td><td>1562238700002</td><td>8</td><td>2019-07-04 19:11:40</td><td>2019-07-04 19:13:17</td><td>97</td><td>82</td><td>18902</td><td>0</td><td>329</td></tr><tr><td>280</td><td>1562238820003</td><td>8</td><td>2019-07-04 19:13:40</td><td>2019-07-04 19:15:15</td><td>95</td><td>81</td><td>18902</td><td>0</td><td>320</td></tr><tr><td>281</td><td>1562238940002</td><td>8</td><td>2019-07-04 19:15:40</td><td>2019-07-04 19:17:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>296</td></tr><tr><td>282</td><td>1562239060002</td><td>8</td><td>2019-07-04 19:17:40</td><td>2019-07-04 19:19:17</td><td>97</td><td>83</td><td>18902</td><td>0</td><td>303</td></tr><tr><td>283</td><td>1562239180003</td><td>8</td><td>2019-07-04 19:19:40</td><td>2019-07-04 19:21:17</td><td>97</td><td>82</td><td>18902</td><td>0</td><td>311</td></tr><tr><td>284</td><td>1562239300002</td><td>8</td><td>2019-07-04 19:21:40</td><td>2019-07-04 19:23:16</td><td>96</td><td>81</td><td>18902</td><td>0</td><td>304</td></tr><tr><td>285</td><td>1562239420003</td><td>8</td><td>2019-07-04 19:23:40</td><td>2019-07-04 19:25:12</td><td>92</td><td>78</td><td>18902</td><td>0</td><td>314</td></tr><tr><td>286</td><td>1562239540003</td><td>8</td><td>2019-07-04 19:25:40</td><td>2019-07-04 19:27:13</td><td>93</td><td>80</td><td>18902</td><td>0</td><td>280</td></tr><tr><td>287</td><td>1562239660003</td><td>8</td><td>2019-07-04 19:27:40</td><td>2019-07-04 19:29:11</td><td>91</td><td>77</td><td>18902</td><td>0</td><td>299</td></tr><tr><td>288</td><td>1562239780002</td><td>8</td><td>2019-07-04 19:29:40</td><td>2019-07-04 19:31:14</td><td>94</td><td>80</td><td>18902</td><td>0</td><td>312</td></tr><tr><td>289</td><td>1562239900002</td><td>8</td><td>2019-07-04 19:31:40</td><td>2019-07-04 19:33:15</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>290</td><td>1562240020002</td><td>8</td><td>2019-07-04 19:33:40</td><td>2019-07-04 19:35:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>291</td><td>1562240140003</td><td>8</td><td>2019-07-04 19:35:40</td><td>2019-07-04 19:37:18</td><td>98</td><td>84</td><td>18902</td><td>0</td><td>243</td></tr><tr><td>292</td><td>1562240260002</td><td>8</td><td>2019-07-04 19:37:40</td><td>2019-07-04 19:39:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>262</td></tr><tr><td>293</td><td>1562240380003</td><td>8</td><td>2019-07-04 19:39:40</td><td>2019-07-04 19:41:16</td><td>96</td><td>84</td><td>18902</td><td>0</td><td>275</td></tr><tr><td>294</td><td>1562240500003</td><td>8</td><td>2019-07-04 19:41:40</td><td>2019-07-04 19:43:18</td><td>98</td><td>85</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>295</td><td>1562240620003</td><td>8</td><td>2019-07-04 19:43:40</td><td>2019-07-04 19:45:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>268</td></tr><tr><td>296</td><td>1562240740003</td><td>8</td><td>2019-07-04 19:45:40</td><td>2019-07-04 19:47:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>297</td><td>1562240860003</td><td>8</td><td>2019-07-04 19:47:40</td><td>2019-07-04 19:49:18</td><td>98</td><td>85</td><td>18902</td><td>0</td><td>261</td></tr><tr><td>298</td><td>1562240980002</td><td>8</td><td>2019-07-04 19:49:40</td><td>2019-07-04 19:51:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>299</td><td>1562241100003</td><td>8</td><td>2019-07-04 19:51:40</td><td>2019-07-04 19:53:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>256</td></tr><tr><td>300</td><td>1562241220003</td><td>8</td><td>2019-07-04 19:53:40</td><td>2019-07-04 19:55:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>280</td></tr><tr><td>301</td><td>1562241340002</td><td>8</td><td>2019-07-04 19:55:40</td><td>2019-07-04 19:57:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>278</td></tr><tr><td>302</td><td>1562241460003</td><td>8</td><td>2019-07-04 19:57:40</td><td>2019-07-04 19:59:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>303</td><td>1562241580003</td><td>8</td><td>2019-07-04 19:59:40</td><td>2019-07-04 20:01:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>304</td><td>1562241700003</td><td>8</td><td>2019-07-04 20:01:40</td><td>2019-07-04 20:03:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>305</td><td>1562241820003</td><td>8</td><td>2019-07-04 20:03:40</td><td>2019-07-04 20:05:12</td><td>92</td><td>81</td><td>18902</td><td>0</td><td>266</td></tr><tr><td>306</td><td>1562241940003</td><td>8</td><td>2019-07-04 20:05:40</td><td>2019-07-04 20:07:16</td><td>96</td><td>81</td><td>18902</td><td>0</td><td>296</td></tr><tr><td>307</td><td>1562242060002</td><td>8</td><td>2019-07-04 20:07:40</td><td>2019-07-04 20:09:15</td><td>95</td><td>80</td><td>18902</td><td>0</td><td>296</td></tr><tr><td>308</td><td>1562242180002</td><td>8</td><td>2019-07-04 20:09:40</td><td>2019-07-04 20:11:17</td><td>97</td><td>82</td><td>18902</td><td>0</td><td>306</td></tr><tr><td>309</td><td>1562242300003</td><td>8</td><td>2019-07-04 20:11:40</td><td>2019-07-04 20:13:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>291</td></tr><tr><td>310</td><td>1562242420003</td><td>8</td><td>2019-07-04 20:13:40</td><td>2019-07-04 20:15:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>267</td></tr><tr><td>311</td><td>1562242540002</td><td>8</td><td>2019-07-04 20:15:40</td><td>2019-07-04 20:17:11</td><td>91</td><td>79</td><td>18902</td><td>0</td><td>255</td></tr><tr><td>312</td><td>1562242660003</td><td>8</td><td>2019-07-04 20:17:40</td><td>2019-07-04 20:19:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>273</td></tr><tr><td>313</td><td>1562242780003</td><td>8</td><td>2019-07-04 20:19:40</td><td>2019-07-04 20:21:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>284</td></tr><tr><td>314</td><td>1562242900002</td><td>8</td><td>2019-07-04 20:21:40</td><td>2019-07-04 20:23:15</td><td>95</td><td>81</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>315</td><td>1562243020003</td><td>8</td><td>2019-07-04 20:23:40</td><td>2019-07-04 20:25:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>266</td></tr><tr><td>316</td><td>1562243140003</td><td>8</td><td>2019-07-04 20:25:40</td><td>2019-07-04 20:27:18</td><td>98</td><td>87</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>317</td><td>1562243260008</td><td>8</td><td>2019-07-04 20:27:40</td><td>2019-07-04 20:29:18</td><td>98</td><td>86</td><td>18902</td><td>0</td><td>297</td></tr><tr><td>318</td><td>1562243380003</td><td>8</td><td>2019-07-04 20:29:40</td><td>2019-07-04 20:31:20</td><td>100</td><td>87</td><td>18902</td><td>0</td><td>289</td></tr><tr><td>319</td><td>1562243500002</td><td>8</td><td>2019-07-04 20:31:40</td><td>2019-07-04 20:33:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>320</td><td>1562243620002</td><td>8</td><td>2019-07-04 20:33:40</td><td>2019-07-04 20:35:16</td><td>96</td><td>83</td><td>18902</td><td>0</td><td>278</td></tr><tr><td>321</td><td>1562243740002</td><td>8</td><td>2019-07-04 20:35:40</td><td>2019-07-04 20:37:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>322</td><td>1562243860003</td><td>8</td><td>2019-07-04 20:37:40</td><td>2019-07-04 20:39:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>264</td></tr><tr><td>323</td><td>1562243980002</td><td>8</td><td>2019-07-04 20:39:40</td><td>2019-07-04 20:41:16</td><td>96</td><td>84</td><td>18902</td><td>0</td><td>236</td></tr><tr><td>324</td><td>1562244100002</td><td>8</td><td>2019-07-04 20:41:40</td><td>2019-07-04 20:43:16</td><td>96</td><td>84</td><td>18902</td><td>0</td><td>248</td></tr><tr><td>325</td><td>1562244220002</td><td>8</td><td>2019-07-04 20:43:40</td><td>2019-07-04 20:45:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>273</td></tr><tr><td>326</td><td>1562244340002</td><td>8</td><td>2019-07-04 20:45:40</td><td>2019-07-04 20:47:12</td><td>92</td><td>79</td><td>18902</td><td>0</td><td>256</td></tr><tr><td>327</td><td>1562244460004</td><td>8</td><td>2019-07-04 20:47:40</td><td>2019-07-04 20:49:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>274</td></tr><tr><td>328</td><td>1562244580003</td><td>8</td><td>2019-07-04 20:49:40</td><td>2019-07-04 20:51:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>284</td></tr><tr><td>329</td><td>1562244700002</td><td>8</td><td>2019-07-04 20:51:40</td><td>2019-07-04 20:53:15</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>276</td></tr><tr><td>330</td><td>1562244820002</td><td>8</td><td>2019-07-04 20:53:40</td><td>2019-07-04 20:55:15</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>235</td></tr><tr><td>331</td><td>1562244940003</td><td>8</td><td>2019-07-04 20:55:40</td><td>2019-07-04 20:57:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>250</td></tr><tr><td>332</td><td>1562245060003</td><td>8</td><td>2019-07-04 20:57:40</td><td>2019-07-04 20:59:13</td><td>93</td><td>80</td><td>18902</td><td>0</td><td>273</td></tr><tr><td>333</td><td>1562245180003</td><td>8</td><td>2019-07-04 20:59:40</td><td>2019-07-04 21:01:10</td><td>90</td><td>78</td><td>18902</td><td>0</td><td>259</td></tr><tr><td>334</td><td>1562245300002</td><td>8</td><td>2019-07-04 21:01:40</td><td>2019-07-04 21:03:13</td><td>93</td><td>80</td><td>18902</td><td>0</td><td>214</td></tr><tr><td>335</td><td>1562245420002</td><td>8</td><td>2019-07-04 21:03:40</td><td>2019-07-04 21:05:11</td><td>91</td><td>79</td><td>18902</td><td>0</td><td>226</td></tr><tr><td>336</td><td>1562245540002</td><td>8</td><td>2019-07-04 21:05:40</td><td>2019-07-04 21:07:15</td><td>95</td><td>84</td><td>18902</td><td>0</td><td>237</td></tr><tr><td>337</td><td>1562245660002</td><td>8</td><td>2019-07-04 21:07:40</td><td>2019-07-04 21:09:11</td><td>91</td><td>80</td><td>18902</td><td>0</td><td>219</td></tr><tr><td>338</td><td>1562245780003</td><td>8</td><td>2019-07-04 21:09:40</td><td>2019-07-04 21:11:19</td><td>99</td><td>87</td><td>18902</td><td>0</td><td>236</td></tr><tr><td>339</td><td>1562245900002</td><td>8</td><td>2019-07-04 21:11:40</td><td>2019-07-04 21:13:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>220</td></tr><tr><td>340</td><td>1562246020003</td><td>8</td><td>2019-07-04 21:13:40</td><td>2019-07-04 21:15:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>222</td></tr><tr><td>341</td><td>1562246140003</td><td>8</td><td>2019-07-04 21:15:40</td><td>2019-07-04 21:17:10</td><td>90</td><td>79</td><td>18902</td><td>0</td><td>197</td></tr><tr><td>342</td><td>1562246260003</td><td>8</td><td>2019-07-04 21:17:40</td><td>2019-07-04 21:19:11</td><td>91</td><td>79</td><td>18902</td><td>0</td><td>218</td></tr><tr><td>343</td><td>1562246380002</td><td>8</td><td>2019-07-04 21:19:40</td><td>2019-07-04 21:21:15</td><td>95</td><td>83</td><td>18902</td><td>0</td><td>212</td></tr><tr><td>344</td><td>1562246500003</td><td>8</td><td>2019-07-04 21:21:40</td><td>2019-07-04 21:23:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>199</td></tr><tr><td>345</td><td>1562246620002</td><td>8</td><td>2019-07-04 21:23:40</td><td>2019-07-04 21:25:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>208</td></tr><tr><td>346</td><td>1562246740003</td><td>8</td><td>2019-07-04 21:25:40</td><td>2019-07-04 21:27:14</td><td>94</td><td>83</td><td>18902</td><td>0</td><td>212</td></tr><tr><td>347</td><td>1562246860003</td><td>8</td><td>2019-07-04 21:27:40</td><td>2019-07-04 21:29:14</td><td>94</td><td>83</td><td>18902</td><td>0</td><td>211</td></tr><tr><td>348</td><td>1562246980003</td><td>8</td><td>2019-07-04 21:29:40</td><td>2019-07-04 21:31:16</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>207</td></tr><tr><td>349</td><td>1562247100003</td><td>8</td><td>2019-07-04 21:31:40</td><td>2019-07-04 21:33:19</td><td>99</td><td>87</td><td>18902</td><td>0</td><td>212</td></tr><tr><td>350</td><td>1562247220002</td><td>8</td><td>2019-07-04 21:33:40</td><td>2019-07-04 21:35:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>193</td></tr><tr><td>351</td><td>1562247340002</td><td>8</td><td>2019-07-04 21:35:40</td><td>2019-07-04 21:37:23</td><td>103</td><td>91</td><td>18902</td><td>0</td><td>198</td></tr><tr><td>352</td><td>1562247460002</td><td>8</td><td>2019-07-04 21:37:40</td><td>2019-07-04 21:39:16</td><td>96</td><td>85</td><td>18902</td><td>0</td><td>206</td></tr><tr><td>353</td><td>1562247580002</td><td>8</td><td>2019-07-04 21:39:40</td><td>2019-07-04 21:41:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>223</td></tr><tr><td>354</td><td>1562247700002</td><td>8</td><td>2019-07-04 21:41:40</td><td>2019-07-04 21:43:14</td><td>94</td><td>82</td><td>18902</td><td>0</td><td>210</td></tr><tr><td>355</td><td>1562247820002</td><td>8</td><td>2019-07-04 21:43:40</td><td>2019-07-04 21:45:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>209</td></tr><tr><td>356</td><td>1562247940002</td><td>8</td><td>2019-07-04 21:45:40</td><td>2019-07-04 21:47:09</td><td>89</td><td>78</td><td>18902</td><td>0</td><td>191</td></tr><tr><td>357</td><td>1562248060003</td><td>8</td><td>2019-07-04 21:47:40</td><td>2019-07-04 21:49:12</td><td>92</td><td>81</td><td>18902</td><td>0</td><td>187</td></tr><tr><td>358</td><td>1562248180002</td><td>8</td><td>2019-07-04 21:49:40</td><td>2019-07-04 21:51:11</td><td>91</td><td>80</td><td>18902</td><td>0</td><td>181</td></tr><tr><td>359</td><td>1562248300003</td><td>8</td><td>2019-07-04 21:51:40</td><td>2019-07-04 21:53:13</td><td>93</td><td>82</td><td>18902</td><td>0</td><td>185</td></tr><tr><td>360</td><td>1562248420003</td><td>8</td><td>2019-07-04 21:53:40</td><td>2019-07-04 21:55:12</td><td>92</td><td>81</td><td>18902</td><td>0</td><td>173</td></tr><tr><td>361</td><td>1562248540002</td><td>8</td><td>2019-07-04 21:55:40</td><td>2019-07-04 21:57:06</td><td>86</td><td>77</td><td>18902</td><td>0</td><td>158</td></tr><tr><td>362</td><td>1562248660034</td><td>8</td><td>2019-07-04 21:57:40</td><td>2019-07-04 21:59:12</td><td>92</td><td>82</td><td>18902</td><td>0</td><td>178</td></tr><tr><td>363</td><td>1562248780002</td><td>8</td><td>2019-07-04 21:59:40</td><td>2019-07-04 22:01:14</td><td>94</td><td>83</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>364</td><td>1562248900002</td><td>8</td><td>2019-07-04 22:01:40</td><td>2019-07-04 22:03:12</td><td>92</td><td>79</td><td>18902</td><td>0</td><td>195</td></tr><tr><td>365</td><td>1562249020002</td><td>8</td><td>2019-07-04 22:03:40</td><td>2019-07-04 22:05:10</td><td>90</td><td>80</td><td>18902</td><td>0</td><td>189</td></tr><tr><td>366</td><td>1562249140003</td><td>8</td><td>2019-07-04 22:05:40</td><td>2019-07-04 22:07:13</td><td>93</td><td>82</td><td>18902</td><td>0</td><td>171</td></tr><tr><td>367</td><td>1562249260002</td><td>8</td><td>2019-07-04 22:07:40</td><td>2019-07-04 22:09:19</td><td>99</td><td>88</td><td>18902</td><td>0</td><td>170</td></tr><tr><td>368</td><td>1562249380002</td><td>8</td><td>2019-07-04 22:09:40</td><td>2019-07-04 22:11:16</td><td>96</td><td>87</td><td>18902</td><td>0</td><td>173</td></tr><tr><td>369</td><td>1562249500003</td><td>8</td><td>2019-07-04 22:11:40</td><td>2019-07-04 22:13:19</td><td>99</td><td>89</td><td>18902</td><td>0</td><td>175</td></tr><tr><td>370</td><td>1562249620003</td><td>8</td><td>2019-07-04 22:13:40</td><td>2019-07-04 22:15:16</td><td>96</td><td>86</td><td>18902</td><td>0</td><td>153</td></tr><tr><td>371</td><td>1562249740002</td><td>8</td><td>2019-07-04 22:15:40</td><td>2019-07-04 22:17:15</td><td>95</td><td>85</td><td>18902</td><td>0</td><td>171</td></tr><tr><td>372</td><td>1562249860003</td><td>8</td><td>2019-07-04 22:17:40</td><td>2019-07-04 22:19:12</td><td>92</td><td>81</td><td>18902</td><td>0</td><td>193</td></tr><tr><td>373</td><td>1562249980002</td><td>8</td><td>2019-07-04 22:19:40</td><td>2019-07-04 22:21:10</td><td>90</td><td>80</td><td>18902</td><td>0</td><td>172</td></tr><tr><td>374</td><td>1562250100002</td><td>8</td><td>2019-07-04 22:21:40</td><td>2019-07-04 22:23:11</td><td>91</td><td>81</td><td>18902</td><td>0</td><td>158</td></tr><tr><td>375</td><td>1562250220003</td><td>8</td><td>2019-07-04 22:23:40</td><td>2019-07-04 22:25:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>159</td></tr><tr><td>376</td><td>1562250340003</td><td>8</td><td>2019-07-04 22:25:40</td><td>2019-07-04 22:27:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>146</td></tr><tr><td>377</td><td>1562250460002</td><td>8</td><td>2019-07-04 22:27:40</td><td>2019-07-04 22:29:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>153</td></tr><tr><td>378</td><td>1562250580002</td><td>8</td><td>2019-07-04 22:29:40</td><td>2019-07-04 22:31:07</td><td>87</td><td>78</td><td>18902</td><td>0</td><td>132</td></tr><tr><td>379</td><td>1562250700003</td><td>8</td><td>2019-07-04 22:31:40</td><td>2019-07-04 22:33:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>131</td></tr><tr><td>380</td><td>1562250820002</td><td>8</td><td>2019-07-04 22:33:40</td><td>2019-07-04 22:35:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>133</td></tr><tr><td>381</td><td>1562250940003</td><td>8</td><td>2019-07-04 22:35:40</td><td>2019-07-04 22:37:16</td><td>96</td><td>86</td><td>18902</td><td>0</td><td>143</td></tr><tr><td>382</td><td>1562251060002</td><td>8</td><td>2019-07-04 22:37:40</td><td>2019-07-04 22:39:15</td><td>95</td><td>84</td><td>18902</td><td>0</td><td>145</td></tr><tr><td>383</td><td>1562251180003</td><td>8</td><td>2019-07-04 22:39:40</td><td>2019-07-04 22:41:13</td><td>93</td><td>83</td><td>18902</td><td>0</td><td>142</td></tr><tr><td>384</td><td>1562251300003</td><td>8</td><td>2019-07-04 22:41:40</td><td>2019-07-04 22:43:10</td><td>90</td><td>80</td><td>18902</td><td>0</td><td>127</td></tr><tr><td>385</td><td>1562251420004</td><td>8</td><td>2019-07-04 22:43:40</td><td>2019-07-04 22:45:08</td><td>88</td><td>78</td><td>18902</td><td>0</td><td>140</td></tr><tr><td>386</td><td>1562251540004</td><td>8</td><td>2019-07-04 22:45:40</td><td>2019-07-04 22:47:09</td><td>89</td><td>78</td><td>18902</td><td>0</td><td>145</td></tr><tr><td>387</td><td>1562251660003</td><td>8</td><td>2019-07-04 22:47:40</td><td>2019-07-04 22:49:11</td><td>91</td><td>81</td><td>18902</td><td>0</td><td>142</td></tr><tr><td>388</td><td>1562251780002</td><td>8</td><td>2019-07-04 22:49:40</td><td>2019-07-04 22:51:08</td><td>88</td><td>78</td><td>18902</td><td>0</td><td>137</td></tr><tr><td>389</td><td>1562251900003</td><td>8</td><td>2019-07-04 22:51:40</td><td>2019-07-04 22:53:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>142</td></tr><tr><td>390</td><td>1562252020004</td><td>8</td><td>2019-07-04 22:53:40</td><td>2019-07-04 22:55:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>138</td></tr><tr><td>391</td><td>1562252140002</td><td>8</td><td>2019-07-04 22:55:40</td><td>2019-07-04 22:57:08</td><td>88</td><td>79</td><td>18902</td><td>0</td><td>136</td></tr><tr><td>392</td><td>1562252260004</td><td>8</td><td>2019-07-04 22:57:40</td><td>2019-07-04 22:59:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>141</td></tr><tr><td>393</td><td>1562252380005</td><td>8</td><td>2019-07-04 22:59:40</td><td>2019-07-04 23:01:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>117</td></tr><tr><td>394</td><td>1562252500005</td><td>8</td><td>2019-07-04 23:01:40</td><td>2019-07-04 23:03:12</td><td>92</td><td>82</td><td>18902</td><td>0</td><td>124</td></tr><tr><td>395</td><td>1562252620003</td><td>8</td><td>2019-07-04 23:03:40</td><td>2019-07-04 23:05:13</td><td>93</td><td>83</td><td>18902</td><td>0</td><td>118</td></tr><tr><td>396</td><td>1562252740002</td><td>8</td><td>2019-07-04 23:05:40</td><td>2019-07-04 23:07:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>106</td></tr><tr><td>397</td><td>1562252860002</td><td>8</td><td>2019-07-04 23:07:40</td><td>2019-07-04 23:09:11</td><td>91</td><td>81</td><td>18902</td><td>0</td><td>125</td></tr><tr><td>398</td><td>1562252980003</td><td>8</td><td>2019-07-04 23:09:40</td><td>2019-07-04 23:11:11</td><td>91</td><td>81</td><td>18902</td><td>0</td><td>144</td></tr><tr><td>399</td><td>1562253100002</td><td>8</td><td>2019-07-04 23:11:40</td><td>2019-07-04 23:13:13</td><td>93</td><td>83</td><td>18902</td><td>0</td><td>141</td></tr><tr><td>400</td><td>1562253220005</td><td>8</td><td>2019-07-04 23:13:40</td><td>2019-07-04 23:15:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>135</td></tr><tr><td>401</td><td>1562253340004</td><td>8</td><td>2019-07-04 23:15:40</td><td>2019-07-04 23:17:16</td><td>96</td><td>86</td><td>18902</td><td>0</td><td>141</td></tr><tr><td>402</td><td>1562253460005</td><td>8</td><td>2019-07-04 23:17:40</td><td>2019-07-04 23:19:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>126</td></tr><tr><td>403</td><td>1562253580004</td><td>8</td><td>2019-07-04 23:19:40</td><td>2019-07-04 23:21:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>118</td></tr><tr><td>404</td><td>1562253700003</td><td>8</td><td>2019-07-04 23:21:40</td><td>2019-07-04 23:23:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>405</td><td>1562253820006</td><td>8</td><td>2019-07-04 23:23:40</td><td>2019-07-04 23:25:10</td><td>90</td><td>80</td><td>18902</td><td>0</td><td>123</td></tr><tr><td>406</td><td>1562253940005</td><td>8</td><td>2019-07-04 23:25:40</td><td>2019-07-04 23:27:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>105</td></tr><tr><td>407</td><td>1562254060006</td><td>8</td><td>2019-07-04 23:27:40</td><td>2019-07-04 23:29:14</td><td>94</td><td>85</td><td>18902</td><td>0</td><td>106</td></tr><tr><td>408</td><td>1562254180008</td><td>8</td><td>2019-07-04 23:29:40</td><td>2019-07-04 23:31:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>109</td></tr><tr><td>409</td><td>1562254300005</td><td>8</td><td>2019-07-04 23:31:40</td><td>2019-07-04 23:33:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>410</td><td>1562254420003</td><td>8</td><td>2019-07-04 23:33:40</td><td>2019-07-04 23:35:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>93</td></tr><tr><td>411</td><td>1562254540006</td><td>8</td><td>2019-07-04 23:35:40</td><td>2019-07-04 23:37:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>99</td></tr><tr><td>412</td><td>1562254660006</td><td>8</td><td>2019-07-04 23:37:40</td><td>2019-07-04 23:39:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>413</td><td>1562254780004</td><td>8</td><td>2019-07-04 23:39:40</td><td>2019-07-04 23:41:08</td><td>88</td><td>79</td><td>18902</td><td>0</td><td>108</td></tr><tr><td>414</td><td>1562254900005</td><td>8</td><td>2019-07-04 23:41:40</td><td>2019-07-04 23:43:05</td><td>85</td><td>76</td><td>18902</td><td>0</td><td>112</td></tr><tr><td>415</td><td>1562255020004</td><td>8</td><td>2019-07-04 23:43:40</td><td>2019-07-04 23:45:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>116</td></tr><tr><td>416</td><td>1562255140004</td><td>8</td><td>2019-07-04 23:45:40</td><td>2019-07-04 23:47:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>122</td></tr><tr><td>417</td><td>1562255260005</td><td>8</td><td>2019-07-04 23:47:40</td><td>2019-07-04 23:49:12</td><td>92</td><td>82</td><td>18902</td><td>0</td><td>110</td></tr><tr><td>418</td><td>1562255380004</td><td>8</td><td>2019-07-04 23:49:40</td><td>2019-07-04 23:51:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>126</td></tr><tr><td>419</td><td>1562255500005</td><td>8</td><td>2019-07-04 23:51:40</td><td>2019-07-04 23:53:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>121</td></tr><tr><td>420</td><td>1562255620004</td><td>8</td><td>2019-07-04 23:53:40</td><td>2019-07-04 23:55:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>110</td></tr><tr><td>421</td><td>1562255740005</td><td>8</td><td>2019-07-04 23:55:40</td><td>2019-07-04 23:57:10</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>116</td></tr><tr><td>422</td><td>1562255860005</td><td>8</td><td>2019-07-04 23:57:40</td><td>2019-07-04 23:59:07</td><td>87</td><td>78</td><td>18902</td><td>0</td><td>128</td></tr><tr><td>423</td><td>1562255980005</td><td>8</td><td>2019-07-04 23:59:40</td><td>2019-07-05 00:01:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>110</td></tr><tr><td>424</td><td>1562256100005</td><td>8</td><td>2019-07-05 00:01:40</td><td>2019-07-05 00:03:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>425</td><td>1562256220005</td><td>8</td><td>2019-07-05 00:03:40</td><td>2019-07-05 00:05:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>105</td></tr><tr><td>426</td><td>1562256340006</td><td>8</td><td>2019-07-05 00:05:40</td><td>2019-07-05 00:07:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>427</td><td>1562256460006</td><td>8</td><td>2019-07-05 00:07:40</td><td>2019-07-05 00:09:09</td><td>89</td><td>80</td><td>18902</td><td>0</td><td>102</td></tr><tr><td>428</td><td>1562256580005</td><td>8</td><td>2019-07-05 00:09:40</td><td>2019-07-05 00:11:05</td><td>85</td><td>77</td><td>18902</td><td>0</td><td>101</td></tr><tr><td>429</td><td>1562256700006</td><td>8</td><td>2019-07-05 00:11:40</td><td>2019-07-05 00:13:08</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>430</td><td>1562256820005</td><td>8</td><td>2019-07-05 00:13:40</td><td>2019-07-05 00:15:08</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>93</td></tr><tr><td>431</td><td>1562256940005</td><td>8</td><td>2019-07-05 00:15:40</td><td>2019-07-05 00:17:06</td><td>86</td><td>78</td><td>18902</td><td>0</td><td>85</td></tr><tr><td>432</td><td>1562257060006</td><td>8</td><td>2019-07-05 00:17:40</td><td>2019-07-05 00:19:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>84</td></tr><tr><td>433</td><td>1562257180006</td><td>8</td><td>2019-07-05 00:19:40</td><td>2019-07-05 00:21:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>434</td><td>1562257300005</td><td>8</td><td>2019-07-05 00:21:40</td><td>2019-07-05 00:23:03</td><td>83</td><td>75</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>435</td><td>1562257420005</td><td>8</td><td>2019-07-05 00:23:40</td><td>2019-07-05 00:25:05</td><td>85</td><td>77</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>436</td><td>1562257540004</td><td>8</td><td>2019-07-05 00:25:40</td><td>2019-07-05 00:27:05</td><td>85</td><td>77</td><td>18902</td><td>0</td><td>96</td></tr><tr><td>437</td><td>1562257660005</td><td>8</td><td>2019-07-05 00:27:40</td><td>2019-07-05 00:29:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>438</td><td>1562257780003</td><td>8</td><td>2019-07-05 00:29:40</td><td>2019-07-05 00:31:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>439</td><td>1562257900005</td><td>8</td><td>2019-07-05 00:31:40</td><td>2019-07-05 00:33:16</td><td>96</td><td>86</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>440</td><td>1562258020005</td><td>8</td><td>2019-07-05 00:33:40</td><td>2019-07-05 00:35:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>111</td></tr><tr><td>441</td><td>1562258140005</td><td>8</td><td>2019-07-05 00:35:40</td><td>2019-07-05 00:37:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>99</td></tr><tr><td>442</td><td>1562258260005</td><td>8</td><td>2019-07-05 00:37:40</td><td>2019-07-05 00:39:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>443</td><td>1562258380004</td><td>8</td><td>2019-07-05 00:39:40</td><td>2019-07-05 00:41:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>109</td></tr><tr><td>444</td><td>1562258500013</td><td>8</td><td>2019-07-05 00:41:40</td><td>2019-07-05 00:43:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>105</td></tr><tr><td>445</td><td>1562258620292</td><td>8</td><td>2019-07-05 00:43:40</td><td>2019-07-05 00:45:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>105</td></tr><tr><td>446</td><td>1562258740004</td><td>8</td><td>2019-07-05 00:45:40</td><td>2019-07-05 00:47:00</td><td>80</td><td>72</td><td>18902</td><td>0</td><td>106</td></tr><tr><td>447</td><td>1562258860002</td><td>8</td><td>2019-07-05 00:47:40</td><td>2019-07-05 00:49:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>102</td></tr><tr><td>448</td><td>1562258980004</td><td>8</td><td>2019-07-05 00:49:40</td><td>2019-07-05 00:51:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>105</td></tr><tr><td>449</td><td>1562259100004</td><td>8</td><td>2019-07-05 00:51:40</td><td>2019-07-05 00:53:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>78</td></tr><tr><td>450</td><td>1562259220002</td><td>8</td><td>2019-07-05 00:53:40</td><td>2019-07-05 00:55:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>451</td><td>1562259340004</td><td>8</td><td>2019-07-05 00:55:40</td><td>2019-07-05 00:57:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>80</td></tr><tr><td>452</td><td>1562259460004</td><td>8</td><td>2019-07-05 00:57:40</td><td>2019-07-05 00:59:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>76</td></tr><tr><td>453</td><td>1562259580006</td><td>8</td><td>2019-07-05 00:59:40</td><td>2019-07-05 01:01:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>84</td></tr><tr><td>454</td><td>1562259700005</td><td>8</td><td>2019-07-05 01:01:40</td><td>2019-07-05 01:03:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>455</td><td>1562259820005</td><td>8</td><td>2019-07-05 01:03:40</td><td>2019-07-05 01:05:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>456</td><td>1562259940004</td><td>8</td><td>2019-07-05 01:05:40</td><td>2019-07-05 01:07:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>457</td><td>1562260060005</td><td>8</td><td>2019-07-05 01:07:40</td><td>2019-07-05 01:09:16</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>98</td></tr><tr><td>458</td><td>1562260180004</td><td>8</td><td>2019-07-05 01:09:40</td><td>2019-07-05 01:11:14</td><td>94</td><td>86</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>459</td><td>1562260300005</td><td>8</td><td>2019-07-05 01:11:40</td><td>2019-07-05 01:13:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>101</td></tr><tr><td>460</td><td>1562260420005</td><td>8</td><td>2019-07-05 01:13:40</td><td>2019-07-05 01:15:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>461</td><td>1562260540004</td><td>8</td><td>2019-07-05 01:15:40</td><td>2019-07-05 01:17:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>102</td></tr><tr><td>462</td><td>1562260660004</td><td>8</td><td>2019-07-05 01:17:40</td><td>2019-07-05 01:19:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>96</td></tr><tr><td>463</td><td>1562260780004</td><td>8</td><td>2019-07-05 01:19:40</td><td>2019-07-05 01:21:18</td><td>98</td><td>90</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>464</td><td>1562260900004</td><td>8</td><td>2019-07-05 01:21:40</td><td>2019-07-05 01:23:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>91</td></tr><tr><td>465</td><td>1562261020005</td><td>8</td><td>2019-07-05 01:23:40</td><td>2019-07-05 01:25:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>466</td><td>1562261140004</td><td>8</td><td>2019-07-05 01:25:40</td><td>2019-07-05 01:27:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>93</td></tr><tr><td>467</td><td>1562261260005</td><td>8</td><td>2019-07-05 01:27:40</td><td>2019-07-05 01:29:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>82</td></tr><tr><td>468</td><td>1562261380005</td><td>8</td><td>2019-07-05 01:29:40</td><td>2019-07-05 01:31:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>82</td></tr><tr><td>469</td><td>1562261500005</td><td>8</td><td>2019-07-05 01:31:40</td><td>2019-07-05 01:33:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>470</td><td>1562261620007</td><td>8</td><td>2019-07-05 01:33:40</td><td>2019-07-05 01:35:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>471</td><td>1562261740005</td><td>8</td><td>2019-07-05 01:35:40</td><td>2019-07-05 01:37:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>85</td></tr><tr><td>472</td><td>1562261860006</td><td>8</td><td>2019-07-05 01:37:40</td><td>2019-07-05 01:39:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>96</td></tr><tr><td>473</td><td>1562261980005</td><td>8</td><td>2019-07-05 01:39:40</td><td>2019-07-05 01:41:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>72</td></tr><tr><td>474</td><td>1562262100004</td><td>8</td><td>2019-07-05 01:41:40</td><td>2019-07-05 01:43:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>81</td></tr><tr><td>475</td><td>1562262220004</td><td>8</td><td>2019-07-05 01:43:40</td><td>2019-07-05 01:45:05</td><td>85</td><td>78</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>476</td><td>1562262340007</td><td>8</td><td>2019-07-05 01:45:40</td><td>2019-07-05 01:47:04</td><td>84</td><td>77</td><td>18902</td><td>0</td><td>75</td></tr><tr><td>477</td><td>1562262460010</td><td>8</td><td>2019-07-05 01:47:40</td><td>2019-07-05 01:49:17</td><td>97</td><td>90</td><td>18902</td><td>0</td><td>77</td></tr><tr><td>478</td><td>1562262580007</td><td>8</td><td>2019-07-05 01:49:40</td><td>2019-07-05 01:51:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>479</td><td>1562262700005</td><td>8</td><td>2019-07-05 01:51:40</td><td>2019-07-05 01:53:13</td><td>93</td><td>86</td><td>18902</td><td>0</td><td>85</td></tr><tr><td>480</td><td>1562262954308</td><td>8</td><td>2019-07-05 01:55:54</td><td>2019-07-05 01:57:24</td><td>90</td><td>81</td><td>18902</td><td>0</td><td>75</td></tr><tr><td>481</td><td>1562263060006</td><td>8</td><td>2019-07-05 01:57:40</td><td>2019-07-05 01:59:07</td><td>87</td><td>80</td><td>18902</td><td>0</td><td>78</td></tr><tr><td>482</td><td>1562263180006</td><td>8</td><td>2019-07-05 01:59:40</td><td>2019-07-05 02:01:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>86</td></tr><tr><td>483</td><td>1562263300006</td><td>8</td><td>2019-07-05 02:01:40</td><td>2019-07-05 02:03:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>484</td><td>1562263420005</td><td>8</td><td>2019-07-05 02:03:40</td><td>2019-07-05 02:05:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>485</td><td>1562263540008</td><td>8</td><td>2019-07-05 02:05:40</td><td>2019-07-05 02:07:06</td><td>86</td><td>77</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>486</td><td>1562263660005</td><td>8</td><td>2019-07-05 02:07:40</td><td>2019-07-05 02:09:03</td><td>83</td><td>76</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>487</td><td>1562263780006</td><td>8</td><td>2019-07-05 02:09:40</td><td>2019-07-05 02:11:15</td><td>95</td><td>88</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>488</td><td>1562263900003</td><td>8</td><td>2019-07-05 02:11:40</td><td>2019-07-05 02:13:17</td><td>97</td><td>88</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>489</td><td>1562264020005</td><td>8</td><td>2019-07-05 02:13:40</td><td>2019-07-05 02:15:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>94</td></tr><tr><td>490</td><td>1562264140005</td><td>8</td><td>2019-07-05 02:15:40</td><td>2019-07-05 02:17:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>91</td></tr><tr><td>491</td><td>1562264260005</td><td>8</td><td>2019-07-05 02:17:40</td><td>2019-07-05 02:19:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>492</td><td>1562264380004</td><td>8</td><td>2019-07-05 02:19:40</td><td>2019-07-05 02:21:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>82</td></tr><tr><td>493</td><td>1562264500004</td><td>8</td><td>2019-07-05 02:21:40</td><td>2019-07-05 02:23:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>494</td><td>1562264620006</td><td>8</td><td>2019-07-05 02:23:40</td><td>2019-07-05 02:25:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>82</td></tr><tr><td>495</td><td>1562264740007</td><td>8</td><td>2019-07-05 02:25:40</td><td>2019-07-05 02:27:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>81</td></tr><tr><td>496</td><td>1562264860005</td><td>8</td><td>2019-07-05 02:27:40</td><td>2019-07-05 02:29:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>86</td></tr><tr><td>497</td><td>1562264980010</td><td>8</td><td>2019-07-05 02:29:40</td><td>2019-07-05 02:31:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>498</td><td>1562265100006</td><td>8</td><td>2019-07-05 02:31:40</td><td>2019-07-05 02:33:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>499</td><td>1562265220006</td><td>8</td><td>2019-07-05 02:33:40</td><td>2019-07-05 02:35:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>85</td></tr><tr><td>500</td><td>1562265340008</td><td>8</td><td>2019-07-05 02:35:40</td><td>2019-07-05 02:37:13</td><td>93</td><td>84</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>501</td><td>1562265460006</td><td>8</td><td>2019-07-05 02:37:40</td><td>2019-07-05 02:39:13</td><td>93</td><td>86</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>502</td><td>1562265580006</td><td>8</td><td>2019-07-05 02:39:40</td><td>2019-07-05 02:41:14</td><td>94</td><td>86</td><td>18902</td><td>0</td><td>91</td></tr><tr><td>503</td><td>1562265700004</td><td>8</td><td>2019-07-05 02:41:40</td><td>2019-07-05 02:43:14</td><td>94</td><td>85</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>504</td><td>1562265820005</td><td>8</td><td>2019-07-05 02:43:40</td><td>2019-07-05 02:45:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>99</td></tr><tr><td>505</td><td>1562265940004</td><td>8</td><td>2019-07-05 02:45:40</td><td>2019-07-05 02:47:02</td><td>82</td><td>75</td><td>18902</td><td>0</td><td>108</td></tr><tr><td>506</td><td>1562266060005</td><td>8</td><td>2019-07-05 02:47:40</td><td>2019-07-05 02:49:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>507</td><td>1562266180006</td><td>8</td><td>2019-07-05 02:49:40</td><td>2019-07-05 02:51:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>98</td></tr><tr><td>508</td><td>1562266300003</td><td>8</td><td>2019-07-05 02:51:40</td><td>2019-07-05 02:53:07</td><td>87</td><td>78</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>509</td><td>1562266420003</td><td>8</td><td>2019-07-05 02:53:40</td><td>2019-07-05 02:55:04</td><td>84</td><td>77</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>510</td><td>1562266540003</td><td>8</td><td>2019-07-05 02:55:40</td><td>2019-07-05 02:57:03</td><td>83</td><td>74</td><td>18902</td><td>0</td><td>107</td></tr><tr><td>511</td><td>1562266660006</td><td>8</td><td>2019-07-05 02:57:40</td><td>2019-07-05 02:59:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>512</td><td>1562266780005</td><td>8</td><td>2019-07-05 02:59:40</td><td>2019-07-05 03:01:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>513</td><td>1562266900006</td><td>8</td><td>2019-07-05 03:01:40</td><td>2019-07-05 03:03:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>100</td></tr><tr><td>514</td><td>1562267020031</td><td>8</td><td>2019-07-05 03:03:40</td><td>2019-07-05 03:05:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>101</td></tr><tr><td>515</td><td>1562267140284</td><td>8</td><td>2019-07-05 03:05:40</td><td>2019-07-05 03:07:15</td><td>94</td><td>87</td><td>18902</td><td>0</td><td>89</td></tr><tr><td>516</td><td>1562267260005</td><td>8</td><td>2019-07-05 03:07:40</td><td>2019-07-05 03:09:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>87</td></tr><tr><td>517</td><td>1562267380273</td><td>8</td><td>2019-07-05 03:09:40</td><td>2019-07-05 03:11:16</td><td>96</td><td>87</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>518</td><td>1562267500290</td><td>8</td><td>2019-07-05 03:11:40</td><td>2019-07-05 03:13:14</td><td>94</td><td>86</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>519</td><td>1562267620291</td><td>8</td><td>2019-07-05 03:13:40</td><td>2019-07-05 03:15:14</td><td>93</td><td>86</td><td>18902</td><td>0</td><td>92</td></tr><tr><td>520</td><td>1562267740004</td><td>8</td><td>2019-07-05 03:15:40</td><td>2019-07-05 03:17:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>79</td></tr><tr><td>521</td><td>1562267860005</td><td>8</td><td>2019-07-05 03:17:40</td><td>2019-07-05 03:19:03</td><td>83</td><td>76</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>522</td><td>1562267980004</td><td>8</td><td>2019-07-05 03:19:40</td><td>2019-07-05 03:21:07</td><td>87</td><td>80</td><td>18902</td><td>0</td><td>52</td></tr><tr><td>523</td><td>1562268100005</td><td>8</td><td>2019-07-05 03:21:40</td><td>2019-07-05 03:23:06</td><td>86</td><td>79</td><td>18902</td><td>0</td><td>55</td></tr><tr><td>524</td><td>1562268220005</td><td>8</td><td>2019-07-05 03:23:40</td><td>2019-07-05 03:25:02</td><td>82</td><td>75</td><td>18902</td><td>0</td><td>55</td></tr><tr><td>525</td><td>1562268340005</td><td>8</td><td>2019-07-05 03:25:40</td><td>2019-07-05 03:27:04</td><td>84</td><td>77</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>526</td><td>1562268460004</td><td>8</td><td>2019-07-05 03:27:40</td><td>2019-07-05 03:29:06</td><td>86</td><td>79</td><td>18902</td><td>0</td><td>67</td></tr><tr><td>527</td><td>1562268580005</td><td>8</td><td>2019-07-05 03:29:40</td><td>2019-07-05 03:31:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>51</td></tr><tr><td>528</td><td>1562268700005</td><td>8</td><td>2019-07-05 03:31:40</td><td>2019-07-05 03:33:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>66</td></tr><tr><td>529</td><td>1562268820005</td><td>8</td><td>2019-07-05 03:33:40</td><td>2019-07-05 03:35:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>530</td><td>1562268940004</td><td>8</td><td>2019-07-05 03:35:40</td><td>2019-07-05 03:37:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>51</td></tr><tr><td>531</td><td>1562269060003</td><td>8</td><td>2019-07-05 03:37:40</td><td>2019-07-05 03:39:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>62</td></tr><tr><td>532</td><td>1562269180006</td><td>8</td><td>2019-07-05 03:39:40</td><td>2019-07-05 03:41:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>61</td></tr><tr><td>533</td><td>1562269300041</td><td>8</td><td>2019-07-05 03:41:40</td><td>2019-07-05 03:43:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>61</td></tr><tr><td>534</td><td>1562269420005</td><td>8</td><td>2019-07-05 03:43:40</td><td>2019-07-05 03:45:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>71</td></tr><tr><td>535</td><td>1562269540005</td><td>8</td><td>2019-07-05 03:45:40</td><td>2019-07-05 03:47:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>67</td></tr><tr><td>536</td><td>1562269660005</td><td>8</td><td>2019-07-05 03:47:40</td><td>2019-07-05 03:49:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>79</td></tr><tr><td>537</td><td>1562269780005</td><td>8</td><td>2019-07-05 03:49:40</td><td>2019-07-05 03:51:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>538</td><td>1562269900004</td><td>8</td><td>2019-07-05 03:51:40</td><td>2019-07-05 03:53:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>81</td></tr><tr><td>539</td><td>1562270020005</td><td>8</td><td>2019-07-05 03:53:40</td><td>2019-07-05 03:55:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>80</td></tr><tr><td>540</td><td>1562270140005</td><td>8</td><td>2019-07-05 03:55:40</td><td>2019-07-05 03:57:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>73</td></tr><tr><td>541</td><td>1562270260305</td><td>8</td><td>2019-07-05 03:57:40</td><td>2019-07-05 03:59:09</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>67</td></tr><tr><td>542</td><td>1562270380004</td><td>8</td><td>2019-07-05 03:59:40</td><td>2019-07-05 04:01:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>59</td></tr><tr><td>543</td><td>1562270500005</td><td>8</td><td>2019-07-05 04:01:40</td><td>2019-07-05 04:03:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>60</td></tr><tr><td>544</td><td>1562270620003</td><td>8</td><td>2019-07-05 04:03:40</td><td>2019-07-05 04:05:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>70</td></tr><tr><td>545</td><td>1562270740003</td><td>8</td><td>2019-07-05 04:05:40</td><td>2019-07-05 04:07:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>67</td></tr><tr><td>546</td><td>1562270860004</td><td>8</td><td>2019-07-05 04:07:40</td><td>2019-07-05 04:09:11</td><td>91</td><td>82</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>547</td><td>1562270980007</td><td>8</td><td>2019-07-05 04:09:40</td><td>2019-07-05 04:11:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>548</td><td>1562271100006</td><td>8</td><td>2019-07-05 04:11:40</td><td>2019-07-05 04:13:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>67</td></tr><tr><td>549</td><td>1562271220003</td><td>8</td><td>2019-07-05 04:13:40</td><td>2019-07-05 04:15:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>61</td></tr><tr><td>550</td><td>1562271340003</td><td>8</td><td>2019-07-05 04:15:40</td><td>2019-07-05 04:17:13</td><td>93</td><td>86</td><td>18902</td><td>0</td><td>73</td></tr><tr><td>551</td><td>1562271460005</td><td>8</td><td>2019-07-05 04:17:40</td><td>2019-07-05 04:19:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>552</td><td>1562271580010</td><td>8</td><td>2019-07-05 04:19:40</td><td>2019-07-05 04:21:14</td><td>94</td><td>86</td><td>18902</td><td>0</td><td>78</td></tr><tr><td>553</td><td>1562271700004</td><td>8</td><td>2019-07-05 04:21:40</td><td>2019-07-05 04:23:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>83</td></tr><tr><td>554</td><td>1562271820005</td><td>8</td><td>2019-07-05 04:23:40</td><td>2019-07-05 04:25:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>65</td></tr><tr><td>555</td><td>1562271940004</td><td>8</td><td>2019-07-05 04:25:40</td><td>2019-07-05 04:27:12</td><td>92</td><td>85</td><td>18902</td><td>0</td><td>75</td></tr><tr><td>556</td><td>1562272060003</td><td>8</td><td>2019-07-05 04:27:40</td><td>2019-07-05 04:29:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>72</td></tr><tr><td>557</td><td>1562272180002</td><td>8</td><td>2019-07-05 04:29:40</td><td>2019-07-05 04:31:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>81</td></tr><tr><td>558</td><td>1562272300005</td><td>8</td><td>2019-07-05 04:31:40</td><td>2019-07-05 04:33:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>559</td><td>1562272420003</td><td>8</td><td>2019-07-05 04:33:40</td><td>2019-07-05 04:35:14</td><td>94</td><td>87</td><td>18902</td><td>0</td><td>85</td></tr><tr><td>560</td><td>1562272540002</td><td>8</td><td>2019-07-05 04:35:40</td><td>2019-07-05 04:37:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>72</td></tr><tr><td>561</td><td>1562272660005</td><td>8</td><td>2019-07-05 04:37:40</td><td>2019-07-05 04:39:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>70</td></tr><tr><td>562</td><td>1562272780004</td><td>8</td><td>2019-07-05 04:39:40</td><td>2019-07-05 04:41:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>84</td></tr><tr><td>563</td><td>1562272900004</td><td>8</td><td>2019-07-05 04:41:40</td><td>2019-07-05 04:43:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>80</td></tr><tr><td>564</td><td>1562273020005</td><td>8</td><td>2019-07-05 04:43:40</td><td>2019-07-05 04:45:05</td><td>85</td><td>77</td><td>18902</td><td>0</td><td>76</td></tr><tr><td>565</td><td>1562273140005</td><td>8</td><td>2019-07-05 04:45:40</td><td>2019-07-05 04:47:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>61</td></tr><tr><td>566</td><td>1562273260004</td><td>8</td><td>2019-07-05 04:47:40</td><td>2019-07-05 04:49:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>68</td></tr><tr><td>567</td><td>1562273380288</td><td>8</td><td>2019-07-05 04:49:40</td><td>2019-07-05 04:51:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>568</td><td>1562273500174</td><td>8</td><td>2019-07-05 04:51:40</td><td>2019-07-05 04:53:12</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>58</td></tr><tr><td>569</td><td>1562273620003</td><td>8</td><td>2019-07-05 04:53:40</td><td>2019-07-05 04:55:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>50</td></tr><tr><td>570</td><td>1562273740003</td><td>8</td><td>2019-07-05 04:55:40</td><td>2019-07-05 04:57:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>57</td></tr><tr><td>571</td><td>1562273860002</td><td>8</td><td>2019-07-05 04:57:40</td><td>2019-07-05 04:59:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>55</td></tr><tr><td>572</td><td>1562273980003</td><td>8</td><td>2019-07-05 04:59:40</td><td>2019-07-05 05:01:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>56</td></tr><tr><td>573</td><td>1562274100002</td><td>8</td><td>2019-07-05 05:01:40</td><td>2019-07-05 05:03:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>62</td></tr><tr><td>574</td><td>1562274220003</td><td>8</td><td>2019-07-05 05:03:40</td><td>2019-07-05 05:05:14</td><td>94</td><td>87</td><td>18902</td><td>0</td><td>53</td></tr><tr><td>575</td><td>1562274340002</td><td>8</td><td>2019-07-05 05:05:40</td><td>2019-07-05 05:07:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>53</td></tr><tr><td>576</td><td>1562274460003</td><td>8</td><td>2019-07-05 05:07:40</td><td>2019-07-05 05:09:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>55</td></tr><tr><td>577</td><td>1562274580002</td><td>8</td><td>2019-07-05 05:09:40</td><td>2019-07-05 05:11:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>55</td></tr><tr><td>578</td><td>1562274700002</td><td>8</td><td>2019-07-05 05:11:40</td><td>2019-07-05 05:13:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>69</td></tr><tr><td>579</td><td>1562274820003</td><td>8</td><td>2019-07-05 05:13:40</td><td>2019-07-05 05:15:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>57</td></tr><tr><td>580</td><td>1562274940003</td><td>8</td><td>2019-07-05 05:15:40</td><td>2019-07-05 05:17:08</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>581</td><td>1562275060002</td><td>8</td><td>2019-07-05 05:17:40</td><td>2019-07-05 05:19:02</td><td>82</td><td>75</td><td>18902</td><td>0</td><td>58</td></tr><tr><td>582</td><td>1562275180002</td><td>8</td><td>2019-07-05 05:19:40</td><td>2019-07-05 05:21:05</td><td>85</td><td>78</td><td>18902</td><td>0</td><td>51</td></tr><tr><td>583</td><td>1562275300003</td><td>8</td><td>2019-07-05 05:21:40</td><td>2019-07-05 05:23:06</td><td>86</td><td>78</td><td>18902</td><td>0</td><td>49</td></tr><tr><td>584</td><td>1562275420003</td><td>8</td><td>2019-07-05 05:23:40</td><td>2019-07-05 05:25:11</td><td>91</td><td>84</td><td>18902</td><td>0</td><td>49</td></tr><tr><td>585</td><td>1562275540003</td><td>8</td><td>2019-07-05 05:25:40</td><td>2019-07-05 05:27:09</td><td>89</td><td>81</td><td>18902</td><td>0</td><td>53</td></tr><tr><td>586</td><td>1562275660003</td><td>8</td><td>2019-07-05 05:27:40</td><td>2019-07-05 05:29:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>64</td></tr><tr><td>587</td><td>1562275780003</td><td>8</td><td>2019-07-05 05:29:40</td><td>2019-07-05 05:31:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>60</td></tr><tr><td>588</td><td>1562275900002</td><td>8</td><td>2019-07-05 05:31:40</td><td>2019-07-05 05:33:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>52</td></tr><tr><td>589</td><td>1562276020003</td><td>8</td><td>2019-07-05 05:33:40</td><td>2019-07-05 05:35:09</td><td>89</td><td>82</td><td>18902</td><td>0</td><td>54</td></tr><tr><td>590</td><td>1562276140002</td><td>8</td><td>2019-07-05 05:35:40</td><td>2019-07-05 05:37:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>53</td></tr><tr><td>591</td><td>1562276260003</td><td>8</td><td>2019-07-05 05:37:40</td><td>2019-07-05 05:39:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>592</td><td>1562276380002</td><td>8</td><td>2019-07-05 05:39:40</td><td>2019-07-05 05:41:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>54</td></tr><tr><td>593</td><td>1562276500002</td><td>8</td><td>2019-07-05 05:41:40</td><td>2019-07-05 05:43:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>63</td></tr><tr><td>594</td><td>1562276620003</td><td>8</td><td>2019-07-05 05:43:40</td><td>2019-07-05 05:45:04</td><td>84</td><td>77</td><td>18902</td><td>0</td><td>68</td></tr><tr><td>595</td><td>1562276740002</td><td>8</td><td>2019-07-05 05:45:40</td><td>2019-07-05 05:47:08</td><td>88</td><td>80</td><td>18902</td><td>0</td><td>82</td></tr><tr><td>596</td><td>1562276860003</td><td>8</td><td>2019-07-05 05:47:40</td><td>2019-07-05 05:49:09</td><td>89</td><td>82</td><td>18902</td><td>0</td><td>61</td></tr><tr><td>597</td><td>1562276980003</td><td>8</td><td>2019-07-05 05:49:40</td><td>2019-07-05 05:51:08</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>60</td></tr><tr><td>598</td><td>1562277100003</td><td>8</td><td>2019-07-05 05:51:40</td><td>2019-07-05 05:53:04</td><td>84</td><td>76</td><td>18902</td><td>0</td><td>73</td></tr><tr><td>599</td><td>1562277220003</td><td>8</td><td>2019-07-05 05:53:40</td><td>2019-07-05 05:55:06</td><td>86</td><td>79</td><td>18902</td><td>0</td><td>64</td></tr><tr><td>600</td><td>1562277340002</td><td>8</td><td>2019-07-05 05:55:40</td><td>2019-07-05 05:57:08</td><td>88</td><td>81</td><td>18902</td><td>0</td><td>79</td></tr><tr><td>601</td><td>1562277460003</td><td>8</td><td>2019-07-05 05:57:40</td><td>2019-07-05 05:59:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>77</td></tr><tr><td>602</td><td>1562277580003</td><td>8</td><td>2019-07-05 05:59:40</td><td>2019-07-05 06:01:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>603</td><td>1562277700003</td><td>8</td><td>2019-07-05 06:01:40</td><td>2019-07-05 06:03:10</td><td>90</td><td>83</td><td>18902</td><td>0</td><td>74</td></tr><tr><td>604</td><td>1562277820003</td><td>8</td><td>2019-07-05 06:03:40</td><td>2019-07-05 06:05:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>75</td></tr><tr><td>605</td><td>1562277940003</td><td>8</td><td>2019-07-05 06:05:40</td><td>2019-07-05 06:07:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>80</td></tr><tr><td>606</td><td>1562278060002</td><td>8</td><td>2019-07-05 06:07:40</td><td>2019-07-05 06:09:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>73</td></tr><tr><td>607</td><td>1562278180002</td><td>8</td><td>2019-07-05 06:09:40</td><td>2019-07-05 06:11:04</td><td>84</td><td>77</td><td>18902</td><td>0</td><td>70</td></tr><tr><td>608</td><td>1562278300003</td><td>8</td><td>2019-07-05 06:11:40</td><td>2019-07-05 06:13:04</td><td>84</td><td>76</td><td>18902</td><td>0</td><td>80</td></tr><tr><td>609</td><td>1562278420002</td><td>8</td><td>2019-07-05 06:13:40</td><td>2019-07-05 06:15:07</td><td>87</td><td>80</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>610</td><td>1562278540003</td><td>8</td><td>2019-07-05 06:15:40</td><td>2019-07-05 06:17:09</td><td>89</td><td>80</td><td>18902</td><td>0</td><td>103</td></tr><tr><td>611</td><td>1562278660003</td><td>8</td><td>2019-07-05 06:17:40</td><td>2019-07-05 06:19:07</td><td>87</td><td>79</td><td>18902</td><td>0</td><td>104</td></tr><tr><td>612</td><td>1562278780003</td><td>8</td><td>2019-07-05 06:19:40</td><td>2019-07-05 06:21:06</td><td>86</td><td>78</td><td>18902</td><td>0</td><td>65</td></tr><tr><td>613</td><td>1562278900003</td><td>8</td><td>2019-07-05 06:21:40</td><td>2019-07-05 06:23:13</td><td>93</td><td>85</td><td>18902</td><td>0</td><td>76</td></tr><tr><td>614</td><td>1562279020003</td><td>8</td><td>2019-07-05 06:23:40</td><td>2019-07-05 06:25:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>615</td><td>1562279140003</td><td>8</td><td>2019-07-05 06:25:40</td><td>2019-07-05 06:27:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>101</td></tr><tr><td>616</td><td>1562279260003</td><td>8</td><td>2019-07-05 06:27:40</td><td>2019-07-05 06:29:14</td><td>94</td><td>87</td><td>18902</td><td>0</td><td>75</td></tr><tr><td>617</td><td>1562279380002</td><td>8</td><td>2019-07-05 06:29:40</td><td>2019-07-05 06:31:14</td><td>94</td><td>86</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>618</td><td>1562279500003</td><td>8</td><td>2019-07-05 06:31:40</td><td>2019-07-05 06:33:15</td><td>95</td><td>86</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>619</td><td>1562279620003</td><td>8</td><td>2019-07-05 06:33:40</td><td>2019-07-05 06:35:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>90</td></tr><tr><td>620</td><td>1562279740003</td><td>8</td><td>2019-07-05 06:35:40</td><td>2019-07-05 06:37:07</td><td>87</td><td>78</td><td>18902</td><td>0</td><td>95</td></tr><tr><td>621</td><td>1562279860003</td><td>8</td><td>2019-07-05 06:37:40</td><td>2019-07-05 06:39:05</td><td>85</td><td>76</td><td>18902</td><td>0</td><td>86</td></tr><tr><td>622</td><td>1562279980003</td><td>8</td><td>2019-07-05 06:39:40</td><td>2019-07-05 06:41:12</td><td>92</td><td>84</td><td>18902</td><td>0</td><td>91</td></tr><tr><td>623</td><td>1562280100002</td><td>8</td><td>2019-07-05 06:41:40</td><td>2019-07-05 06:43:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>94</td></tr><tr><td>624</td><td>1562280220002</td><td>8</td><td>2019-07-05 06:43:40</td><td>2019-07-05 06:45:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>91</td></tr><tr><td>625</td><td>1562280340003</td><td>8</td><td>2019-07-05 06:45:40</td><td>2019-07-05 06:47:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>88</td></tr><tr><td>626</td><td>1562280460002</td><td>8</td><td>2019-07-05 06:47:40</td><td>2019-07-05 06:49:12</td><td>92</td><td>83</td><td>18902</td><td>0</td><td>121</td></tr><tr><td>627</td><td>1562280580003</td><td>8</td><td>2019-07-05 06:49:40</td><td>2019-07-05 06:51:11</td><td>91</td><td>83</td><td>18902</td><td>0</td><td>97</td></tr><tr><td>628</td><td>1562280700002</td><td>8</td><td>2019-07-05 06:51:40</td><td>2019-07-05 06:53:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>76</td></tr><tr><td>629</td><td>1562280820003</td><td>8</td><td>2019-07-05 06:53:40</td><td>2019-07-05 06:55:10</td><td>90</td><td>82</td><td>18902</td><td>0</td><td>98</td></tr><tr><td>630</td><td>1562280940002</td><td>8</td><td>2019-07-05 06:55:40</td><td>2019-07-05 06:57:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>114</td></tr><tr><td>631</td><td>1562281060003</td><td>8</td><td>2019-07-05 06:57:40</td><td>2019-07-05 06:59:15</td><td>95</td><td>87</td><td>18902</td><td>0</td><td>106</td></tr><tr><td>632</td><td>1562281180002</td><td>8</td><td>2019-07-05 06:59:40</td><td>2019-07-05 07:01:16</td><td>96</td><td>88</td><td>18902</td><td>0</td><td>116</td></tr><tr><td>633</td><td>1562281300003</td><td>8</td><td>2019-07-05 07:01:40</td><td>2019-07-05 07:03:14</td><td>94</td><td>85</td><td>18902</td><td>0</td><td>123</td></tr><tr><td>634</td><td>1562281420002</td><td>8</td><td>2019-07-05 07:03:40</td><td>2019-07-05 07:05:08</td><td>88</td><td>79</td><td>18902</td><td>0</td><td>126</td></tr><tr><td>635</td><td>1562281540003</td><td>8</td><td>2019-07-05 07:05:40</td><td>2019-07-05 07:07:09</td><td>89</td><td>80</td><td>18902</td><td>0</td><td>121</td></tr><tr><td>636</td><td>1562281660002</td><td>8</td><td>2019-07-05 07:07:40</td><td>2019-07-05 07:09:14</td><td>94</td><td>85</td><td>18902</td><td>0</td><td>137</td></tr><tr><td>637</td><td>1562281780003</td><td>8</td><td>2019-07-05 07:09:40</td><td>2019-07-05 07:11:13</td><td>93</td><td>83</td><td>18902</td><td>0</td><td>156</td></tr><tr><td>638</td><td>1562281900002</td><td>8</td><td>2019-07-05 07:11:40</td><td>2019-07-05 07:13:11</td><td>91</td><td>80</td><td>18902</td><td>0</td><td>141</td></tr><tr><td>639</td><td>1562282020003</td><td>8</td><td>2019-07-05 07:13:40</td><td>2019-07-05 07:15:10</td><td>90</td><td>80</td><td>18902</td><td>0</td><td>167</td></tr><tr><td>640</td><td>1562282140003</td><td>8</td><td>2019-07-05 07:15:40</td><td>2019-07-05 07:17:13</td><td>93</td><td>81</td><td>18902</td><td>0</td><td>189</td></tr><tr><td>641</td><td>1562282260003</td><td>8</td><td>2019-07-05 07:17:40</td><td>2019-07-05 07:19:12</td><td>92</td><td>80</td><td>18902</td><td>0</td><td>183</td></tr><tr><td>642</td><td>1562282380003</td><td>8</td><td>2019-07-05 07:19:40</td><td>2019-07-05 07:21:15</td><td>95</td><td>84</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>643</td><td>1562282500002</td><td>8</td><td>2019-07-05 07:21:40</td><td>2019-07-05 07:23:15</td><td>95</td><td>84</td><td>18902</td><td>0</td><td>198</td></tr><tr><td>644</td><td>1562282620003</td><td>8</td><td>2019-07-05 07:23:40</td><td>2019-07-05 07:25:12</td><td>92</td><td>79</td><td>18902</td><td>0</td><td>208</td></tr><tr><td>645</td><td>1562282740002</td><td>8</td><td>2019-07-05 07:25:40</td><td>2019-07-05 07:27:09</td><td>89</td><td>77</td><td>18902</td><td>0</td><td>227</td></tr><tr><td>646</td><td>1562282860003</td><td>8</td><td>2019-07-05 07:27:40</td><td>2019-07-05 07:29:15</td><td>95</td><td>81</td><td>18902</td><td>0</td><td>249</td></tr><tr><td>647</td><td>1562282980003</td><td>8</td><td>2019-07-05 07:29:40</td><td>2019-07-05 07:31:17</td><td>97</td><td>83</td><td>18902</td><td>0</td><td>273</td></tr><tr><td>648</td><td>1562283100003</td><td>8</td><td>2019-07-05 07:31:40</td><td>2019-07-05 07:33:17</td><td>97</td><td>81</td><td>18902</td><td>0</td><td>287</td></tr><tr><td>649</td><td>1562283220002</td><td>8</td><td>2019-07-05 07:33:40</td><td>2019-07-05 07:35:14</td><td>94</td><td>77</td><td>18902</td><td>0</td><td>297</td></tr><tr><td>650</td><td>1562283340003</td><td>8</td><td>2019-07-05 07:35:40</td><td>2019-07-05 07:37:17</td><td>97</td><td>80</td><td>18902</td><td>0</td><td>311</td></tr><tr><td>651</td><td>1562283460002</td><td>8</td><td>2019-07-05 07:37:40</td><td>2019-07-05 07:39:22</td><td>102</td><td>84</td><td>18902</td><td>0</td><td>329</td></tr><tr><td>652</td><td>1562283580003</td><td>8</td><td>2019-07-05 07:39:40</td><td>2019-07-05 07:41:16</td><td>96</td><td>79</td><td>18902</td><td>0</td><td>319</td></tr><tr><td>653</td><td>1562283700002</td><td>8</td><td>2019-07-05 07:41:40</td><td>2019-07-05 07:43:17</td><td>97</td><td>80</td><td>18902</td><td>0</td><td>306</td></tr><tr><td>654</td><td>1562283820003</td><td>8</td><td>2019-07-05 07:43:40</td><td>2019-07-05 07:45:19</td><td>99</td><td>81</td><td>18902</td><td>0</td><td>348</td></tr><tr><td>655</td><td>1562283940002</td><td>8</td><td>2019-07-05 07:45:40</td><td>2019-07-05 07:47:19</td><td>99</td><td>80</td><td>18902</td><td>0</td><td>359</td></tr><tr><td>656</td><td>1562284060003</td><td>8</td><td>2019-07-05 07:47:40</td><td>2019-07-05 07:49:16</td><td>96</td><td>78</td><td>18902</td><td>0</td><td>363</td></tr><tr><td>657</td><td>1562284180002</td><td>8</td><td>2019-07-05 07:49:40</td><td>2019-07-05 07:51:17</td><td>97</td><td>79</td><td>18902</td><td>0</td><td>380</td></tr><tr><td>658</td><td>1562284300002</td><td>8</td><td>2019-07-05 07:51:40</td><td>2019-07-05 07:53:22</td><td>102</td><td>82</td><td>18902</td><td>0</td><td>381</td></tr><tr><td>659</td><td>1562284420003</td><td>8</td><td>2019-07-05 07:53:40</td><td>2019-07-05 07:55:20</td><td>100</td><td>80</td><td>18902</td><td>0</td><td>400</td></tr><tr><td>660</td><td>1562284540002</td><td>8</td><td>2019-07-05 07:55:40</td><td>2019-07-05 07:57:15</td><td>95</td><td>77</td><td>18902</td><td>0</td><td>383</td></tr><tr><td>661</td><td>1562284660002</td><td>8</td><td>2019-07-05 07:57:40</td><td>2019-07-05 07:59:19</td><td>99</td><td>80</td><td>18902</td><td>0</td><td>396</td></tr><tr><td>662</td><td>1562284780003</td><td>8</td><td>2019-07-05 07:59:40</td><td>2019-07-05 08:01:25</td><td>105</td><td>86</td><td>18902</td><td>0</td><td>378</td></tr><tr><td>663</td><td>1562284900002</td><td>8</td><td>2019-07-05 08:01:40</td><td>2019-07-05 08:03:23</td><td>103</td><td>82</td><td>18902</td><td>0</td><td>390</td></tr><tr><td>664</td><td>1562285020002</td><td>8</td><td>2019-07-05 08:03:40</td><td>2019-07-05 08:05:23</td><td>103</td><td>82</td><td>18902</td><td>0</td><td>385</td></tr><tr><td>665</td><td>1562285140002</td><td>8</td><td>2019-07-05 08:05:40</td><td>2019-07-05 08:07:22</td><td>102</td><td>82</td><td>18902</td><td>0</td><td>395</td></tr><tr><td>666</td><td>1562285260003</td><td>8</td><td>2019-07-05 08:07:40</td><td>2019-07-05 08:09:20</td><td>100</td><td>78</td><td>18902</td><td>0</td><td>415</td></tr><tr><td>667</td><td>1562285380002</td><td>8</td><td>2019-07-05 08:09:40</td><td>2019-07-05 08:11:21</td><td>101</td><td>80</td><td>18902</td><td>0</td><td>411</td></tr><tr><td>668</td><td>1562285500002</td><td>8</td><td>2019-07-05 08:11:40</td><td>2019-07-05 08:13:24</td><td>104</td><td>84</td><td>18902</td><td>0</td><td>398</td></tr><tr><td>669</td><td>1562285620003</td><td>8</td><td>2019-07-05 08:13:40</td><td>2019-07-05 08:15:24</td><td>104</td><td>83</td><td>18902</td><td>0</td><td>390</td></tr><tr><td>670</td><td>1562285740002</td><td>8</td><td>2019-07-05 08:15:40</td><td>2019-07-05 08:17:24</td><td>104</td><td>82</td><td>18901</td><td>1</td><td>396</td></tr><tr><td>671</td><td>1562285860003</td><td>8</td><td>2019-07-05 08:17:40</td><td>2019-07-05 08:19:25</td><td>105</td><td>82</td><td>18902</td><td>0</td><td>393</td></tr><tr><td>672</td><td>1562285980002</td><td>8</td><td>2019-07-05 08:19:40</td><td>2019-07-05 08:21:23</td><td>103</td><td>78</td><td>18902</td><td>0</td><td>440</td></tr><tr><td>673</td><td>1562286100002</td><td>8</td><td>2019-07-05 08:21:40</td><td>2019-07-05 08:23:29</td><td>109</td><td>87</td><td>18902</td><td>0</td><td>426</td></tr><tr><td>674</td><td>1562286220002</td><td>8</td><td>2019-07-05 08:23:40</td><td>2019-07-05 08:25:29</td><td>109</td><td>87</td><td>18902</td><td>0</td><td>425</td></tr><tr><td>675</td><td>1562286340002</td><td>8</td><td>2019-07-05 08:25:40</td><td>2019-07-05 08:27:28</td><td>108</td><td>87</td><td>18902</td><td>0</td><td>419</td></tr><tr><td>676</td><td>1562286460003</td><td>8</td><td>2019-07-05 08:27:40</td><td>2019-07-05 08:29:27</td><td>107</td><td>83</td><td>18902</td><td>0</td><td>412</td></tr><tr><td>677</td><td>1562286580003</td><td>8</td><td>2019-07-05 08:29:40</td><td>2019-07-05 08:31:22</td><td>102</td><td>81</td><td>18902</td><td>0</td><td>410</td></tr><tr><td>678</td><td>1562286700003</td><td>8</td><td>2019-07-05 08:31:40</td><td>2019-07-05 08:33:20</td><td>100</td><td>79</td><td>18902</td><td>0</td><td>406</td></tr><tr><td>679</td><td>1562286820003</td><td>8</td><td>2019-07-05 08:33:40</td><td>2019-07-05 08:35:34</td><td>114</td><td>90</td><td>18900</td><td>2</td><td>410</td></tr><tr><td>680</td><td>1562286940003</td><td>8</td><td>2019-07-05 08:35:40</td><td>2019-07-05 08:37:24</td><td>104</td><td>82</td><td>18902</td><td>0</td><td>370</td></tr><tr><td>681</td><td>1562287060003</td><td>8</td><td>2019-07-05 08:37:40</td><td>2019-07-05 08:39:24</td><td>104</td><td>83</td><td>18902</td><td>0</td><td>369</td></tr><tr><td>682</td><td>1562287180002</td><td>8</td><td>2019-07-05 08:39:40</td><td>2019-07-05 08:41:28</td><td>108</td><td>88</td><td>18902</td><td>0</td><td>386</td></tr><tr><td>683</td><td>1562287300003</td><td>8</td><td>2019-07-05 08:41:40</td><td>2019-07-05 08:43:27</td><td>107</td><td>88</td><td>18902</td><td>0</td><td>368</td></tr><tr><td>684</td><td>1562287420002</td><td>8</td><td>2019-07-05 08:43:40</td><td>2019-07-05 08:45:25</td><td>105</td><td>86</td><td>18902</td><td>0</td><td>376</td></tr><tr><td>685</td><td>1562287540002</td><td>8</td><td>2019-07-05 08:45:40</td><td>2019-07-05 08:47:24</td><td>104</td><td>84</td><td>18902</td><td>0</td><td>379</td></tr><tr><td>686</td><td>1562287660003</td><td>8</td><td>2019-07-05 08:47:40</td><td>2019-07-05 08:49:22</td><td>102</td><td>82</td><td>18902</td><td>0</td><td>363</td></tr><tr><td>687</td><td>1562287780003</td><td>8</td><td>2019-07-05 08:49:40</td><td>2019-07-05 08:51:26</td><td>106</td><td>85</td><td>18902</td><td>0</td><td>365</td></tr><tr><td>688</td><td>1562287900003</td><td>8</td><td>2019-07-05 08:51:40</td><td>2019-07-05 08:53:23</td><td>103</td><td>84</td><td>18902</td><td>0</td><td>377</td></tr><tr><td>689</td><td>1562288020002</td><td>8</td><td>2019-07-05 08:53:40</td><td>2019-07-05 08:55:21</td><td>101</td><td>82</td><td>18902</td><td>0</td><td>367</td></tr><tr><td>690</td><td>1562288140003</td><td>8</td><td>2019-07-05 08:55:40</td><td>2019-07-05 08:57:20</td><td>100</td><td>82</td><td>18902</td><td>0</td><td>351</td></tr><tr><td>691</td><td>1562288260003</td><td>8</td><td>2019-07-05 08:57:40</td><td>2019-07-05 08:59:21</td><td>101</td><td>82</td><td>18902</td><td>0</td><td>321</td></tr><tr><td>692</td><td>1562288380003</td><td>8</td><td>2019-07-05 08:59:40</td><td>2019-07-05 09:01:18</td><td>98</td><td>81</td><td>18902</td><td>0</td><td>330</td></tr><tr><td>693</td><td>1562288500002</td><td>8</td><td>2019-07-05 09:01:40</td><td>2019-07-05 09:03:18</td><td>98</td><td>82</td><td>18902</td><td>0</td><td>309</td></tr><tr><td>694</td><td>1562288620003</td><td>8</td><td>2019-07-05 09:03:40</td><td>2019-07-05 09:05:22</td><td>102</td><td>85</td><td>18902</td><td>0</td><td>310</td></tr><tr><td>695</td><td>1562288740003</td><td>8</td><td>2019-07-05 09:05:40</td><td>2019-07-05 09:07:19</td><td>99</td><td>83</td><td>18902</td><td>0</td><td>309</td></tr><tr><td>696</td><td>1562288860002</td><td>8</td><td>2019-07-05 09:07:40</td><td>2019-07-05 09:09:19</td><td>99</td><td>81</td><td>18902</td><td>0</td><td>326</td></tr><tr><td>697</td><td>1562288980003</td><td>8</td><td>2019-07-05 09:09:40</td><td>2019-07-05 09:11:13</td><td>93</td><td>77</td><td>18902</td><td>0</td><td>312</td></tr><tr><td>698</td><td>1562289100002</td><td>8</td><td>2019-07-05 09:11:40</td><td>2019-07-05 09:13:13</td><td>93</td><td>78</td><td>18902</td><td>0</td><td>299</td></tr><tr><td>699</td><td>1562289220003</td><td>8</td><td>2019-07-05 09:13:40</td><td>2019-07-05 09:15:20</td><td>100</td><td>84</td><td>18902</td><td>0</td><td>298</td></tr><tr><td>700</td><td>1562289340003</td><td>8</td><td>2019-07-05 09:15:40</td><td>2019-07-05 09:17:44</td><td>124</td><td>107</td><td>18900</td><td>2</td><td>262</td></tr><tr><td>701</td><td>1562289480003</td><td>8</td><td>2019-07-05 09:18:00</td><td>2019-07-05 09:21:22</td><td>202</td><td>172</td><td>18900</td><td>2</td><td>311</td></tr><tr><td>702</td><td>1562289700003</td><td>8</td><td>2019-07-05 09:21:40</td><td>2019-07-05 09:23:38</td><td>118</td><td>102</td><td>18902</td><td>0</td><td>321</td></tr><tr><td>703</td><td>1562289820003</td><td>8</td><td>2019-07-05 09:23:40</td><td>2019-07-05 09:26:13</td><td>153</td><td>124</td><td>18900</td><td>2</td><td>326</td></tr><tr><td>704</td><td>1562290000003</td><td>8</td><td>2019-07-05 09:26:40</td><td>2019-07-05 09:29:12</td><td>152</td><td>129</td><td>18902</td><td>0</td><td>333</td></tr><tr><td>705</td><td>1562290180003</td><td>8</td><td>2019-07-05 09:29:40</td><td>2019-07-05 09:32:59</td><td>199</td><td>178</td><td>18900</td><td>2</td><td>322</td></tr><tr><td>706</td><td>1562290380003</td><td>8</td><td>2019-07-05 09:33:00</td><td>2019-07-05 09:36:27</td><td>207</td><td>162</td><td>18897</td><td>5</td><td>315</td></tr><tr><td>707</td><td>1562290600003</td><td>8</td><td>2019-07-05 09:36:40</td><td>2019-07-05 09:41:17</td><td>277</td><td>238</td><td>18896</td><td>6</td><td>306</td></tr><tr><td>708</td><td>1562290900002</td><td>8</td><td>2019-07-05 09:41:40</td><td>2019-07-05 09:45:31</td><td>231</td><td>201</td><td>18899</td><td>3</td><td>336</td></tr><tr><td>709</td><td>1562291140003</td><td>8</td><td>2019-07-05 09:45:40</td><td>2019-07-05 09:47:49</td><td>129</td><td>111</td><td>18902</td><td>0</td><td>341</td></tr><tr><td>710</td><td>1562291280002</td><td>8</td><td>2019-07-05 09:48:00</td><td>2019-07-05 09:49:40</td><td>100</td><td>83</td><td>18902</td><td>0</td><td>325</td></tr><tr><td>711</td><td>1562291400002</td><td>8</td><td>2019-07-05 09:50:00</td><td>2019-07-05 09:51:38</td><td>98</td><td>81</td><td>18902</td><td>0</td><td>314</td></tr><tr><td>712</td><td>1562291500002</td><td>8</td><td>2019-07-05 09:51:40</td><td>2019-07-05 09:53:19</td><td>99</td><td>83</td><td>18902</td><td>0</td><td>297</td></tr><tr><td>713</td><td>1562291620002</td><td>8</td><td>2019-07-05 09:53:40</td><td>2019-07-05 09:55:22</td><td>102</td><td>85</td><td>18902</td><td>0</td><td>317</td></tr><tr><td>714</td><td>1562291740003</td><td>8</td><td>2019-07-05 09:55:40</td><td>2019-07-05 09:57:26</td><td>106</td><td>89</td><td>18901</td><td>1</td><td>293</td></tr><tr><td>715</td><td>1562291860003</td><td>8</td><td>2019-07-05 09:57:40</td><td>2019-07-05 09:59:27</td><td>107</td><td>91</td><td>18902</td><td>0</td><td>313</td></tr><tr><td>716</td><td>1562291980002</td><td>8</td><td>2019-07-05 09:59:40</td><td>2019-07-05 10:01:25</td><td>105</td><td>88</td><td>18902</td><td>0</td><td>319</td></tr><tr><td>717</td><td>1562292100003</td><td>8</td><td>2019-07-05 10:01:40</td><td>2019-07-05 10:03:22</td><td>102</td><td>84</td><td>18901</td><td>1</td><td>297</td></tr><tr><td>718</td><td>1562292220002</td><td>8</td><td>2019-07-05 10:03:40</td><td>2019-07-05 10:05:25</td><td>105</td><td>87</td><td>18900</td><td>2</td><td>290</td></tr><tr><td>719</td><td>1562292340002</td><td>8</td><td>2019-07-05 10:05:40</td><td>2019-07-05 10:07:16</td><td>96</td><td>81</td><td>18902</td><td>0</td><td>292</td></tr><tr><td>720</td><td>1562292460002</td><td>8</td><td>2019-07-05 10:07:40</td><td>2019-07-05 10:09:23</td><td>103</td><td>88</td><td>18902</td><td>0</td><td>270</td></tr><tr><td>721</td><td>1562292580003</td><td>8</td><td>2019-07-05 10:09:40</td><td>2019-07-05 10:11:29</td><td>109</td><td>93</td><td>18902</td><td>0</td><td>288</td></tr><tr><td>722</td><td>1562292700003</td><td>8</td><td>2019-07-05 10:11:40</td><td>2019-07-05 10:13:24</td><td>104</td><td>87</td><td>18901</td><td>1</td><td>289</td></tr><tr><td>723</td><td>1562292820003</td><td>8</td><td>2019-07-05 10:13:40</td><td>2019-07-05 10:15:32</td><td>112</td><td>94</td><td>18899</td><td>3</td><td>299</td></tr><tr><td>724</td><td>1562292940002</td><td>8</td><td>2019-07-05 10:15:40</td><td>2019-07-05 10:17:16</td><td>96</td><td>79</td><td>18902</td><td>0</td><td>287</td></tr><tr><td>725</td><td>1562293060002</td><td>8</td><td>2019-07-05 10:17:40</td><td>2019-07-05 10:19:17</td><td>97</td><td>82</td><td>18902</td><td>0</td><td>301</td></tr><tr><td>726</td><td>1562293180002</td><td>8</td><td>2019-07-05 10:19:40</td><td>2019-07-05 10:21:48</td><td>128</td><td>101</td><td>18901</td><td>1</td><td>283</td></tr><tr><td>727</td><td>1562293320002</td><td>8</td><td>2019-07-05 10:22:00</td><td>2019-07-05 10:23:46</td><td>106</td><td>90</td><td>18902</td><td>0</td><td>314</td></tr><tr><td>728</td><td>1562293440003</td><td>8</td><td>2019-07-05 10:24:00</td><td>2019-07-05 10:25:43</td><td>103</td><td>87</td><td>18902</td><td>0</td><td>299</td></tr><tr><td>729</td><td>1562293560003</td><td>8</td><td>2019-07-05 10:26:00</td><td>2019-07-05 10:27:38</td><td>98</td><td>82</td><td>18902</td><td>0</td><td>301</td></tr><tr><td>730</td><td>1562293660003</td><td>8</td><td>2019-07-05 10:27:40</td><td>2019-07-05 10:29:24</td><td>104</td><td>87</td><td>18902</td><td>0</td><td>295</td></tr><tr><td>731</td><td>1562293780002</td><td>8</td><td>2019-07-05 10:29:40</td><td>2019-07-05 10:31:21</td><td>101</td><td>85</td><td>18902</td><td>0</td><td>269</td></tr><tr><td>732</td><td>1562293900003</td><td>8</td><td>2019-07-05 10:31:40</td><td>2019-07-05 10:33:21</td><td>101</td><td>87</td><td>18902</td><td>0</td><td>266</td></tr><tr><td>733</td><td>1562294020002</td><td>8</td><td>2019-07-05 10:33:40</td><td>2019-07-05 10:35:17</td><td>97</td><td>81</td><td>18902</td><td>0</td><td>267</td></tr><tr><td>734</td><td>1562294140002</td><td>8</td><td>2019-07-05 10:35:40</td><td>2019-07-05 10:37:15</td><td>95</td><td>82</td><td>18902</td><td>0</td><td>254</td></tr><tr><td>735</td><td>1562294260002</td><td>8</td><td>2019-07-05 10:37:40</td><td>2019-07-05 10:39:20</td><td>100</td><td>87</td><td>18902</td><td>0</td><td>235</td></tr><tr><td>736</td><td>1562294380003</td><td>8</td><td>2019-07-05 10:39:40</td><td>2019-07-05 10:41:18</td><td>98</td><td>82</td><td>18902</td><td>0</td><td>252</td></tr><tr><td>737</td><td>1562294500003</td><td>8</td><td>2019-07-05 10:41:40</td><td>2019-07-05 10:43:23</td><td>103</td><td>87</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>738</td><td>1562294620002</td><td>8</td><td>2019-07-05 10:43:40</td><td>2019-07-05 10:45:30</td><td>110</td><td>94</td><td>18902</td><td>0</td><td>274</td></tr><tr><td>739</td><td>1562294740002</td><td>8</td><td>2019-07-05 10:45:40</td><td>2019-07-05 10:47:23</td><td>103</td><td>87</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>740</td><td>1562294860003</td><td>8</td><td>2019-07-05 10:47:40</td><td>2019-07-05 10:49:22</td><td>102</td><td>85</td><td>18902</td><td>0</td><td>271</td></tr><tr><td>741</td><td>1562294980002</td><td>8</td><td>2019-07-05 10:49:40</td><td>2019-07-05 10:51:25</td><td>105</td><td>90</td><td>18902</td><td>0</td><td>268</td></tr><tr><td>742</td><td>1562295100002</td><td>8</td><td>2019-07-05 10:51:40</td><td>2019-07-05 10:53:23</td><td>103</td><td>88</td><td>18902</td><td>0</td><td>286</td></tr><tr><td>743</td><td>1562295220003</td><td>8</td><td>2019-07-05 10:53:40</td><td>2019-07-05 10:55:25</td><td>105</td><td>88</td><td>18902</td><td>0</td><td>258</td></tr><tr><td>744</td><td>1562295340003</td><td>8</td><td>2019-07-05 10:55:40</td><td>2019-07-05 10:57:54</td><td>134</td><td>117</td><td>18901</td><td>1</td><td>252</td></tr><tr><td>745</td><td>1562295480002</td><td>8</td><td>2019-07-05 10:58:00</td><td>2019-07-05 10:59:55</td><td>115</td><td>98</td><td>18902</td><td>0</td><td>266</td></tr><tr><td>746</td><td>1562295600002</td><td>8</td><td>2019-07-05 11:00:00</td><td>2019-07-05 11:01:44</td><td>104</td><td>87</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>747</td><td>1562295720002</td><td>8</td><td>2019-07-05 11:02:00</td><td>2019-07-05 11:03:49</td><td>109</td><td>94</td><td>18902</td><td>0</td><td>267</td></tr><tr><td>748</td><td>1562295840003</td><td>8</td><td>2019-07-05 11:04:00</td><td>2019-07-05 11:05:45</td><td>105</td><td>86</td><td>18901</td><td>1</td><td>267</td></tr><tr><td>749</td><td>1562295960002</td><td>8</td><td>2019-07-05 11:06:00</td><td>2019-07-05 11:07:46</td><td>106</td><td>91</td><td>18902</td><td>0</td><td>251</td></tr><tr><td>750</td><td>1562296080002</td><td>8</td><td>2019-07-05 11:08:00</td><td>2019-07-05 11:09:41</td><td>101</td><td>85</td><td>18901</td><td>1</td><td>250</td></tr><tr><td>751</td><td>1562296200002</td><td>8</td><td>2019-07-05 11:10:00</td><td>2019-07-05 11:11:48</td><td>108</td><td>91</td><td>18901</td><td>1</td><td>264</td></tr><tr><td>752</td><td>1562296320003</td><td>8</td><td>2019-07-05 11:12:00</td><td>2019-07-05 11:13:41</td><td>101</td><td>86</td><td>18902</td><td>0</td><td>270</td></tr><tr><td>753</td><td>1562296440003</td><td>8</td><td>2019-07-05 11:14:00</td><td>2019-07-05 11:15:45</td><td>105</td><td>90</td><td>18902</td><td>0</td><td>272</td></tr><tr><td>754</td><td>1562296560003</td><td>8</td><td>2019-07-05 11:16:00</td><td>2019-07-05 11:17:42</td><td>102</td><td>88</td><td>18901</td><td>1</td><td>273</td></tr><tr><td>755</td><td>1562296680003</td><td>8</td><td>2019-07-05 11:18:00</td><td>2019-07-05 11:19:40</td><td>100</td><td>86</td><td>18902</td><td>0</td><td>279</td></tr><tr><td>756</td><td>1562296800002</td><td>8</td><td>2019-07-05 11:20:00</td><td>2019-07-05 11:21:44</td><td>104</td><td>91</td><td>18902</td><td>0</td><td>252</td></tr><tr><td>757</td><td>1562296920002</td><td>8</td><td>2019-07-05 11:22:00</td><td>2019-07-05 11:23:50</td><td>110</td><td>95</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>758</td><td>1562297040003</td><td>8</td><td>2019-07-05 11:24:00</td><td>2019-07-05 11:25:40</td><td>100</td><td>86</td><td>18902</td><td>0</td><td>257</td></tr><tr><td>759</td><td>1562297160003</td><td>8</td><td>2019-07-05 11:26:00</td><td>2019-07-05 11:27:41</td><td>101</td><td>87</td><td>18902</td><td>0</td><td>265</td></tr><tr><td>760</td><td>1562297280002</td><td>8</td><td>2019-07-05 11:28:00</td><td>2019-07-05 11:29:47</td><td>107</td><td>93</td><td>18902</td><td>0</td><td>260</td></tr><tr><td>761</td><td>1562297400002</td><td>8</td><td>2019-07-05 11:30:00</td><td>2019-07-05 11:31:45</td><td>105</td><td>92</td><td>18902</td><td>0</td><td>235</td></tr><tr><td>762</td><td>1562297520002</td><td>8</td><td>2019-07-05 11:32:00</td><td>2019-07-05 11:33:38</td><td>98</td><td>87</td><td>18902</td><td>0</td><td>197</td></tr><tr><td>763</td><td>1562297620002</td><td>8</td><td>2019-07-05 11:33:40</td><td>2019-07-05 11:35:26</td><td>106</td><td>94</td><td>18902</td><td>0</td><td>209</td></tr><tr><td>764</td><td>1562297740002</td><td>8</td><td>2019-07-05 11:35:40</td><td>2019-07-05 11:37:21</td><td>101</td><td>88</td><td>18902</td><td>0</td><td>212</td></tr><tr><td>765</td><td>1562297860003</td><td>8</td><td>2019-07-05 11:37:40</td><td>2019-07-05 11:39:19</td><td>99</td><td>84</td><td>18902</td><td>0</td><td>224</td></tr><tr><td>766</td><td>1562297980003</td><td>8</td><td>2019-07-05 11:39:40</td><td>2019-07-05 11:41:13</td><td>93</td><td>80</td><td>18902</td><td>0</td><td>220</td></tr><tr><td>767</td><td>1562298100002</td><td>8</td><td>2019-07-05 11:41:40</td><td>2019-07-05 11:43:37</td><td>117</td><td>102</td><td>18901</td><td>1</td><td>215</td></tr><tr><td>768</td><td>1562298220003</td><td>8</td><td>2019-07-05 11:43:40</td><td>2019-07-05 11:45:27</td><td>107</td><td>95</td><td>18902</td><td>0</td><td>217</td></tr><tr><td>769</td><td>1562298340003</td><td>8</td><td>2019-07-05 11:45:40</td><td>2019-07-05 11:47:31</td><td>111</td><td>98</td><td>18902</td><td>0</td><td>209</td></tr><tr><td>770</td><td>1562298460002</td><td>8</td><td>2019-07-05 11:47:40</td><td>2019-07-05 11:49:21</td><td>101</td><td>89</td><td>18902</td><td>0</td><td>221</td></tr><tr><td>771</td><td>1562298580002</td><td>8</td><td>2019-07-05 11:49:40</td><td>2019-07-05 11:51:18</td><td>97</td><td>85</td><td>18902</td><td>0</td><td>231</td></tr><tr><td>772</td><td>1562298700002</td><td>8</td><td>2019-07-05 11:51:40</td><td>2019-07-05 11:53:23</td><td>103</td><td>92</td><td>18902</td><td>0</td><td>232</td></tr><tr><td>773</td><td>1562298820002</td><td>8</td><td>2019-07-05 11:53:40</td><td>2019-07-05 11:55:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>220</td></tr><tr><td>774</td><td>1562298940003</td><td>8</td><td>2019-07-05 11:55:40</td><td>2019-07-05 11:57:24</td><td>104</td><td>90</td><td>18900</td><td>2</td><td>225</td></tr><tr><td>775</td><td>1562299060002</td><td>8</td><td>2019-07-05 11:57:40</td><td>2019-07-05 11:59:57</td><td>137</td><td>121</td><td>18899</td><td>3</td><td>233</td></tr><tr><td>776</td><td>1562299200005</td><td>8</td><td>2019-07-05 12:00:00</td><td>2019-07-05 12:01:41</td><td>101</td><td>85</td><td>18901</td><td>1</td><td>207</td></tr><tr><td>777</td><td>1562299320002</td><td>8</td><td>2019-07-05 12:02:00</td><td>2019-07-05 12:03:37</td><td>97</td><td>86</td><td>18902</td><td>0</td><td>203</td></tr><tr><td>778</td><td>1562299420003</td><td>8</td><td>2019-07-05 12:03:40</td><td>2019-07-05 12:05:18</td><td>98</td><td>88</td><td>18902</td><td>0</td><td>193</td></tr><tr><td>779</td><td>1562299540003</td><td>8</td><td>2019-07-05 12:05:40</td><td>2019-07-05 12:07:17</td><td>97</td><td>83</td><td>18902</td><td>0</td><td>197</td></tr><tr><td>780</td><td>1562299660003</td><td>8</td><td>2019-07-05 12:07:40</td><td>2019-07-05 12:09:10</td><td>90</td><td>77</td><td>18902</td><td>0</td><td>196</td></tr><tr><td>781</td><td>1562299780002</td><td>8</td><td>2019-07-05 12:09:40</td><td>2019-07-05 12:11:10</td><td>90</td><td>78</td><td>18902</td><td>0</td><td>211</td></tr><tr><td>782</td><td>1562299900002</td><td>8</td><td>2019-07-05 12:11:40</td><td>2019-07-05 12:13:19</td><td>99</td><td>86</td><td>18901</td><td>1</td><td>203</td></tr><tr><td>783</td><td>1562300020002</td><td>8</td><td>2019-07-05 12:13:40</td><td>2019-07-05 12:15:17</td><td>97</td><td>86</td><td>18902</td><td>0</td><td>190</td></tr><tr><td>784</td><td>1562300140002</td><td>8</td><td>2019-07-05 12:15:40</td><td>2019-07-05 12:17:18</td><td>98</td><td>87</td><td>18902</td><td>0</td><td>187</td></tr><tr><td>785</td><td>1562300260003</td><td>8</td><td>2019-07-05 12:17:40</td><td>2019-07-05 12:19:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>183</td></tr><tr><td>786</td><td>1562300380002</td><td>8</td><td>2019-07-05 12:19:40</td><td>2019-07-05 12:21:25</td><td>105</td><td>95</td><td>18902</td><td>0</td><td>183</td></tr><tr><td>787</td><td>1562300500010</td><td>8</td><td>2019-07-05 12:21:40</td><td>2019-07-05 12:23:19</td><td>99</td><td>87</td><td>18901</td><td>1</td><td>172</td></tr><tr><td>788</td><td>1562300620004</td><td>8</td><td>2019-07-05 12:23:40</td><td>2019-07-05 12:25:13</td><td>93</td><td>82</td><td>18902</td><td>0</td><td>184</td></tr><tr><td>789</td><td>1562300740004</td><td>8</td><td>2019-07-05 12:25:40</td><td>2019-07-05 12:27:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>190</td></tr><tr><td>790</td><td>1562300860003</td><td>8</td><td>2019-07-05 12:27:40</td><td>2019-07-05 12:29:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>171</td></tr><tr><td>791</td><td>1562300980004</td><td>8</td><td>2019-07-05 12:29:40</td><td>2019-07-05 12:31:25</td><td>105</td><td>94</td><td>18902</td><td>0</td><td>169</td></tr><tr><td>792</td><td>1562301100003</td><td>8</td><td>2019-07-05 12:31:40</td><td>2019-07-05 12:33:19</td><td>99</td><td>88</td><td>18902</td><td>0</td><td>182</td></tr><tr><td>793</td><td>1562301220004</td><td>8</td><td>2019-07-05 12:33:40</td><td>2019-07-05 12:35:16</td><td>96</td><td>86</td><td>18902</td><td>0</td><td>172</td></tr><tr><td>794</td><td>1562301340003</td><td>8</td><td>2019-07-05 12:35:40</td><td>2019-07-05 12:37:21</td><td>101</td><td>89</td><td>18902</td><td>0</td><td>164</td></tr><tr><td>795</td><td>1562301460004</td><td>8</td><td>2019-07-05 12:37:40</td><td>2019-07-05 12:39:17</td><td>97</td><td>85</td><td>18902</td><td>0</td><td>158</td></tr><tr><td>796</td><td>1562301580003</td><td>8</td><td>2019-07-05 12:39:40</td><td>2019-07-05 12:41:25</td><td>105</td><td>93</td><td>18902</td><td>0</td><td>184</td></tr><tr><td>797</td><td>1562301700005</td><td>8</td><td>2019-07-05 12:41:40</td><td>2019-07-05 12:43:19</td><td>99</td><td>88</td><td>18902</td><td>0</td><td>173</td></tr><tr><td>798</td><td>1562301820004</td><td>8</td><td>2019-07-05 12:43:40</td><td>2019-07-05 12:45:14</td><td>94</td><td>84</td><td>18902</td><td>0</td><td>155</td></tr><tr><td>799</td><td>1562301940004</td><td>8</td><td>2019-07-05 12:45:40</td><td>2019-07-05 12:47:20</td><td>100</td><td>88</td><td>18902</td><td>0</td><td>158</td></tr><tr><td>800</td><td>1562302060004</td><td>8</td><td>2019-07-05 12:47:40</td><td>2019-07-05 12:49:18</td><td>98</td><td>88</td><td>18902</td><td>0</td><td>146</td></tr><tr><td>801</td><td>1562302180003</td><td>8</td><td>2019-07-05 12:49:40</td><td>2019-07-05 12:51:26</td><td>106</td><td>93</td><td>18902</td><td>0</td><td>165</td></tr><tr><td>802</td><td>1562302300003</td><td>8</td><td>2019-07-05 12:51:40</td><td>2019-07-05 12:53:23</td><td>103</td><td>92</td><td>18902</td><td>0</td><td>172</td></tr><tr><td>803</td><td>1562302420004</td><td>8</td><td>2019-07-05 12:53:40</td><td>2019-07-05 12:55:29</td><td>109</td><td>96</td><td>18902</td><td>0</td><td>183</td></tr><tr><td>804</td><td>1562302540005</td><td>8</td><td>2019-07-05 12:55:40</td><td>2019-07-05 12:57:26</td><td>106</td><td>95</td><td>18902</td><td>0</td><td>140</td></tr><tr><td>805</td><td>1562302660004</td><td>8</td><td>2019-07-05 12:57:40</td><td>2019-07-05 12:59:20</td><td>100</td><td>89</td><td>18902</td><td>0</td><td>143</td></tr><tr><td>806</td><td>1562302780004</td><td>8</td><td>2019-07-05 12:59:40</td><td>2019-07-05 13:01:21</td><td>101</td><td>89</td><td>18902</td><td>0</td><td>145</td></tr><tr><td>807</td><td>1562302900004</td><td>8</td><td>2019-07-05 13:01:40</td><td>2019-07-05 13:03:25</td><td>105</td><td>94</td><td>18902</td><td>0</td><td>155</td></tr><tr><td>808</td><td>1562303020005</td><td>8</td><td>2019-07-05 13:03:40</td><td>2019-07-05 13:05:18</td><td>98</td><td>86</td><td>18902</td><td>0</td><td>164</td></tr><tr><td>809</td><td>1562303140004</td><td>8</td><td>2019-07-05 13:05:40</td><td>2019-07-05 13:07:19</td><td>99</td><td>89</td><td>18902</td><td>0</td><td>176</td></tr><tr><td>810</td><td>1562303260007</td><td>8</td><td>2019-07-05 13:07:40</td><td>2019-07-05 13:09:22</td><td>102</td><td>91</td><td>18902</td><td>0</td><td>153</td></tr><tr><td>811</td><td>1562303380006</td><td>8</td><td>2019-07-05 13:09:40</td><td>2019-07-05 13:11:21</td><td>101</td><td>91</td><td>18902</td><td>0</td><td>166</td></tr><tr><td>812</td><td>1562303500005</td><td>8</td><td>2019-07-05 13:11:40</td><td>2019-07-05 13:13:18</td><td>98</td><td>85</td><td>18901</td><td>1</td><td>151</td></tr></tbody></table><h4 id="完整数据"><a href="#完整数据" class="headerlink" title="完整数据"></a>完整数据</h4><p>完整数据可通过连接数据库查看:</p><p>DBType: MariaDB<br>schemas: traffic-service-v2<br><del>host: 192.168.10.224</del><br>port: 3306<br>username: root<br>password: 123456</p><h4 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h4><p>通过以上数据,我们可以做个简单汇总分析:</p><ol><li>一个分析周期内网络请求所消耗的时间占用了总消耗时间的 4/5, 这里说的网络请求时间指的是请求百度瓦片所消耗的时间</li><li>一个分析周期内: 总消耗时间的平均值为: 98.7 s, 网络请求所消耗的平均时间为: 85.7 s, 服务处理所消耗的平均时间为 13 s ;至于时间为什么会呈这样的分布,下面会有详细的解释</li><li>7 月 4 日的晚高峰拥堵时间开始与 17:09 左右, 于 19:33 左右结束, 并且在 17:58 至 18:00 达到了最高峰; 在最高峰时间服务分析耗时 31 s, 处理了 613 张拥堵瓦片.同理,还可以对 7 月 5 日进行同样的分析,这里不再列举</li><li>单张瓦片平均处理时间为 : 0.06976290 s</li><li>每个分析周期都会请求 18902 次瓦片,为什么有的周期请求时间断,而有的周期请求时间长?<br>原因有 2 :<pre><code> 1. 请求过程中可能会发生阻塞的情况,虽然这种情况较少,但是会拖慢单个线程的处理速度 2. 每次分析的拥堵状况不同, 涉及拥堵的瓦片被填充的有效像素点的数量也不同,这就导致每次同一编号瓦片,但是大小不同,消耗的时间也就不同</code></pre></li></ol><h4 id="机器表现"><a href="#机器表现" class="headerlink" title="机器表现"></a>机器表现</h4><p>经过一周的服务性能测试,机器的表现如下</p><ol><li>CPU</li></ol><p><img src="http://image.joylau.cn/blog/ts_cpu-overview.gif" alt="CPU-OVERVIEW"></p><p>这是一个分析周期的资源占用情况, 一个分析周期指的是分析完一遍合肥市拥堵情况的动作<br>截取其中几分钟的的监控情况如下:</p><p><img src="http://image.joylau.cn/blog/ts_cpu.gif" alt="CPU"></p><p>简单解释:<br>第二张图中每个驼峰代表一次分析过程,图中 11:06 - 11:13,经过了 4 个分析周期,每个分析周期的的大致状态是前期和后期 CPU 占用率都不高,中间部分 CPU 占有率高, 约 80% 左右<br>这是因为在抓取地图瓦片的时候是按 <code>从北向南</code> , <code>从西向东</code> 的顺序来抓取的<br>很显然合肥市市内是较整个合肥市拥堵情况较重的,而市内是则位于整片区域的中心部分<br>于是就能解释为什么在一个分析周期前期和后期 CPU 占用率都不高,中间部分 CPU 占有率高的原因</p><ol start="2"><li>线程<br><img src="http://image.joylau.cn/blog/ts_thread.gif" alt="Thread"></li></ol><p>简单解释:<br>重点看 <code>ts_</code> 前缀开头的线程<br>这 8 条线代表分析服务的 8 个线程,绿色代表正在运行, 黄色代表在等待中<br>中间被隔开代表分析服务已经进行了一个周期<br>可以看出单个线程在执行一个分析周期的时候,有至少三分之一的时间是处于等待的<br>这是因为服务分析速度很快,分析完毕之后就从队列中拿出下一条任务出来分析,而在分析之前,会先进行网络请求<br>请求瓦片是 TCP 请求, 经历上一次请求关闭的四次挥手和连接建立的三次握手, 这种 IO 请求的耗时对 CPU 来说简直如隔三秋<br>( 对于一次分析周期,去除无道路信息的瓦片,有 18902 张瓦片, 这些都是几十 KB 到几百 KB 大小不等的图片, 需要进行 18902 次 IO 请求,其开销必然不小 )<br>但是 CPU 不会闲着,他会去处理其他线程的请求<br>这样的分析也能够解释了上述表格中 <code>总耗时</code> 和 <code>网络请求耗时</code> 之间的关系  </p><p>线程中甚至还会出现这样的情况  </p><p><img src="http://image.joylau.cn/blog/ts_thread_waiting.png" alt="Thread Waiting"></p><p>这种情况会拖慢单个线程的执行效率<br>这种情况是因为在请求百度瓦片的时候某一张耗时过长被阻塞了,导致线程一直在等待,直到等待时间大于等于连接超时时间或者数据传输超时时间,该线程会被主动释放,后面又恢复正常运行<br>不过这种情况出现的次数比较少,主要看网络的稳定性,有出现的情况都在日志里记录下来了,即上述表格中的出错数</p><ol start="3"><li>内存<br><img src="http://image.joylau.cn/blog/ts_memory.gif" alt="Memory"></li></ol><p>对于服务器内存来说, 24G 内存还是比较吃紧的<br>其中最消耗服务器内存是核心分析服务, 为 java 服务<br>java 12 初始化堆大小和最大堆大小均没有配置,为缺省值<br>这时最大堆大小 Xmx 为物理内存的 1/4 , 即 6 GB</p><p>通过上面的图可以得出:<br>核心分析服务达到峰值时, 以达到最大内存 6G, 后来内存占用又会减少,很有可能是 6G 内存不够使用,已触发 GC, 导致内存释放<br>结合整个机器内存占用普遍在 80% 以上, 更能说明这一点</p><ol start="4"><li>磁盘<br><img src="http://image.joylau.cn/blog/ts_disk.gif" alt="Disk"></li></ol><p>磁盘的 IO 情况其实并没有太大变动,只是在分析的高峰会有写入和读取</p><ol start="5"><li>网络<br><img src="http://image.joylau.cn/blog/ts_networks.gif" alt="Networks"></li></ol><p>8 线程并发请求, 外网下载速度平稳在 350 kb/s 左右, 对网络带宽大小要求不高,但要求网络稳定,无抖动,无丢包</p><h4 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h4><p>经过上面的分析,我认为可以从下面几个点再继续优化:</p><ol><li>提示机器内存: 显然测试机器的内存有点吃紧, 至少 64 G 为合适</li><li>CPU 的频率不需要太高,可选择核数多 CPU, 因为整个耗时最长的是网络请求时间, 而这种 IO 并不消耗 CPU 时间,可将线程数调节至 CPU 逻辑核心数的 3 倍到 5 倍. 推荐 IntelXeon E5 系列 CPU</li><li>提供更稳定的网络</li><li>既然请求百度的瓦片耗时高,那么先缓存一部分瓦片到本地进行分析,效率是否更高? (下面进行测试) 不过带来的坏处就是丧失了分析服务的实时性</li></ol><h4 id="本地缓存分析"><a href="#本地缓存分析" class="headerlink" title="本地缓存分析"></a>本地缓存分析</h4><p>我事先缓存了 2019年07月04日17:00:00 到 2019年07月04日18:00:00, 60 分钟内每分钟的瓦片数据, 共计 18902 * 60 = 1134120 张瓦片到本地磁盘</p><h5 id="Nginx-读取"><a href="#Nginx-读取" class="headerlink" title="Nginx  读取"></a>Nginx  读取</h5><p>将这 110w 张瓦片放到 nginx 目录下, 在进行测试<br>发现测试结果并不能够令人满意,和上面的结果几乎无差,这里就不再贴出表格数据了<br>仔细分析结果是没错的.还是同样的 TCP 请求,只不过不同的是从远端服务器变成了本地服务器</p><h5 id="本地读取瓦片"><a href="#本地读取瓦片" class="headerlink" title="本地读取瓦片"></a>本地读取瓦片</h5><p>将 TCP 请求更换为本地读取文件形式,结果分析时间令人欣慰, 这里也不贴出表格数据了,放一张日志的截图对比下</p><p><img src="http://image.joylau.cn/blog/ts_file_system.png" alt="File System"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>本分析服务对服务器的要求并不高, 要求 CPU 尽量多核心,网络稳定</li><li>开销时间主要集中在网络请求耗时, 目前较好的解决方式是先本地缓存再分析,牺牲了分析的实时性</li></ol>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle 配置代理</title>
      <link href="/2019/07/04/Gradle-Proxy/"/>
      <url>/2019/07/04/Gradle-Proxy/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>用 gradle 构建经常失败,主要是国内网络的原因,这时候配置 gradle 使用代理,构建过程要轻松许多</p><h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><ol><li><p>JVM system properties<br>例如:<br>System.setProperty(‘http.proxyHost’, ‘<a href="http://www.somehost.org&#39;" target="_blank" rel="noopener">www.somehost.org&#39;</a>)</p></li><li><p>配置 gradle.properties</p></li></ol><pre><code class="properties">    ## http    systemProp.http.proxyHost=www.somehost.org    systemProp.http.proxyPort=8080    systemProp.http.proxyUser=userid    systemProp.http.proxyPassword=password    systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost    ## https    systemProp.https.proxyHost=www.somehost.org    systemProp.https.proxyPort=8080    systemProp.https.proxyUser=userid    systemProp.https.proxyPassword=password    systemProp.https.nonProxyHosts=*.nonproxyrepos.com|localhost</code></pre>]]></content>
      
      
      <categories>
          
          <category> Gradle篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖系列 --- 使用群晖搭建 Docker 私有仓库并管理</title>
      <link href="/2019/06/29/Synology-Private-Docker/"/>
      <url>/2019/06/29/Synology-Private-Docker/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>docker 仓库存储大量的镜像,占用的空间很大,放到群晖上存储再合适不过了<br>之前写过基于 docker compose 使用 Harbor 搭建 Docker 私有仓库并管理,但是群晖里只有 docker 的管理,没有 docker compose 的直接支持<br>现在来个简单的仓库管理</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ol><li>安装 docker 套件</li><li>下载 registry 和 joxit/docker-registry-ui 镜像</li><li>分别启动这 2 个容器,注意配置</li></ol><h3 id="registry-配置"><a href="#registry-配置" class="headerlink" title="registry 配置"></a>registry 配置</h3><ol><li>配置挂载目录</li><li>配置环境变量,因为默认的 registry 镜像不支持跨域请求和没有开启删除镜像的功能,我曾尝试在镜像里修改配置文件,然后在导出镜像,但是失败了,新导出的镜像启动后无法提供服务</li><li>环境配置如下</li></ol><p><img src="http://image.joylau.cn/blog/Synology-Private-Docker.png" alt="Synology-Private-Docker"></p><p>REGISTRY_STORAGE_DELETE_ENABLED:true<br>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Headers:[‘Origin,Accept,Content-Type,Authorization’]<br>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Methods:[‘GET,POST,PUT,DELETE’,’HEAD’]<br>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Origin:[‘*’]<br>REGISTRY_HTTP_HEADERS_Access-Control-Expose-Headers:[‘Docker-Content-Digest’]  </p><h3 id="后续配置"><a href="#后续配置" class="headerlink" title="后续配置"></a>后续配置</h3><p>路由器开启端口映射即可</p><h3 id="镜像的删除"><a href="#镜像的删除" class="headerlink" title="镜像的删除"></a>镜像的删除</h3><p>首先要说的是,这里有个坑, 官方提供的删除镜像仓库中镜像的接口，仅仅是把 manifest 删除了，真正的镜像文件还存在！官方并没有提供删除镜像层的接口！这也就是说，当我们调用删除镜像的接口之后，仅仅是查看镜像的列表时看不到原镜像了，然而原有镜像仍然在磁盘中，占用着宝贵的文件存储空间</p><p>这里使用官方提供的 GC 工具来清除无用文件</p><h3 id="删除方式-1"><a href="#删除方式-1" class="headerlink" title="删除方式 1"></a>删除方式 1</h3><ol><li>在 web 界面上删除,或者调用 api 删除:</li></ol><pre><code class="text">    获取待删镜像的digest    获取镜像digest的API为：    GET /v2/&lt;tag&gt;/manifests/&lt;version&gt;    例如: /v2/joy/blog.joylau.cn/manifests/1.0    其中，name是仓库名，reference是标签，此时需要注意，调用时需要加上header内容：    Accept： application/vnd.docker.distribution.manifest.v2+json    其中Docker-Content-Digest的值就是镜像的digest    3、调用官方的HTTP API V2删除镜像    删除镜像的API为：    DELETE /v2/&lt;name&gt;/manifests/&lt;sha256&gt;    例如: /v2/joy/blog.joylau.cn/manifests/sha256:6c2daa1642b94dabdfaa32a9d3943cb92036c55117961fa9fcc4cc29348e5d39    其中，name是仓库名称，reference是包含“sha256：”的digest。</code></pre><ol start="2"><li>进入容器里调用GC清理镜像文件</li></ol><pre><code class="bash">    bin/registry garbage-collect /etc/docker/registry/config.yml</code></pre><p>注意: gc不是事务操作，当gc过程中刚好有push操作时，则可能会误删数据，建议设置read-only模式之后再进行gc，然后再改回来</p><ol start="3"><li>重启 docker registry<br>注意，如果不重启会导致push相同镜像时产生layer already exists错误。</li></ol><h3 id="删除方式-2"><a href="#删除方式-2" class="headerlink" title="删除方式 2"></a>删除方式 2</h3><p>使用第三方开源工具: <a href="https://github.com/burnettk/delete-docker-registry-image" target="_blank" rel="noopener">https://github.com/burnettk/delete-docker-registry-image</a></p><p>该工具也提供了dry-run的方式，只输出待删除的信息不执行删除操作。在命令后加上——dry-run即可</p><p>跟gc方式一样，删除镜像之后要重启docker registry，不然还是会出现相同镜像push不成功的问题。</p><h3 id="docker-registry-ui-对于有认证的-docker-私服的配置-2020-04-09-更新"><a href="#docker-registry-ui-对于有认证的-docker-私服的配置-2020-04-09-更新" class="headerlink" title="docker-registry-ui 对于有认证的 docker 私服的配置 [2020-04-09 更新]"></a>docker-registry-ui 对于有认证的 docker 私服的配置 [2020-04-09 更新]</h3><p>对于没有认证的 docker 私服,使用方式上面已经有配置了<br>对于有认证的 docker 私服,却有点变化<br>需要改变:</p><p>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Methods:[‘GET,POST,PUT,DELETE’,’HEAD’]<br>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Origin:[‘<your docker-registry-ui url>‘]<br>REGISTRY_HTTP_HEADERS_Access-Control-Allow-Credentials: [true]</p><p>另外,对于有认证的 docker 私服,删除镜像还有有问题的:<br>具体情况见: <a href="https://github.com/Joxit/docker-registry-ui/issues/104" target="_blank" rel="noopener">https://github.com/Joxit/docker-registry-ui/issues/104</a></p><p>简单来说是 docker 私服的锅,并不是 Joxit/docker-registry-ui 的问题,因为在浏览器再监测是否允许跨域请求发出的 options 请求被返回了 401 状态,导致后续请求无法发出</p><p>而实际上应该返回 20x 的请求</p><p>作者给出方法是: 将 docker 私服和 docker-registry-ui 放到同一个域下</p><p>那我这边还是以 群晖的 docker 来配置 nginx 来实现这样的功能</p><p>nginx 配置如下:</p><ol><li>/etc/nginx/nginx.conf, 这个没有变化,我们将其外置,方便日后修改:</li></ol><pre><code class="editorconfig">    user  nginx;    worker_processes  1;    error_log  /var/log/nginx/error.log warn;    pid        /var/run/nginx.pid;    events {        worker_connections  1024;    }    http {        include       /etc/nginx/mime.types;        default_type  application/octet-stream;        log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;                          &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;                          &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;        access_log  /var/log/nginx/access.log  main;        sendfile        on;        #tcp_nopush     on;        keepalive_timeout  65;        #gzip  on;        include /etc/nginx/conf.d/*.conf;    }</code></pre><ol start="2"><li>/etc/nginx/conf.d/default.conf: 这个文件我们添加反向代理,使得 docker 私服和 docker-registry-ui 在同一个域下</li></ol><pre><code class="editorconfig">    server {        listen       80;        server_name  localhost;        #charset koi8-r;        #access_log  /var/log/nginx/host.access.log  main;        location / {            root   /usr/share/nginx/html;            index  index.html index.htm;        }        #location / {        #    #rewrite ^/b/(.*)$ /$1 break;        #    proxy_set_header Host $host;        #    proxy_set_header X-Real-IP $remote_addr;        #    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        #    proxy_pass http://nas.joylau.cn:5007/; # 转发地址,注意要有/        #}        location /v2 {            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_pass http://xxxx:xxx/v2; # 转发地址        }        location /ui {            rewrite ^/b/(.*)$ /$1 break; # 去除本地接口/ui前缀, 否则会出现404            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_pass http://xxxx:xxx/; # 转发地址,注意要有/        }        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html {            root   /usr/share/nginx/html;        }        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \.php$ {        #    proxy_pass   http://127.0.0.1;        #}        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \.php$ {        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #}        # deny access to .htaccess files, if Apache&#39;s document root        # concurs with nginx&#39;s one        #        #location ~ /\.ht {        #    deny  all;        #}    }</code></pre><p>访问方式:</p><ol><li>docker-registry-ui 的访问直接使用 nginx 的地址, 后面加上 <code>/ui/</code>, 这样就会代理到之前的 docker-registry-ui 的服务</li><li>docker registry 的地址直接填 nginx 提供服务的<code>主机 + 端口号</code>即可, 后面不需要加其他东西</li></ol><p>这样方式在 docker-registry-ui 连接 docker 私服时会弹框输入用户名密码, 也能完美解决删除镜像的问题</p>]]></content>
      
      
      <categories>
          
          <category> 群晖篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于 iKuai 软路由系统的单线多拨和多线多拨</title>
      <link href="/2019/06/11/Daily-Multi-PPPoE/"/>
      <url>/2019/06/11/Daily-Multi-PPPoE/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>基于 iKuai 软路由系统的单线多拨和多线多拨<br>家里一条电信 50M 带宽(上行 10M)<br>一条 100M 的长城宽带(上行 100M, 下行实际外网带宽 10M)<br>谁不想带宽叠加,网速更快呢</p><h2 id="单线多拨"><a href="#单线多拨" class="headerlink" title="单线多拨"></a>单线多拨</h2><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ol><li>选择基于物理网卡的混合模式</li><li>勾选开启多拨,并输入个数,我这里是 4, 也就是 4 拨,这个数字是我在电信的网站上,进入我的业务,套餐里看到的,允许 4 个终端拨号上网</li><li>依次在底下列表里添加 4 个拨号项,都是相同的账号和密码</li><li>在多线负载配置中,添加一条规则: 源 IP + 目的 IP + 目的端口,运营商选全部,负载比例 1:1:1:1</li><li>打开 speedtest.cn 进行测速,在线路监控里看到 4 条线路中每一条线路都有流量流过</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>单线多拨成功, <strong>但是总带宽不叠加</strong>,4 条线路的总带宽还是 50M,应该是运营商做了端口限制,暂时无解</p><h2 id="多线多拨"><a href="#多线多拨" class="headerlink" title="多线多拨"></a>多线多拨</h2><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><ol><li>2条带宽均选择 ADSL/PPPoE 拨号,并正常拨号成功上网</li><li>网络设置 &gt; DNS设置 &gt; DNS设置中首选DNS配置成 192.168.1.1, 并开启 DNS加速服务, DNS加速模式选择代理模式,勾选强制客户端DNS代理</li><li>在多线负载配置中,添加一条规则: 源 IP + 目的 IP + 目的端口,运营商选全部,负载比例 1:1:1:1</li><li>打开 speedtest.cn 进行测速,在线路监控里看到 2 条线路中都有流量流过,并且都能达到峰值</li></ol><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><strong>多线多拨并宽带叠加成功</strong>,但是部分网页会打不开,游戏也会掉线,因为目的地址有 2 个,这是需要配合其他的策略进行负载均衡,具体配置根据实际情况来添加</p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖系列 --- 使用豆瓣的削刮器来检索视频的元数据</title>
      <link href="/2019/05/30/Synology-DouBan-Scraper/"/>
      <url>/2019/05/30/Synology-DouBan-Scraper/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Video Station 自带的削刮器好像并不是很好用,很多电视剧都搜不到元数据,换了豆瓣的就比较好用了</p><h3 id="安装方法："><a href="#安装方法：" class="headerlink" title="安装方法："></a>安装方法：</h3><ol><li>开启DSM的ssh，并登入</li><li>执行一句话安装：</li></ol><pre><code class="bash">    sudo wget -N --no-check-certificate https://sh.9hut.cn/dsvp.sh &amp;&amp; sudo bash dsvp.sh install</code></pre><h3 id="卸载方法："><a href="#卸载方法：" class="headerlink" title="卸载方法："></a>卸载方法：</h3><ol><li>开启DSM的ssh，并登入</li><li>执行一句话卸载：</li></ol><pre><code class="bash">    sudo wget -N --no-check-certificate https://sh.9hut.cn/dsvp.sh &amp;&amp; sudo bash dsvp.sh uninstall</code></pre>]]></content>
      
      
      <categories>
          
          <category> 群晖篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖系列 --- 如何半洗白操作</title>
      <link href="/2019/05/29/Synology-Semi-Activation/"/>
      <url>/2019/05/29/Synology-Semi-Activation/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>安装的黑群晖发现无法使用 video station 的缩略图和转码功能,使用的体验性大大减少<br>上 google 搜寻得知,半洗白即可解决上述问题</p><h3 id="半洗白和全洗白的区别"><a href="#半洗白和全洗白的区别" class="headerlink" title="半洗白和全洗白的区别"></a>半洗白和全洗白的区别</h3><ul><li>全洗白: 群晖的所有功能都可以使用</li><li>半洗白: 只需要正确的序列号即可,mac 地址不合法也无所谓,可以使用视频的缩略图和转码功能,但是无法使用 qc 功能</li></ul><h3 id="如何半洗白"><a href="#如何半洗白" class="headerlink" title="如何半洗白"></a>如何半洗白</h3><p>只要获取到正确的 sn 码即可</p><h4 id="DDSM"><a href="#DDSM" class="headerlink" title="DDSM"></a>DDSM</h4><ol><li>安装 docker 套件</li><li>控制面板 &gt; 网络 &gt; 网络界面 &gt; 管理 &gt; Open vSwitch 设置 , 启用 Open vSwitch</li><li>手动下载文件在上传安装,启动一个新的 DSM</li><li>查看新的 DSM 的序列号,并记录下来</li><li>使用 U 盘的 PE 系统启动, 使用 diskgeuneis 修改 ESP 分区里的 grub.cfg 的文件中 sn 码</li><li>重启即可</li></ol><h4 id="Google-图片搜索"><a href="#Google-图片搜索" class="headerlink" title="Google 图片搜索"></a>Google 图片搜索</h4><p>在 google 图片里搜索和黑群晖版本一直的系统信息的图片,记录下来自己使用,[手动阴险]</p><h3 id="我的方法"><a href="#我的方法" class="headerlink" title="我的方法"></a>我的方法</h3><p>我是看的人家的开箱视频,开机体验,打开系统信息的时候没有打码,让我看到了序列号,我就拿来用了,再次 [手动阴险]</p>]]></content>
      
      
      <categories>
          
          <category> 群晖篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>群晖系列 --- 如何恢复群晖系统数据盘的数据</title>
      <link href="/2019/05/29/Synology-Recover-Data/"/>
      <url>/2019/05/29/Synology-Recover-Data/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>之前使用的是二合一的引导安装黑群晖系统,进入系统中发现一个 9G 的存储空间,顺手就把他删除了,重新建了个存储池,把 mSATA 盘上的引导折腾没了,无法进入系统<br>在 PE 系统下发现无法读取数据盘的数据<br>那么重做系统后如何恢复数据?</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>使用计算机和 Ubuntu live CD 恢复其硬盘上存储的数据。<br>确保 Synology NAS 硬盘上运行的文件系统是 EXT4 或 Btrfs</p><h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><ol><li>准备一台具有足够数量硬盘插槽的计算机，用于安装从 Synology NAS 卸下的硬盘。</li><li>从 Synology NAS 中卸下硬盘，然后将其安装到计算机中。对于 RAID 或 SHR 配置，必须同时在计算机中安装所有硬盘（不包括 Hot Spare 硬盘）。</li><li>在 Windows 上创建可启动 U 盘中的说明准备 Ubuntu 环境。</li><li>打开终端</li><li>如果要从 RAID 或 SHR 配置恢复数据，请执行步骤 6 到 9；如果要从只有一个硬盘的基本存储类型恢复文件，请执行步骤 9。</li><li>输入以下命令（sudo 执行 root 权限）。<ul><li>Ubuntu@ubuntu:~$ sudo -i</li></ul></li><li>输入以下命令以安装 mdadm 和 lvm2两者都是 RAID 管理工具。必须安装 lvm2，否则 vgchange 无法正常工作。<ul><li>root@ubuntu:~$ apt-get update</li><li>root@ubuntu:~$ apt-get install -y mdadm lvm2</li></ul></li><li>输入以下命令以装载从 Synology NAS 中卸下的所有硬盘。根据 Synology NAS 上的存储池配置，结果可能有所不同。<ul><li>root@ubuntu:~$ mdadm -Asf &amp;&amp; vgchange -ay</li></ul></li><li>输入以下命令以采用只读方式装载所有硬盘，从而可访问数据。在 ${device_path} 中输入设备路径，并在 ${mount_point} 中输入装载点。数据会放在装载点下。<ul><li>$ mount ${device_path} ${mount_point} -o ro</li></ul></li></ol><h3 id="Ubuntu-启动盘制作"><a href="#Ubuntu-启动盘制作" class="headerlink" title="Ubuntu 启动盘制作"></a>Ubuntu 启动盘制作</h3><h4 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h4><ul><li>一个4GB或更大的 U 盘</li><li>Microsoft Windows XP或更高版本</li><li>Rufus，一款免费的开源工具</li><li>一个Ubuntu ISO 文件<h4 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h4><img src="http://image.joylau.cn/blog/rufus-ubuntu.png" alt=""></li></ul>]]></content>
      
      
      <categories>
          
          <category> 群晖篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 群晖 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- 蜗牛星际安装黑群晖</title>
      <link href="/2019/05/27/Daily-NAS/"/>
      <url>/2019/05/27/Daily-NAS/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>前一段时间矿难,坑了 20 亿, 5600 多的矿机现在 200 多的甩卖</p><h3 id="蜗牛星际"><a href="#蜗牛星际" class="headerlink" title="蜗牛星际"></a>蜗牛星际</h3><p>蜗牛星际指的是这批矿机的名字, 现一共有四款<br>型号根据网口数据不一样也有不一样的叫法。一个网口称为单，两个网口称为双。<br>分别有：A单，A双；B单，B双；C单，C双；D单。<br>下面是网络上整理的一个表单</p><p><img src="http://image.joylau.cn/blog/heiqun_catg.jpg" alt=""></p><p>我买的是 B 款单网口的 intel i211 的网卡<br>双网卡,还有一个网卡是 82583 需要短接主板上 2 个触电可完美使用双千兆</p><h3 id="安装黑群晖"><a href="#安装黑群晖" class="headerlink" title="安装黑群晖"></a>安装黑群晖</h3><h4 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h4><p>U 盘作为引导启动盘, 系统装入主板上的 16 G SATA 盘</p><h4 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h4><p>将引导系统和系统主程序都装入 sata 盘上</p><p>我选择的是第二种，因为我不想插着个 U 盘在后面的主板上，而且我也没有那么小的U盘</p><h4 id="方式一安装步骤"><a href="#方式一安装步骤" class="headerlink" title="方式一安装步骤"></a>方式一安装步骤</h4><ol start="0"><li>所需资料: 链接: <a href="https://pan.baidu.com/s/1Dk220UoOpDFuTjSV9dUAHw" target="_blank" rel="noopener">https://pan.baidu.com/s/1Dk220UoOpDFuTjSV9dUAHw</a> 提取码: c32z </li><li>插入优盘, 使用芯片精灵查看 U盘的 vid 和 pid ,记录下来</li><li>将引导系统写入 U 盘</li><li>打开 U盘,找到 grub.cfg 文件,修改 pid 和 vid 和 U 盘中的一致即可</li><li>重启</li><li>找到机器的 IP,在浏览器上打开,端口默认是 5000, 在线安装最先的版本即可</li></ol><h4 id="方式二安装步骤"><a href="#方式二安装步骤" class="headerlink" title="方式二安装步骤"></a>方式二安装步骤</h4><ol><li>U 盘上安装一份 PE 系统，这里推荐使用微 PE</li><li>将系统镜像 和 写盘工具 拷贝到 U 盘上：链接: <a href="https://pan.baidu.com/s/1T2KibqcSi6t99BPq8VQA7g" target="_blank" rel="noopener">https://pan.baidu.com/s/1T2KibqcSi6t99BPq8VQA7g</a> 提取码: y7x5 ; 链接: <a href="https://pan.baidu.com/s/1QhAkpGxjYoJiKGgMSdFhyQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1QhAkpGxjYoJiKGgMSdFhyQ</a> 提取码: 1s45 </li><li>进入 PE 系统，使用 diskgenius 删除 ssd 上的所有分区，再使用写盘工具将镜像写入 ssd 上</li><li>重启系统</li></ol><h3 id="如何洗白"><a href="#如何洗白" class="headerlink" title="如何洗白?"></a>如何洗白?</h3><p>想要洗白, 修改 grub.cfg 配置文件的 sn 和 mac 地址即可<br>mac 地址需要是 001132 开头的<br>这就需要修改机器的物理 IP<br>我这里提供一个方法: 链接: <a href="https://pan.baidu.com/s/1km_LpQprkxPvpQOoe8Pq9w" target="_blank" rel="noopener">https://pan.baidu.com/s/1km_LpQprkxPvpQOoe8Pq9w</a> 提取码: qsvd<br>SN 需要算号器,我这里提供个工具: 链接: <a href="https://pan.baidu.com/s/1-k9Wp82occb6IzUxt37EBw" target="_blank" rel="noopener">https://pan.baidu.com/s/1-k9Wp82occb6IzUxt37EBw</a> 提取码: yxj6</p><h3 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h3><ol><li>自带的 ZUMAX 电源并不是很好,带 4 块硬盘怕只能呵呵,想稳定点还是换个好点的电源,我换了台达 80 金牌 DPS-400AB-12A 1U 电源</li><li>有条件的话,硬盘的背板也还是换了吧,看着做工不是很好</li></ol><h3 id="关于洗白"><a href="#关于洗白" class="headerlink" title="关于洗白"></a>关于洗白</h3><p>个人的建议是:不要洗白!</p><ol><li>因为洗白的主要是用群晖的快连功能,但是据我所用快连的速度并不是很好,还不如自建内网穿透服务  </li><li>容易被检测出来,容易被封号,一旦被封号,系统显示硬盘损毁,数据拷贝不出来,就损失大了  </li></ol><p>黑群一时爽,一直黑群一直爽</p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- 软路由攒机记录</title>
      <link href="/2019/05/22/Daily-Soft-Router/"/>
      <url>/2019/05/22/Daily-Soft-Router/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>上篇说到了家里使用多条宽带,而一般的路由器无法使用多个运营商的宽带进行拨号,这就需要软路由了,其实也就是个小主机</p><h3 id="实机"><a href="#实机" class="headerlink" title="实机"></a>实机</h3><p>看下我攒的把</p><p><img src="http://image.joylau.cn/blog/IMG_0314.jpg" alt=""></p><p><img src="http://image.joylau.cn/blog/IMG_0315.jpg" alt=""></p><p><img src="http://image.joylau.cn/blog/IMG_0316.jpg" alt=""></p><h3 id="硬件配置"><a href="#硬件配置" class="headerlink" title="硬件配置"></a>硬件配置</h3><h3 id="主要硬件"><a href="#主要硬件" class="headerlink" title="主要硬件"></a>主要硬件</h3><ul><li>CPU Intel(R) Atom(TM) CPU D525 @ 1.80GHz | 512 KB | 1796 MHz | ×4</li><li>硬盘 ATA DragonDiamond D2 5 (3.75GB)</li><li>内存 2037MB</li><li>主板芯片：Intel Corporation Atom Processor D4xx/D5xx/N4xx/N5xx DMI Bridge (rev 02)</li><li>网卡：Intel Corporation 82583V Gigabit Network Connection (eth0 20:90:30:e8:2f:99)</li><li>网卡：Intel Corporation 82583V Gigabit Network Connection (eth1 20:90:30:e8:2f:9a)</li><li>网卡：Intel Corporation 82583V Gigabit Network Connection (eth2 20:90:30:e8:2f:9b)</li><li>网卡：Intel Corporation 82583V Gigabit Network Connection (eth3 20:90:30:e8:2f:9c)</li></ul><h3 id="其它硬件"><a href="#其它硬件" class="headerlink" title="其它硬件"></a>其它硬件</h3><ul><li>显卡：Intel Corporation Atom Processor D4xx/D5xx/N4xx/N5xx Integrated Graphics Controller (rev 02)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #4 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #5 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB2 EHCI Controller #2 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #1 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #2 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #3 (rev 03)</li><li>USB控制器：Intel Corporation 82801H (ICH8 Family) USB2 EHCI Controller #1 (rev 03)</li><li>PCI桥：Intel Corporation 82801H (ICH8 Family) PCI Express Port 1 (rev 03)</li><li>PCI桥：Intel Corporation 82801H (ICH8 Family) PCI Express Port 2 (rev 03)</li><li>PCI桥：Intel Corporation 82801H (ICH8 Family) PCI Express Port 3 (rev 03)</li><li>PCI桥：Intel Corporation 82801H (ICH8 Family) PCI Express Port 4 (rev 03)</li><li>PCI桥：Intel Corporation 82801H (ICH8 Family) PCI Express Port 5 (rev 03)</li><li>PCI桥：Intel Corporation 82801 Mobile PCI Bridge (rev f3)</li><li>IDE接口：Intel Corporation 82801HM/HEM (ICH8M/ICH8M-E) IDE Controller (rev 03)</li><li>IDE接口：Intel Corporation 82801HM/HEM (ICH8M/ICH8M-E) SATA Controller [IDE mode] (rev 03)</li><li>SMBus：Intel Corporation 82801H (ICH8 Family) SMBus Controller (rev 03)</li></ul><h3 id="我的使用"><a href="#我的使用" class="headerlink" title="我的使用"></a>我的使用</h3><ol><li>四个网口,2 个作为 WAN 口,一个电信宽带,一个长城宽带,一个作为 LAN 口,接台式机,最后一个作为 LAN 口,接路由器的 LAN 口提供 WIFI</li><li>2 个宽带使用负载均衡实现宽带叠加</li><li>端口分流,实现 WIFI 设备走长城宽带的流量,台式机和一些静态的 DHCP 的 IP 走电信流量</li><li>还有一些端口映射和 DMZ 主机和动态域名绑定等普通路由器的功能 (支持 阿里云的 DDNS, 提供 accessKey 和 Access Key Secret 即可)</li></ol><h3 id="花费"><a href="#花费" class="headerlink" title="花费"></a>花费</h3><p>目前这样的配置完全跑个软路由系统绰绰有余了, 我用的是 iKuai, CPU 温度在 22 度左右, CPU 使用率低于 10%, 内存使用率 20% 左右<br>全部花费 234 元</p>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日常折腾 --- 家里网线改造记录</title>
      <link href="/2019/05/22/Daily-Reform-Cable/"/>
      <url>/2019/05/22/Daily-Reform-Cable/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>我新办了个电信宽带,并且搞到了公网 IP, 但是原来的长城宽带没到期我还想继续用,而且办的电信宽带有 iTV, 我还想看电视<br>但是现在从墙里的多媒体集线箱到我卧室的线有 2 根,一根电话线,一根超 5 类网线<br>看我如何改造操作</p><h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><ol><li>一根电话线(4 根铜线)</li><li>一根超 5 类网线</li></ol><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><ol><li>同时使用 电信宽带和原来的长城宽带</li><li>能看 iTV 电视, iTV 的线不与电信宽带共享速率, 也就是电信宽带和 iTV 都直接接到电信的光猫上</li></ol><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><ul><li>百兆网类,网络数据的传输使用的 B 类网线接法的 1,2,3,6 根线</li><li>4,5,7,8 其实并没有参与数据传输,只是保持数据的稳定性以及抗干扰</li></ul><table><thead><tr><th align="center">序号</th><th align="center">1</th><th align="center">2</th><th align="center">3</th><th align="center">4</th><th align="center">5</th><th align="center">6</th><th align="center">7</th><th align="center">8</th></tr></thead><tbody><tr><td align="center">颜色</td><td align="center">白橙</td><td align="center">橙</td><td align="center">白绿</td><td align="center">蓝</td><td align="center">白蓝</td><td align="center">绿</td><td align="center">白棕</td><td align="center">棕</td></tr></tbody></table><p>进行拆分</p><table><thead><tr><th>序号</th><th>1</th><th>2</th><th>3</th><th>6</th></tr></thead><tbody><tr><td>颜色</td><td>白橙</td><td>橙</td><td>白绿</td><td>绿</td></tr></tbody></table><table><thead><tr><th>序号</th><th>4</th><th>5</th><th>7</th><th>8</th></tr></thead><tbody><tr><td>颜色</td><td>蓝</td><td>白蓝</td><td>白棕</td><td>棕</td></tr></tbody></table><h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><ul><li>8 根铜线的超五类网线分拆为 2 个 4 根线的网线</li><li>这 2 根线分别直接连接电信光猫,一根连接光猫的 LAN1 口, 一根连接 LAN2 口</li><li>电话线也按 1,2,3,6 的接法连接长城宽带</li></ul><h3 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h3><ul><li>水晶头</li><li>网线钳</li><li>网线直通连接器</li><li>软路由</li></ul>]]></content>
      
      
      <categories>
          
          <category> 日常折腾篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日常折腾 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 知识点速记</title>
      <link href="/2019/05/17/OpenCV-Knowledge-Points/"/>
      <url>/2019/05/17/OpenCV-Knowledge-Points/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="CV-type-的转换"><a href="#CV-type-的转换" class="headerlink" title="CV type 的转换"></a>CV type 的转换</h4><p>CV_8UC3 转 CV_8UC1 : convertTo 或者 cvtColor<br>CV_8UC1 转 CV_8UC3 : cvtColor (灰度相同,通道已经转化, CV_GRAY2RGB)</p><h4 id="Mat-初始化"><a href="#Mat-初始化" class="headerlink" title="Mat 初始化"></a>Mat 初始化</h4><p>Mat.zeros: 创建全 0 矩阵<br>Mat.ones: 创建全 1 矩阵<br>Mat.eye: 创建单位矩阵</p><h4 id="零碎"><a href="#零碎" class="headerlink" title="零碎"></a>零碎</h4><ol><li>判断点与多边形的关系: pointPolygonTest  </li><li>ROI 区域: Rect(col,row,width,height)<ol><li>col: x 坐标 (坐标以 0 开始, 左上角 0,0)</li><li>row: y 坐标</li><li>width: 宽度</li><li>height: 高度</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 基于 OpenCV 的百度路况研究记录 (四)</title>
      <link href="/2019/05/15/OpenCV-Baidu-Traffic-4/"/>
      <url>/2019/05/15/OpenCV-Baidu-Traffic-4/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本篇主要内容:</p><ol><li>搭建离线地址解析服务</li></ol><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><p>继上篇研究内容之后,重新思考了之前抛出的问题: 如何获取某个省或市的道路信息?</p><p>之前对于该问题的解法有 2 种:</p><ol><li><p>使用总队或者支队提供的道路信息,然后根据分析出来的经纬度和提供的道路信息进行匹配</p></li><li><p>调用互联网接口,进行经纬度转道路地址</p></li></ol><p>分析这 2 中方式之后,其弊端很明显:</p><p>第一种方式:  </p><ol><li><p>无法确定总队或者支队是否能够提供道路信息; </p></li><li><p>提供的数据又是否足够详细全面,要知道在百度地图 17 等级下,解析出来的道路是很详细的 </p></li><li><p>姑且算是提供了,格式又是否能够统一? 能否做到一套代码解决普遍问题?</p></li></ol><p>第二种方式:</p><ol><li><p>需要个人申请 key ,才能调用 API</p></li><li><p>解析 API 每日有次数限制, 5000次/天,对于该城市版分析服务来说,远远不够 </p></li></ol><p>经过一番分析和折腾后,于内网搭建了离线版的地址解析服务,提供 API,将经纬度转化为道路信息, API 返回数据如下:</p><p><img src="http://image.joylau.cn/blog/geocoder-reverse.png" alt=""></p><p>支持返回的数据很详细: 省,市,行政区划,邮编,道路名,附近的建筑物,公交站牌,商场等</p><p>该服务 数据范围覆盖全国,  支持多线程调用,  单次 API 调用耗时为 10 ms - 30 ms 左右,  对机器的磁盘要求高</p><p>最后,我录了个短视频看下实际的使用效果:</p><center><video src="http://image.joylau.cn/blog/geocoder-reverse.mp4" loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 基于 OpenCV 的百度路况研究记录 (三)</title>
      <link href="/2019/05/10/OpenCV-Baidu-Traffic-3/"/>
      <url>/2019/05/10/OpenCV-Baidu-Traffic-3/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本篇研究的内容有:</p><ol><li><p>分析得到的大量拥堵点抽稀处理</p></li><li><p>拥堵区域骨架提取</p></li><li><p>部分优化算法和性能</p></li></ol><h3 id="抽稀处理"><a href="#抽稀处理" class="headerlink" title="抽稀处理"></a>抽稀处理</h3><p>根据之前的处理得到一张瓦片的一块拥堵区域时,需要对其进行结构化数据的分析:将坐标转化为百度坐标系的坐标,坐标转经纬度,拥堵距离计算,</p><p>但是一块区域有很多的拥堵点,如果要对每个点进行操作计算的话,会导致性能问题,而且对于密集的点来说</p><p>意义不大,没有必要这么做,如果说能够给这些点进行稀释处理,仅仅分析稀释后点,那么既能保证数据的正确性,又能提升算法的性能</p><p>算法的基本思想: 连接起点 A 和终点 B, 找出某一点到线段 AB 距离 S 最大的点 P, 如果 S 小于手动设置的阈值 H, 则舍弃其他点,直接连接 A B, 抽稀完成</p><p>如 S &gt; H , 则以 P 为终点, 分别计算 2 端 AP 和 PB 上点到相应线段的最大距离,再重复上述步骤, 直到所有的距离均小于 S , 抽稀完成 </p><p>抽稀结果示例:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.27.04.png" alt="">  </p><p>上图中,已经将上面的拥堵部分大量点稀释的只剩下 3 个点了,这三个点还是位于原来的轨迹上, 可能看的不太清楚,放大了看  </p><p><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.27.19.png" alt=""><br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.27.26.png" alt="">  </p><p>示例 2 :</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-4.15.27.png" alt="">  </p><p>对于抽稀最大直观效果,我通过下面 2 张动图来演示:  </p><p>抽稀前:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.02.49.gif" alt=""></p><p>抽稀后:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.05.08.gif" alt=""></p><h3 id="骨架提取"><a href="#骨架提取" class="headerlink" title="骨架提取"></a>骨架提取</h3><p>骨架提取是指从原来的图中层层剥离点,最后仍然要保持原来的形状</p><p>算法基本思想:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-16-52-57.jpeg" alt=""></p><p>效果示例:</p><p>我以这张拥堵瓦片图来看, 我提取出左上角的拥堵部分来处理</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/17.png" alt=""></p><p>轮廓提取:</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.24.43.png" alt=""></p><p>填充内部:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.24.59.png" alt=""></p><p>上述 2 中图进行加运算, 得到整个拥堵部分,再进行骨架提取:</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.25.07.png" alt=""></p><p>已经得到最小化的骨架了,基本上都是 1 像素值,这对后续的处理很有利,再放大点看:<br><img src="http://image.joylau.cn/blog/baidu-traffic/2019-04-30-2.25.24.png" alt=""></p><p>最后,我录了个视频，以展示目前的演示效果:</p><center><video src="http://image.joylau.cn/blog/baidu-traffic/traffic-demo.mp4" loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 基于 OpenCV 的百度路况研究记录 (二)</title>
      <link href="/2019/05/05/OpenCV-Baidu-Traffic-2/"/>
      <url>/2019/05/05/OpenCV-Baidu-Traffic-2/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本篇就之前对于拥堵路段为曲线状且涉及多个路段时分析的结果差强人意的情况进行了算法重构</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>之前算法核心是 找出分段拥堵,并提取信息<br>之前算法的缺陷是使用霍夫变换提取瓦片中的直线时, 无法很好的控制参数, 导致在临近的曲线情况下分析结果不正确<br>简单示意图:<br><img src="http://image.joylau.cn/blog/baidu-traffic/8.gif" alt="">  </p><p>在二维的坐标系中, 控制直线的是参数 m(斜率) 和 b(截距)</p><p>转化为极坐标系再化简后,控制直线的参数是  θ (极角) 和 r(极径)</p><p>原来的思路是曲线是有很多小部分的直线段构成的,如若能够将曲线分成适合的若干线段,那么同样可以将整个曲线提取出来,继而提取其他信息</p><p>这种思路得考虑三种主要的参数:</p><ol><li><p>threshold：识别某部分为一条直线时必须达到的值</p></li><li><p>min_theta：检测到的直线的最小角度</p></li><li><p>max_theta：检测到的直线的最大角度</p></li></ol><p>然而经过多次测试,按照这个想法进行处理,结果并不好, 出现更多的结果是</p><ol><li><p>曲线 a 会被他的相邻曲线 b 干扰,继续分析的结果是会从 a 与 b 的相邻端直接跳到 b 曲线上,接着分析的线路走向就会直接沿着 b 走下去, 就是上次截图所示的结果</p></li><li><p>曲线 a 会有多处幅度较大的弯曲时,会沿着角度大的地方直接放射出去, 例如下面所测试的</p></li></ol><h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><p>下面测试的参数</p><p>threshold: 65</p><p>min_theta: 0</p><p>max_theta: 5</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/9.gif" alt="">  </p><p>对于形态各异的瓦片图来说,很难调整出一个适当的参数.  </p><p>于是我开始重整思路, 但是思路的核心还是不变: 找出分段拥堵  </p><p>目前的思路是:</p><ol><li><p>读入瓦片原图(RGBA)</p></li><li><p>进行色彩空间转换: 将带透明通道的 RGBA 转换为 BGR, 再将 BRG 转化为 HSV 色彩空间,方便颜色的提取</p></li><li><p>在 HSV 的色彩空间上提取出黄色(缓行)和红色(拥堵), 并各自区分保存</p></li><li><p>得到的图像信息二值化, 方便下一步处理</p></li><li><p>在二值化的图像上提取黄色和红色的边缘信息, 分析边缘信息得到分段拥堵的外包矩形</p></li><li><p>已有的黄,红拥堵段做外包矩形的位置定位,得出分段拥堵信息</p></li><li><p>大量坐标点抽稀处理</p></li></ol><p>开发一系列流程截图如下:</p><p><img src="http://image.joylau.cn/blog/baidu-traffic/10.gif" alt="">  </p><p>图示的顺序依次对应思路的步骤, 在最后一张图中,已经将分析出来的分段拥堵信息再绘制到原图上, 准确度很高  </p><p>对于之前算法没有解决的瓦片,这个算法暂时算是解决了,那么面对更加复杂的拥堵情况呢?  </p><p>为此我特地抽取了北京天安门附近的拥堵瓦片图  </p><p><img src="http://image.joylau.cn/blog/baidu-traffic/11.gif" alt="">  </p><p>这张图里反应的拥堵情况应该很具有代表性了,下面再用此算法对这张图进行分析:  </p><p><img src="http://image.joylau.cn/blog/baidu-traffic/12.gif" alt="">  </p><p>值得一提的是, 前一张图片处理耗时时间是: 0.08534727 s; 而后一张图片处理的时间是: 0.084427357 s, 时间基本无差.</p>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV --- 基于 OpenCV 的百度路况研究记录 (一)</title>
      <link href="/2019/05/01/OpenCV-Baidu-Traffic-1/"/>
      <url>/2019/05/01/OpenCV-Baidu-Traffic-1/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>城市版交通路况的分析基于高速公路路况的基础上以合肥为试点城市进行的研究课题. </p><h3 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h3><p>目前该研究课题已完成:</p><ol><li>筛选出合肥市在百度地图 17 等级下的路况瓦片 62354 张</li><li>对合肥二环路内圈的路况进行分析,目前分析出的路况开发截图</li></ol><p><img src="http://image.joylau.cn/blog/baidu-traffic/1.gif" alt=""></p><p>分析结果: 用蓝色的线表示,画线时未区分颜色,实际分析已区分<br><img src="http://image.joylau.cn/blog/baidu-traffic/2.gif" alt=""></p><p>目前已分析提取出的数据有:</p><ol><li><p>拥堵段 2 端点的经纬度(百度,WGS84坐标系)</p></li><li><p>拥堵段距离,精确到到 0.1 m</p></li><li><p>拥堵段的拥堵状态 (缓行,拥堵,严重拥堵)</p></li><li><p>拥堵段的 WKT 空间信息, 单段 拥堵为 lineString格式, 近距离多段拥堵为 multiLineString 格式, 此信息可直接绘制在地图上</p></li><li><p>提取出瓦片的拥堵信息,再根据我们自己项目中使用的地图的比例尺渲染成适合我们地图的路况图层</p></li></ol><p>目前该研究课题存在的问题:</p><ol><li>有些复杂路口分析不正确,例如:<br><img src="http://image.joylau.cn/blog/baidu-traffic/3.gif" alt="">  </li></ol><p>进行分析后,会变成下面这样:<br><img src="http://image.joylau.cn/blog/baidu-traffic/4.gif" alt="">  </p><p>还有这样的:<br><img src="http://image.joylau.cn/blog/baidu-traffic/5.gif" alt="">  </p><p>结果 :<br><img src="http://image.joylau.cn/blog/baidu-traffic/6.gif" alt="">  </p><p>目前的分析算法对于单张瓦片多处拥堵,且拥堵路段呈直线状分析结果准确,对于拥堵路段为曲线状且涉及多个路段时分析的结果不如人意,这是目前分析算法的原因,尚待改进.  </p><p>性能问题,我目前测试了合肥二环路内圈的路况耗时日志结果如下:<br><img src="http://image.joylau.cn/blog/baidu-traffic/7.gif" alt="">  </p><p>该测试结果是我在笔记本上运行的结果,其中参数配置是:  </p><ol><li><p>CPU : 2.8 GHz Intel Core i7-4 * 2核心, RAM:  16 GB 2133 MHz LPDDR3 , Graphics Card: Radeon Pro 555 2 GB</p></li><li><p>程序运行核心线程数 2 , 最大线程数 5, 运行过程中 CPU 使用率 50% ~ 60%</p></li><li><p>测试时间  4 月 16 日下午 16 点左右</p></li></ol><p>测试结果: 单机运行, 12685 张图片耗时 714 s, 平均处理速度 18 张/秒 左右</p><p>相对于安徽高速,城市版的瓦片分析已经从 Java 的图片处理切换到 OpenCV,有个因素是 OpenCV 绝大数 API 是支持图形卡加速的,我本机的开发环境是开启了图形卡加速,但是一般的服务器是没有图形卡的.</p><p>未知因素: 获取合肥市内路网信息,获取后可进一步分析出以下信息:</p><ol><li><p>获取详细的拥堵文字描述信息</p></li><li><p>按照某一条路进行分组,方便对一条路上多段拥堵进行合并</p></li><li><p>分析出拥堵路段涉及的行政区划</p></li><li><p>分析出该次拥堵的状态(首次拥堵,持续拥堵,结束拥堵),及拥堵持续时间</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 序列化返回对象时忽略空或者 null 属性</title>
      <link href="/2019/04/25/SpringBoot-Response-Ignore-Null/"/>
      <url>/2019/04/25/SpringBoot-Response-Ignore-Null/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><p>在类上加入注解<br><code>@JsonInclude(JsonInclude.Include.NON_EMPTY)</code></p><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p><code>Include.Include.ALWAYS</code>: 默认<br><code>Include.NON_DEFAULT</code>: 属性为默认值不序列化<br><code>Include.NON_EMPTY</code>: 属性为 空（””） 或者为 NULL 都不序列化<br><code>Include.NON_NULL</code>: 属性为NULL 不序列化</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 使用 Ajax FromData 上传文件并传参</title>
      <link href="/2019/04/15/SpringBoot-Ajax-FormData/"/>
      <url>/2019/04/15/SpringBoot-Ajax-FormData/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h3><pre><code class="javascript">    const formData = new FormData();    fileList.forEach(file =&gt; {        formData.append(&#39;file&#39;, file.originFileObj);    });    // 每个表单是否填写完成    let params = [];    .....    let data = {};    data.filePath = &quot;&quot;;    data.markers = params;    formData.append(&quot;params&quot;, data);    $.ajax({        url: &quot;/marker/file&quot;,        type: &quot;POST&quot;,        processData: false,        contentType: false,        data: formData,        success: function (data) {        },        error: function (err) {        }    });</code></pre><h3 id="spring-boot-处理"><a href="#spring-boot-处理" class="headerlink" title="spring boot 处理"></a>spring boot 处理</h3><pre><code class="java">    @PostMapping(&quot;/file&quot;)    public Object markerFile(@RequestParam(&quot;file&quot;) MultipartFile multipartFile, Params params){        return markerService.marker(multipartFile,params);    }</code></pre><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol><li>antd 上传组件里,真正的文件是 file.originFileObj</li><li>params 是复杂的对象的话, spring boot 接受的 Params 对象需要使用 String 字符串进行序列化成对象; 或者将 Params 对象的属性分开来写, 如果某个属性又是复杂对象的话通用需要序列化</li></ol>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 优雅的远程桌面服务端配置</title>
      <link href="/2019/04/10/Ubuntu-Remote-Desktop/"/>
      <url>/2019/04/10/Ubuntu-Remote-Desktop/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>上一篇文章记录了因为远程桌面连接把 Ubuntu 的 <code>/home</code> 弄坏了<br>好一番折腾。。。。<br>其实这个远程桌面我早就想重新配置了，今天我终于受不了它了，于是我觉得仔细研究一番找到适合我自己的方式来操作</p><h2 id="以前的方式"><a href="#以前的方式" class="headerlink" title="以前的方式"></a>以前的方式</h2><p>之前我的远程配置是 <code>xrdp</code> + <code>tightvncserver</code><br>然后我每次都是使用 Windows 上的 <code>mstsc</code> 来连接的<br>连接上后会出现 <code>xrpd</code> 的登录选项<br>每次我都选第一个 <code>sesman-Xvnc</code> 然后输入用户名密码即可</p><p>可这样的连接方式有个很不好的方面，就是这种方式是多用户的，想回家继续没干完的事情<br>连接上发现是一个新的桌面<br>都不知道做到什么地方了</p><p>这也就算了</p><p>最大的问题远程操作操作这就没响应了，鼠标的指针变成了 × 号，所有的东西都不能点，而且第二天到公司桌面卡死不动，只能重启桌面或重启系统，很多打开软件和工具都会还原</p><p>这是我最不能忍的地方</p><h2 id="决定改变"><a href="#决定改变" class="headerlink" title="决定改变"></a>决定改变</h2><p>我决定不使用这种方式来进行远程，远程 <code>teamviewer</code> 是比较合适的选择，但是工作由于连接的终端太多，被检测商用，每次连接都是只有 1 min 的操作时间<br>很尴尬…</p><p>最后决定使用轻量级的 <code>vnc</code> 服务来解决这个问题，并且搭配 <code>xrdp</code> 的 <code>any vnc</code> 来使用 <code>mstsc</code> 远程连接</p><h2 id="重新配置"><a href="#重新配置" class="headerlink" title="重新配置"></a>重新配置</h2><h3 id="x11vnc"><a href="#x11vnc" class="headerlink" title="x11vnc"></a>x11vnc</h3><ol><li>卸载以前的 vnc 服务端</li></ol><pre><code class="bash">    sudo apt remove tigervncserver    sudo apt remove tightvncserver    systemcrl auto remove</code></pre><ol start="2"><li>安装 <code>x11vnc</code> ,并进行配置</li></ol><pre><code class="bash">    sudo apt install x11vnc -y    sudo x11vnc -storepasswd /etc/x11vnc.pass # 配置访问密码并存储    vim  /lib/systemd/system/x11vnc.service # 创建系统服务    # 服务配置    [Unit]    Description=Start x11vnc at startup.    After=multi-user.target    [Service]    Type=simple    ExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /etc/x11vnc.pass -rfbport 5900 -shared    [Install]    WantedBy=multi-user.target    systemctl enable x11vnc.service    systemctl start x11vnc.service</code></pre><ol start="3"><li>解决复制粘贴的问题<ul><li><code>sudo apt install autocutsel</code> 安装 autocutsel</li><li><code>autocutsel -f</code> 后台运行</li></ul></li></ol><h3 id="问题及解决"><a href="#问题及解决" class="headerlink" title="问题及解决"></a>问题及解决</h3><p>下载 vnc-view 新建一个连接发现连不上…<br>尴尬。。。<br>检查 <code>5900</code> 端口，是开放的</p><pre><code class="bash">    joylau@joylau-work-192:~$ sudo netstat -tnlp | grep :5900    tcp        0      0 0.0.0.0:5900            0.0.0.0:*               LISTEN      4022/vino-server    tcp6       0      0 :::5900                 :::*                    LISTEN      4022/vino-server</code></pre><p>但是使用的进程是 <code>vino-server</code> ，这是 Ubuntu 自带程序开启的服务<br>原来端口被占用了<br>关闭服务 ： 找到桌面共享，关闭 <code>允许其他人查看您的桌面</code><br>重启 <code>x11vnc</code> 服务<br>连接成功</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>现在有 4 中方式使用</p><ol><li>使用 <code>vnc-view</code> 使用是单用户的，类似 <code>teamviewer</code> 那样，2 边操作都能互相看见</li><li>使用 <code>mstsc</code> , 连接到 <code>xrdp</code> 后，再选中 <code>any vnc</code> 使用 <code>vnc</code> 协议连接，效果和第一种是一样的，只不过不需要客户端了</li><li>浏览器直接远程，这种最方便，下面有说明</li><li>以前的那种使用方式， 多用户的，估计我是不会再用了</li></ol><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>第三种多用户方式连接，没连接一次就生成一个新的桌面，这个很烦，想连接回上次的桌面，可修改配置 <code>/etc/xrdp/xrdp.ini</code></p><pre><code class="bash">    [globals]    bitmap_cache=yes 位图缓存    bitmap_compression=yes 位图压缩    port=3389 xrdp监听的端口（重要）    crypt_level=low 加密程度（low为40位，high为128位，medium为双40位）    channel_code=1    max_bpp=24 XRDP最大连接数    [xrdp1]    name=sesman-Xvnc XRDP的连接模式    lib=libvnc.so    username=ask    password=ask    ip=127.0.0.1    port=-1</code></pre><p>修改 port 为 固定端口号或者 <code>ask-1</code><br>下次连接不修改即可</p><p>注：再记录下 <code>sesman.ini</code> 的配置</p><pre><code class="bash">    [Globals]    ListenAddress=127.0.0.1 监听ip地址(默认即可)    ListenPort=3350 监听端口(默认即可)    EnableUserWindowManager=1 1为开启,可让用户自定义自己的启动脚本    UserWindowManager=startwm.sh    DefaultWindowManager=startwm.sh    [Security]    AllowRootLogin=1 允许root登陆    MaxLoginRetry=4 最大重试次数    TerminalServerUsers=tSUSErs 允许连接的用户组(如果不存在则默认全部用户允许连接)    TerminalServerAdmins=tsadmins 允许连接的超级用户(如果不存在则默认全部用户允许连接)    [Sessions]    MaxSessions=10 每个用户最大会话数    KillDisconnected=0 是否立即关闭断开的连接(如果为1,则断开连接后会自动注销)    IdleTimeLimit=0 空闲会话时间限制(0为没有限制)    DisconnectedTimeLimit=0 断开连接的存活时间(0为没有限制)    [Logging]    LogFile=./sesman.log 登陆日志文件    LogLevel=DEBUG 登陆日志记录等级(级别分别为,core,error,warn,info,debug)    EnableSyslog=0 是否开启日志    SyslogLevel=DEBUG 系统日志记录等级</code></pre><h2 id="使用浏览器来远程桌面"><a href="#使用浏览器来远程桌面" class="headerlink" title="使用浏览器来远程桌面"></a>使用浏览器来远程桌面</h2><p>像阿里云等云服务提供商一样直接在浏览器上进行远程操作</p><pre><code class="bash">    docker run  -e REMOTE_HOST=192.168.10.192 -e REMOTE_PORT=5900 -p 8081:8081 -d --restart always --name novnc dougw/novnc</code></pre><p>打开浏览器 <a href="http://host:8081/vnc.html" target="_blank" rel="noopener">http://host:8081/vnc.html</a></p><p>秀啊！！！</p>]]></content>
      
      
      <categories>
          
          <category> Ubuntu篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一次 Ubuntu 因磁盘问题导致开机进入紧急模式的情况</title>
      <link href="/2019/04/10/Linux-Fix-DiskError/"/>
      <url>/2019/04/10/Linux-Fix-DiskError/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在家里使用 vnc 协议远程连接公司的 Ubuntu 电脑<br>导致桌面卡死<br>期间还遇到了 搜狗输入法崩溃，提示我删除用户目录下的一个文件然后重启<br>鼠标可以动<br>界面上的任何东西都无法点击<br>没再操作<br>等第二天到公司解决</p><h2 id="不重启解决-Ubuntu-桌面卡死"><a href="#不重启解决-Ubuntu-桌面卡死" class="headerlink" title="不重启解决 Ubuntu 桌面卡死"></a>不重启解决 Ubuntu 桌面卡死</h2><p>这样的情况遇到很多了<br>ctrl + alt + f1</p><pre><code class="bash">    ps -t tty7    PID TTY          TIME CMD    1758 tty7     00:00:55 Xorg    kill -9 1758</code></pre><p>之后桌面上的应用都会被关闭，回到登录界面</p><h2 id="重启进入紧急模式"><a href="#重启进入紧急模式" class="headerlink" title="重启进入紧急模式"></a>重启进入紧急模式</h2><p>之后我想着电脑很久没关机了，想重启一下，顺便去倒杯水<br>回来之后发现系统正在进行磁盘检测并且之后进入了紧急模式</p><p><code>journalctl -xb</code> 查看启动日志</p><p>一直往下翻</p><p>发现 <code>/dev/sdb6</code> 分区出现问题导致系统无法启动</p><p>使用 <code>lsblk</code> 查看分区挂载情况</p><pre><code class="bash">    joylau@joylau-work-192:~$ lsblk -f    NAME   FSTYPE   LABEL    UUID                                 MOUNTPOINT    loop1  squashfs                                               /snap/core/6405    sdb                                                               ├─sdb2                                                            ├─sdb5 ext4              4ff695c6-b2ef-46d9-8501-c7e8ee61edda /    ├─sdb1 ext4              98f0eb66-3d90-4bc5-a1f0-d3117de87809 /boot    └─sdb6 ext4              76ad5dc1-37b7-4624-830b-d923dac8ac48     loop4  squashfs                                               /snap/redis-desktop-manager/191    loop2  squashfs                                               /snap/core/6673    loop0  squashfs                                               /snap/redis-desktop-manager/156    sdc                                                               ├─sdc2 ntfs     新加卷   AE5CA91F5CA8E2F7                     /media/extra    └─sdc1 ntfs     新加卷   0CBC9840BC9825EC                         sda                                                               ├─sda2 ntfs              5E68EE4D68EE240D                         ├─sda7 ntfs              EAD67107D670D573                         ├─sda5 ntfs              9E14908214905ED9                         ├─sda3                                                            ├─sda1 ntfs     系统保留 A27AE98B7AE95C93                         └─sda6 ntfs              E2D84A6BD84A3E53                     /media/extra_2    loop3  squashfs             </code></pre><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>上面看到 sdb6 没有挂载点，实际上是有的，只不过现在出问题了没有挂载上<br>可以找 UUID <strong>76ad5dc1-37b7-4624-830b-d923dac8ac48</strong></p><p>查看 <code>/etc/fstab</code></p><pre><code class="bash">    # /etc/fstab: static file system information.    #    # Use &#39;blkid&#39; to print the universally unique identifier for a    # device; this may be used with UUID= as a more robust way to name devices    # that works even if disks are added and removed. See fstab(5).    #    # &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;    # / was on /dev/sdb5 during installation    UUID=4ff695c6-b2ef-46d9-8501-c7e8ee61edda /               ext4    errors=remount-ro 0       1    # /boot was on /dev/sdb1 during installation    UUID=98f0eb66-3d90-4bc5-a1f0-d3117de87809 /boot           ext4    defaults        0       2    # /home was on /dev/sdb6 during installation    UUID=76ad5dc1-37b7-4624-830b-d923dac8ac48 /home           ext4    defaults        0       2    # swap was on /dev/sdc5 during installation    #UUID=a99b0d98-9282-4e52-8f49-74b9b1f2ed8e none            swap    sw              0       0    UUID=AE5CA91F5CA8E2F7                     /media/extra    ntfs   defaults         0       0    UUID=E2D84A6BD84A3E53                     /media/extra_2    ntfs   defaults         0       0</code></pre><p>查看到 <strong>76ad5dc1-37b7-4624-830b-d923dac8ac48</strong> 对应挂载的 <code>/home</code> 目录</p><p>后面的 pass 写的是 2 ，就是说开机进行磁盘检查，并且数值越小，越先检查</p><p>这里有个临时的解决方式就是将 <code>/home</code> 的 pass 改为 0 ，也就是开机不进行检查，该分区有问题并不代表分区不可用</p><p>改完后依然可以访问 <code>/home</code> 目录</p><h2 id="磁盘修复"><a href="#磁盘修复" class="headerlink" title="磁盘修复"></a>磁盘修复</h2><p>强迫症让我不能就这么将就<br>我觉得修复这个磁盘错误<br>使用命令修复这个错误如下</p><pre><code class="bash">    fsck -y /dev/sdb6</code></pre><p>结果提示 分区已挂载，操作被终止</p><p>修改 fstab 将 sdb6 挂载的那行注释<br>重启<br>进入紧急模式<br>运行 <code>fsck -y /dev/sdb6</code><br>这时会打印很多日志<br>重复执行，直到没有日志打印</p><p>这时在修改 fstab, 去掉注释，pass 改为 2<br>重启<br>解决 </p>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 启动报错： Error starting daemon： Error initializing network controller： list bridge addresses failed： no available network</title>
      <link href="/2019/04/08/Docker-Start-Error/"/>
      <url>/2019/04/08/Docker-Start-Error/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Docker 启动报错： Error starting daemon: Error initializing network controller: list bridge addresses failed: no available network</p><h2 id="错误详情"><a href="#错误详情" class="headerlink" title="错误详情"></a>错误详情</h2><p>查看错误日志： <code>journalctl -xe | grep docker</code></p><pre><code class="bash">    [root@lenovo docker]# journalctl -xe | grep docker    -- Subject: Unit docker.socket has begun start-up    -- Unit docker.socket has begun starting up.    -- Subject: Unit docker.socket has finished start-up    -- Unit docker.socket has finished starting up.    -- Subject: Unit docker.service has begun start-up    -- Unit docker.service has begun starting up.    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.909025064+08:00&quot; level=info msg=&quot;parsed scheme: \&quot;unix\&quot;&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.909923898+08:00&quot; level=info msg=&quot;scheme \&quot;unix\&quot; not registered, fallback to default scheme&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.910865280+08:00&quot; level=info msg=&quot;parsed scheme: \&quot;unix\&quot;&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.910909267+08:00&quot; level=info msg=&quot;scheme \&quot;unix\&quot; not registered, fallback to default scheme&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.928785984+08:00&quot; level=info msg=&quot;ccResolverWrapper: sending new addresses to cc: [{unix:///run/containerd/containerd.sock 0  &lt;nil&gt;}]&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.928902169+08:00&quot; level=info msg=&quot;ClientConn switching balancer to \&quot;pick_first\&quot;&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.929039549+08:00&quot; level=info msg=&quot;pickfirstBalancer: HandleSubConnStateChange: 0xc420606e00, CONNECTING&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.937533340+08:00&quot; level=info msg=&quot;ccResolverWrapper: sending new addresses to cc: [{unix:///run/containerd/containerd.sock 0  &lt;nil&gt;}]&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.937601232+08:00&quot; level=info msg=&quot;ClientConn switching balancer to \&quot;pick_first\&quot;&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.937707487+08:00&quot; level=info msg=&quot;pickfirstBalancer: HandleSubConnStateChange: 0xc42015bf00, CONNECTING&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.950807950+08:00&quot; level=info msg=&quot;pickfirstBalancer: HandleSubConnStateChange: 0xc42015bf00, READY&quot; module=grpc    4月 08 16:42:09 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:09.952160247+08:00&quot; level=info msg=&quot;pickfirstBalancer: HandleSubConnStateChange: 0xc420606e00, READY&quot; module=grpc    4月 08 16:42:10 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:10.216864045+08:00&quot; level=info msg=&quot;Graph migration to content-addressability took 0.00 seconds&quot;    4月 08 16:42:10 lenovo dockerd[1742]: time=&quot;2019-04-08T16:42:10.218710988+08:00&quot; level=info msg=&quot;Loading containers: start.&quot;    4月 08 16:42:10 lenovo dockerd[1742]: Error starting daemon: Error initializing network controller: list bridge addresses failed: no available network    4月 08 16:42:10 lenovo systemd[1]: docker.service: main process exited, code=exited, status=1/FAILURE    -- Subject: Unit docker.service has failed    -- Unit docker.service has failed.    4月 08 16:42:10 lenovo systemd[1]: Unit docker.service entered failed state.    4月 08 16:42:10 lenovo systemd[1]: docker.service failed.    4月 08 16:42:13 lenovo systemd[1]: docker.service holdoff time over, scheduling restart.    -- Subject: Unit docker.socket has begun shutting down    -- Unit docker.socket has begun shutting down.    -- Subject: Unit docker.socket has begun start-up    -- Unit docker.socket has begun starting up.    -- Subject: Unit docker.socket has finished start-up    -- Unit docker.socket has finished starting up.    -- Subject: Unit docker.service has begun start-up    -- Unit docker.service has begun starting up.</code></pre><p>看到这样一句话： <strong>Error starting daemon: Error initializing network controller: list bridge addresses failed: no available network</strong></p><p>查看本机网络： <code>ip a</code></p><pre><code class="bash">    [root@lenovo docker]# ip a    1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00        inet 127.0.0.1/8 scope host lo           valid_lft forever preferred_lft forever        inet6 ::1/128 scope host            valid_lft forever preferred_lft forever    2: enp7s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000        link/ether b8:70:f4:24:61:a7 brd ff:ff:ff:ff:ff:ff    3: wlp8s0b1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000        link/ether cc:af:78:25:31:51 brd ff:ff:ff:ff:ff:ff        inet 192.168.10.145/24 brd 192.168.10.255 scope global noprefixroute wlp8s0b1           valid_lft forever preferred_lft forever        inet6 fe80::8de1:5b7d:b7d7:2788/64 scope link noprefixroute            valid_lft forever preferred_lft forever    4: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100        link/none         inet 192.168.255.10 peer 192.168.255.9/32 scope global tun0           valid_lft forever preferred_lft forever        inet6 fe80::e41d:195:f566:33e1/64 scope link flags 800            valid_lft forever preferred_lft forever</code></pre><p>没有 docker0 的桥接网络</p><p>手动添加一个即可</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><pre><code class="bash">    ip link add name docker0 type bridge    ip addr add dev docker0 172.17.0.1/16</code></pre><p>再看一下，多了一个 docker0</p><pre><code class="bash">    5: docker0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000        link/ether a6:7d:d7:94:ab:f3 brd ff:ff:ff:ff:ff:ff        inet 172.17.0.1/16 scope global docker0           valid_lft forever preferred_lft forever</code></pre><p>重启 docker 即可</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV 读取数据流图片</title>
      <link href="/2019/04/03/OpenCV-ByteImage/"/>
      <url>/2019/04/03/OpenCV-ByteImage/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>OpenCV 提供的 API 是直接根据路径读取图片的, 在实际生产环境中,可能大部分情况下都是直接读取网络图片</p><p>在内存就完成图片和 opencv 的 Mat 对象的转换</p><p>那么该如何读取 byte[] 的图片呢?</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>openCV 提供的 API</p><pre><code class="java">    Mat src = Imgcodecs.imread(&quot;/static/img/17.png&quot;);</code></pre><p>很简单的就转化为 Mat 对象</p><p>而 该方法后面还有一个参数, flags, 该参数可选项有:</p><ul><li><strong>IMREAD_UNCHANGED</strong> = -1,</li><li><strong>IMREAD_GRAYSCALE</strong> = 0,</li><li><strong>IMREAD_COLOR</strong> = 1,</li><li><strong>IMREAD_ANYDEPTH</strong> = 2,</li><li><strong>IMREAD_ANYCOLOR</strong> = 4,</li><li><strong>IMREAD_LOAD_GDAL</strong> = 8,</li><li><strong>IMREAD_REDUCED_GRAYSCALE_2</strong> = 16,</li><li><strong>IMREAD_REDUCED_COLOR_2</strong> = 17,</li><li><strong>IMREAD_REDUCED_GRAYSCALE_4</strong> = 32,</li><li><strong>IMREAD_REDUCED_COLOR_4</strong> = 33,</li><li><strong>IMREAD_REDUCED_GRAYSCALE_8</strong> = 64,</li><li><strong>IMREAD_REDUCED_COLOR_8</strong> = 65,</li><li><strong>IMREAD_IGNORE_ORIENTATION</strong> = 128;</li></ul><p>IMREAD_UNCHANGED: 以图片原有的方式读入,不进行任何改变<br>IMREAD_GRAYSCALE: 以灰度图读取<br>IMREAD_COLOR: 以彩色图读取</p><h3 id="过渡"><a href="#过渡" class="headerlink" title="过渡"></a>过渡</h3><p>为了支持 OpenCV 读取 byte[] 的图片,为此我查找了很多资料做了大量的实验,有很多失败报错了,也有读取成功的,下面我将一一列举出来….</p><h3 id="读取失败"><a href="#读取失败" class="headerlink" title="读取失败"></a>读取失败</h3><h4 id="Converters-类"><a href="#Converters-类" class="headerlink" title="Converters 类"></a>Converters 类</h4><p>我留意到 opencv 提供的 api 里有一个 <code>utils</code> 包, 里面有个转换类 <code>Converters</code>, 可以将 Mat 和 一些 java 的基本数据类型进行互相转换,其中有这样 2 个方法: <code>vector_uchar_to_Mat</code> 和 <code>vector_char_to_Mat</code><br>参数是 <code>List&lt;Byte&gt;</code></p><pre><code class="java">    private static Mat testConvertChar2Mat(byte[] bytes){        @SuppressWarnings(&quot;unchecked&quot;)        List&lt;Byte&gt; bs = CollectionUtils.arrayToList(bytes);        return Converters.vector_uchar_to_Mat(bs);//        return Converters.vector_char_to_Mat(bs);    }</code></pre><p><code>vector_uchar_to_Mat</code>  指有符号</p><p>转换出来的图片是一个像素的竖直线,读取失败</p><h4 id="new-Mat"><a href="#new-Mat" class="headerlink" title="new Mat"></a>new Mat</h4><p>Mat 对象除了转化得到,还可以 new , 再利用 Mat 的 put 方法,来创建 Mat</p><pre><code class="java">    private static Mat testNewMat(int height, int width, byte[] bytes) throws IOException {        Mat data = new Mat(height, width, CvType.CV_8UC3);        data.put(0, 0, bytes);        return data;    }</code></pre><p>转换出来的图片也不对,一些花花绿绿的像素点</p><h4 id="new-BufferByte"><a href="#new-BufferByte" class="headerlink" title="new BufferByte"></a>new BufferByte</h4><p>Mat 对象还有个构造方法,最后一个参数是传入 BufferByte,这时只需要在上述步骤中再将 byte[] 转化为 BufferByte</p><pre><code class="java">    private static Mat testNewBuffer(int height, int width, byte[] bytes){        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);        return new Mat(height, width, CvType.CV_8UC3,byteBuffer);    }</code></pre><p>抛出异常: <strong>CvException [org.opencv.core.CvException: cv::Exception: OpenCV(4.1.0-pre) /Users/joylau/opencv4/opencv/modules/core/include/opencv2/core/mat.inl.hpp:548: error: (-215:Assertion failed) total() == 0 || data != NULL in function ‘Mat’</strong></p><h3 id="读取成功"><a href="#读取成功" class="headerlink" title="读取成功"></a>读取成功</h3><h4 id="BufferedImage-转换"><a href="#BufferedImage-转换" class="headerlink" title="BufferedImage 转换"></a>BufferedImage 转换</h4><p>一次我在调试代码时 发现<code>HighGui.waitKey();</code> 的实现是将 Mat 对象转化为 BufferedImage 的逻辑,于是我明白了,OpenCV 里操作的 Mat 在显示的时候也需要转化为 BufferedImage<br>源码里有这样一段代码</p><pre><code class="java">    public static Image toBufferedImage(Mat m) {        int type = BufferedImage.TYPE_BYTE_GRAY;        if (m.channels() &gt; 1) {            type = BufferedImage.TYPE_3BYTE_BGR;        }        int bufferSize = m.channels() * m.cols() * m.rows();        byte[] b = new byte[bufferSize];        m.get(0, 0, b); // get all the pixels        BufferedImage image = new BufferedImage(m.cols(), m.rows(), type);        final byte[] targetPixels = ((DataBufferByte) image.getRaster().getDataBuffer()).getData();        System.arraycopy(b, 0, targetPixels, 0, b.length);        return image;    }</code></pre><p>此时,我逆向转化,将 byte[] 转 BufferedImage ,BufferedImage 再转 Mat 即可</p><pre><code class="java">    private static byte[] getBufferedImageByte(byte[] bytes) throws IOException{        BufferedImage bImage = ImageIO.read(new ByteArrayInputStream(bytes));        return ((DataBufferByte) bImage.getRaster().getDataBuffer()).getData();    }    // 再将从 BufferedImage 得到的 byte[] 使用 new Mat 对象    private static Mat testNewMat(int height, int width, byte[] bytes) throws IOException {        Mat data = new Mat(height, width, CvType.CV_8UC3);        data.put(0, 0, bytes);        return data;    }</code></pre><p>该方法成功读取显示了图片</p><p>于是又引发了我的思考: 为什么直接从文件读取的 byte[] 无法被转化,而 BufferedImage 中得到的 byte[] 却可以被转化</p><p>于是我将 BufferedImage 中得到的 byte[] 在使用,调用 <code>Converters.vector_char_to_Mat</code> 方法</p><p>可惜却失败了…..</p><h4 id="imdecode"><a href="#imdecode" class="headerlink" title="imdecode"></a>imdecode</h4><p>Imgcodecs 类中有一个编码的方法 <code>Imgcodecs.imdecode(Mat buf, int flags)</code><br>Mat 还有个子类 MatOfByte</p><pre><code class="java">    private static Mat testImdecode(byte[] bytes){        return Imgcodecs.imdecode(new MatOfByte(bytes), Imgcodecs.IMREAD_COLOR);    }</code></pre><p>该方法可成功转化</p><p>而且比上一个方法的优势是:</p><ol><li>byte[] 不需要再通过 BufferedImage 转化</li><li>不需要初始化 Mat 的长和宽</li></ol><p>为此还可以逆向得出 Mat 转换成 byte[] 的方法</p><pre><code class="java">    /**     * Mat转换成byte数组     *     * @param matrix        要转换的Mat     * @param fileExtension 格式为 &quot;.jpg&quot;, &quot;.png&quot;, etc     */    public static byte[] mat2Byte(Mat matrix, String fileExtension) {        MatOfByte mob = new MatOfByte();        Imgcodecs.imencode(fileExtension, matrix, mob);        return mob.toArray();    }</code></pre><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>以下是全部测试代码</p><pre><code class="java">    /**     * Created by liuf on 2019-04-01.     * cn.joylau.code     * liuf@ahtsoft.com     */    @Slf4j    public class Byte2Mat {        public static void main(String[] args) throws Exception {            System.loadLibrary(Core.NATIVE_LIBRARY_NAME);    //        Mat mat = testImdecode(getImageByte());    //        Mat mat = testConvertChar2Mat(getBufferedImageByte(getImageByte()));    //        Mat mat = testNewBuffer(480,480,getImageByte());    //        Mat mat = testNewMat(480,480,getImageByte());            Mat mat = testNewMat(480,480,getBufferedImageByte(getImageByte()));            log.info(&quot;{},{}&quot;,mat.rows(),mat.cols());            HighGui.imshow(&quot;byte2mat&quot;,mat);            HighGui.waitKey();            HighGui.destroyAllWindows();        }        private static byte[] getImageByte() throws IOException{            Resource resource = new FileSystemResource(&quot;/Users/joylau/work/anhui-project/traffic-service-layer/src/main/resources/static/img/1.jpg&quot;);            return IOUtils.toByteArray(resource.getInputStream());        }        private static byte[] getBufferedImageByte(byte[] bytes) throws IOException{            BufferedImage bImage = ImageIO.read(new ByteArrayInputStream(bytes));            return ((DataBufferByte) bImage.getRaster().getDataBuffer()).getData();        }        private static Mat testNewMat(int height, int width, byte[] bytes) throws IOException {            Mat data = new Mat(height, width, CvType.CV_8UC3);            data.put(0, 0, bytes);            return data;        }        private static Mat testNewBuffer(int height, int width, byte[] bytes){            ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);            return new Mat(height, width, CvType.CV_8UC3,byteBuffer);        }        private static Mat testConvertChar2Mat(byte[] bytes){            @SuppressWarnings(&quot;unchecked&quot;)            List&lt;Byte&gt; bs = CollectionUtils.arrayToList(bytes);            return Converters.vector_uchar_to_Mat(bs);    //        return Converters.vector_char_to_Mat(bs);        }        private static Mat testImdecode(byte[] bytes){            return Imgcodecs.imdecode(new MatOfByte(bytes), Imgcodecs.IMREAD_COLOR);        }        /**         * Mat转换成byte数组         *         * @param matrix        要转换的Mat         * @param fileExtension 格式为 &quot;.jpg&quot;, &quot;.png&quot;, etc         */        public static byte[] mat2Byte(Mat matrix, String fileExtension) {            MatOfByte mob = new MatOfByte();            Imgcodecs.imencode(fileExtension, matrix, mob);            return mob.toArray();        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenCV 基础知识与概念</title>
      <link href="/2019/03/28/OpenCV-Basic/"/>
      <url>/2019/03/28/OpenCV-Basic/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h2><h3 id="数字图像"><a href="#数字图像" class="headerlink" title="数字图像"></a>数字图像</h3><p>数字图像指的是现在的图像都是以二维数字表示，每个像素的灰度值均由一个数字表示，范围为0-255(2^8)</p><h3 id="二值图像"><a href="#二值图像" class="headerlink" title="二值图像"></a>二值图像</h3><p>图像中每个像素的灰度值仅可取0或1，即不是取黑，就是取白，二值图像可理解为黑白图像</p><h3 id="灰度图像"><a href="#灰度图像" class="headerlink" title="灰度图像"></a>灰度图像</h3><p>图像中每个像素可以由0-255的灰度值表示，具体表现为从全黑到全白中间有255个介于中间的灰色值可以取</p><h3 id="彩色图像"><a href="#彩色图像" class="headerlink" title="彩色图像"></a>彩色图像</h3><p>每幅图像是由三幅灰度图像组合而成，依次表示红绿蓝三通道的灰度值，即我们熟知的RGB，此时彩色图像要视为三维的 <code>[height，width, 3]</code></p><h2 id="CvType"><a href="#CvType" class="headerlink" title="CvType"></a>CvType</h2><h3 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h3><p>OpenCV 中，图像可以分别为1，2，3，4 通道</p><ul><li>通道为灰度图；</li><li>通道的图像是RGB555和RGB565。2通道图在程序处理中会用到，如傅里叶变换，可能会用到，一个通道为实数，一个通道为虚数，主要是编程方便。RGB555是16位的，2个字节，5+6+5，第一字节的前5位是R，后三位+第二字节是G，第二字节后5位是B，可见对原图像进行压缩了</li><li>通道为彩色图（RGB）；</li><li>通道为 RGBA ，是RGB加上一个A通道，也叫alpha通道，表示透明度，PNG图像是一种典型的4通道图像。alpha通道可以赋值0到1，或者0到255，表示透明到不透明</li></ul><p>常使用的是1，3，4通道； 2通道不常见</p><h3 id="组合规则"><a href="#组合规则" class="headerlink" title="组合规则"></a>组合规则</h3><p><code>CV_[bite](U|S|F)C[channels]</code></p><p>bite : 比特数，位数。 有 8bite，16bite，32bite，64bite,对应在 Mat 中，每个像素的所占的空间大小，8位即 CV_8</p><p>U|S|F ：<br>    - U : unsigned int , 无符号整形<br>    - S : signed int , 有符号整形<br>    - F : float , 单精度浮点型,float类型本身即有符号</p><p>这里的有符号、无符号是针对图像二进制编码来讲的。我在写的过程中大多数情况下都是使用的无符号，即 CV_8U ,CV_16U，当有计算时可能会介入有符号（存在负数），没学过 C++，对底层也一知半解，望高手解答。</p><p>C (channels)：图像的通道数</p><p>比如: <code>CV_8UC3</code> 即 8位无符号的3通道（RGB 彩色）图像</p><h3 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h3><p>8U<br>    - 说明：无符号的8位图<br>    - 值：CV_8UC1,CV_8UC2,CV_8UC3,CV_8UC4<br>    - 通道取值范围：0~255</p><p>8S<br>    - 说明：有符号的8位图<br>    - 值：CV_8SC1,CV_8SC2,CV_8SC3,CV_8SC4<br>    - 通道取值范围：-128~127</p><p>16U<br>    - 说明：无符号的16位图<br>    - 值：CV_16UC1,CV_16UC2,CV_16UC3,CV_16UC4<br>    - 通道取值范围：0~65535</p><p>16S<br>    - 说明：有符号的16位图<br>    - 值：CV_16SC1,CV_16SC2,CV_16SC3,CV_16SC4<br>    - 通道取值范围：-32768~32767</p><p>32S<br>    - 说明：无符号的32位图<br>    - 值：CV_32SC1,CV_32SC2,CV_32SC3,CV_32SC4<br>    - 通道取值范围：2147483648~2147483647</p><p>32F<br>    - 说明：浮点型32位图<br>    - 值：CV_32FC1,CV_32FC2,CV_32FC3,CV_32FC4<br>    - 通道取值范围：1.18<em>(10(-38次方))~3.40</em>(10(38次方))</p><p>64F<br>    - 说明：浮点型64位图<br>    -值：CV_64FC1,CV_64FC2,CV_64FC3,CV_64FC4<br>    - 通道取值范围：2.23<em>(10(-308次方))~1.79</em>(10(308次方))</p><p>1U<br>    - 说明：1位<br>    - 值：IPL_DEPTH_1U<br>    - 通道取值范围：0~1</p><h2 id="色彩空间"><a href="#色彩空间" class="headerlink" title="色彩空间"></a>色彩空间</h2><h3 id="常见的色彩空间"><a href="#常见的色彩空间" class="headerlink" title="常见的色彩空间"></a>常见的色彩空间</h3><ul><li>RGB</li><li>HSV</li><li>HIS</li><li>YCRCB</li><li>YUV</li></ul><h3 id="HSV"><a href="#HSV" class="headerlink" title="HSV"></a>HSV</h3><p>HSV分别是色调（Hue），饱和度（Saturation）和亮度（Value）</p><p>H调整颜色；S越大，图像色彩越丰富，颜色越鲜艳；V越大，图像越亮</p><h4 id="HSV颜色取值范围"><a href="#HSV颜色取值范围" class="headerlink" title="HSV颜色取值范围"></a>HSV颜色取值范围</h4><ol><li><p>H:0— 180 : 之所以不是 360,是因为 8 位图 最大是 255,360 已经超出范围,以 180 为限定</p></li><li><p>S: 0— 255</p></li><li><p>V: 0— 255</p></li></ol><p>记住下面这张图, 可使用这张图中的范围来查找某种颜色</p><p><img src="http://image.joylau.cn/blog/OpenCV-HSV.png" alt="HSV"></p><h4 id="转换方法"><a href="#转换方法" class="headerlink" title="转换方法"></a>转换方法</h4><p><code>Imgproc.cvtColor(src,det,Imgproc.COLOR_BGR2HSV);</code></p>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 容器挂载宿主机上的目录时出现 Permission denied</title>
      <link href="/2019/03/21/Docker-MountVolumes/"/>
      <url>/2019/03/21/Docker-MountVolumes/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>启动 docker 容器时挂载容器以前存在的数据文件时出现了 Permission denied 的错误</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ol><li>首先以为是挂载的文件夹有读写数据的权限问题 <code>chmod -R 777 xxxx</code> , 没有解决，依然报错</li><li>再分析是文件目录的所属者的问题： <code>chown -R gname:uname xxxx</code> , 没有解决，依然报错</li><li>这时我们进入容器之后 使用 ll 查看挂载的目录的所属者，发现组名和户名跟宿主机的组名和用户名不一致</li><li>原因在于，操作系统判断用户组和用户其实并不是根据名称来的，而是根据名称对应的 id 来的</li><li>查看用户组和用户名对象的 id, 可查看 <code>/etc/passwd</code></li><li>此时，我们需要将宿主机的用户组用户的 ID 和 容器内挂在目录所需的用户组和用户的 ID 对应起来，写一直即可</li><li>举个例子</li><li>redis 镜像产生的数据文件在 <code>/var/lib/redis</code> 中，并且该目录的用户组和用户都为 <code>redis</code>， 此时我们查看容器的 <code>redis:redis</code> 的 id , 假如是 <code>102:103</code></li><li>此时我们宿主机挂载目录是 <code>/opt/docker/redis/data</code> ,我们改变这个目录的所属者 <code>chown -R 102:103 /opt/docker/redis/data</code></li><li>不要管 <code>102:103</code> 在宿主机系统中有没有该用户组和用户</li><li>再次进入容器就可以看到 <code>/var/lib/redis</code> 目录的所属者是正确的了</li></ol><h3 id="mysql-和-mariaDB-的问题"><a href="#mysql-和-mariaDB-的问题" class="headerlink" title="mysql 和 mariaDB 的问题"></a>mysql 和 mariaDB 的问题</h3><p>这样的情况也发生在 mysql 和 mariaDB 上<br>按照上述的方法似乎没有奏效，确切的说奏效一半<br>因为 <code>/var/lib/mysql</code> 目录中文件夹可以看到，文件却没有权限看到<br>类似这样</p><pre><code class="shell">    190321 06:02:13 mysqld_safe Logging to &#39;/var/lib/mysql/d240623581db.err&#39;.    190321 06:02:13 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql    chown: /var/lib/mysql/60689c28e4a1.err: Permission denied    chown: /var/lib/mysql/60689c28e4a1.pid: Permission denied    chown: /var/lib/mysql/aria_log.00000001: Permission denied    chown: /var/lib/mysql/aria_log_control: Permission denied    chown: /var/lib/mysql/ib_buffer_pool: Permission denied    chown: /var/lib/mysql/ibdata1: Permission denied    chown: /var/lib/mysql/ib_logfile0: Permission denied    chown: /var/lib/mysql/ib_logfile1: Permission denied    chown: /var/lib/mysql/ibtmp1: Permission denied    chown: /var/lib/mysql/multi-master.info: Permission denied    chown: /var/lib/mysql/mysql: Permission denied    chown: /var/lib/mysql/mysql-bin.000001: Permission denied    chown: /var/lib/mysql/mysql-bin.000002: Permission denied    chown: /var/lib/mysql/mysql-bin.000003: Permission denied    chown: /var/lib/mysql/mysql-bin.000004: Permission denied    chown: /var/lib/mysql/mysql-bin.000005: Permission denied    chown: /var/lib/mysql/mysql-bin.000006: Permission denied    chown: /var/lib/mysql/mysql-bin.000007: Permission denied    chown: /var/lib/mysql/mysql-bin.000008: Permission denied    chown: /var/lib/mysql/mysql-bin.000009: Permission denied    chown: /var/lib/mysql/mysql-bin.index: Permission denied    chown: /var/lib/mysql/owncloud: Permission denied    chown: /var/lib/mysql/performance_schema: Permission denied    chown: /var/lib/mysql: Permission denied    chown: /var/lib/mysql: Permission denied    190321 06:02:14 mysqld_safe Logging to &#39;/var/lib/mysql/d240623581db.err&#39;.    190321 06:02:14 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql    chown: /var/lib/mysql/60689c28e4a1.err: Permission denied    chown: /var/lib/mysql/60689c28e4a1.pid: Permission denied    chown: /var/lib/mysql/aria_log.00000001: Permission denied    chown: /var/lib/mysql/aria_log_control: Permission denied    chown: /var/lib/mysql/ib_buffer_pool: Permission denied    chown: /var/lib/mysql/ibdata1: Permission denied    chown: /var/lib/mysql/ib_logfile0: Permission denied    chown: /var/lib/mysql/ib_logfile1: Permission denied    chown: /var/lib/mysql/ibtmp1: Permission denied    chown: /var/lib/mysql/multi-master.info: Permission denied    chown: /var/lib/mysql/mysql: Permission denied    chown: /var/lib/mysql/mysql-bin.000001: Permission denied    chown: /var/lib/mysql/mysql-bin.000002: Permission denied    chown: /var/lib/mysql/mysql-bin.000003: Permission denied    chown: /var/lib/mysql/mysql-bin.000004: Permission denied    chown: /var/lib/mysql/mysql-bin.000005: Permission denied    chown: /var/lib/mysql/mysql-bin.000006: Permission denied    chown: /var/lib/mysql/mysql-bin.000007: Permission denied    chown: /var/lib/mysql/mysql-bin.000008: Permission denied    chown: /var/lib/mysql/mysql-bin.000009: Permission denied    chown: /var/lib/mysql/mysql-bin.index: Permission denied    chown: /var/lib/mysql/owncloud: Permission denied    chown: /var/lib/mysql/performance_schema: Permission denied    chown: /var/lib/mysql: Permission denied    chown: /var/lib/mysql: Permission denied</code></pre><p>原因分析是：<br>SELinux 造成的<br>有以下 4 中解决方法：</p><ol><li><code>setenforce 0</code> : 临时关闭 </li><li><code>vi /etc/selinux/config</code> ： 将 <code>SELINUX=enforcing</code> 改为 <code>SELINUX=disabled</code> ，重启</li><li>在docker run 中加入 <code>--privileged=true</code> 给容器加上特定权限</li><li>修改 SELinux 规则 <code>chcon -t mysqld_db_t  -R /opt/docker/mysql/data</code></li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IntelliJ IDEA (WebStorm) 识别 @ 作为别名进行导包</title>
      <link href="/2019/03/20/IntelliJIDEA-Support-@-Alias/"/>
      <url>/2019/03/20/IntelliJIDEA-Support-@-Alias/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="配置前"><a href="#配置前" class="headerlink" title="配置前"></a>配置前</h3><p><img src="http://image.joylau.cn/blog/idea-support-alas-1.png" alt="配置前"></p><p>@ 导包的类无法点击跳转,也不识别</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>在项目根目录添加配置文件 webpack.config.js</p><pre><code class="js">    /**     * 不是真实的 webpack 配置，仅为兼容 webstorm 和 intellij idea 代码跳转     */    module.exports = {      resolve: {        alias: {          &#39;@&#39;: require(&#39;path&#39;).resolve(__dirname, &#39;src&#39;), // eslint-disable-line        },      },    };</code></pre><p>然后,在 idea 的 preference -&gt; language &amp; frameworks -&gt; javascript -&gt; webpack 路径到更目录下的webpack.config.js</p><p>完成</p>]]></content>
      
      
      <categories>
          
          <category> IntelliJ IDEA篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IntelliJ IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS , Ubuntu 和 Mac OS 上编译安装 OpenCV4 及 SpringBoot 的结合使用</title>
      <link href="/2019/03/15/OpenCV-Build/"/>
      <url>/2019/03/15/OpenCV-Build/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="为什么没有-Windows-下的编译安装"><a href="#为什么没有-Windows-下的编译安装" class="headerlink" title="为什么没有 Windows 下的编译安装"></a>为什么没有 Windows 下的编译安装</h3><p>因为官网已经提供的编译好的 exe 包,双击运行就会解压到特定的目录了,除此之外官网还提供了 ios 版和 安卓版<br>这里着重记录下 CentOS , Ubuntu 和 Mac OS 下的安装,因为官网没有提供编译好的包</p><h3 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h3><ol><li>GCC 4.4.x or later</li><li>CMake 2.8.7 or higher</li><li>Git</li><li>GTK+2.x or higher, including headers (libgtk2.0-dev)</li><li>pkg-config</li><li>Python 2.6 or later and Numpy 1.5 or later with developer packages (python-dev, python-numpy)</li><li>ffmpeg or libav development packages: libavcodec-dev, libavformat-dev, libswscale-dev</li><li>[optional] libtbb2 libtbb-dev</li><li>[optional] libdc1394 2.x</li><li>[optional] libjpeg-dev, libpng-dev, libtiff-dev, libjasper-dev, libdc1394-22-dev</li><li>[optional] CUDA Toolkit 6.5 or higher</li></ol><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>安装常用的开发编译工具包, Centos 的命令为: yum groupinstall “Development Tools”, Ubuntu 的命令为: apt-get install build-essential</li><li>安装 cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev</li><li>mkdir opencv4; cd opencv4</li><li>git clone <a href="https://github.com/opencv/opencv.git" target="_blank" rel="noopener">https://github.com/opencv/opencv.git</a></li><li>git clone <a href="https://github.com/opencv/opencv_contrib.git" target="_blank" rel="noopener">https://github.com/opencv/opencv_contrib.git</a></li><li>cd opencv</li><li>mkdir build</li><li>cd build</li><li>cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..  (如果不工作的话,删除 -D的空格,cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local ..)</li><li>make -j7 # runs 7 jobs in parallel 使用7个并行任务来编译</li><li>生成文档 cd ~/opencv/build/doc/; make -j7 doxygen</li><li>make install</li></ol><h3 id="编译好的包"><a href="#编译好的包" class="headerlink" title="编译好的包"></a>编译好的包</h3><ol><li>centos7 版: <a href="http://cloud.joylau.cn:1194/s/kUoNelmj1SX810K" target="_blank" rel="noopener">http://cloud.joylau.cn:1194/s/kUoNelmj1SX810K</a> 或者  <a href="https://pan.baidu.com/s/1qaZ-TbF0xP0DxaEJKbdt-A" target="_blank" rel="noopener">https://pan.baidu.com/s/1qaZ-TbF0xP0DxaEJKbdt-A</a> 提取码: jkir</li><li>Ubuntu 16.04 版: <a href="http://cloud.joylau.cn:1194/s/TsNRKwxJhM0v0HE" target="_blank" rel="noopener">http://cloud.joylau.cn:1194/s/TsNRKwxJhM0v0HE</a>  或者  <a href="https://pan.baidu.com/s/1ha6nATLrSt5WPL1iQlmWSg" target="_blank" rel="noopener">https://pan.baidu.com/s/1ha6nATLrSt5WPL1iQlmWSg</a> 提取码: gduu</li><li>java 调用所需 opencv-410.jar 包: <a href="http://image.joylau.cn/blog/opencv-410.jar" target="_blank" rel="noopener">http://image.joylau.cn/blog/opencv-410.jar</a></li></ol><h3 id="Mac-OS-上"><a href="#Mac-OS-上" class="headerlink" title="Mac OS 上"></a>Mac OS 上</h3><ol><li>AppStore 上安装 XCode, 安装完成打开 XCode , 同意 license</li><li>安装 HomeBrew</li><li>安装必要依赖: Python 3, CMake and Qt 5</li></ol><pre><code class="bash">    brew install python3    brew install cmake    brew install qt5</code></pre><ol start="4"><li>安装环境</li></ol><pre><code class="bash">    mkdir ~/opencv4    git clone https://github.com/opencv/opencv.git    git clone https://github.com/opencv/opencv_contrib.git    # 变量定义    cwd=$(pwd)    cvVersion=&quot;master&quot;    QT5PATH=/usr/local/Cellar/qt/5.12.2    rm -rf opencv/build    rm -rf opencv_contrib/build    # Create directory for installation    mkdir -p installation/OpenCV-&quot;$cvVersion&quot;    sudo -H pip3 install -U pip numpy    # Install virtual environment    sudo -H python3 -m pip install virtualenv virtualenvwrapper    VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3    echo &quot;VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3&quot; &gt;&gt; ~/.bash_profile    echo &quot;# Virtual Environment Wrapper&quot; &gt;&gt; ~/.bash_profile    echo &quot;source /usr/local/bin/virtualenvwrapper.sh&quot; &gt;&gt; ~/.bash_profile    cd $cwd    source /usr/local/bin/virtualenvwrapper.sh    ############ For Python 3 ############    # create virtual environment 由于 mac OS 本身使用的是 Python 2.7 , 而一些本身的应用依赖于 Python 2 ,为了不影响原来的环境,这里创建一个 Python3 的虚拟环境来进行编译    mkvirtualenv OpenCV-&quot;$cvVersion&quot;-py3 -p python3    workon OpenCV-&quot;$cvVersion&quot;-py3    # now install python libraries within this virtual environment    pip install cmake numpy scipy matplotlib scikit-image scikit-learn ipython dlib    # quit virtual environment    deactivate    ######################################    cd opencv    mkdir build    cd build    cmake -D CMAKE_BUILD_TYPE=RELEASE \                -D CMAKE_INSTALL_PREFIX=$cwd/installation/OpenCV-&quot;$cvVersion&quot; \                -D INSTALL_C_EXAMPLES=ON \                -D INSTALL_PYTHON_EXAMPLES=ON \                -D WITH_TBB=ON \                -D WITH_V4L=ON \                -D OPENCV_SKIP_PYTHON_LOADER=ON \                -D CMAKE_PREFIX_PATH=$QT5PATH \                -D CMAKE_MODULE_PATH=&quot;$QT5PATH&quot;/lib/cmake \                -D OPENCV_PYTHON3_INSTALL_PATH=~/.virtualenvs/OpenCV-&quot;$cvVersion&quot;-py3/lib/python3.7/site-packages \            -D WITH_QT=ON \            -D WITH_OPENGL=ON \            -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \            -D BUILD_EXAMPLES=ON ..    make -j$(sysctl -n hw.physicalcpu)    make install</code></pre><ol start="5"><li>cmake 后输出如下:</li></ol><pre><code class="bash">    --   OpenCV modules:    --     To be built:                 aruco bgsegm bioinspired calib3d ccalib core cvv datasets dnn dnn_objdetect dpm face features2d flann freetype fuzzy gapi hfs highgui img_hash imgcodecs imgproc java java_bindings_generator line_descriptor ml objdetect optflow phase_unwrapping photo plot python2 python3 python_bindings_generator quality reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto    --     Disabled:                    world    --     Disabled by dependency:      -    --     Unavailable:                 cnn_3dobj cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev hdf js matlab ovis sfm viz    --     Applications:                tests perf_tests examples apps    --     Documentation:               NO    --     Non-free algorithms:         NO    --     --   GUI:     --     QT:                          YES (ver 5.12.2)    --       QT OpenGL support:         YES (Qt5::OpenGL 5.12.2)    --     Cocoa:                       YES    --     OpenGL support:              YES (/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/OpenGL.framework /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/OpenGL.framework)    --     VTK support:                 NO    --     --   Media I/O:     --     ZLib:                        build (ver 1.2.11)    --     JPEG:                        build-libjpeg-turbo (ver 2.0.2-62)    --     WEBP:                        build (ver encoder: 0x020e)    --     PNG:                         build (ver 1.6.36)    --     TIFF:                        build (ver 42 - 4.0.10)    --     JPEG 2000:                   build (ver 1.900.1)    --     OpenEXR:                     build (ver 1.7.1)    --     HDR:                         YES    --     SUNRASTER:                   YES    --     PXM:                         YES    --     PFM:                         YES    --     --   Video I/O:    --     DC1394:                      NO    --     FFMPEG:                      YES    --       avcodec:                   YES (58.35.100)    --       avformat:                  YES (58.20.100)    --       avutil:                    YES (56.22.100)    --       swscale:                   YES (5.3.100)    --       avresample:                YES (4.0.0)    --     GStreamer:                   NO    --     AVFoundation:                YES    --     v4l/v4l2:                    NO    --     --   Parallel framework:            GCD    --     --   Trace:                         YES (with Intel ITT)    --     --   Other third-party libraries:    --     Intel IPP:                   2019.0.0 Gold [2019.0.0]    --            at:                   /Users/joylau/opencv4/opencv/build/3rdparty/ippicv/ippicv_mac/icv    --     Intel IPP IW:                sources (2019.0.0)    --               at:                /Users/joylau/opencv4/opencv/build/3rdparty/ippicv/ippicv_mac/iw    --     Lapack:                      YES (/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/Accelerate.framework)    --     Eigen:                       NO    --     Custom HAL:                  NO    --     Protobuf:                    build (3.5.1)    --     --   OpenCL:                        YES (no extra features)    --     Include path:                NO    --     Link libraries:              -framework OpenCL    --     --   Python 2:    --     Interpreter:                 /usr/bin/python2.7 (ver 2.7.10)    --     Libraries:                   /usr/lib/libpython2.7.dylib (ver 2.7.10)    --     numpy:                       /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/include (ver 1.8.0rc1)    --     install path:                lib/python2.7/site-packages    --     --   Python 3:    --     Interpreter:                 /usr/local/bin/python3 (ver 3.7.2)    --     Libraries:                   /usr/local/Frameworks/Python.framework/Versions/3.7/lib/libpython3.7m.dylib (ver 3.7.2)    --     numpy:                       /usr/local/lib/python3.7/site-packages/numpy/core/include (ver 1.16.2)    --     install path:                /Users/joylau/.virtualenvs/OpenCV-master-py3/lib/python3.7/site-packages    --     --   Python (for build):            /usr/bin/python2.7    --     --   Java:                              --     ant:                         /Users/joylau/dev/apache-ant-1.10.5/bin/ant (ver 1.10.5)    --     JNI:                         /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/JavaVM.framework/Headers /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/JavaVM.framework/Headers /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/JavaVM.framework/Headers    --     Java wrappers:               YES    --     Java tests:                  YES    --     --   Install to:                    /Users/joylau/opencv4/installation/OpenCV-master    -- -----------------------------------------------------------------    --     -- Configuring done    -- Generating done    -- Build files have been written to: /Users/joylau/opencv4/opencv/build</code></pre><ol start="6"><li>编译好的安装包: <a href="http://cloud.joylau.cn:1194/s/6GMLl09ZAYNAUMU" target="_blank" rel="noopener">http://cloud.joylau.cn:1194/s/6GMLl09ZAYNAUMU</a> 或者: <a href="https://pan.baidu.com/s/1YBxUD_vB1zKOcxHeAtn6Xw" target="_blank" rel="noopener">https://pan.baidu.com/s/1YBxUD_vB1zKOcxHeAtn6Xw</a> 提取码: twsq </li></ol><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><h4 id="CentOS-上-CMake-版本太低的解决方法"><a href="#CentOS-上-CMake-版本太低的解决方法" class="headerlink" title="CentOS 上 CMake 版本太低的解决方法"></a>CentOS 上 CMake 版本太低的解决方法</h4><ol><li><p>yum 上安装的版本太低,先卸载掉版本低的,yum remove cmake</p></li><li><p>cd /opt<br>tar zxvf cmake-3.10.2-Linux-x86_64.tar.gz</p></li><li><p>vim /etc/profile<br>export CMAKE_HOME=/opt/cmake-3.10.2-Linux-x86_64<br>export PATH=$PATH:$CMAKE_HOME/bin</p></li><li><p>source /etc/profile </p></li></ol><h4 id="没有生成-opencv-410-jar"><a href="#没有生成-opencv-410-jar" class="headerlink" title="没有生成 opencv-410.jar"></a>没有生成 opencv-410.jar</h4><pre><code class="bash">    Java:                              --     ant:                         /bin/ant (ver 1.9.4)    --     JNI:                         /usr/lib/jvm/java-1.8.0-openjdk/include /usr/lib/jvm/java-1.8.0-openjdk/include/linux /usr/lib/jvm/java-1.8.0-openjdk/include    --     Java wrappers:               YES    --     Java tests:                  NO</code></pre><p>需要 ant 环境,安装后即可, java 即可进行调用</p><h3 id="IDEA-及-Spring-Boot-项目中的使用"><a href="#IDEA-及-Spring-Boot-项目中的使用" class="headerlink" title="IDEA 及 Spring Boot 项目中的使用"></a>IDEA 及 Spring Boot 项目中的使用</h3><ol><li>下载 opencv-410.jar 包,引入到项目中</li></ol><pre><code class="groovy">   dependencies {       implementation &#39;org.springframework.boot:spring-boot-starter-web&#39;       compileOnly &#39;org.projectlombok:lombok&#39;       annotationProcessor &#39;org.projectlombok:lombok&#39;       testImplementation &#39;org.springframework.boot:spring-boot-starter-test&#39;       compile fileTree(dir:&#39;libs&#39;,include:[&#39;*.jar&#39;])   } </code></pre><ol start="2"><li>配置动态库路径, vm options: -Djava.library.path=/home/joylau/opencv4/opencv/build/lib</li></ol><p><img src="http://image.joylau.cn/blog/vm_options_config.jpg" alt="vm options"></p><p>mac os 下路径为: -Djava.library.path=/Users/joylau/opencv4/installation/OpenCV-master/share/java/opencv4</p><ol start="3"><li>加载动态库</li></ol><pre><code class="java">    @SpringBootApplication    public class OpencvTestApplication {        public static void main(String[] args) {            System.loadLibrary(Core.NATIVE_LIBRARY_NAME);            System.out.println(Core.VERSION);            SpringApplication.run(OpencvTestApplication.class, args);        }    }</code></pre><ol start="4"><li>脸部识别 demo</li></ol><pre><code class="java">    private static void testFace() {            // 1 读取OpenCV自带的人脸识别特征XML文件            CascadeClassifier facebook = new CascadeClassifier(&quot;/home/joylau/opencv4/opencv/data/haarcascades/haarcascade_frontalface_alt.xml&quot;);            // 2 读取测试图片            Mat image = Imgcodecs.imread(&quot;/home/joylau/图片/image-test-4.jpg&quot;);            // 3 特征匹配            MatOfRect face = new MatOfRect();            facebook.detectMultiScale(image, face);            // 4 匹配 Rect 矩阵 数组            Rect[] rects = face.toArray();            System.out.println(&quot;匹配到 &quot; + rects.length + &quot; 个人脸&quot;);            // 5 为每张识别到的人脸画一个框            for (int i = 0; i &lt; rects.length; i++) {                Imgproc.rectangle(image,new Point(rects[i].x, rects[i].y), new Point(rects[i].x + rects[i].width, rects[i].y + rects[i].height), new Scalar(0, 0, 255));                Imgproc.putText(image,&quot;face-&quot; + i, new Point(rects[i].x, rects[i].y),Imgproc.FONT_HERSHEY_SIMPLEX, 1.0, new Scalar(0, 255, 0),1,Imgproc.LINE_AA,false);            }            // 6 展示图片            HighGui.imshow(&quot;人脸-匹配&quot;, image);            HighGui.waitKey(0);        }</code></pre><p><img src="http://image.joylau.cn/blog/opencv_test_face.jpg" alt="test_face"></p><blockquote><p>注: 图片来自微博</p></blockquote><ol start="5"><li>边缘检测 demo</li></ol><pre><code class="java">    private static void testContours() {            //1 获取原图            Mat src = Imgcodecs.imread(&quot;/home/joylau/图片/image-test.jpg&quot;);            //2 图片灰度化            Mat gary = new Mat();            Imgproc.cvtColor(src, gary, Imgproc.COLOR_RGB2GRAY);            //3 图像边缘处理            Mat edges = new Mat();            Imgproc.Canny(gary, edges, 200, 500, 3, false);            //4 发现轮廓            List&lt;MatOfPoint&gt; list = new ArrayList&lt;MatOfPoint&gt;();            Mat hierarchy = new Mat();            Imgproc.findContours(edges, list, hierarchy, Imgproc.RETR_TREE, Imgproc.CHAIN_APPROX_SIMPLE);            //5 绘制轮廓            for (int i = 0, len = list.size(); i &lt; len; i++) {                Imgproc.drawContours(src, list, i, new Scalar(0, 255, 0), 1, Imgproc.LINE_AA);            }            HighGui.imshow(&quot;边缘检测&quot;, src);            HighGui.waitKey(0);        }</code></pre><p><img src="http://image.joylau.cn/blog/image-test.jpg" alt="test_source"><br><img src="http://image.joylau.cn/blog/test_contours.jpg" alt="test_contours"></p><ol start="6"><li>实时人脸识别</li></ol><pre><code class="java">    /**         * OpenCV-4.0.0 实时人脸识别         *         */        public static void videoFace() {            VideoCapture capture=new VideoCapture(0);            Mat image=new Mat();            int index=0;            if (capture.isOpened()) {                do {                    capture.read(image);                    HighGui.imshow(&quot;实时人脸识别&quot;, getFace(image));                    index = HighGui.waitKey(1);                } while (index != 27);            }        }        /**         * OpenCV-4.0.0 人脸识别         * @param image 待处理Mat图片(视频中的某一帧)         * @return 处理后的图片         */        public static Mat getFace(Mat image) {            // 1 读取OpenCV自带的人脸识别特征XML文件            CascadeClassifier facebook=new CascadeClassifier(&quot;/Users/joylau/opencv4/opencv/data/haarcascades/haarcascade_frontalface_alt.xml&quot;);            // 2  特征匹配类            MatOfRect face = new MatOfRect();            // 3 特征匹配            facebook.detectMultiScale(image, face);            Rect[] rects=face.toArray();            log.info(&quot;匹配到 &quot;+rects.length+&quot; 个人脸&quot;);            // 4 为每张识别到的人脸画一个圈            for (Rect rect : rects) {                Imgproc.rectangle(image, new Point(rect.x, rect.y), new Point(rect.x + rect.width, rect.y + rect.height), new Scalar(0, 255, 0));                Imgproc.putText(image, &quot;Human&quot;, new Point(rect.x, rect.y), Imgproc.FONT_HERSHEY_SIMPLEX, 2.0, new Scalar(0, 255, 0), 1, Imgproc.LINE_AA, false);                //Mat dst=image.clone();                //Imgproc.resize(image, image, new Size(300,300));            }            return image;        }</code></pre><center><video src="http://image.joylau.cn/blog/opencv-video-face.mp4" loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center>]]></content>
      
      
      <categories>
          
          <category> OpenCV篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker-Swarm 自定义服务部署的节点</title>
      <link href="/2019/03/01/Docker-Swarm-Choice-Node/"/>
      <url>/2019/03/01/Docker-Swarm-Choice-Node/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>使用 docker stack 部署一组服务时,docker 会根据集群的每个节点的资源的情况来进行分配,作为使用者无法参与其中的分配,该怎么解决呢?</p><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ol><li>docker 1.13.0+</li><li>compose version 3+</li></ol><h3 id="deploy-mode"><a href="#deploy-mode" class="headerlink" title="deploy mode"></a>deploy mode</h3><ol><li><code>replicated</code> 默认模式,可自定义服务的副本数,此模式不能决定服务部署到哪个节点上</li></ol><pre><code class="yaml">    deploy:          mode: replicated          replicas: 2</code></pre><ol start="2"><li><code>global</code> 定义每个节点均部署一个服务的副本</li></ol><pre><code class="yaml">    deploy:          mode: global</code></pre><h3 id="node-labels"><a href="#node-labels" class="headerlink" title="node labels"></a>node labels</h3><p>该方法是通过给节点添加标签,然后在 yaml 文件里通过配置标签来决定服务部署到哪些节点</p><ol><li>docker node ls 查看节点</li><li>docker node update –label-add role=service-1 nodeId 给 nodeId 的节点添加 label role=service-1, label 的形式是 map 的键值对形式</li><li>docker node inspect nodeId 查看节点的 labels 信息</li><li>docker node update –label-rm role=service-1 nodeId 删除 label</li></ol><h4 id="service-部署"><a href="#service-部署" class="headerlink" title="service 部署"></a>service 部署</h4><pre><code class="bash">    docker service create \      --name nginx \      --constraint &#39;node.labels.role == service-1&#39; \      nginx</code></pre><h4 id="stack-部署"><a href="#stack-部署" class="headerlink" title="stack 部署"></a>stack 部署</h4><pre><code class="yaml">    deploy:          placement:            constraints:              - node.labels.role == service-2</code></pre><p>constraints 填写多个时，它们之间的关系是 AND;constraints 可以匹配 node 标签和  engine 标签<br>例如</p><pre><code class="yaml">    deploy:          placement:            constraints: [node.role == manager]</code></pre><pre><code class="yaml">    deploy:          placement:            constraints:              - node.role == manager              - engine.labels.operatingsystem == ubuntu 14.04</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Docker Swarm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker-Swarm 集群搭建</title>
      <link href="/2019/02/18/Docker-Swarm-Cluster/"/>
      <url>/2019/02/18/Docker-Swarm-Cluster/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ol><li>docker 18.09</li></ol><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li>本篇文章中的搭建过程有多台物理机,如果说是自己测试使用的话,或者只有一台机器,可以使用 docker-machine 来创建多个 docker 主机</li><li>比如创建一个主机名为 work 的 docker 主机 : <code>docker-machine create -d virtualbox worker</code></li><li>之后进入刚才创建的主机 : <code>docker-machine ssh worker</code></li><li>然后就当成是一台独立机器来执行以下的操作</li></ol><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>初始化 swarm 集群 : <code>docker swarm init --advertise-addr 34.0.7.183</code><ol><li>机器有多个网卡的指定 IP 地址 –advertise-addr</li><li>默认创建的是管理节点</li></ol></li><li>加入刚才创建 swarm 集群</li></ol><pre><code class="shell">    docker swarm join --token SWMTKN-1-1o1yfsquxasw7c7ah4t7lmd4i89i62u74tutzhtcbgb7wx6csc-1hf4tjv9oz9vpo937955mi0z2 34.0.7.183:2377</code></pre><p>如果说忘了集群管理节点的 token, 可以使用 <code>docker swarm join-token work/manage</code> 来查看加入该集群的命令</p><ol start="3"><li>查看集群节点: <code>docker node list</code></li></ol><h3 id="服务部署"><a href="#服务部署" class="headerlink" title="服务部署"></a>服务部署</h3><ol><li><p>单服务部署 <code>docker service create --name nginx -p 80:80 --replaces 4 containAddress</code><br> 上述命令部署了4个 nginx 服务,如果集群有2台主机的话,会在每台主机上部署 2 个服务</p></li><li><p>多服务部署, 使用 yml 配置文件,具体语法参看 <a href="https://docs.docker.com/compose/compose-file/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/</a></p></li></ol><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><h4 id="docker-swarm"><a href="#docker-swarm" class="headerlink" title="docker swarm"></a>docker swarm</h4><p>docker swarm init    初始化集群<br>docker swarm join-token worker    查看工作节点的 token<br>docker swarm join-token manager    查看管理节点的 token<br>docker swarm join  加入集群中</p><h4 id="docker-stack"><a href="#docker-stack" class="headerlink" title="docker stack"></a>docker stack</h4><p>docker stack deploy    部署新的服务或更新现有服务<br>docker stack ls    列出现有服务<br>docker stack ps    列出服务中的任务<br>docker stack rm    删除服务<br>docker stack services    列出服务中的具体项<br>docker stack down    移除某个服务（不会删除数据）</p><h4 id="docker-node"><a href="#docker-node" class="headerlink" title="docker node"></a>docker node</h4><p>docker node ls    查看所有集群节点<br>docker node rm    删除某个节点（-f强制删除）<br>docker node inspect    查看节点详情<br>docker node demote    节点降级，由管理节点降级为工作节点<br>docker node promote    节点升级，由工作节点升级为管理节点<br>docker node update    更新节点<br>docker node ps    查看节点中的 Task 任务</p><h4 id="docker-service"><a href="#docker-service" class="headerlink" title="docker service"></a>docker service</h4><p>docker service create    部署服务<br>docker service inspect    查看服务详情<br>docker service logs    产看某个服务日志<br>docker service ls    查看所有服务详情<br>docker service rm    删除某个服务（-f强制删除）<br>docker service scale    设置某个服务个数<br>docker service update    更新某个服务</p><h4 id="docker-machine"><a href="#docker-machine" class="headerlink" title="docker machine"></a>docker machine</h4><p>docker-machine create    创建一个 Docker 主机（常用-d virtualbox）<br>docker-machine ls    查看所有的 Docker 主机<br>docker-machine ssh    SSH 到主机上执行命令<br>docker-machine env    显示连接到某个主机需要的环境变量<br>docker-machine inspect    输出主机更多信息<br>docker-machine kill    停止某个主机<br>docker-machine restart    重启某台主机<br>docker-machine rm    删除某台主机<br>docker-machine scp    在主机之间复制文件<br>docker-machine start    启动一个主机<br>docker-machine status    查看主机状态<br>docker-machine stop    停止一个主机</p><h3 id="swarm-集群节点可视化工具"><a href="#swarm-集群节点可视化工具" class="headerlink" title="swarm 集群节点可视化工具"></a>swarm 集群节点可视化工具</h3><p>portainer : 很强大的工具,可以监控本机和远程服务器或者集群环境,远程 docker 主机的话需要远程 docker 主机开启在 2375 端口的服务</p><p><a href="https://www.portainer.io/installation/" target="_blank" rel="noopener">https://www.portainer.io/installation/</a></p><pre><code class="yaml">    version: &#39;3&#39;    services:      portainer:        image: 34.0.7.183:5000/joylau/portainer:latest        container_name: portainer        ports:          - 80:9000        restart: always        volumes:          - /home/liufa/portainer/data:/data</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Docker Swarm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Validated 注解的 groups 使用记录</title>
      <link href="/2019/01/26/SpringBoot-Validated/"/>
      <url>/2019/01/26/SpringBoot-Validated/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Valid-和-Validated"><a href="#Valid-和-Validated" class="headerlink" title="@Valid 和 @Validated"></a>@Valid 和 @Validated</h3><ol><li><code>@Valid</code> 和 <code>@Validated</code> 注解都用于字段校验</li><li><code>@Valid</code> 所属包为：<code>javax.validation.Valid</code> ; <code>@Validated</code> 所属包为 <code>org.springframework.validation.annotation.Validated</code></li><li><code>@Validated</code> 是 <code>@Valid</code> 的一次封装，是Spring提供的校验机制使用。<code>@Valid</code> 不提供分组功能</li></ol><h3 id="Validated的特殊用法"><a href="#Validated的特殊用法" class="headerlink" title="@Validated的特殊用法"></a>@Validated的特殊用法</h3><p>当一个实体类需要多种验证方式时，例：对于一个实体类的id来说，新增的时候是不需要的，对于更新时是必须的</p><pre><code class="java">    public class Attachment {        @Id        @NotBlank(message = &quot;id can not be blank!&quot;, groups = {All.class, Update.class})        private String id;        @NotBlank(message = &quot;fileName can not be blank!&quot;, groups = {All.class})        private String fileName;        @NotBlank(message = &quot;filePath can not be blank!&quot;, groups = {All.class})        private String filePath;        @Field        private byte[] data;        @NotBlank(message = &quot;metaData can not be empty!&quot;, groups = {All.class})        private String metaData;        @NotBlank(message = &quot;uploadTime can not be blank!&quot;, groups = {All.class})        private String uploadTime;        public Attachment(@NotBlank(message = &quot;id can not be blank!&quot;, groups = {All.class, Update.class}) String id) {            this.id = id;        }        public interface All {        }        public interface Update {        }    }</code></pre><p>单独对 <code>groups</code> 进行校验</p><pre><code class="java">    /**     * 添加附件     */    @PostMapping(&quot;addAttachment&quot;)    public MessageBody addAttachment(@RequestParam(&quot;file&quot;) final MultipartFile multipartFile,                                     @Validated(Attachment.All.class) Attachment attachment,                                     BindingResult results){        return attachmentApiService.addAttachment(multipartFile,attachment,results);    }    /**     * 更新单个附件     */    @PostMapping(&quot;updateAttachment&quot;)    public MessageBody updateAttachment(@RequestParam(value = &quot;file&quot;,required = false) final MultipartFile multipartFile,                                        @Validated(Attachment.Update.class) Attachment attachment){        return attachmentApiService.updateAttachment(multipartFile,attachment);    }</code></pre><h3 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h3><ol><li>校验的注解中不分配 groups，默认每次都要进行验证</li><li>@Validated 没有添加 groups 属性时，默认验证没有分组的验证属性</li><li>@Validated 添加特定 groups 属性时,只校验该注解中分配了该 groups 的属性</li><li>一个功能方法上处理多个模型对象时，需添加多个验证结果对象,如下所示</li></ol><pre><code class="java">    @RequestMapping(&quot;/addPeople&quot;)      public @ResponseBody String addPeople(@Validated People p,BindingResult result,@Validated Person p2,BindingResult result2)  {    } </code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 删除 状态为Dead 的容器</title>
      <link href="/2019/01/25/Docker-RemoveDeadContainer/"/>
      <url>/2019/01/25/Docker-RemoveDeadContainer/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="错误信息"><a href="#错误信息" class="headerlink" title="错误信息"></a>错误信息</h3><p>因为一些不正确的操作,导致容器的状态变成了 dead</p><pre><code class="bash">    CONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                      PORTS                                                              NAMES    c21c993c5107        34.0.7.183:5000/joylau/traffic-service:2.1.7          &quot;java -Djava.secur...&quot;   2 weeks ago         Dead                                                                                           traffic-service    dfbd1cdb31c2        34.0.7.183:5000/joylau/traffic-service-admin:1.2.1    &quot;java -Djava.secur...&quot;   2 weeks ago         Dead                                                                                           traffic-service-admin    8778a28ab120        34.0.7.183:5000/joylau/traffic-service-data:2.0.4     &quot;java -Djava.secur...&quot;   2 weeks ago         Dead                                                                                           traffic-service-data    65a3885e08b5        34.0.7.183:5000/joylau/traffic-service-node:1.2.3     &quot;/bin/sh -c &#39;./nod...&quot;   2 weeks ago         Dead                                                                                           traffic-service-node    90700440e1df        34.0.7.183:5000/joylau/traffic-service-server:1.2.1   &quot;java -Djava.secur...&quot;   2 weeks ago         Dead                                                                                           traffic-service-server</code></pre><p>这类的容器删除时会报错</p><pre><code class="bash">    # docker rm c21c993c5107    Error response from daemon: Driver overlay2 failed to remove root filesystem c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64: remove /var/lib/docker/overlay2/099974dbeef827a3bbd932b7b36502763482ae8df25bd80f61a288b71b0ab810/merged: device or resource busy</code></pre><h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p>找到 filesystem 后面的字符串</p><pre><code class="bash">    # grep c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64 /proc/*/mountinfo</code></pre><p>得到如下输出:</p><pre><code class="bash">    /proc/28032/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28033/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28034/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28035/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28036/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28037/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28038/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28039/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28040/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28041/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28042/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28043/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28044/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28045/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28046/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28047/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k    /proc/28048/mountinfo:973 957 0:164 / /var/lib/docker/containers/c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64/shm rw,nosuid,nodev,noexec,relatime shared:189 - tmpfs shm rw,size=65536k</code></pre><p>proc 和 mountinfo 中间的数字将其 kill 掉即可</p><p>写一个批量处理的脚本列出所有的 pid</p><pre><code class="bash">    grep c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64 /proc/*/mountinfo | awk &#39;{print substr($1,7,5)}&#39;</code></pre><p>再 kill 掉</p><pre><code class="bash">    grep c21c993c51073f41653aa7fd37dbfd232f8439ca79fd4315a410d0b41d8b0e64 /proc/*/mountinfo | awk &#39;{print substr($1,7,5)}&#39; | xargs kill -9</code></pre><p>print 是awk打印指定内容的主要命令</p><p>$0           表示整个当前行<br>$1           每行第一个字段,每个字段以空格隔开<br>substr($1,7,5) 每行第一个字段,第7个字符开始,截取5个字符</p><p>然后在 <code>docker rm container</code></p><p>完美解决.</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch analyzer 和 search_analyzer 的使用记录</title>
      <link href="/2019/01/24/Elasticsearch-Analyzer/"/>
      <url>/2019/01/24/Elasticsearch-Analyzer/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li>elasticsearch 6.4.3</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>下面一段文字用 ik 进行分词</p><p><a href="http://34.0.7.184:9200/_analyze/" target="_blank" rel="noopener">http://34.0.7.184:9200/_analyze/</a> POST</p><pre><code class="json">    {      &quot;analyzer&quot;: &quot;ik_smart&quot;,      &quot;text&quot;: &quot;关于加快建设合肥地铁七号线的通知说明&quot;    }</code></pre><p>分词结果</p><pre><code class="json">    {    &quot;tokens&quot;: [    {    &quot;token&quot;: &quot;关于&quot;,    &quot;start_offset&quot;: 0,    &quot;end_offset&quot;: 2,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 0    }    ,    {    &quot;token&quot;: &quot;加快&quot;,    &quot;start_offset&quot;: 2,    &quot;end_offset&quot;: 4,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 1    }    ,    {    &quot;token&quot;: &quot;建设&quot;,    &quot;start_offset&quot;: 4,    &quot;end_offset&quot;: 6,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 2    }    ,    {    &quot;token&quot;: &quot;合肥&quot;,    &quot;start_offset&quot;: 6,    &quot;end_offset&quot;: 8,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 3    }    ,    {    &quot;token&quot;: &quot;地铁&quot;,    &quot;start_offset&quot;: 8,    &quot;end_offset&quot;: 10,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 4    }    ,    {    &quot;token&quot;: &quot;七号&quot;,    &quot;start_offset&quot;: 10,    &quot;end_offset&quot;: 12,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 5    }    ,    {    &quot;token&quot;: &quot;线&quot;,    &quot;start_offset&quot;: 12,    &quot;end_offset&quot;: 13,    &quot;type&quot;: &quot;CN_CHAR&quot;,    &quot;position&quot;: 6    }    ,    {    &quot;token&quot;: &quot;的&quot;,    &quot;start_offset&quot;: 13,    &quot;end_offset&quot;: 14,    &quot;type&quot;: &quot;CN_CHAR&quot;,    &quot;position&quot;: 7    }    ,    {    &quot;token&quot;: &quot;通知&quot;,    &quot;start_offset&quot;: 14,    &quot;end_offset&quot;: 16,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 8    }    ,    {    &quot;token&quot;: &quot;说明&quot;,    &quot;start_offset&quot;: 16,    &quot;end_offset&quot;: 18,    &quot;type&quot;: &quot;CN_WORD&quot;,    &quot;position&quot;: 9    }    ]    }</code></pre><ul><li><p>这个时候如果配置的 analyzer 为 ik_smart 或者 analyzer 和 search_analyzer 都为 ik_smart, 则短语中每一个字都能搜到结果,还可以设置高亮信息来着重看一下</p></li><li><p>如果配置的 analyzer 为 ik search_analyzer 为 standard ,则 <code>通知</code>,<code>说明</code>,<code>七号</code> 这样的词是搜不到的,而 <code>线</code> 和 <code>的</code> 这样的词可以搜到,理解一下</p></li></ul><p><a href="http://34.0.7.184:9200/attachment_libs/_search" target="_blank" rel="noopener">http://34.0.7.184:9200/attachment_libs/_search</a> POST</p><pre><code class="json">    {      &quot;query&quot;: {        &quot;multi_match&quot;: {          &quot;query&quot;: &quot;关于&quot;,          &quot;fields&quot;: [            &quot;fileName^1.0&quot;          ],          &quot;type&quot;: &quot;best_fields&quot;,          &quot;operator&quot;: &quot;OR&quot;,          &quot;slop&quot;: 0,          &quot;prefix_length&quot;: 0,          &quot;max_expansions&quot;: 50,          &quot;zero_terms_query&quot;: &quot;NONE&quot;,          &quot;auto_generate_synonyms_phrase_query&quot;: true,          &quot;fuzzy_transpositions&quot;: true,          &quot;boost&quot;: 1        }      },      &quot;_source&quot;: {        &quot;includes&quot;: [          &quot;fileName&quot;        ],        &quot;excludes&quot;: [          &quot;data&quot;        ]      },      &quot;highlight&quot;: {        &quot;pre_tags&quot;: [          &quot;&lt;span style = &#39;color:red&#39;&gt;&quot;        ],        &quot;post_tags&quot;: [          &quot;&lt;/span&gt;&quot;        ],        &quot;fields&quot;: {          &quot;*&quot;: {}        }      }    }</code></pre><p>返回的结果为:</p><pre><code class="json">    {    &quot;took&quot;: 2,    &quot;timed_out&quot;: false,    &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0    },    &quot;hits&quot;: {    &quot;total&quot;: 0,    &quot;max_score&quot;: null,    &quot;hits&quot;: [ ]    }    }</code></pre><p>而搜索 <code>线</code> 返回的结果为:</p><pre><code class="json">    {    &quot;took&quot;: 5,    &quot;timed_out&quot;: false,    &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0    },    &quot;hits&quot;: {    &quot;total&quot;: 1,    &quot;max_score&quot;: 0.2876821,    &quot;hits&quot;: [    {    &quot;_index&quot;: &quot;attachment_libs&quot;,    &quot;_type&quot;: &quot;attachment_info&quot;,    &quot;_id&quot;: &quot;fd45d5be-c314-488a-99d3-041acc015377&quot;,    &quot;_score&quot;: 0.2876821,    &quot;_source&quot;: {    &quot;fileName&quot;: &quot;关于加快建设合肥地铁七号线的通知说明&quot;    },    &quot;highlight&quot;: {    &quot;fileName&quot;: [    &quot;关于加快建设合肥地铁七号&lt;span style = &#39;color:red&#39;&gt;线&lt;/span&gt;的通知说明&quot;    ]    }    }    ]    }    }</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>分析器主要有两种情况会被使用，一种是插入文档时，将text类型的字段做分词然后插入倒排索引，第二种就是在查询时，先对要查询的text类型的输入做分词，再去倒排索引搜索</li><li>如果想要让 索引 和 查询 时使用不同的分词器，ElasticSearch也是能支持的，只需要在字段上加上search_analyzer参数<ol><li>在索引时，只会去看字段有没有定义analyzer，有定义的话就用定义的，没定义就用ES预设的</li><li>在查询时，会先去看字段有没有定义search_analyzer，如果没有定义，就去看有没有analyzer，再没有定义，才会去使用ES预设的</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker elasticsearch 集群搭建记录</title>
      <link href="/2019/01/23/Docker-Elasticsearch/"/>
      <url>/2019/01/23/Docker-Elasticsearch/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="env"><a href="#env" class="headerlink" title=".env"></a>.env</h3><pre><code class=".env">    PRIVATE_REPO=34.0.7.183:5000    ES_VERSION=6.4.3    ELASTICSEARCH_CLUSTER_DIR=/Users/joylau/dev/idea-project/dev-app/es-doc-office/elasticsearch-cluster</code></pre><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><pre><code class="yaml">    version: &#39;2.2&#39;    services:      node-0:        image: ${PRIVATE_REPO}/joylau/es-doc:${ES_VERSION}        container_name: node-0        ports:          - 9200:9200          - 9300:9300        restart: always        volumes:          - ${ELASTICSEARCH_CLUSTER_DIR}/data/node-0:/usr/share/elasticsearch/data          - ${ELASTICSEARCH_CLUSTER_DIR}/logs/node-0:/usr/share/elasticsearch/logs        environment:          - bootstrap.memory_lock=true          - cluster.name=es-doc-office          - node.name=node-0          - &quot;ES_JAVA_OPTS=-Xms2g -Xmx2g&quot;        ulimits:          memlock:            soft: -1            hard: -1        networks:          - esnet      node-1:        image: ${PRIVATE_REPO}/joylau/es-doc:${ES_VERSION}        container_name: node-1        restart: always        ports:          - 9201:9200          - 9301:9300        volumes:          - ${ELASTICSEARCH_CLUSTER_DIR}/data/node-1:/usr/share/elasticsearch/data          - ${ELASTICSEARCH_CLUSTER_DIR}/logs/node-1:/usr/share/elasticsearch/logs        environment:          - bootstrap.memory_lock=true          - cluster.name=es-doc-office          - node.name=node-1          - &quot;ES_JAVA_OPTS=-Xms2g -Xmx2g&quot;          - &quot;discovery.zen.ping.unicast.hosts=node-0&quot;        ulimits:          memlock:            soft: -1            hard: -1        networks:          - esnet      node-2:        image: ${PRIVATE_REPO}/joylau/es-doc:${ES_VERSION}        container_name: node-2        ports:          - 9202:9200          - 9302:9300        restart: always        volumes:          - ${ELASTICSEARCH_CLUSTER_DIR}/data/node-2:/usr/share/elasticsearch/data          - ${ELASTICSEARCH_CLUSTER_DIR}/logs/node-2:/usr/share/elasticsearch/logs        environment:          - bootstrap.memory_lock=true          - cluster.name=es-doc-office          - node.name=node-2          - &quot;ES_JAVA_OPTS=-Xms2g -Xmx2g&quot;          - &quot;discovery.zen.ping.unicast.hosts=master,node-1&quot;        ulimits:          memlock:            soft: -1            hard: -1        networks:          - esnet      node-3:        image: ${PRIVATE_REPO}/joylau/es-doc:${ES_VERSION}        container_name: node-3        ports:          - 9203:9200          - 9303:9300        restart: always        volumes:          - ${ELASTICSEARCH_CLUSTER_DIR}/data/node-3:/usr/share/elasticsearch/data          - ${ELASTICSEARCH_CLUSTER_DIR}/logs/node-3:/usr/share/elasticsearch/logs        environment:          - bootstrap.memory_lock=true          - cluster.name=es-doc-office          - node.name=node-3          - &quot;ES_JAVA_OPTS=-Xms2g -Xmx2g&quot;          - &quot;discovery.zen.ping.unicast.hosts=master,node-1,node-2&quot;        ulimits:          memlock:            soft: -1            hard: -1        networks:          - esnet      node-4:        image: ${PRIVATE_REPO}/joylau/es-doc:${ES_VERSION}        container_name: node-4        ports:          - 9204:9200          - 9304:9300        restart: always        volumes:          - ${ELASTICSEARCH_CLUSTER_DIR}/data/node-4:/usr/share/elasticsearch/data          - ${ELASTICSEARCH_CLUSTER_DIR}/logs/node-4:/usr/share/elasticsearch/logs        environment:          - bootstrap.memory_lock=true          - cluster.name=es-doc-office          - node.name=node-4          - &quot;ES_JAVA_OPTS=-Xms2g -Xmx2g&quot;          - &quot;discovery.zen.ping.unicast.hosts=master,node-1,node-3&quot;        ulimits:          memlock:            soft: -1            hard: -1        networks:          - esnet    networks:      esnet:</code></pre><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol><li>挂载的日志和数据文件的权限</li><li><code>vm.max_map_count</code> 数目的设置</li><li>mac 环境下注意配置 docker 的内存大小设置</li></ol><h3 id="env-init"><a href="#env-init" class="headerlink" title="env.init"></a>env.init</h3><pre><code class="bash">    #!/usr/bin/env bash    mkdir -p /home/liufa/es-data/data/{node-0,node-1,node-2,node-3,node-4} &amp;&amp; echo es-data directory created success || echo es-data directory created failure &amp;&amp; \    mkdir -p /home/liufa/es-data/logs/{node-0,node-1,node-2,node-3,node-4} &amp;&amp; echo es-logs directory created success || echo es-logs directory created failure &amp;&amp; \    groupadd elasticsearch &amp;&amp; \    useradd elasticsearch -g elasticsearch &amp;&amp; \    chown -R elasticsearch:elasticsearch /home/liufa/es-data/* &amp;&amp; \    chmod -R 777 /home/liufa/es-data/* &amp;&amp; \    echo &#39;vm.max_map_count=262144&#39; &gt;&gt; /etc/sysctl.conf &amp;&amp; \    sysctl -p</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- Elasticsearch health check failed</title>
      <link href="/2019/01/16/SpringBoot-Elasticsearch-HealthCheck/"/>
      <url>/2019/01/16/SpringBoot-Elasticsearch-HealthCheck/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="版本环境"><a href="#版本环境" class="headerlink" title="版本环境"></a>版本环境</h3><ol><li>spring boot : 2.1.2.RELEASE</li><li>spring-data-elasticsearch :3.1.4.RELEASE</li><li>elasticsearch: 6.4.3</li></ol><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>使用 spring data elasticsearch 来连接使用 elasticsearch, 配置如下:</p><pre><code class="yaml">    spring:      data:        elasticsearch:          cluster-name: docker-cluster          cluster-nodes: 192.168.10.68:9300</code></pre><p>已经确认 elasticsearch 的 9300 和 9200 端口无任何问题,均可进行连接</p><p>可是在启动项目是报出如下错误:</p><pre><code class="bash">    2019-01-16 17:17:35.376  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : no modules loaded    2019-01-16 17:17:35.378  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]    2019-01-16 17:17:35.378  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : loaded plugin [org.elasticsearch.join.ParentJoinPlugin]    2019-01-16 17:17:35.378  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]    2019-01-16 17:17:35.378  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]    2019-01-16 17:17:35.378  INFO 36410 --- [           main] o.elasticsearch.plugins.PluginsService   : loaded plugin [org.elasticsearch.transport.Netty4Plugin]    2019-01-16 17:17:36.045  INFO 36410 --- [           main] o.s.d.e.c.TransportClientFactoryBean     : Adding transport node : 192.168.10.68:9300    2019-01-16 17:17:36.740  INFO 36410 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService &#39;applicationTaskExecutor&#39;    2019-01-16 17:17:36.987  INFO 36410 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 15 endpoint(s) beneath base path &#39;/actuator&#39;    2019-01-16 17:17:37.041  INFO 36410 --- [           main] org.xnio                                 : XNIO version 3.3.8.Final    2019-01-16 17:17:37.049  INFO 36410 --- [           main] org.xnio.nio                             : XNIO NIO Implementation Version 3.3.8.Final    2019-01-16 17:17:37.091  INFO 36410 --- [           main] o.s.b.w.e.u.UndertowServletWebServer     : Undertow started on port(s) 8080 (http) with context path &#39;&#39;    2019-01-16 17:17:37.094  INFO 36410 --- [           main] cn.joylau.code.EsDocOfficeApplication    : Started EsDocOfficeApplication in 3.517 seconds (JVM running for 4.124)    2019-01-16 17:17:37.641  INFO 36410 --- [on(4)-127.0.0.1] io.undertow.servlet                      : Initializing Spring DispatcherServlet &#39;dispatcherServlet&#39;    2019-01-16 17:17:37.641  INFO 36410 --- [on(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet &#39;dispatcherServlet&#39;    2019-01-16 17:17:37.660  INFO 36410 --- [on(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 19 ms    2019-01-16 17:17:37.704  WARN 36410 --- [on(5)-127.0.0.1] s.b.a.e.ElasticsearchRestHealthIndicator : Elasticsearch health check failed    java.net.ConnectException: Connection refused        at org.elasticsearch.client.RestClient$SyncResponseListener.get(RestClient.java:943) ~[elasticsearch-rest-client-6.4.3.jar:6.4.3]        at org.elasticsearch.client.RestClient.performRequest(RestClient.java:227) ~[elasticsearch-rest-client-6.4.3.jar:6.4.3]        at org.springframework.boot.actuate.elasticsearch.ElasticsearchRestHealthIndicator.doHealthCheck(ElasticsearchRestHealthIndicator.java:61) ~[spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.health.AbstractHealthIndicator.health(AbstractHealthIndicator.java:84) ~[spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.health.CompositeHealthIndicator.health(CompositeHealthIndicator.java:98) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.health.HealthEndpoint.health(HealthEndpoint.java:50) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]        at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]        at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:246) [spring-core-5.1.4.RELEASE.jar:5.1.4.RELEASE]        at org.springframework.boot.actuate.endpoint.invoke.reflect.ReflectiveOperationInvoker.invoke(ReflectiveOperationInvoker.java:76) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.endpoint.annotation.AbstractDiscoveredOperation.invoke(AbstractDiscoveredOperation.java:61) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.endpoint.jmx.EndpointMBean.invoke(EndpointMBean.java:126) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at org.springframework.boot.actuate.endpoint.jmx.EndpointMBean.invoke(EndpointMBean.java:99) [spring-boot-actuator-2.1.2.RELEASE.jar:2.1.2.RELEASE]        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819) [na:1.8.0_131]        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801) [na:1.8.0_131]        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468) [na:1.8.0_131]        at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76) [na:1.8.0_131]        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309) [na:1.8.0_131]        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401) [na:1.8.0_131]        at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829) [na:1.8.0_131]        at sun.reflect.GeneratedMethodAccessor32.invoke(Unknown Source) ~[na:na]        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]        at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:346) [na:1.8.0_131]        at sun.rmi.transport.Transport$1.run(Transport.java:200) [na:1.8.0_131]        at sun.rmi.transport.Transport$1.run(Transport.java:197) [na:1.8.0_131]        at java.security.AccessController.doPrivileged(Native Method) [na:1.8.0_131]        at sun.rmi.transport.Transport.serviceCall(Transport.java:196) [na:1.8.0_131]        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568) [na:1.8.0_131]        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826) [na:1.8.0_131]        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683) [na:1.8.0_131]        at java.security.AccessController.doPrivileged(Native Method) [na:1.8.0_131]        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682) [na:1.8.0_131]        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]        at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]    Caused by: java.net.ConnectException: Connection refused        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.8.0_131]        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[na:1.8.0_131]        at org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvent(DefaultConnectingIOReactor.java:171) ~[httpcore-nio-4.4.10.jar:4.4.10]        at org.apache.http.impl.nio.reactor.DefaultConnectingIOReactor.processEvents(DefaultConnectingIOReactor.java:145) ~[httpcore-nio-4.4.10.jar:4.4.10]        at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor.execute(AbstractMultiworkerIOReactor.java:348) ~[httpcore-nio-4.4.10.jar:4.4.10]        at org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager.execute(PoolingNHttpClientConnectionManager.java:221) ~[httpasyncclient-4.1.4.jar:4.1.4]        at org.apache.http.impl.nio.client.CloseableHttpAsyncClientBase$1.run(CloseableHttpAsyncClientBase.java:64) ~[httpasyncclient-4.1.4.jar:4.1.4]        ... 1 common frames omitted</code></pre><p>连接被拒绝???</p><p>发现无法进行 elasticsearch 的健康检查,于是想到我使用了 actuator 进行端点健康监控</p><p>经过调试发现如下代码为返回数据:<br>ElasticsearchRestHealthIndicator 类中</p><pre><code class="java">        @Override        protected void doHealthCheck(Health.Builder builder) throws Exception {            Response response = this.client                    .performRequest(new Request(&quot;GET&quot;, &quot;/_cluster/health/&quot;));            StatusLine statusLine = response.getStatusLine();            if (statusLine.getStatusCode() != HttpStatus.SC_OK) {                builder.down();                builder.withDetail(&quot;statusCode&quot;, statusLine.getStatusCode());                builder.withDetail(&quot;reasonPhrase&quot;, statusLine.getReasonPhrase());                return;            }            try (InputStream inputStream = response.getEntity().getContent()) {                doHealthCheck(builder,                        StreamUtils.copyToString(inputStream, StandardCharsets.UTF_8));            }        }</code></pre><p><code>new Request(&quot;GET&quot;, &quot;/_cluster/health/&quot;)</code> 正是 elasticsearch 健康的请求,但是没有看到 host 和 port</p><p>于是用抓包工具发现其请求的是 <code>127.0.0.1:9200</code></p><p>那这肯定是 springboot 的默认配置了</p><h3 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h3><p>查看 <code>spring-boot-autoconfigure-2.1.2.RELEASE.jar</code><br>找到 elasticsearch 的配置 <code>org.springframework.boot.autoconfigure.elasticsearch</code><br>在找到类 <code>RestClientProperties</code><br>看到如下源码:</p><pre><code class="java">    @ConfigurationProperties(prefix = &quot;spring.elasticsearch.rest&quot;)    public class RestClientProperties {        /**         * Comma-separated list of the Elasticsearch instances to use.         */        private List&lt;String&gt; uris = new ArrayList&lt;&gt;(                Collections.singletonList(&quot;http://localhost:9200&quot;));        /**         * Credentials username.         */        private String username;        /**         * Credentials password.         */        private String password;        public List&lt;String&gt; getUris() {            return this.uris;        }        public void setUris(List&lt;String&gt; uris) {            this.uris = uris;        }        public String getUsername() {            return this.username;        }        public void setUsername(String username) {            this.username = username;        }        public String getPassword() {            return this.password;        }        public void setPassword(String password) {            this.password = password;        }    }</code></pre><p><code>Collections.singletonList(&quot;http://localhost:9200&quot;));</code> 没错了,这就是错误的起因</p><p>顺藤摸瓜, 根据 <code>spring.elasticsearch.rest</code> 的配置,配置好 <code>uris</code> 即可</p><p>于是进行如下配置:</p><pre><code class="yaml">    spring:      data:        elasticsearch:          cluster-name: docker-cluster          cluster-nodes: 192.168.10.68:9300      elasticsearch:        rest:          uris: [&quot;http://192.168.10.68:9200&quot;]</code></pre><p>集群中的多个节点就写多个</p><p>启动,没有出现错误</p><p>还有一种方式也可以解决,但是并不是一种好的解决方式,那就是关闭 actuator 对 elasticsearch 的健康检查</p><pre><code class="yaml">    management:      health:        elasticsearch:          enabled: false</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle 构建 elastic-job 项目的奇怪依赖问题</title>
      <link href="/2019/01/14/Gradle-Elastic-Job-Dependency/"/>
      <url>/2019/01/14/Gradle-Elastic-Job-Dependency/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li>按照官网的说法, gradle 的配置如下:</li></ol><pre><code class="groovy">        compile (&#39;com.dangdang:elastic-job-lite-core:2.1.5&#39;)        compile (&#39;com.dangdang:elastic-job-lite-spring:2.1.5&#39;)</code></pre><ol start="2"><li>这样配置后,写好示例代码,发现始终连接不上 zookeeper,抛出以下错误:</li></ol><pre><code class="java">    ***************************    APPLICATION FAILED TO START    ***************************    Description:    An attempt was made to call the method org.apache.curator.framework.api.CreateBuilder.creatingParentsIfNeeded()Lorg/apache/curator/framework/api/ProtectACLCreateModePathAndBytesable; but it does not exist. Its class, org.apache.curator.framework.api.CreateBuilder, is available from the following locations:        jar:file:/Users/joylau/.gradle/caches/modules-2/files-2.1/org.apache.curator/curator-framework/4.0.1/3da85d2bda41cb43dc18c089820b67d12ba38826/curator-framework-4.0.1.jar!/org/apache/curator/framework/api/CreateBuilder.class    It was loaded from the following location:        file:/Users/joylau/.gradle/caches/modules-2/files-2.1/org.apache.curator/curator-framework/4.0.1/3da85d2bda41cb43dc18c089820b67d12ba38826/curator-framework-4.0.1.jar    Action:    Correct the classpath of your application so that it contains a single, compatible version of org.apache.curator.framework.api.CreateBuilder</code></pre><ol start="3"><li><p>一开始我以为是搭建的 zookeeper 环境有问题,但是用其他工具可以连接的上</p></li><li><p>又怀疑是 zookeeper 的版本问题,查看了 <code>com.dangdang:elastic-job-common-core:2.1.5</code> , 发现其依赖的 zookeeper 版本是 <code>org.apache.zookeeper:zookeeper:3.5.3-beta</code></p></li><li><p>于是又用 docker 搭建了个 3.5.3-beta 的版本的 zookeeper 单机版</p></li><li><p>结果问题依旧…….</p></li><li><p>中间查找问题花费了很长的时间…..</p></li><li><p>后来把官方的 demo clone 到本地跑次看看,官方的 demo 仅仅依赖一个包 <code>com.dangdang:elastic-job-lite-core:2.1.5</code></p></li><li><p>发现这个 demo 没有问题,可以连接的上 zookeeper</p></li><li><p>对比发现2个项目的依赖版本号不一致</p></li></ol><p><img src="http://image.joylau.cn/blog/elastic-job-gradle-dependencies.png" alt="对比图"></p><ol start="11"><li><p>看到 demo 里依赖的 <code>org.apache.curator:curator-framework</code> 和 <code>org.apache.curator:curator-recipes</code> 都是 2.10.0, 而我引入的版本却是gradle 上的最新版 4.0.1, 而且也能看到2者的 zookeeper 的版本也不一致,一个是 3.4.6,一个是 3.5.3-beta</p></li><li><p>问题所在找到了</p></li><li><p>解决问题</p></li></ol><pre><code class="groovy">    compile (&#39;com.dangdang:elastic-job-lite-core:2.1.5&#39;)    compile (&#39;com.dangdang:elastic-job-lite-spring:2.1.5&#39;)    compile (&#39;org.apache.curator:curator-framework:2.10.0&#39;)    compile (&#39;org.apache.curator:curator-recipes:2.10.0&#39;)</code></pre><ol start="14"><li><p>手动声明版本为 2.10.0</p></li><li><p>问题解决,但是为什么 gradle 会造成这样的问题? 为什么传递依赖时, gradle 会去找最新的依赖版本? 这些问题我还没搞清楚….</p></li><li><p>日后搞清楚了,或者有眉目了,再来更新这篇文章.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Gradle篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Jdk 8 Stream 的使用记录</title>
      <link href="/2018/12/24/JDK8-Stream-Use/"/>
      <url>/2018/12/24/JDK8-Stream-Use/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="LocalDateTime-将-long-格式的时间转化本地时间字符串"><a href="#LocalDateTime-将-long-格式的时间转化本地时间字符串" class="headerlink" title="LocalDateTime 将 long 格式的时间转化本地时间字符串"></a>LocalDateTime 将 long 格式的时间转化本地时间字符串</h2><pre><code class="java">    LocalDateTime            .ofEpochSecond(System.currentTimeMillis() / 1000, 0, ZoneOffset.ofHours(8))            .format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;))</code></pre><h2 id="reduce-导致的源集合对象改变"><a href="#reduce-导致的源集合对象改变" class="headerlink" title="reduce 导致的源集合对象改变"></a>reduce 导致的源集合对象改变</h2><p>例如下属代码导致 images 里的 DataImage 对象里的 stake 对象的数量改变</p><pre><code class="java">     Map&lt;String,List&lt;HighwayStake&gt;&gt; roadStakeMap = images.stream()                    .filter(image -&gt; !image.getStakes().isEmpty())                    .map(DataImage::getStakes())                    .reduce((highwayStakes, highwayStakes2) -&gt; {                        highwayStakes2.addAll(highwayStakes);                        return highwayStakes2;                    })                    .orElse(new ArrayList&lt;&gt;())                    .stream()                    .collect(Collectors.groupingBy(HighwayStake::getDlmc));</code></pre><p>因为对 dataImage 的 stakes 集合进行了合并,将 map 操作改为 复制一个新的 list , 而不是操作原来的 stakes</p><pre><code class="java">     Map&lt;String,List&lt;HighwayStake&gt;&gt; roadStakeMap = images.stream()                    .filter(image -&gt; !image.getStakes().isEmpty())                    .map(dataImage -&gt; new ArrayList&lt;&gt;(dataImage.getStakes()))                    .reduce((highwayStakes, highwayStakes2) -&gt; {                        highwayStakes2.addAll(highwayStakes);                        return highwayStakes2;                    })                    .orElse(new ArrayList&lt;&gt;())                    .stream()                    .collect(Collectors.groupingBy(HighwayStake::getDlmc));</code></pre><h2 id="List-的深度拷贝"><a href="#List-的深度拷贝" class="headerlink" title="List 的深度拷贝"></a>List 的深度拷贝</h2><p>上述的问题实际上是一个 list 的拷贝,而且是 浅度复制</p><p><code>new ArrayList&lt;&gt;(list)</code> 和 <code>Collections.copy(dest,src)</code> 都是浅度复制</p><p>下面代码是一个靠谱的 深度拷贝, 需要 T 实现序列化接口</p><pre><code class="java">    /**     * list 深度复制     */    public static &lt;T&gt; List&lt;T&gt; deepCopy(List&lt;T&gt; source) {        ByteArrayOutputStream byteOut = new ByteArrayOutputStream();        List&lt;T&gt; dest = new ArrayList&lt;&gt;();        try {            ObjectOutputStream out = new ObjectOutputStream(byteOut);            out.writeObject(source);            ByteArrayInputStream byteIn = new ByteArrayInputStream(byteOut.toByteArray());            ObjectInputStream in = new ObjectInputStream(byteIn);            dest = (List&lt;T&gt;) in.readObject();        } catch (IOException | ClassNotFoundException e) {            e.printStackTrace();        }        return dest;    }</code></pre><h2 id="reduce-使用记录"><a href="#reduce-使用记录" class="headerlink" title="reduce() 使用记录"></a>reduce() 使用记录</h2><p>reduce 有三种方法可以使用:</p><ul><li><code>Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator)</code></li><li><code>T reduce(T identity, BinaryOperator&lt;T&gt; accumulator)</code></li><li><code>&lt;U&gt; U reduce(U identity,BiFunction&lt;U, ? super T, U&gt; accumulator,BinaryOperator&lt;U&gt; combiner)</code></li></ul><p>第一种传入二元运算表达式,第二种是带初始值的二元运算表达式,这里着重记录下第三种的使用方式</p><p>第三种第一个参数方法的返回值类型,<br>第二个参数是一个二元运算表达式,这个表达式的第一个参数是方法的返回值,也就是方法的第一个参数,第二个参数是 Stream 里的值<br>第三个参数也是一个二元运算表达式,表达式的2个参数都是方法返回值的类型,用于对返回值类型的操作</p><p>第三个参数在非并发的情况下返回任何类型(甚至是 null)都没有影响,因为在非并发情况下,第三个二元表达式根本不会执行</p><p>那么第三个二元表达式用在并发的情况下,在并发的情况下,第二个二元表达式的第一个参数始终是方法的第一个类型,第三个三元表达式用于将不同线程操作的结果汇总起来</p><h2 id="map-和-flatMap"><a href="#map-和-flatMap" class="headerlink" title="map() 和 flatMap()"></a>map() 和 flatMap()</h2><p>区别在于, map() 返回自定义对象, 而 flatMap() 返回 Stream 流对象</p><h2 id="distinct-使用记录"><a href="#distinct-使用记录" class="headerlink" title="distinct() 使用记录"></a>distinct() 使用记录</h2><p>最近在 lamda 的 stream 进行 list 去重复的时候，发现没有生效<br>代码如下：</p><pre><code class="java">    Map&lt;String, Map&lt;String, List&lt;FollowAnalysisPojo&gt;&gt;&gt; maps = allList                .parallelStream()                .distinct()                .collect(Collectors.groupingBy(FollowAnalysisPojo::getMainPlateNum,Collectors.groupingBy(FollowAnalysisPojo::getPlateNum)));</code></pre><p>实体类：</p><pre><code class="java">    @Data    public class FollowAnalysisPojo {        /*被跟车牌*/        private String mainPlateNum;        /*跟踪车牌*/        private String plateNum;        private String vehicleType;        private String siteName;        private String directionName;        /*车主时间*/        private String passTimeMain;        /*伴随时间*/        private String passTimeSub;        /*跟踪次数*/        private Integer trackCount;        /*该条记录被跟踪车占据的行数，用于在前端合并单元格*/        private Integer mainRowSpan = 0;        /*该条记录跟踪车占据的行数，用于在前端合并单元格*/        private Integer rowSpan;        private String key = UUID.randomUUID().toString();      }</code></pre><p>上面的代码是想做 先对查询出来的数据进行去重复的操作，然后在按照被跟车牌和跟踪车牌进行分组操作<br>有点需要说明的是 <code>parallelStream()</code> 比我们常用的 <code>stream()</code> 是并行多管操作，速度上更快</p><p>然后发现的问题是并没有去重复，当时也在奇怪 distinct() 里并没有任何参数来指定如何使用规则来去重复</p><h3 id="正解"><a href="#正解" class="headerlink" title="正解"></a>正解</h3><p>重写List中实体类的 <code>equals()</code> 方法</p><pre><code class="java">    @Data    public class FollowAnalysisPojo {        ......        /**         * 当车主时间,伴随时间都相同时，则认为是一个对象         * @param obj 对象         * @return Boolean         */        @Override        public boolean equals(Object obj) {            if(!(obj instanceof FollowAnalysisPojo))return false;            FollowAnalysisPojo followAnalysisPojo = (FollowAnalysisPojo)obj;            return passTimeMain.equals(followAnalysisPojo.passTimeMain) &amp;&amp; passTimeSub.equals(followAnalysisPojo.passTimeSub);        }    }</code></pre><p>这样我们就按照我自定义的规则进行去重复了<br>运行了一下，发现还是不起作用<br>debug了一下，发现根本没有执行重写的 equals 方法<br>原来还需要重写 <code>hashCode()</code> 方法<br>在 <code>equals()</code> 方法 执行前会先执行 <code>hashCode()</code> 方法</p><pre><code class="java">    @Data    public class FollowAnalysisPojo {        ......        /**         * 重新 equals 方法必须重新 hashCode方法         * @return int         */        @Override        public int hashCode(){            int result = passTimeMain.hashCode();            result = 31 * result + passTimeMain.hashCode();            return result;        }    }</code></pre><p>这样就可以了。</p><h3 id="2018-9-13-更新"><a href="#2018-9-13-更新" class="headerlink" title="2018-9-13 更新"></a>2018-9-13 更新</h3><p>如果我们不重写方法，有没有办法按照List中bean的某个属性来去重复呢？答案是有的，利用的是 stream 的 reduce，用一个set 来存放 key,代码如下：</p><pre><code class="java">    List&lt;JSONObject&gt; result = trails.stream()                .filter(distinctByKey(VehicleTrail::getPlateNbr))                .collect(Collectors.toList());    private  &lt;T&gt; Predicate&lt;T&gt; distinctByKey(Function&lt;? super T, ?&gt; keyExtractor) {        Set&lt;Object&gt; seen = ConcurrentHashMap.newKeySet();        return t -&gt; seen.add(keyExtractor.apply(t));    }</code></pre><h2 id="2个集合的元素两两组合成一个-n-m-的集合"><a href="#2个集合的元素两两组合成一个-n-m-的集合" class="headerlink" title="2个集合的元素两两组合成一个 n * m 的集合"></a>2个集合的元素两两组合成一个 n * m 的集合</h2><pre><code class="java">    Integer[] xs = new Integer[]{3, 4};    Integer[] ys = new Integer[]{5, 6};    List&lt;Image&gt; images = Arrays.stream(xs).flatMap(x -&gt; Arrays.stream(ys).map(y -&gt; new Image(x,y))).collect(Collectors.toList());</code></pre><h2 id="集合合并"><a href="#集合合并" class="headerlink" title="集合合并"></a>集合合并</h2><p>比如: List&lt;List<Demo>&gt; list 将所有的 Demo 合并到一个集合;</p><ol><li>reduce</li></ol><pre><code class="java">    // 第一种    List&lt;Demo&gt; demos  = list.stream().reduce(new ArrayList&lt;&gt;(),(demo1,demo2) -&gt; {demo1.addAll(demo2); return demo2;});    // 第二种    List&lt;Demo&gt; demos  = list.stream().reduce(new ArrayList&lt;&gt;(),(demo1,demo2) -&gt; Stream.concat(demo1.stream(),demo2.stream()).collect(Collectors.toList()));</code></pre><ol start="2"><li>flatMap</li></ol><pre><code class="java">    List&lt;Demo&gt; demos = list.stream().flatMap(Collection::stream).collect(Collectors.toList());</code></pre>]]></content>
      
      
      <categories>
          
          <category> Java篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker exec failed docker 无法进入容器问题解决</title>
      <link href="/2018/12/19/Docker-Exec-Failed/"/>
      <url>/2018/12/19/Docker-Exec-Failed/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="无法进入容器"><a href="#无法进入容器" class="headerlink" title="无法进入容器"></a>无法进入容器</h3><p>docker exec -it name /bin/sh 失败,<br>查看容器 inspect 报错信息如下:</p><pre><code class="bash">    pc error: code = 2 desc = oci runtime error: exec failed:     container_linux.go:247: starting container process caused &quot;process_linux.go:110:     decoding init error from pipe caused \&quot;read parent: connection reset by peer\&quot;&quot;</code></pre><h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><ol><li>docker 版本为: Docker version 1.13.1, build 07f3374/1.13.1</li><li>centos 版本为: CentOS Linux release 7.3.1611 (Core) </li><li>错误原因: 似乎是 docker RPM 软件包的更新时引入的错误。一个临时的解决方法是将所有docker软件包降级到以前的版本（1.13.1-75似乎可以）</li></ol><h3 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h3><pre><code class="shell">    yum downgrade docker docker-client docker-common</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker-Compose 中多容器启动顺序问题</title>
      <link href="/2018/12/19/Docker-Compose-StartOrder/"/>
      <url>/2018/12/19/Docker-Compose-StartOrder/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>我们在 docker-compose 一条命令就启动我们的多个容器时,需要考虑到容器之间的启动顺序问题…..</p><p>比如有的服务依赖数据库的启动, service 依赖 eureka 的启动完成</p><p>docker compose 里有 depends_on 配置,但是他不能等上一个容器里的服务完全启动完成,才启动下一个容器,这仅仅定义了启动的顺序, 那么这就会导致很多问题的发生</p><p>比如应用正在等待数据库就绪,而此时数据库正在初始化数据, 导致无法连接退出等等</p><h3 id="官方的做法"><a href="#官方的做法" class="headerlink" title="官方的做法"></a>官方的做法</h3><p>地址 : <a href="https://docs.docker.com/compose/startup-order/" target="_blank" rel="noopener">https://docs.docker.com/compose/startup-order/</a><br>官方的思路是使用一个脚本,轮询给定的主机和端口，直到它接受 TCP 连接<br>个人感觉这种方式不是很好</p><p>还有几个开源的工具解决方法, 这些是一些小型脚本,和上面的原理类似:</p><ol><li>wait-for-it : <a href="https://github.com/vishnubob/wait-for-it" target="_blank" rel="noopener">https://github.com/vishnubob/wait-for-it</a></li><li>dockerize : <a href="https://github.com/jwilder/dockerize" target="_blank" rel="noopener">https://github.com/jwilder/dockerize</a></li><li>wait-for : <a href="https://github.com/Eficode/wait-for" target="_blank" rel="noopener">https://github.com/Eficode/wait-for</a></li></ol><p>这些工具也能解决问题,但有很大的局限性: 需要重新定义 command , 在执行完自己的脚本后在执行容器里的启动脚本</p><p>如果不知道容器的启动脚本或者容器的启动脚本很长,并且带有参数,那将非常头疼</p><p>查看容器的启动脚本:</p><pre><code class="bash">    docker ps --no-trunc --format=&quot;table {{.ID}}\t{{.Command}}:&quot;</code></pre><p>或者</p><pre><code class="bash">    docker inspect container</code></pre><h3 id="health-健康检查方法"><a href="#health-健康检查方法" class="headerlink" title="health 健康检查方法"></a>health 健康检查方法</h3><p>比如下面的配置</p><pre><code class="yaml">      server:        image: 34.0.7.183:5000/joylau/traffic-service-server:1.2.0        container_name: traffic-service-server        ports:          - 9368:9368        restart: always        volumes:          - /Users/joylau/log/server:/home/liufa/app/server/logs        environment:          activeProfile: prod        hostname: traffic-service-eureka        healthcheck:          test: &quot;/bin/netstat -anp | grep 9367&quot;          interval: 10s          timeout: 3s          retries: 1      admin:        image: 34.0.7.183:5000/joylau/traffic-service-admin:1.2.0        container_name: traffic-service-admin        ports:          - 9335:9335        restart: always        volumes:          - /Users/joylau/log/admin:/home/liufa/app/admin/logs        environment:          activeProfile: prod        depends_on:          server:            condition: service_healthy        hostname: traffic-service-admin        links:          - server:traffic-service-eureka</code></pre><p>server 使用了健康检查 healthcheck</p><ul><li><code>test</code> : 命令,必须是字符串或列表，如果它是一个列表，第一项必须是 NONE，CMD 或 CMD-SHELL ；如果它是一个字符串，则相当于指定CMD-SHELL 后跟该字符串, 例如: <code>test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;]</code> 或者 <code>test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost || exit 1&quot;]</code>  或者 <code>test: curl -f https://localhost || exit 1</code></li><li><code>interval</code>: 每次执行的时间间隔</li><li><code>timeout</code>: 每次执行时的超时时间,超过这个时间,则认为不健康</li><li><code>retries</code>: 重试次数,如果 retries 次后都是失败,则认为容器不健康</li><li><code>start_period</code>: 启动后等待多次时间再做检查, version 2.3 版本才有</li></ul><p>interval, timeout, start_period 格式如下:</p><pre><code class="text">    2.5s    10s    1m30s    2h32m    5h34m56s</code></pre><p>健康状态返回 0 (health) 1 (unhealth) 2(reserved)</p><p>test 命令的通用是 <code>&#39;xxxx &amp;&amp; exit 0 || exit 1&#39;</code> , 2 一般不使用</p><p>admin depends_on server ,且条件是 service_healthy ,即容器为健康状态,即 9368 端口开启</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><ol><li>depends_on 在 2.0 版本就有, healthcheck 在 2.1 版本上才添加,因此上述的写法至少在 docker-compose  version: ‘2.1’ 版本中才生效</li><li>docker-compose version 3 将不再支持 depends_on 中的 condition 条件</li><li>depends_on 在 version 3 中以 docker swarm 模式部署时,将被忽略</li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Docker-Compose </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud --- Docker 部署问题记录</title>
      <link href="/2018/12/18/SpringCloud-Docker/"/>
      <url>/2018/12/18/SpringCloud-Docker/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Docker-容器中-IP-的配置"><a href="#Docker-容器中-IP-的配置" class="headerlink" title="Docker 容器中 IP 的配置"></a>Docker 容器中 IP 的配置</h3><p>将 spring cloud 项目部署到 docker 容器中后,虽然可以配置容器的端口映射到宿主机的端口<br>但是在 eureka 界面显示的instance id 是一串随机的字符串,类似于 d97d725bf6ae 这样的<br>但是,事实上,我们想让他显示出 IP ,这样我们可以直接点击而打开 info 端点信息</p><p>修改 3 处配置项:</p><pre><code class="yaml">    eureka:      client:        service-url:          defaultZone: http://34.0.7.183:9368/eureka/      instance:        prefer-ip-address: true        instance-id: ${eureka.instance.ip-address}:${server.port}        ip-address: 34.0.7.183</code></pre><ol><li><code>eureka.instance.prefer-ip-address</code> 配置为 true , 表示 instance 使用 ip 配置</li><li><code>eureka.instance.prefer-ip-address</code> 配置当前 instance 的物理 IP</li><li><code>eureka.instance.prefer-instance-id</code> 界面上的 instance-id 显示为 ip + 端口</li></ol><h3 id="docker-compose-的解决方法"><a href="#docker-compose-的解决方法" class="headerlink" title="docker-compose 的解决方法"></a>docker-compose 的解决方法</h3><p>通常情况下,我们使用 springcloud 都会有很多的服务需要部署,就会产生很多的容器,这么多的容器再使用 docker 一个个操作就显得很复杂<br>这时候需要一个编排工具,于是我们就使用 docker-compose 来部署 springcloud 服务</p><ol><li>修改 eureka 的配置</li></ol><pre><code class="yaml">    spring:      application:        name: traffic-service-eureka    eureka:      instance:        hostname: ${spring.application.name}    </code></pre><p>使用 docker-compose 我们放弃使用 ip 来进行容器间的相互通信,继而使用 hostname,这就相当于在 <code>/etc/hosts</code> 添加了一条记录</p><ol start="2"><li>接下来所有的 eureka 的 client 都使用 traffic-service-eureka 这个 hostname 来连接</li></ol><pre><code class="yaml">    eureka:      client:        service-url:          defaultZone: http://traffic-service-eureka:9368/eureka/</code></pre><ol start="3"><li>如果说想在 eureka 的界面上能够直接显示宿主机的 IP 和 连接地址的话,还需要设置</li></ol><pre><code class="yaml">    eureka:      instance:        prefer-ip-address: true        instance-id: ${eureka.instance.ip-address}:${server.port}        ip-address: 34.0.7.183</code></pre><ol start="4"><li>docker-compose 的配置:</li></ol><pre><code class="yaml">        server:          image: 34.0.7.183:5000/joylau/traffic-service-server:1.2.0          container_name: traffic-service-server          ports:            - 9368:9368          restart: always          volumes:            - /Users/joylau/log/server:/home/liufa/app/server/logs          environment:            activeProfile: prod          hostname: traffic-service-eureka          healthcheck:            test: &quot;/bin/netstat -anp | grep 9368&quot;            interval: 10s            timeout: 3s            retries: 1        admin:          image: 34.0.7.183:5000/joylau/traffic-service-admin:1.2.0          container_name: traffic-service-admin          ports:            - 9335:9335          restart: always          volumes:            - /Users/joylau/log/admin:/home/liufa/app/admin/logs          environment:            activeProfile: prod          depends_on:            server:              condition: service_healthy          hostname: traffic-service-admin          links:            - server:traffic-service-eureka</code></pre><p>service 模块 links server 模块,再起个别名 traffic-service-eureka ,因为我配置文件里配置的是 traffic-service-eureka,<br>这样 service 模块就可以通过 server 或者 traffic-service-eureka 来访问 server 了</p><p>另外,配置的 hostname,可以进入 容器中查看 <code>/etc/hosts</code> 该配置会在 文件中生成一个容器的 ip 和 hostname 的记录</p><h3 id="多个服务加载顺序问题"><a href="#多个服务加载顺序问题" class="headerlink" title="多个服务加载顺序问题"></a>多个服务加载顺序问题</h3><p>详见 : <a href="http://blog.joylau.cn/2018/12/19/Docker-Compose-StartOrder/">http://blog.joylau.cn/2018/12/19/Docker-Compose-StartOrder/</a></p>]]></content>
      
      
      <categories>
          
          <category> SpringCloud篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS 上路由表的操作记录</title>
      <link href="/2018/12/14/MacOS-Route/"/>
      <url>/2018/12/14/MacOS-Route/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li><p>查看路由表: <code>netstat -nr</code></p></li><li><p>添加路由: <code>sudo route add 34.0.7.0 34.0.7.1</code></p></li><li><p>删除路由: <code>sudo route delete 0.0.0.0</code></p></li><li><p>清空路由表: <code>networksetup -setadditionalroutes &quot;Ethernet&quot;</code>,  “Ethernet” 指定路由走哪个设备（查看当前的设备可以使用这个命令 <code>networksetup -listallnetworkservices</code></p></li><li><p>清空路由表: <code>sudo route flush</code> , 是否有效没测试过,通过 <code>man route</code> 看到的,等哪天试过了,再来更新这个内容是否有效</p></li></ol><h3 id="无线网卡和-USB-有线网卡同时使用"><a href="#无线网卡和-USB-有线网卡同时使用" class="headerlink" title="无线网卡和 USB 有线网卡同时使用"></a>无线网卡和 USB 有线网卡同时使用</h3><p>我这里的使用场景是无线接外网, USB 网卡接内网,无线路由的网关是 192.168.0.1, USB 网卡的网关是 34.0.7.1</p><ol><li><p>删除默认路由: <code>sudo route delete 0.0.0.0</code></p></li><li><p>添加默认路由走无线网卡: <code>sudo route add 0.0.0.0 192.168.0.1</code></p></li><li><p>内网走 USB 网卡: <code>sudo route add 34.0.7.0 34.0.7.1</code></p></li><li><p>调整网络顺序,网络属性里面的多个网卡的优先级顺序问题。基本原则是哪个网卡访问互联网，他的优先级就在上面就可以了</p></li></ol><blockquote><p>有个问题没搞明白, 按逻辑说这样添加的静态路由是临时的,在重启后会消失失效,可实际上我重启了之后并没有失效</p></blockquote><h3 id="配置永久静态路由"><a href="#配置永久静态路由" class="headerlink" title="配置永久静态路由"></a>配置永久静态路由</h3><ol><li><p><code>networksetup</code> mac 自带的工具,升级到最新的Sierra后拥有,是个“系统偏好设置”中网络设置工具的终端版</p></li><li><p><code>networksetup –help</code> 可以查看具体的帮助</p></li><li><p>添加静态永久路由: <code>networksetup -setadditionalroutes &quot;USB 10/100/1000 LAN&quot; 10.188.12.0 255.255.255.0 192.168.8.254</code><br> “USB 10/100/1000 LAN” 指定路由走哪个设备（查看当前的设备可以使用这个命令 <code>networksetup -listallnetworkservices</code> </p></li><li><p><code>netstat -nr</code> 查看路由表</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 定时删除 10 天前的日志文件</title>
      <link href="/2018/12/13/Linux-Cron/"/>
      <url>/2018/12/13/Linux-Cron/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们的程序在 Linux 上运行会产生大量日志文件,这些日志文件如果不定时清理的话会很快将磁盘占满</p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><pre><code class="bash">    # For details see man 4 crontabs    # Example of job definition:    # .---------------- minute (0 - 59)    # |  .------------- hour (0 - 23)    # |  |  .---------- day of month (1 - 31)    # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...    # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat    # |  |  |  |  |    # *  *  *  *  * user-name  command to be executed</code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="配置一个定时清理的任务"><a href="#配置一个定时清理的任务" class="headerlink" title="配置一个定时清理的任务"></a>配置一个定时清理的任务</h3><ol><li><code>crontab -e</code> , 添加一个定时任务, 或者 <code>vim /etc/crontab</code> 添加一条记录</li></ol><pre><code class="bash">    10 0 * * * /home/liufa/app/cron/del_log.sh &gt; /dev/null 2&gt;&amp;1 &amp;</code></pre><pre><code class="bash">    10 0 * * * root sh /home/liufa/app/cron/del_log.sh &gt; /dev/null 2&gt;&amp;1 &amp;</code></pre><p>每天 0 点 10 分运行上述命令文件</p><ol start="2"><li><p>创建文件: del_log.sh</p></li><li><p>授权 <code>chmod +x ./del_log.sh</code></p></li><li><p>删除 10 天的日志文件 </p></li></ol><pre><code class="bash">    #!/usr/bin/env bash    find /home/liufa/app/node/logs -mtime +10 -name &quot;*.log&quot; -exec rm -rf {} \;</code></pre><ol start="4"><li>重启定时任务, <code>systemctl restart crond</code> , 在 Ubuntu 上叫 cron <code>systemctl restart cron</code></li></ol><h3 id="关于定时任务的配置目录"><a href="#关于定时任务的配置目录" class="headerlink" title="关于定时任务的配置目录"></a>关于定时任务的配置目录</h3><ol><li><code>/etc/crontab</code> 文件, 系统级别的定时任务,需要加入用户名</li><li><code>/var/spool/cron</code> 目录, 以用户作为区分,一般会有一个和用户名相同的文件,里面记录了定时任务, 一般使用 crontab -e 创建, 语法中不需要指定用户名</li><li><code>/etc/cron.d/</code> 和 crontab 文件类似,需要指定用户名</li></ol><p>cron执行时，也就是要读取三个地方的配置文件</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol><li>执行脚本使用/bin/sh（防止脚本无执行权限），要执行的文件路径是从根开始的绝对路径（防止找不到文件）</li><li>尽量把要执行的命令放在脚本里，然后把脚本放在定时任务里。对于调用脚本的定时任务，可以把标准输出错误输出重定向到空。</li><li>定时任务中带%无法执行，需要加\转义</li><li>如果时上有值，分钟上必须有值</li><li>日和周不要同时使用，会冲突</li><li><code>&gt;&gt;</code> 与 <code>&gt;/dev/null 2&gt;&amp;1</code> 不要同时存在</li></ol><h3 id="日志位置"><a href="#日志位置" class="headerlink" title="日志位置"></a>日志位置</h3><p>日志位置位于 <strong>/var/log/cron.log</strong>,如果没有看到日志,可能由于没有开启 cron 日志记录,开启方法: </p><p><code>vim /etc/rsyslog.d/50-default.conf</code></p><p>/var/log/cron.log相关行，将前面注释符#去掉</p><p>重启 rsyslog</p><p><code>service rsyslog  restart</code></p><p>或者查看系统日志, 使用命令:</p><p><code>grep cron /var/log/syslog</code></p><p>能看到和 cron 相关的日志信息</p><h3 id="任务脚本中变量不生效"><a href="#任务脚本中变量不生效" class="headerlink" title="任务脚本中变量不生效"></a>任务脚本中变量不生效</h3><p>在脚本里除了一些自动设置的全局变量,可能有些变量没有生效, 当手动执行脚本OK，但是crontab死活不执行时,在脚本里使用下面的方式</p><p>1）脚本中涉及文件路径时写全局路径；<br>2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量</p><pre><code class="bash">    #!/bin/sh    source /etc/profile</code></pre><p>3) */1 * * * * . /etc/profile;/bin/sh /path/run.sh</p>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Cron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 问题记录</title>
      <link href="/2018/12/13/Docker-Questions/"/>
      <url>/2018/12/13/Docker-Questions/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="时区问题"><a href="#时区问题" class="headerlink" title="时区问题"></a>时区问题</h3><h4 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h4><p>时区的配置在 <code>/etc/localtime</code></p><p>localtime 文件会指向 <code>/usr/share/zoneinfo/Asia/</code> 目录下的某个文件</p><p>我们只需要将其指向 ShangHai 即可</p><p>Dockerfile 可以这样配置</p><pre><code class="bash">    RUN rm -rf /etc/localtime &amp;&amp; \        ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</code></pre><p>先删除,在创建一个软连接即可</p><p>如果是在容器内直接操作的话:</p><ol><li>apt-get install tzdata</li><li>然后依次选择 6 , 70 即可</li><li>使用 dpkg-reconfigure tzdata 来重写选择</li></ol><h4 id="已构建好的镜像"><a href="#已构建好的镜像" class="headerlink" title="已构建好的镜像"></a>已构建好的镜像</h4><p>启动一个容器，加上如下参数，即可使用宿主机时间</p><pre><code class="bash">    -v /etc/localtime:/etc/localtime:ro</code></pre><h4 id="已经在运行的容器"><a href="#已经在运行的容器" class="headerlink" title="已经在运行的容器"></a>已经在运行的容器</h4><pre><code class="bash">    docker cp /etc/localtime [container]:/etc/localtime</code></pre><p>在检查下是否修改成功:</p><pre><code class="bash">    docker exec [container] date</code></pre><h4 id="springboot-应用的时区"><a href="#springboot-应用的时区" class="headerlink" title="springboot 应用的时区"></a>springboot 应用的时区</h4><p>如果构建的 springboot 项目的镜像,基于 jib 插件构建的话,并且基础镜像选择的是 openjdk:8<br>那么这时 <code>jvmFlags</code> 参数加上一个 <code>-Duser.timezone=GMT+08</code> boot 服务启动时会使用东八区的时间<br>而且这不会改变容器的时区,如果你进入容器,执行 date 打印的话,还是会发现时间少 8 个小时<br>但是对于应用来说已经没有问题了</p><h4 id="mariadb-容器的时区"><a href="#mariadb-容器的时区" class="headerlink" title="mariadb 容器的时区"></a>mariadb 容器的时区</h4><p>默认官方的 mariadb 的镜像时区是 0 时区的,想要改变的话,添加执行参数 <code>--default-time-zone=&#39;+8:00&#39;</code><br>完整 docker-compose.yml</p><pre><code class="yaml">      db:        image: mariadb        container_name: mariadb        restart: always        networks:          - job-net        ports:          - 3306:3306        volumes:          - /home/liufa/joy-job/db-data:/var/lib/mysql        environment:          - MYSQL_ROOT_PASSWORD=123456          - MYSQL_ROOT_HOST=%        command: --default-time-zone=&#39;+8:00&#39;</code></pre><h3 id="pm2-web-命令错误问题"><a href="#pm2-web-命令错误问题" class="headerlink" title="pm2-web 命令错误问题"></a>pm2-web 命令错误问题</h3><p>通常我们都是将 node_modules 文件夹直接复制到镜像中</p><p>有时候会出现问题,就比如 pm2-web ,构建成镜像后,命令无法使用</p><p>原因在于开发的机器的操作系统和镜像的操作系统不一致,会导致一些包出问题</p><p>解决的方式就是重新 <code>nmp install</code></p><p>Dockerfile 如下:</p><pre><code class="bash">    RUN rm -rf ./node_modules &amp;&amp; \        rm -rf ./package-lock.json &amp;&amp; \        npm install</code></pre><h3 id="更改-docker数据目录"><a href="#更改-docker数据目录" class="headerlink" title="更改 docker数据目录"></a>更改 docker数据目录</h3><p>默认安装的 docker 数据目录在 <code>/var/lib/docker</code> 下<br>想要更改的话<br>在 docker 的 service 文件添加参数 <code>--graph=/home/lifa</code><br>之后重启 docker 服务</p><h3 id="查看-docker-使用的空间"><a href="#查看-docker-使用的空间" class="headerlink" title="查看 docker 使用的空间"></a>查看 docker 使用的空间</h3><p>有时我们下载镜像和运行的容器多了,会占用很多磁盘,该怎么查看呢?<br><code>du sh *</code><br>或者<br><code>du -m --max-depth=1</code></p><h3 id="基于已有-docker-镜像制作自己的镜像"><a href="#基于已有-docker-镜像制作自己的镜像" class="headerlink" title="基于已有 docker 镜像制作自己的镜像"></a>基于已有 docker 镜像制作自己的镜像</h3><h4 id="编写-Dockerfile-文件"><a href="#编写-Dockerfile-文件" class="headerlink" title="编写 Dockerfile 文件"></a>编写 Dockerfile 文件</h4><p>这里就不细说了,了解 Dockerfile 文件里的命令即可</p><h4 id="使用-docker-commit提交容器"><a href="#使用-docker-commit提交容器" class="headerlink" title="使用 docker commit提交容器"></a>使用 docker commit提交容器</h4><p>比如说 openjdk:8 ,我想让他支持 node , php , python 等该怎么办?<br>有个简单方法<br>先 pull 下来<br>再<br><code>docker run -it openjdk:8 /bin/bash</code><br>这样就进入到该镜像了,我们可以安装自己需要的东西了<br>我自己遇到了棘手的问题<br>就是 openjdk:8 是 debian 系统的,使用的是 apt-get 包管理器<br>要安装其他东西就要先更新源<br>可以使用 <code>apt update</code> 更新<br>但是我遇到的问题是更新了也无法安装….<br>于是我就想着切换到阿里或者科大的源<br>但是发现这个简单的镜像连 vi 和 gedit 等编辑器都没有,又没法安装他们<br>无法编辑 <code>/etc/apt/source.list</code> 源文件<br>后来我是 cp 先备份,在 <code>echo &quot;xxxx&quot; &gt;&gt; /ect/apt/source.list</code> 更新的<br>之后再 update 就可以安装了<br>安装好之后退出容器,之后<br><code>docker commit containID xxx/xxxx:latest</code><br>提交容器的改变,之后就看到一个新的镜像了</p><p>这里有个问题,就是我想定义自己的启动脚本,貌似无法做到,后来看了官方文档<br>docker commit 有个 -c 参数,解释是这样的:</p><blockquote><p>commit Apply Dockerfile instruction to the created image</p></blockquote><p>以为使用 Dockerfile 的语法来创建镜像, 还有 3 个参数</p><p>-a, –author string    制定个作者<br>-m, –message string   本次提交信息<br>-p, –pause            提交镜像时暂停容器,默认是 true</p><p>假如我有个 blog 的容器, 示例:</p><blockquote><p>docker commit -c ‘CMD [“sh”, “/my-blog/bash/init.sh”]’ -c “EXPOSE 80” -c “EXPOSE 8080” -a “JoyLau” -m “JoyLau’s Blog Docker Image”  blog nas.joylau.cn:5007/joy/blog.joylau.cn:2.1</p></blockquote><h3 id="docker-安装在内网服务器-如何-pull-镜像"><a href="#docker-安装在内网服务器-如何-pull-镜像" class="headerlink" title="docker 安装在内网服务器, 如何 pull 镜像"></a>docker 安装在内网服务器, 如何 pull 镜像</h3><p>在命令行使用 export HTTP_PROXY=xxxx:xx , 命令行里绝大部分命令都可以使用此代理联网,但是安装的 docker 不行,无法 pull 下来镜像文件,想要 pull 使用代理的话,需要添加代理的变量<br>vim /usr/lib/systemd/system/docker.service<br>添加<br>Environment=HTTP_PROXY=<a href="http://xxxx:xxx">http://xxxx:xxx</a><br>Environment=HTTPS_PROXY=<a href="http://xxxx:xxx">http://xxxx:xxx</a><br>保存<br>systemctl deamon-reload<br>systemctl restart docker</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yum 私服搭建记录</title>
      <link href="/2018/12/08/Linux-Private-Yum/"/>
      <url>/2018/12/08/Linux-Private-Yum/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>有时我们的服务器网络并不允许连接互联网,这时候 yum 安装软件就有很多麻烦事情了, 我们也许会通过 yumdownloader 来从可以连接互联网的机器上下载好 rpm 安装包,<br>然后再拷贝到 服务器上.<br>命令 : <code>yumdownloader  --resolve mariadb-server</code> , 所有依赖下载到当前文件夹下</p><p>这样做会存在很多问题:</p><ol><li>虽然上述命令已经加上了 <code>--resolve</code> 来解决依赖,但是一些基础的依赖包仍然没有下载到,这时安装就有问题了</li><li>下载的很多依赖包都有安装的先后顺序,包太多的话,根本无法搞清楚顺序</li></ol><h2 id="rsync-同步科大的源"><a href="#rsync-同步科大的源" class="headerlink" title="rsync 同步科大的源"></a>rsync 同步科大的源</h2><ol><li><code>yum install rsync</code></li><li><code>df -h</code> 查看磁盘上目录的存储的空间情况</li><li>找到最大的磁盘的空间目录,最好准备好 50 GB 以上的空间</li><li>新建目录如下:</li></ol><pre><code class="bash">    mkdir -p ./yum_data/centos/7/os/x86_64    mkdir -p ./yum_data/centos/7/extras/x86_64    mkdir -p ./yum_data/centos/7/updates/x86_64    mkdir -p ./yum_data/centos/7/epel/x86_64</code></pre><ol start="5"><li>开始同步 base extras updates epel 源</li></ol><pre><code class="bash">    cd yum_data    rsync -av rsync://rsync.mirrors.ustc.edu.cn/centos/7/os/x86_64/ ./centos/7/os/x86_64/    rsync -av rsync://rsync.mirrors.ustc.edu.cn/centos/7/extras/x86_64/ ./centos/7/extras/x86_64/    rsync -av rsync://rsync.mirrors.ustc.edu.cn/centos/7/updates/x86_64/ ./7/updates/x86_64/    rsync -av rsync://rsync.mirrors.ustc.edu.cn/epel/7/x86_64/ ./epel/7/x86_64/</code></pre><ol start="6"><li>开始漫长的等待……</li><li>等待全部同步完毕, <code>tar -czf yum_data.tar.gz ./yum_data</code> ,压缩目录</li><li>压缩包拷贝到服务器上</li></ol><h2 id="配置本地-yum-源"><a href="#配置本地-yum-源" class="headerlink" title="配置本地 yum 源"></a>配置本地 yum 源</h2><ol><li>找到一个空间大的目录下,解压包: <code>tar -xvf yum_data.tar.gz</code></li><li>创建一个新的源配置: <code>touch /etc/yum.repos.d/private.repo</code></li><li>插入一下内容:</li></ol><pre><code class="bash">    [local-base]    name=Base Server Repository    baseurl=file:///home/liufa/yum_data/centos/7/os/x86_64    enabled=1    gpgcheck=0    priority=1    [local-extras]    name=Extras Repository    baseurl=file:///home/liufa/yum_data/centos/7/extras/x86_64    enabled=1    gpgcheck=0    priority=2    [local-updates]    name=Updates Server Repository    baseurl=file:///home/liufa/yum_data/centos/7/updates/x86_64    enabled=1    gpgcheck=0    priority=3    [local-epel]    name=Epel Server Repository    baseurl=file:///home/liufa/yum_data/centos/7/epel/x86_64    enabled=1    gpgcheck=0    priority=4</code></pre><ol start="4"><li>禁用原来的 Base Extras Updates 源: <code>yum-config-manager --disable Base,Extras,Updates</code></li><li><code>yum clean all</code></li><li><code>yum makecache</code></li><li><code>yum repolist</code> 查看源信息</li></ol><h2 id="配置网络-yum-源"><a href="#配置网络-yum-源" class="headerlink" title="配置网络 yum 源"></a>配置网络 yum 源</h2><p>有时候我们搭建的私有 yum 还需要提供给其他的机器使用,这时候再做一个网络的 yum 即可,用 Apache 或者 Nginx 搭建个服务即可</p><ol><li><code>yum install nginx</code></li><li><code>vim /etc/nginx/nginx.conf</code> 修改</li></ol><pre><code class="bash">        server {            listen       80 default_server;            listen       [::]:80 default_server;            server_name  _;            root         /home/liufa/yum_data;            # Load configuration files for the default server block.            include /etc/nginx/default.d/*.conf;            location / {            }            error_page 404 /404.html;                location = /40x.html {            }            error_page 500 502 503 504 /50x.html;                location = /50x.html {            }        }</code></pre><ol start="4"><li>这时 private.repo 里的 baseurl 全改为网络地址即可</li></ol><h2 id="403-权限问题"><a href="#403-权限问题" class="headerlink" title="403 权限问题"></a>403 权限问题</h2><p>修改 nginx.conf 配置文件的 user 为 root</p>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> YUM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>$.post() 和 $.ajax() 的问题记录</title>
      <link href="/2018/12/04/Jquery-Post/"/>
      <url>/2018/12/04/Jquery-Post/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>想着写个 demo, 用个简单的 jq 的 post 请求传递数组,却发现遇到了不少问题…<br>一顿研究,总结如下:</p><h3 id="post"><a href="#post" class="headerlink" title="$.post()"></a>$.post()</h3><p>语法:<br>$.post(url,data,success(data, textStatus, jqXHR),dataType)</p><p>url    必需。规定把请求发送到哪个 URL。<br>data    可选。映射或字符串值。规定连同请求发送到服务器的数据。<br>success(data, textStatus, jqXHR)    可选。请求成功时执行的回调函数。<br>dataType    可选。规定预期的服务器响应的数据类型。默认执行智能判断（xml、json、script 或 html)</p><p>该语法等价于:</p><pre><code class="js">    $.ajax({        type: &#39;POST&#39;,        url: url,        data: {            pageNumber: 10        },        success: function (res, status) {            console.info(res)        },    });</code></pre><p>总结需要注意的是: </p><ul><li>请求的 Content-Type 是 <code>application/x-www-form-urlencoded; charset=UTF-8</code> 就是表单提交的, dataType 指得是规定服务器的响应方式</li><li>第二个参数 data 的类型是键值对的对象,不能为 JSON.stringify 后的 json 字符串</li><li>传数组会有问题,会将数组中每个对象的拆开然后堆到一起作为键值对传输数据, 可以通过 <code>jQuery.ajaxSettings.traditional = true;</code> 在 post 请求之前设置,防止这样的情况发生,但是对象不会被序列化,会变成 Object 这样的格式,这也不是我们想要的结果</li><li><code>traditional</code> 可在 <code>$.ajax</code> 的配置项里显式声明</li></ul><p>注意:</p><blockquote><p>Content-Type 是 <code>application/x-www-form-urlencoded; charset=UTF-8</code> 传参时<br>Spirng Boot 后台的接受的参数的形式可以为对象, 不需要加注解<br>该对象的属性需要包含 data 里的值, 否则的话,接受到的对象里的属性为空</p></blockquote><h3 id="ajax"><a href="#ajax" class="headerlink" title="$.ajax()"></a>$.ajax()</h3><p>很传统的使用方式了:<br>发送 post 请求<br>我们的 points 的是数组,里面是多个对象<br>数据传输使用 Request Payload 方式</p><pre><code class="javascript">    $.ajax({        type: &#39;POST&#39;,        url: location.origin + &quot;/trafficService/pixelToLngLat&quot;,        data: JSON.stringify(points),        contentType: &quot;application/json; charset=UTF-8&quot;,        success: function (res, status) {            res.map(point =&gt; {                console.info(point)            });        },    });</code></pre><p>后台使用方式:</p><pre><code class="java">    @PostMapping(&quot;/pixelToLngLat&quot;)    public JSONArray pixelToLngLat(@RequestBody JSONArray points){        return restTemplate.postForObject(baiduApi.getNodeService() + &quot;/traffic/pixelToLngLat&quot;,points,JSONArray.class);    }</code></pre><p>很传统的使用方式</p><p>这种请求的 Content-Type 是 <code>application/json; charset=UTF-8</code>, 后台必须用 <code>@RequestBody</code> 注解接受参数<br>这种方式容错性比较高, <code>@RequestBody</code> 注解的对象可以是 HashMap, JSONObject, JSONArray, String, Object 都可以获取到数据<br>不像 <code>application/x-www-form-urlencoded</code>, 需要对象和传的值一一对应才能获取到值</p><h3 id="强行使用-post"><a href="#强行使用-post" class="headerlink" title="强行使用 $.post()"></a>强行使用 $.post()</h3><p>这个时候我们参数还是传输的键值对方式,只不过将值转化为 json 字符串进行传输</p><pre><code class="javascript">    jQuery.ajaxSettings.traditional = true;    $.post(location.origin + &quot;/trafficService/pixelToLngLat&quot;, {points:JSON.stringify(points)},function (res, status) {        res.map(point =&gt; {            console.info(point)        });    },&quot;json&quot;)</code></pre><p>后台使用</p><pre><code class="java">    @PostMapping(&quot;/pixelToLngLat&quot;)    public JSONArray pixelToLngLat(@RequestParam(&quot;points&quot;) String points){        JSONArray array = JSONArray.parseArray(points);        return restTemplate.postForObject(baiduApi.getNodeService() + &quot;/traffic/pixelToLngLat&quot;,array,JSONArray.class);    }</code></pre><p>@RequestParam(“points”) 显式指定了接受 points 的值, 即字符串 JSON.stringify(points)<br>其实完全可以在后台定义一个 Points 对象, 属性和前台的传的数据属性一一对应, 用来接受前台传过来的数据</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>表单提交方式,如果后台有相应的对象的来接受参数的话,直接在方法是使用对象即可,这种方式需要事先定义一个对象, 前台传的数据就按照这个对象的属性来, 这种方式看起来数据很清晰</li><li><code>application/json</code> 需要注解 <code>@RequestBody</code>, 注解的对象可以是 HashMap, JSONObject, JSONArray, String, Object 都可以获取到数据, 灵活性高</li></ol>]]></content>
      
      
      <categories>
          
          <category> 前端篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jquery </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 理解 ThreadPoolTaskExecutor</title>
      <link href="/2018/11/24/SpringBoot-ThreadPoolTaskExecutor/"/>
      <url>/2018/11/24/SpringBoot-ThreadPoolTaskExecutor/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="spring-的线程池-ThreadPoolTaskExecutor"><a href="#spring-的线程池-ThreadPoolTaskExecutor" class="headerlink" title="spring 的线程池 ThreadPoolTaskExecutor"></a>spring 的线程池 ThreadPoolTaskExecutor</h3><p>spring 为我们实现了一个基于 ThreadPoolExecutor 线程池</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><ol><li>yml </li></ol><pre><code class="yml">    traffic:      executor:        name: &quot;trafficServiceExecutor&quot;        core-pool-size: 5        max-pool-size: 10        queue-capacity: 20        thread-name-prefix: &quot;traffic-service-&quot;</code></pre><ol start="2"><li>Configuration</li></ol><pre><code class="java">    @Data    @Configuration    @ConfigurationProperties(prefix = &quot;traffic.executor&quot;)    public class Executor {        private String name;        private Integer corePoolSize;        private Integer maxPoolSize;        private Integer queueCapacity;        private String threadNamePrefix;    }</code></pre><ol start="3"><li>Bean</li></ol><pre><code class="java">    @Configuration    @ConditionalOnBean(Executor.class)    public class ExecutorConfig {        @Bean        public ThreadPoolTaskExecutor trafficServiceExecutor(@Autowired Executor executor) {            ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor();            threadPoolTaskExecutor.setCorePoolSize(executor.getCorePoolSize());            threadPoolTaskExecutor.setMaxPoolSize(executor.getMaxPoolSize());            threadPoolTaskExecutor.setQueueCapacity(executor.getQueueCapacity());            threadPoolTaskExecutor.setThreadNamePrefix(executor.getThreadNamePrefix());            threadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());            threadPoolTaskExecutor.initialize();            return threadPoolTaskExecutor;        }    }</code></pre><p>仅此步骤,我们在使用的时候,只需要注解 @Async(“trafficServiceExecutor”) 配置好 name 即可</p><h3 id="个人理解"><a href="#个人理解" class="headerlink" title="个人理解"></a>个人理解</h3><p>理解图<br><img src="http://image.joylau.cn/blog/springboot-ThreadPoolTaskExecutor.jpg" alt=""></p><h3 id="看点数据"><a href="#看点数据" class="headerlink" title="看点数据"></a>看点数据</h3><p>在线程池整个运作过程中,想看下运行状态的话可以这么做:<br>常用状态：</p><ul><li><code>taskCount</code>：线程需要执行的任务个数。</li><li><code>completedTaskCount</code>：线程池在运行过程中已完成的任务数。</li><li><code>largestPoolSize</code>：线程池曾经创建过的最大线程数量。</li><li><code>getPoolSize</code>: 获取当前线程池的线程数量。</li><li><code>getActiveCount</code>：获取活动的线程的数量</li></ul><p>通过继承线程池，重写beforeExecute，afterExecute和terminated方法来在线程执行任务前，线程执行任务结束，和线程终结前获取线程的运行情况，根据具体情况调整线程池的线程数量</p><h3 id="重写一波"><a href="#重写一波" class="headerlink" title="重写一波"></a>重写一波</h3><pre><code class="java">    @Slf4j    public class MyExecutor extends ExecutorConfigurationSupport            implements AsyncListenableTaskExecutor, SchedulingTaskExecutor {        private final Object poolSizeMonitor = new Object();        private int corePoolSize = 1;        private int maxPoolSize = Integer.MAX_VALUE;        private int keepAliveSeconds = 60;        private int queueCapacity = Integer.MAX_VALUE;        private boolean allowCoreThreadTimeOut = false;        @Nullable        private TaskDecorator taskDecorator;        @Nullable        private ThreadPoolExecutor threadPoolExecutor;        // Runnable decorator to user-level FutureTask, if different        private final Map&lt;Runnable, Object&gt; decoratedTaskMap =                new ConcurrentReferenceHashMap&lt;&gt;(16, ConcurrentReferenceHashMap.ReferenceType.WEAK);        public void setCorePoolSize(int corePoolSize) {            synchronized (this.poolSizeMonitor) {                this.corePoolSize = corePoolSize;                if (this.threadPoolExecutor != null) {                    this.threadPoolExecutor.setCorePoolSize(corePoolSize);                }            }        }        public int getCorePoolSize() {            synchronized (this.poolSizeMonitor) {                return this.corePoolSize;            }        }        public void setMaxPoolSize(int maxPoolSize) {            synchronized (this.poolSizeMonitor) {                this.maxPoolSize = maxPoolSize;                if (this.threadPoolExecutor != null) {                    this.threadPoolExecutor.setMaximumPoolSize(maxPoolSize);                }            }        }        public int getMaxPoolSize() {            synchronized (this.poolSizeMonitor) {                return this.maxPoolSize;            }        }        public void setKeepAliveSeconds(int keepAliveSeconds) {            synchronized (this.poolSizeMonitor) {                this.keepAliveSeconds = keepAliveSeconds;                if (this.threadPoolExecutor != null) {                    this.threadPoolExecutor.setKeepAliveTime(keepAliveSeconds, TimeUnit.SECONDS);                }            }        }        public int getKeepAliveSeconds() {            synchronized (this.poolSizeMonitor) {                return this.keepAliveSeconds;            }        }        public void setQueueCapacity(int queueCapacity) {            this.queueCapacity = queueCapacity;        }        public void setAllowCoreThreadTimeOut(boolean allowCoreThreadTimeOut) {            this.allowCoreThreadTimeOut = allowCoreThreadTimeOut;        }        public void setTaskDecorator(TaskDecorator taskDecorator) {            this.taskDecorator = taskDecorator;        }        @Override        protected ExecutorService initializeExecutor(                ThreadFactory threadFactory, RejectedExecutionHandler rejectedExecutionHandler) {            BlockingQueue&lt;Runnable&gt; queue = createQueue(this.queueCapacity);            ThreadPoolExecutor executor;            if (this.taskDecorator != null) {                executor = new ThreadPoolExecutor(                        this.corePoolSize, this.maxPoolSize, this.keepAliveSeconds, TimeUnit.SECONDS,                        queue, threadFactory, rejectedExecutionHandler) {                    @Override                    public void execute(Runnable command) {                        Runnable decorated = taskDecorator.decorate(command);                        if (decorated != command) {                            decoratedTaskMap.put(decorated, command);                        }                        super.execute(decorated);                    }                };            }            else {                executor = new ThreadPoolExecutor(                        this.corePoolSize, this.maxPoolSize, this.keepAliveSeconds, TimeUnit.SECONDS,                        queue, threadFactory, rejectedExecutionHandler){                    @Override                    public void beforeExecute(Thread t, Runnable r) {    //                    log.error(&quot;线程开始......&quot;);    //                    log.error(&quot;当前线程池的线程数量:{}&quot;,MyExecutor.this.getPoolSize());    //                    log.error(&quot;活动的线程的数量:{}&quot;,MyExecutor.this.getActiveCount());    //                    log.error(&quot;线程需要执行的任务个数:{}&quot;,getTaskCount());    //                    log.error(&quot;线程池在运行过程中已完成的任务数:{}&quot;,getCompletedTaskCount());                    }                    @Override                    public void afterExecute(Runnable r, Throwable t) {                        log.error(&quot;线程池在运行过程中已完成的任务数:{}&quot;,getCompletedTaskCount());                    }                };            }            if (this.allowCoreThreadTimeOut) {                executor.allowCoreThreadTimeOut(true);            }            this.threadPoolExecutor = executor;            return executor;        }        protected BlockingQueue&lt;Runnable&gt; createQueue(int queueCapacity) {            if (queueCapacity &gt; 0) {                return new LinkedBlockingQueue&lt;&gt;(queueCapacity);            }            else {                return new SynchronousQueue&lt;&gt;();            }        }        public ThreadPoolExecutor getThreadPoolExecutor() throws IllegalStateException {            Assert.state(this.threadPoolExecutor != null, &quot;ThreadPoolTaskExecutor not initialized&quot;);            return this.threadPoolExecutor;        }        public int getPoolSize() {            if (this.threadPoolExecutor == null) {                // Not initialized yet: assume core pool size.                return this.corePoolSize;            }            return this.threadPoolExecutor.getPoolSize();        }        public int getActiveCount() {            if (this.threadPoolExecutor == null) {                // Not initialized yet: assume no active threads.                return 0;            }            return this.threadPoolExecutor.getActiveCount();        }        @Override        public void execute(Runnable task) {            Executor executor = getThreadPoolExecutor();            try {                executor.execute(task);            }            catch (RejectedExecutionException ex) {                throw new TaskRejectedException(&quot;Executor [&quot; + executor + &quot;] did not accept task: &quot; + task, ex);            }        }        @Override        public void execute(Runnable task, long startTimeout) {            execute(task);        }        @Override        public Future&lt;?&gt; submit(Runnable task) {            ExecutorService executor = getThreadPoolExecutor();            try {                return executor.submit(task);            }            catch (RejectedExecutionException ex) {                throw new TaskRejectedException(&quot;Executor [&quot; + executor + &quot;] did not accept task: &quot; + task, ex);            }        }        @Override        public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) {            ExecutorService executor = getThreadPoolExecutor();            try {                return executor.submit(task);            }            catch (RejectedExecutionException ex) {                throw new TaskRejectedException(&quot;Executor [&quot; + executor + &quot;] did not accept task: &quot; + task, ex);            }        }        @Override        public ListenableFuture&lt;?&gt; submitListenable(Runnable task) {            ExecutorService executor = getThreadPoolExecutor();            try {                ListenableFutureTask&lt;Object&gt; future = new ListenableFutureTask&lt;&gt;(task, null);                executor.execute(future);                return future;            }            catch (RejectedExecutionException ex) {                throw new TaskRejectedException(&quot;Executor [&quot; + executor + &quot;] did not accept task: &quot; + task, ex);            }        }        @Override        public &lt;T&gt; ListenableFuture&lt;T&gt; submitListenable(Callable&lt;T&gt; task) {            ExecutorService executor = getThreadPoolExecutor();            try {                ListenableFutureTask&lt;T&gt; future = new ListenableFutureTask&lt;&gt;(task);                executor.execute(future);                return future;            }            catch (RejectedExecutionException ex) {                throw new TaskRejectedException(&quot;Executor [&quot; + executor + &quot;] did not accept task: &quot; + task, ex);            }        }        @Override        protected void cancelRemainingTask(Runnable task) {            super.cancelRemainingTask(task);            // Cancel associated user-level Future handle as well            Object original = this.decoratedTaskMap.get(task);            if (original instanceof Future) {                ((Future&lt;?&gt;) original).cancel(true);            }        }    }</code></pre><p>主要看 <code>initializeExecutor</code> 方法,我重写了 <code>ThreadPoolExecutor</code> 的 <code>beforeExecute</code> 和 <code>afterExecute</code> 打印了一些信息,可以帮助理解整个过程</p><h3 id="配置参考"><a href="#配置参考" class="headerlink" title="配置参考"></a>配置参考</h3><ul><li>如果是CPU密集型任务，那么线程池的线程个数应该尽量少一些，一般为CPU的个数+1条线程。 linux 查看 CPU 信息 : <code>cat /proc/cpuinfo</code></li><li>如果是IO密集型任务，那么线程池的线程可以放的很大，如2*CPU的个数。</li><li>对于混合型任务，如果可以拆分的话，通过拆分成CPU密集型和IO密集型两种来提高执行效率；如果不能拆分的的话就可以根据实际情况来调整线程池中线程的个数。</li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker OpenVPN 服务搭建记录</title>
      <link href="/2018/11/20/Docker-OpenVPN/"/>
      <url>/2018/11/20/Docker-OpenVPN/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>出差在外或者在家工作都需要连接公司网络,没有 VPN 怎么能行</p><h2 id="OpenVPN-服务端部署"><a href="#OpenVPN-服务端部署" class="headerlink" title="OpenVPN 服务端部署"></a>OpenVPN 服务端部署</h2><ol><li>全局变量配置: OVPN_DATA=”/home/joylau/ovpn-data”</li><li><code>mkdir ${OVPN_DATA}</code> , <code>cd ${OVPN_DATA}</code></li><li>这里我使用的是 tcp, udp 的好像没映射, 我用起来有问题,后来换的 tcp 方式, <code>docker run -v ${OVPN_DATA}:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u tcp://公网 IP</code></li><li>初始化,这里的密码我们都设置为 123456, <code>docker run -v ${OVPN_DATA}:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki</code></li><li>创建用户 liufa , 不使用密码的话在最后面加上 nopass, 使用密码就键入密码,这里我们使用 123456, <code>docker run -v ${OVPN_DATA}:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full liufa</code></li><li>为用户 liufa 生成秘钥, <code>docker run -v ${OVPN_DATA}:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient liufa &gt; ${OVPN_DATA}/liufa.ovpn</code></li><li>创建的文件中端口默认使用的是 1194, 而我用的是 6001,那我们还得修改下 liufa.ovpn 文件的端口</li><li>运行容器,这里我的宿主机端口为 6001, <code>docker run --name openvpn -v ${OVPN_DATA}:/etc/openvpn -d -p 6001:1194 --privileged kylemanna/openvpn</code></li></ol><h2 id="OpenVPN-管理接口"><a href="#OpenVPN-管理接口" class="headerlink" title="OpenVPN 管理接口"></a>OpenVPN 管理接口</h2><p>服务端配置文件加入 management 0.0.0.0 5555</p><p>可以使用 telnet ip 5555 来使用管理接口, 输入 help 查看详细命令, 具体如下:</p><pre><code class="shell">    Commands:    auth-retry t           : Auth failure retry mode (none,interact,nointeract).    bytecount n            : Show bytes in/out, update every n secs (0=off).    echo [on|off] [N|all]  : Like log, but only show messages in echo buffer.    exit|quit              : Close management session.    forget-passwords       : Forget passwords entered so far.    help                   : Print this message.    hold [on|off|release]  : Set/show hold flag to on/off state, or                             release current hold and start tunnel.    kill cn                : Kill the client instance(s) having common name cn.    kill IP:port           : Kill the client instance connecting from IP:port.    load-stats             : Show global server load stats.    log [on|off] [N|all]   : Turn on/off realtime log display                             + show last N lines or &#39;all&#39; for entire history.    mute [n]               : Set log mute level to n, or show level if n is absent.    needok type action     : Enter confirmation for NEED-OK request of &#39;type&#39;,                             where action = &#39;ok&#39; or &#39;cancel&#39;.    needstr type action    : Enter confirmation for NEED-STR request of &#39;type&#39;,                             where action is reply string.    net                    : (Windows only) Show network info and routing table.    password type p        : Enter password p for a queried OpenVPN password.    remote type [host port] : Override remote directive, type=ACCEPT|MOD|SKIP.    proxy type [host port flags] : Enter dynamic proxy server info.    pid                    : Show process ID of the current OpenVPN process.    client-auth CID KID    : Authenticate client-id/key-id CID/KID (MULTILINE)    client-auth-nt CID KID : Authenticate client-id/key-id CID/KID    client-deny CID KID R [CR] : Deny auth client-id/key-id CID/KID with log reason                                 text R and optional client reason text CR    client-kill CID [M]    : Kill client instance CID with message M (def=RESTART)    env-filter [level]     : Set env-var filter level    client-pf CID          : Define packet filter for client CID (MULTILINE)    rsa-sig                : Enter an RSA signature in response to &gt;RSA_SIGN challenge                             Enter signature base64 on subsequent lines followed by END    certificate            : Enter a client certificate in response to &gt;NEED-CERT challenge                             Enter certificate base64 on subsequent lines followed by END    signal s               : Send signal s to daemon,                             s = SIGHUP|SIGTERM|SIGUSR1|SIGUSR2.    state [on|off] [N|all] : Like log, but show state history.    status [n]             : Show current daemon status info using format #n.    test n                 : Produce n lines of output for testing/debugging.    username type u        : Enter username u for a queried OpenVPN username.    verb [n]               : Set log verbosity level to n, or show if n is absent.    version                : Show current version number.    END</code></pre><h2 id="OpenVPN-客户端使用说明"><a href="#OpenVPN-客户端使用说明" class="headerlink" title="OpenVPN 客户端使用说明"></a>OpenVPN 客户端使用说明</h2><p><img src="https://img.shields.io/badge/author-joylau-green.svg" alt="">    <img src="https://img.shields.io/badge/date-2018--11--20-yellow.svg" alt="">    <img src="https://img.shields.io/badge/version-1.0-blue.svg" alt=""></p><h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><ol><li>安装 openVPN windows 客户端，地址：<a href="https://swupdate.openvpn.org/community/releases/openvpn-install-2.4.6-I602.exe" target="_blank" rel="noopener">https://swupdate.openvpn.org/community/releases/openvpn-install-2.4.6-I602.exe</a> , 该地址需要梯子</li><li>启动客户端，右键，选择 import file, 导入 ovpn 文件，文件请 联系管理员发给你</li><li>右键 connect,如果弹出框提示输入密码，输入默认密码 123456 ，等待连接成功即可</li></ol><h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><ol><li>安装 openvpn：<code>sudo yum install openvpn</code> 或者 <code>sudo apt install openvpn</code></li><li>找到 ovpn 文件所在目录： <code>sudo openvpn --config ./liufa.ovpn</code>, 看到成功信息时即连接成功</li><li><code>--daemon</code> 参数以守护进程运行</li><li>或者写个 service 文件以守护进程并且开机启动运行</li></ol><h4 id="GUI-客户端-2020-04-29更新"><a href="#GUI-客户端-2020-04-29更新" class="headerlink" title="GUI 客户端 [2020-04-29更新]"></a>GUI 客户端 [2020-04-29更新]</h4><p>可以使用开源客户端工具： <a href="https://client.pritunl.com/#features" target="_blank" rel="noopener">pritunl-client-electron</a><br>安装方法：<br>Ubuntu 16.04:</p><pre><code class="bash">    sudo tee /etc/apt/sources.list.d/pritunl.list &lt;&lt; EOF    deb http://repo.pritunl.com/stable/apt xenial main    EOF    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292A    sudo apt-get update    sudo apt-get install pritunl-client-electron</code></pre><p>注意 apt 安装需要科学上网来设置代理</p><p>或者从 GitHub 上下载软件包： <a href="https://github.com/pritunl/pritunl-client-electron/releases" target="_blank" rel="noopener">https://github.com/pritunl/pritunl-client-electron/releases</a></p><h3 id="MacOS"><a href="#MacOS" class="headerlink" title="MacOS"></a>MacOS</h3><ol><li>安装 Tunnelblick，地址：<a href="https://tunnelblick.net/" target="_blank" rel="noopener">https://tunnelblick.net/</a></li><li>导入 ovpn文件</li><li>状态栏上点击连接VPN</li></ol><h2 id="路由设置"><a href="#路由设置" class="headerlink" title="路由设置"></a>路由设置</h2><p>连接上 VPN 后,默认所有流量都走的 VPN,但事实上我们并不想这么做</p><h3 id="Windows-上路由手动配置"><a href="#Windows-上路由手动配置" class="headerlink" title="Windows 上路由手动配置"></a>Windows 上路由手动配置</h3><ul><li>⽐如公司内网的网段为 192.168.10.0 网段,我们先删除 2 个 0.0.0.0 的路由: <code>route delete 0.0.0.0</code></li><li>然后添加 0.0.0.0 到本机的网段 <code>route add 0.0.0.0 mask 255.255.255.0 本机内网网关</code> </li><li>再指定 10 网段走 VPN 通道 <code>route add 192.168.10.0 mask 255.255.255.0 VPN 网关</code></li><li>以上路由添加默认是临时的,重启失效,⽤久保存可加 -p 参数</li></ul><h3 id="OpenVPN-服务端配置"><a href="#OpenVPN-服务端配置" class="headerlink" title="OpenVPN 服务端配置"></a>OpenVPN 服务端配置</h3><p>修改配置文件 <code>openvpn.conf</code><br>在 </p><pre><code class="bash">    ### Route Configurations Below    route 192.168.254.0 255.255.255.0</code></pre><p>下面添加路由即可， 客户端连接时会收到服务端推送的路由</p><h3 id="OpenVPN-客户端设置"><a href="#OpenVPN-客户端设置" class="headerlink" title="OpenVPN 客户端设置"></a>OpenVPN 客户端设置</h3><p>很多时候我们希望自己的客户端能够自定义路由，而且更该服务端的配置并不是一个相对较好的做法</p><p>找到我们的 ovpn 配置文件 </p><p>到最后一行</p><p><code>redirect-gateway def1</code><br>即是我们全部流量走 VPN 的配置</p><h4 id="route-nopull"><a href="#route-nopull" class="headerlink" title="route-nopull"></a>route-nopull</h4><p>客户端加入这个参数后,OpenVPN 连接后不会添加路由,也就是不会有任何网络请求走 OpenVPN</p><h4 id="vpn-gateway"><a href="#vpn-gateway" class="headerlink" title="vpn_gateway"></a>vpn_gateway</h4><p>当客户端加入 <code>route-nopull</code> 后,所有出去的访问都不从 OpenVPN 出去,但可通过添加 vpn_gateway 参数使部分IP访问走 OpenVPN 出去</p><pre><code class="bash">    route 192.168.255.0 255.255.255.0 vpn_gateway    route 192.168.10.0 255.255.255.0 vpn_gateway</code></pre><h4 id="net-gateway"><a href="#net-gateway" class="headerlink" title="net_gateway"></a>net_gateway</h4><p>和 <code>vpn_gateway</code> 相反,他表示在默认出去的访问全部走 OpenVPN 时,强行指定部分 IP 访问不通过 OpenVPN 出去</p><pre><code class="bash">    max-routes 1000 # 表示可以添加路由的条数,默认只允许添加100条路由,如果少于100条路由可不加这个参数    route 172.121.0.0 255.255.0.0 net_gateway</code></pre><h2 id="客户端互相访问"><a href="#客户端互相访问" class="headerlink" title="客户端互相访问"></a>客户端互相访问</h2><ol><li>配置 client-to-client</li><li>192.168.255.0 的路由要能够走VPN通道, 可以配置 <code>redirect-gateway def1</code> 或者 <code>route-nopull  route 192.168.255.0 255.255.255.0 vpn_gateway</code></li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> OpenVPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 私服搭建记录</title>
      <link href="/2018/11/19/Docker-PrivateRepo/"/>
      <url>/2018/11/19/Docker-PrivateRepo/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li><p>docker pull registry</p></li><li><p>docker run -itd -v /data/registry:/var/lib/registry -p 5000:5000 –restart=always –privileged=true –name registry registry:latest<br> 参数说明<br> -itd：在容器中打开一个伪终端进行交互操作，并在后台运行；<br> -v：把宿主机的/data/registry目录绑定 到 容器/var/lib/registry目录(这个目录是registry容器中存放镜像文件的目录)，来实现数据的持久化；<br> -p：映射端口；访问宿主机的5000端口就访问到registry容器的服务了；<br> –restart=always：这是重启的策略，假如这个容器异常退出会自动重启容器；<br> –privileged=true 在CentOS7中的安全模块selinux把权限禁掉了，参数给容器加特权，不加上传镜像会报权限错误OSError: [Errno 13] Permission denied: ‘/tmp/registry/repositories/liibrary’)或者（Received unexpected HTTP status: 500 Internal Server Error）错误<br> –name registry：创建容器命名为registry，你可以随便命名；<br> registry:latest：这个是刚才pull下来的镜像；</p></li><li><p>测试是否成功: curl <a href="http://127.0.0.1:5000/v2/_catalog" target="_blank" rel="noopener">http://127.0.0.1:5000/v2/_catalog</a>, 返回仓库的镜像列表</p></li><li><p>在中央仓库下载一个镜像: docker pull openjdk</p></li><li><p>更改这个镜像的标签: docker tag imageId domain:5000/openjdk 或者 docker tag imageName:tag domain:5000/openjdk</p></li><li><p>上传镜像到私服: docker push domain:5000/openjdk</p></li></ol><p>报错: Get <a href="https://172.18.18.90:5000/v2/" target="_blank" rel="noopener">https://172.18.18.90:5000/v2/</a>: http: server gave HTTP response to HTTPS client</p><p>解决: 需要https的方法才能上传，我们可以修改下daemon.json<br>      vim /etc/docker/daemon.json<br>      {<br>        “insecure-registries”: [ “domain:5000”]<br>      }</p><h3 id="无网络搭建"><a href="#无网络搭建" class="headerlink" title="无网络搭建"></a>无网络搭建</h3><ol><li>在有网络的机器上 <code>docker pull registry</code></li><li><code>docker save registry &gt; registry.tar</code> 保存到个 tar 包</li><li>拷贝到服务器上, <code>docker load -i registry.tar</code> 导入镜像</li><li><code>docker images</code> 查看镜像</li><li>再继续上面的操作</li></ol><h3 id="docker-开启-tcp-端口"><a href="#docker-开启-tcp-端口" class="headerlink" title="docker 开启 tcp 端口"></a>docker 开启 tcp 端口</h3><ul><li><code>vim /usr/lib/systemd/system/docker.service</code></li></ul><p>修改</p><pre><code class="bash">    ExecStart=/usr/bin/dockerd-current -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock \</code></pre><p>重启即可,之后 idea 可输入 tcp://ip:2375 连接</p><h3 id="允许跨域请求"><a href="#允许跨域请求" class="headerlink" title="允许跨域请求"></a>允许跨域请求</h3><pre><code class="bash">    version: 0.1    log:      fields:        service: registry    storage:      cache:        blobdescriptor: inmemory      filesystem:        rootdirectory: /var/lib/registry    http:      addr: :5000      headers:        X-Content-Type-Options: [nosniff]        Access-Control-Allow-Headers: [&#39;Origin,Accept,Content-Type,Authorization&#39;]        Access-Control-Allow-Origin: [&#39;*&#39;]        Access-Control-Allow-Methods: [&#39;GET,POST,PUT,DELETE&#39;]    health:      storagedriver:        enabled: true        interval: 10s        threshold: 3</code></pre><p>head 添加</p><pre><code class="yml">    Access-Control-Allow-Headers: [&#39;Origin,Accept,Content-Type,Authorization&#39;]    Access-Control-Allow-Origin: [&#39;*&#39;]    Access-Control-Allow-Methods: [&#39;GET,POST,PUT,DELETE&#39;]</code></pre><p>之后保存到本地,再挂载到容器的 /etc/docker/registry/config.yml 中</p><h3 id="Harbor-搭建-Docker-私服"><a href="#Harbor-搭建-Docker-私服" class="headerlink" title="Harbor 搭建 Docker 私服"></a>Harbor 搭建 Docker 私服</h3><p>上述方式搭建的 docker 私服,属于比较简单使用的方法,只能在命令行上操作,很不方便,比如不能直接删除镜像,无法添加用户,设置私有仓库<br>Harbor 是一个图形化的私服管理界面,安装使用更易于操作</p><blockquote><p>Harbor是一个用于存储和分发Docker镜像的企业级Registry服务器，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源Docker Distribution。作为一个企业级私有Registry服务器，Harbor提供了更好的性能和安全。提升用户使用Registry构建和运行环境传输镜像的效率。</p></blockquote><ol><li>下载离线包: <a href="https://github.com/goharbor/harbor/releases" target="_blank" rel="noopener">https://github.com/goharbor/harbor/releases</a></li><li>解压</li><li>更改配置文件 <code>docker-compose.yml</code> 私服的仓库端口我们默认设置为 5000,但是 docker-compose.yml 文件中并没有配置,我们需要添加一个 ports 配置</li></ol><pre><code class="yml">      registry:        networks:          - harbor        ports:          - 5000:5000</code></pre><ol start="4"><li>Harbor 默认使用的是 80 端口,不想使用的话可切换其他端口, 配置在 docker-compose.yml 的最下方</li></ol><pre><code class="yml">      proxy:        image: goharbor/nginx-photon:v1.7.0        ports:          - 9339:80          - 443:443          - 4443:4443</code></pre><p>此处需要注意的是,如果更改了其他端口,则需要在 <code>common/templates/registry/config.yml</code> 文件中更改一个配置 realm 加上端口,否则登录会出现错误</p><pre><code class="yml">    auth:      token:        issuer: harbor-token-issuer        realm: $public_url:9339/service/token        rootcertbundle: /etc/registry/root.crt        service: harbor-registry</code></pre><ol start="5"><li>修改配置文件 <code>harbor.cfg</code></li></ol><pre><code class="bash">    hostname = 34.0.7.183 ## 改为 IP 或者 域名,不要写错 localhost 或者 127.0.0.1    ui_url_protocol = http ## http 方式    harbor_admin_password = Hardor12345 ## admin 账号的默认登录密码</code></pre><ol start="6"><li><p><code>./prepare</code> 完成配置</p></li><li><p><code>./install.sh</code> 开始安装</p></li><li><p>打开浏览器</p></li><li><p>创建一个项目 <code>joylau</code> 注意这个名称很重要,名称对不上的话,会造成 image push 不成功,还有就是若果这个项目的是公开的话,则所有人都可以 pull ,但是 push 的话是需要登录的,登录的用户名和密码在该项目的成员下.默认的 admin 用户就可以</p></li><li><p>登录,退出命令 <code>docker login 34.0.7.183:5000 ; docker logout 34.0.7.183:5000</code></p></li><li><p>之后的操作都是日常操作了</p></li></ol><h3 id="Docker-Registry-添加认证"><a href="#Docker-Registry-添加认证" class="headerlink" title="Docker Registry 添加认证"></a>Docker Registry 添加认证</h3><h4 id="生成用户名密码"><a href="#生成用户名密码" class="headerlink" title="生成用户名密码"></a>生成用户名密码</h4><pre><code class="bash">    docker run --rm --entrypoint htpasswd registry -Bbn username password &gt; ./htpasswd</code></pre><p>假设将生成的文件放到 /registry/pwd/htpasswd</p><h4 id="挂载用户名密码文件"><a href="#挂载用户名密码文件" class="headerlink" title="挂载用户名密码文件"></a>挂载用户名密码文件</h4><p>-v /registry/pwd:/auth -e “REGISTRY_AUTH=htpasswd” -e “REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm” -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd</p><p>至此,添加用户名密码完成,现在 pull 和 push 都需要登录</p><h3 id="Docker-login-密码存储"><a href="#Docker-login-密码存储" class="headerlink" title="Docker login 密码存储"></a>Docker login 密码存储</h3><p>默认存储位置为: $HOME/.docker/config.json<br>很不安全, 使用 base64 解密即可看到用户名密码</p><p>将密码存储到钥匙串:</p><ol><li>下载工具: <a href="https://github.com/docker/docker-credential-helpers/releases" target="_blank" rel="noopener">https://github.com/docker/docker-credential-helpers/releases</a></li><li>将 docker-credential-osxkeychain 配置到 path 路径</li><li>配置 config.json</li></ol><pre><code class="json">    {      &quot;credsStore&quot;: &quot;osxkeychain&quot;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录 -- Docker 三种方式部署 ownCloud</title>
      <link href="/2018/10/26/Docker-ownCloud/"/>
      <url>/2018/10/26/Docker-ownCloud/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>ownCloud 除了传统的部署方式,在如今 docker 大行其道的环境下,使用 docker 部署 ownCloud 才是最方便的</p><h3 id="第一种-owncloud-镜像直接安装"><a href="#第一种-owncloud-镜像直接安装" class="headerlink" title="第一种 owncloud 镜像直接安装"></a>第一种 owncloud 镜像直接安装</h3><p>直接部署 owncloud 镜像,该镜像地址: <a href="https://hub.docker.com/r/_/owncloud/" target="_blank" rel="noopener">https://hub.docker.com/r/_/owncloud/</a></p><pre><code class="sbtshell">    docker pull owncloud    docker run -d -p 80:80 owncloud</code></pre><p>这种方式的需要你提前装好 MariaDb 数据库,在启动完成后打开页面会按照流程填写数据库的链接信息,之后就可以使用 ownCloud 了</p><h3 id="第二种-分别安装"><a href="#第二种-分别安装" class="headerlink" title="第二种 分别安装"></a>第二种 分别安装</h3><p>分别先后使用 docker 按照 redis,mariadb,ownCloud<br>安装 redis 的 mariadb</p><pre><code class="shell">    docker volume create owncloud_redis    docker run -d \      --name redis \      -e REDIS_DATABASES=1 \      --volume owncloud_redis:/var/lib/redis \      webhippie/redis:latest    docker volume create owncloud_mysql    docker volume create owncloud_backup    docker run -d \      --name mariadb \      -e MARIADB_ROOT_PASSWORD=owncloud \      -e MARIADB_USERNAME=owncloud \      -e MARIADB_PASSWORD=owncloud \      -e MARIADB_DATABASE=owncloud \      --volume owncloud_mysql:/var/lib/mysql \      --volume owncloud_backup:/var/lib/backup \      webhippie/mariadb:latest</code></pre><p>接着我们配置一些 ownCloud web 服务的环境变量,并在启动容器时使用这些变量</p><pre><code class="shell">    export OWNCLOUD_VERSION=10.0    export OWNCLOUD_DOMAIN=localhost    export ADMIN_USERNAME=admin    export ADMIN_PASSWORD=admin    export HTTP_PORT=80    docker volume create owncloud_files    docker run -d \      --name owncloud \      --link mariadb:db \      --link redis:redis \      -p ${HTTP_PORT}:8080 \      -e OWNCLOUD_DOMAIN=${OWNCLOUD_DOMAIN} \      -e OWNCLOUD_DB_TYPE=mysql \      -e OWNCLOUD_DB_NAME=owncloud \      -e OWNCLOUD_DB_USERNAME=owncloud \      -e OWNCLOUD_DB_PASSWORD=owncloud \      -e OWNCLOUD_DB_HOST=db \      -e OWNCLOUD_ADMIN_USERNAME=${ADMIN_USERNAME} \      -e OWNCLOUD_ADMIN_PASSWORD=${ADMIN_PASSWORD} \      -e OWNCLOUD_REDIS_ENABLED=true \      -e OWNCLOUD_REDIS_HOST=redis \      --volume owncloud_files:/mnt/data \      owncloud/server:${OWNCLOUD_VERSION}</code></pre><p>之后稍等片刻,打开网页即可</p><h3 id="第三种-docker-compose-部署"><a href="#第三种-docker-compose-部署" class="headerlink" title="第三种 docker-compose 部署"></a>第三种 docker-compose 部署</h3><p>首先保证 docker-compose 的版本在 1.12.0+ </p><pre><code class="sbtshell">    # 创建一个新的目录    mkdir owncloud-docker-server    cd owncloud-docker-server    # 下载 docker-compose.yml 文件    wget https://raw.githubusercontent.com/owncloud-docker/server/master/docker-compose.yml    # 配置环境变量文件    cat &lt;&lt; EOF &gt; .env    OWNCLOUD_VERSION=10.0    OWNCLOUD_DOMAIN=localhost    ADMIN_USERNAME=admin    ADMIN_PASSWORD=admin    HTTP_PORT=80    HTTPS_PORT=443    EOF    # 构建并启动容器    docker-compose up -d</code></pre><p>当上面的流程都完成时，通过运行 <code>docker-compose ps</code> 检查所有容器是否已成功启动<br>还可以使用 <code>docker-compose logs --follow owncloud</code> 来查看日志<br><code>docker-compose stop</code> 停止容器<br><code>docker-compose down</code> 停止和删除容器</p><h4 id="版本更新"><a href="#版本更新" class="headerlink" title="版本更新"></a>版本更新</h4><ol><li>进入 .yaml 或 .env 目录</li><li>将 ownCloud 设置维护模式,<code>docker-compose exec server occ maintenance:mode --on</code></li><li>停止容器, <code>docker-compose down</code></li><li>修改. env 文件的版本号,手动或者 <code>sed -i &#39;s/^OWNCLOUD_VERSION=.*$/OWNCLOUD_VERSION=&lt;newVersion&gt;/&#39; /compose/*/.env</code></li><li>重新构建并启动, <code>docker-compose up -d</code></li></ol><h4 id="指定挂载目录"><a href="#指定挂载目录" class="headerlink" title="指定挂载目录"></a>指定挂载目录</h4><ol><li>owncloud-server : /mnt/data</li></ol><p>注意挂载本地目录时,要设置递归文件夹的可读权限 <code>chmod -R 777 ./owncloud/*</code></p><p>配置说明<br>OWNCLOUD_VERSION:  ownCloud 版本<br>OWNCLOUD_DOMAIN: ownCloud 可访问的域<br>ADMIN_USERNAME: 管理员用户名<br>ADMIN_PASSWORD: 管理员密码<br>HTTP_PORT: 使用的端口<br>HTTPS_PORT: SSL使用的端口</p><p>总结来说,推荐使用第三种方式来部署.</p><h3 id="docker-compose-文件备份"><a href="#docker-compose-文件备份" class="headerlink" title="docker-compose 文件备份"></a>docker-compose 文件备份</h3><p>docker-compose.yml:</p><pre><code class="yaml">    version: &#39;2.1&#39;    volumes:      files:        driver: local      mysql:        driver: local      backup:        driver: local      redis:        driver: local    services:      owncloud:        image: owncloud/server:${OWNCLOUD_VERSION}        restart: always        container_name: owncloud-server        ports:          - ${HTTP_PORT}:8080        depends_on:          - db          - redis        environment:          - OWNCLOUD_DOMAIN=${OWNCLOUD_DOMAIN}          - OWNCLOUD_DB_TYPE=mysql          - OWNCLOUD_DB_NAME=owncloud          - OWNCLOUD_DB_USERNAME=owncloud          - OWNCLOUD_DB_PASSWORD=owncloud          - OWNCLOUD_DB_HOST=db          - OWNCLOUD_ADMIN_USERNAME=${ADMIN_USERNAME}          - OWNCLOUD_ADMIN_PASSWORD=${ADMIN_PASSWORD}          - OWNCLOUD_MYSQL_UTF8MB4=true          - OWNCLOUD_REDIS_ENABLED=true          - OWNCLOUD_REDIS_HOST=redis        healthcheck:          test: [&quot;CMD&quot;, &quot;/usr/bin/healthcheck&quot;]          interval: 30s          timeout: 10s          retries: 5        volumes:          - /home/liufa/owncloud-data:/mnt/data      db:        image: webhippie/mariadb:latest        restart: always        container_name: owncloud-mysql        environment:          - MARIADB_ROOT_PASSWORD=owncloud          - MARIADB_USERNAME=owncloud          - MARIADB_PASSWORD=owncloud          - MARIADB_DATABASE=owncloud          - MARIADB_MAX_ALLOWED_PACKET=128M          - MARIADB_INNODB_LOG_FILE_SIZE=64M        healthcheck:          test: [&quot;CMD&quot;, &quot;/usr/bin/healthcheck&quot;]          interval: 30s          timeout: 10s          retries: 5        volumes:          - /home/liufa/owncloud-mysql:/var/lib/mysql          - /home/liufa/owncloud-mysql-backup:/var/lib/backup      redis:        image: webhippie/redis:latest        container_name: owncloud-redis        restart: always        environment:          - REDIS_DATABASES=1        healthcheck:          test: [&quot;CMD&quot;, &quot;/usr/bin/healthcheck&quot;]          interval: 30s          timeout: 10s          retries: 5        volumes:          - /home/liufa/owncloud-redis:/var/lib/redis</code></pre><p>.env:</p><pre><code class="bash">    OWNCLOUD_VERSION=10.0    OWNCLOUD_DOMAIN=0.0.0.0    ADMIN_USERNAME=admin    ADMIN_PASSWORD=    HTTP_PORT=1194    HTTPS_PORT=443</code></pre><h3 id="nginx-反向代理时的配置"><a href="#nginx-反向代理时的配置" class="headerlink" title="nginx 反向代理时的配置"></a>nginx 反向代理时的配置</h3><p>注意配置 请求头 和 限制上传文件的大小</p><pre><code class="bash">    server {            listen       80;            #listen       [::]:80 default_server;            server_name  cloud.joylau.cn;            location / {               # proxy_pass http://JoyCloud;                proxy_set_header X-Forwarded-For $remote_addr;                proxy_set_header Host            $http_host;                proxy_pass   http://127.0.0.1:1194;                client_max_body_size    10000m;            }        }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> ownCloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 关键字自动补全的实现</title>
      <link href="/2018/08/13/Elasticsearch-AutoComplete/"/>
      <url>/2018/08/13/Elasticsearch-AutoComplete/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>我们经常能看到在各大电商网站搜索关键字的时候,底下下拉框会补全你要搜索的商品,或者类似的商品,有时候甚至连错别字也能纠正过来,其实ElasticSearch也能实现这样的功能</p><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><p>首先,能够被自动补全的需要设置索引类型为”completion”,其次,还可以设置自动提示为中文分词</p><pre><code class="json">    {      &quot;settings&quot;: {        &quot;analysis&quot;: {          &quot;analyzer&quot;: {            &quot;ik&quot;: {              &quot;tokenizer&quot;: &quot;ik_max_word&quot;            },            &quot;ngram_analyzer&quot;: {              &quot;tokenizer&quot;: &quot;ngram_tokenizer&quot;            }          },          &quot;tokenizer&quot;: {            &quot;ngram_tokenizer&quot;: {              &quot;type&quot;: &quot;ngram&quot;,              &quot;min_gram&quot;: 1,              &quot;max_gram&quot;: 30,              &quot;token_chars&quot;: [                &quot;letter&quot;,                &quot;digit&quot;              ]            }          }        }      },      &quot;mappings&quot;: {        &quot;knowledge_info&quot;: {          &quot;properties&quot;: {            &quot;infoId&quot;: {              &quot;type&quot;: &quot;string&quot;            },            &quot;infoTitle&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;,              &quot;fields&quot;: {                &quot;suggest&quot;: {                  &quot;max_input_length&quot;: 30,                  &quot;preserve_position_increments&quot;: false,                  &quot;type&quot;: &quot;completion&quot;,                  &quot;preserve_separators&quot;: false,                  &quot;analyzer&quot;: &quot;ik_max_word&quot;                },                &quot;wordCloud&quot;: {                  &quot;type&quot;: &quot;string&quot;,                  &quot;analyzer&quot;: &quot;ik_smart&quot;,                  &quot;fielddata&quot;:&quot;true&quot;                }              }            },            &quot;infoKeywords&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;,              &quot;fields&quot;: {                &quot;suggest&quot;: {                  &quot;max_input_length&quot;: 30,                  &quot;preserve_position_increments&quot;: false,                  &quot;type&quot;: &quot;completion&quot;,                  &quot;preserve_separators&quot;: false,                  &quot;analyzer&quot;: &quot;ik_max_word&quot;                },                &quot;wordCloud&quot;: {                  &quot;type&quot;: &quot;string&quot;,                  &quot;analyzer&quot;: &quot;ik_smart&quot;,                  &quot;fielddata&quot;:&quot;true&quot;                }              }            },            &quot;infoSummary&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;,              &quot;fields&quot;: {                &quot;suggest&quot;: {                  &quot;max_input_length&quot;: 30,                  &quot;preserve_position_increments&quot;: false,                  &quot;type&quot;: &quot;completion&quot;,                  &quot;preserve_separators&quot;: false,                  &quot;analyzer&quot;: &quot;ik_max_word&quot;                },                &quot;wordCloud&quot;: {                  &quot;type&quot;: &quot;string&quot;,                  &quot;analyzer&quot;: &quot;ik_smart&quot;,                  &quot;fielddata&quot;:&quot;true&quot;                }              }            },            &quot;infoContent&quot;: {              &quot;type&quot;: &quot;text&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyAuthor&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyIssueUnit&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyStandardCode&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyLiteratureCategory&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyLcCode&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;propertyLiteratureCode&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;data&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;attachment.content&quot;: {              &quot;type&quot;: &quot;text&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;auditState&quot;: {              &quot;type&quot;: &quot;string&quot;            },            &quot;infoType&quot;: {              &quot;type&quot;: &quot;string&quot;            },            &quot;infoFileUrl&quot;: {              &quot;type&quot;: &quot;string&quot;            },            &quot;infoFileName&quot;: {              &quot;type&quot;: &quot;string&quot;,              &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;,              &quot;fields&quot;: {                &quot;suggest&quot;: {                  &quot;max_input_length&quot;: 60,                  &quot;preserve_position_increments&quot;: false,                  &quot;type&quot;: &quot;completion&quot;,                  &quot;preserve_separators&quot;: false,                  &quot;analyzer&quot;: &quot;ik_max_word&quot;                }              }            },            &quot;createTime&quot;: {              &quot;type&quot;: &quot;string&quot;            }          }        }      }    }</code></pre><p>其中 elasticsearch 需要安装中文分词 ik 插件和附件处理插件 ingest-attachment</p><h3 id="Java-API-调用"><a href="#Java-API-调用" class="headerlink" title="Java API 调用"></a>Java API 调用</h3><pre><code class="java">    /**     * 自动完成提示     * @param search search     * @return MessageBody     */    public MessageBody autoCompleteKnowledgeInfo(KnowledgeSearch search) {        //设置搜索建议        CompletionSuggestionBuilder infoTitleSuggestion = new CompletionSuggestionBuilder(&quot;infoTitle.suggest&quot;)                .text(search.getQuery())                .size(6);        CompletionSuggestionBuilder infoKeywordsSuggestion = new CompletionSuggestionBuilder(&quot;infoKeywords.suggest&quot;)                .text(search.getQuery())                .size(6);        CompletionSuggestionBuilder infoSummarySuggestion = new CompletionSuggestionBuilder(&quot;infoSummary.suggest&quot;)                .text(search.getQuery())                .size(6);        CompletionSuggestionBuilder infoFileNameSuggestion = new CompletionSuggestionBuilder(&quot;infoFileName.suggest&quot;)                .text(search.getQuery())                .size(6);        SuggestBuilder suggestBuilder = new SuggestBuilder()                .addSuggestion(&quot;标题&quot;, infoTitleSuggestion)                .addSuggestion(&quot;关键字&quot;, infoKeywordsSuggestion)                .addSuggestion(&quot;摘要&quot;, infoSummarySuggestion)                .addSuggestion(&quot;附件&quot;,infoFileNameSuggestion);        SearchRequestBuilder searchRequest = client.prepareSearch(ES_KNOWLEDGE_INDEX)                .setFetchSource(false)                .suggest(suggestBuilder);        List&lt;JSONObject&gt; list = new ArrayList&lt;&gt;();        //查询结果        SearchResponse searchResponse = searchRequest.get();        /*没查到结果*/        if (searchResponse.getSuggest() == null) {            return MessageBody.success(list);        }        searchResponse.getSuggest().forEach(entries -&gt; {            String name = entries.getName();            for (Suggest.Suggestion.Entry&lt;? extends Suggest.Suggestion.Entry.Option&gt; entry : entries) {                for (Suggest.Suggestion.Entry.Option option : entry.getOptions()) {                    JSONObject object = new JSONObject();                    object.put(&quot;name&quot;,name);                    object.put(&quot;text&quot;,option.getText().string());                    list.add(object);                }            }        });        return MessageBody.success(list);    }</code></pre><p>代码摘取自项目中的部分, 另外前端还可以配合自动完成的插件,最终来实现效果.</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 查询全部数据</title>
      <link href="/2018/08/09/Elasticsearch-SearchAll/"/>
      <url>/2018/08/09/Elasticsearch-SearchAll/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>有时我们希望查询 固定条件下的全部数据<br>ES 默认的策略是返回10条数据<br>虽然可以 setSize()<br>但是默认上限是 10 万还是 100 万条数据,这不够优雅,一般不这么干</p><h3 id="TransportClient-方法"><a href="#TransportClient-方法" class="headerlink" title="TransportClient 方法"></a>TransportClient 方法</h3><pre><code class="java">    TimeValue keepAlive = TimeValue.timeValueMinutes(30);        SearchRequestBuilder searchRequest = client.prepareSearch(ES_KNOWLEDGE_INDEX)                .setScroll(keepAlive)                .setSize(10000);        SearchResponse searchResponse = searchRequest.get();        do {            //处理的业务 saveIds(searchResponse);            searchResponse = client.prepareSearchScroll(searchResponse.getScrollId()).setScroll(keepAlive).execute()                    .actionGet();        } while (searchResponse.getHits().getHits().length != 0);</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>$(...).autocomplete is not a function 问题的解决</title>
      <link href="/2018/08/09/Jquery-Load-Plugins/"/>
      <url>/2018/08/09/Jquery-Load-Plugins/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>因项目需求,需要一个自动提示的功能,想到之前有 jquery 的 jQuery-Autocomplete 插件,于是就直接拿来用了,<br>直接在github 上找到了一个 starts 最多的项目 <a href="https://github.com/devbridge/jQuery-Autocomplete.git" target="_blank" rel="noopener">jQuery-Autocomplete</a><br>看了下插件的 API 可配置项很多,有一个 appendTo 配置,是我想要的,于是就决定使用这个差价</p><p>直接把 插件下载下来 放到项目中去,直接 $(…).autocomplete is not a function<br>……</p><p>项目中我写的只是其中的一个模块,页面的代码是纯 html 页面写的,然后通过 panel 引入 html 代码片段<br>很奇怪,为什么插件无法加载</p><p>于是就就把官方的demo跑了一下,没有问题</p><p>又怀疑是 jQuery 版本的问题,<br>官方的demo jQuery 版本是 1.8.2,项目使用的是1.11.1,<br>于是又在官方的 demo 下替换jQuery的版本<br>发现使用没有问题</p><p>又怀疑是插件的版本过高,于是再 GitHub 的 release 上找了个2014年发布的1.2.2的版本,这已经是能找到的最低版本了<br>发现还是不行</p><p>这就奇怪了,我之前也引入过其他的插件,正常使用都没有问题,偏偏使用这个有问题<br>于是想着插件的引入方式有问题,打开一看,jQuery插件的引入方式都是大同小异的<br>本人前端不擅长,也不知道怎么改…..</p><p>于是又在 GitHub上找了其他的插件,有的能用,但是没有我想要的功能….</p><p>一直这么来来回回的测试,已经晚上 10 点了…..<br>从吃完晚饭一直研究到现在还是没有解决<br>心里好气啊!!!!!<br>空调一关,直接回家了!!!!</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>今天早上来又差了点资料,找到了个不太靠谱,但又想尝试了下的方法<br><a href="https://blog.verysu.com/article/328" target="_blank" rel="noopener">TypeError: $(…).autocomplete is not a function</a></p><p>试一下吧,没想到真的可以</p><p>发一张对比图</p><p><img src="http://image.joylau.cn/blog/Jquery-Load-Plugins.md.png" alt="query-Load-Plugins"></p>]]></content>
      
      
      <categories>
          
          <category> 前端篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jquery </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 使用 ss 代理和 Ubuntu 使用 ss 全局代理</title>
      <link href="/2018/08/07/Git-Proxy-And-Ubuntu-Global-Proxy/"/>
      <url>/2018/08/07/Git-Proxy-And-Ubuntu-Global-Proxy/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这一段时间 GitHub 在国内的访问又出问题,代码提交不上去,需要在 Git 上走代理了</p><h2 id="Git-使用-ss-代理配置"><a href="#Git-使用-ss-代理配置" class="headerlink" title="Git 使用 ss 代理配置"></a>Git 使用 ss 代理配置</h2><ol><li>需要全局 git 都走代理</li></ol><pre><code class="bash">    git config --global http.proxy &#39;socks5://127.0.0.1:1080&#39;    git config --global https.proxy &#39;socks5://127.0.0.1:1080&#39;</code></pre><p>取消</p><pre><code class="bash">    git config --global --unset http.proxy    git config --global --unset https.proxy</code></pre><p>但是有时候我们并不需要所有的 git 仓库都走代理,可以去掉上述的命令中的 <code>--global</code>,然后到你需要走代理的那个 git 仓库下执行命令,或者添加配置:</p><ol start="2"><li>单独配置 git 走代理<br>在 .git =&gt; config 文件中加入配置</li></ol><pre><code class="bash">    [https]        proxy = socks5://127.0.0.1:1080    [http]        proxy = socks5://127.0.0.1:1080</code></pre><p>其实,也就是上述命令执行后添加的配置.配置后就可以愉快的 clone push 了.</p><h2 id="Ubuntu-使用全局代理"><a href="#Ubuntu-使用全局代理" class="headerlink" title="Ubuntu 使用全局代理"></a>Ubuntu 使用全局代理</h2><p>Windows 和 MacOS 下的 ss 全局代理很方便,点击切换下就可以了,而 Ubuntu 下需要多点操作:</p><ol><li>启动 shadowsocks-qt5，并连接上</li><li>生成 pac 文件,如果有现成的 pac 文件,直接进入第四步</li><li>生成 pac 文件</li></ol><p>安装 pip </p><pre><code class="shell">    $ sudo pip install genpac    $ pip install -U genpac ## 安装或更新</code></pre><p>创建 user-rules.txt 文件</p><pre><code class="shell">    mkdir vpnPAC    cd vpnPAC    touch user-rules.txt</code></pre><p>生成 autoproxy.pac 文件</p><pre><code class="shell">    genpac --format=pac --pac-proxy=&quot;SOCKS5 127.0.0.1:1080&quot; --output=&quot;autoproxy2.pac&quot; --gfwlist-url=&quot;https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt&quot; --user-rule-from=&quot;user-rules.txt&quot;</code></pre><p>github 上的 gfwlist.txt 文件可能读取不到,多试几次</p><ol start="4"><li>配置使用</li></ol><p><img src="http://image.joylau.cn/blog/ubuntu-global-proxy.png" alt="配置使用"></p>]]></content>
      
      
      <categories>
          
          <category> Git篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>宽带速率转换</title>
      <link href="/2018/08/03/BroadbandSpeedConversion/"/>
      <url>/2018/08/03/BroadbandSpeedConversion/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>昨天和别人吃饭谈起了家里宽带的问题，办了多少兆的宽带，网速能有多少等云云，对方是个小白，和他说了半天，但是有些深层次的原理我也弄不清楚，后来我上网科普了一下，现在整理如下</p><h3 id="什么是宽带速率？"><a href="#什么是宽带速率？" class="headerlink" title="什么是宽带速率？"></a>什么是宽带速率？</h3><p>宽带速率是指技术上所能达到的理论最高信息传送比特率，一般是上传和下载的速度，速率越高，上传和下载的越快。用户申请的宽带业务速率指技术上所能达到的最大理论速率值。但用户上网时还受到用户电脑软硬件的配置、所浏览网站的地址、终端网站带宽等情况的影响。因此，用户上网时的速率通常低于理论速率值。</p><p>理论上，2M，即2Mb/s，宽带理论速率是 256KB/S。实际速率大约为103–200KB/S。（其原因是受用户计算机性能、网络设备质量、资源使用情况、网络高峰期、网站服务能力、线路衰耗、信号衰减等多因素的影响而造成的）。4M，即4Mb/s宽带理论速率是 512KB/S 实际速率大约为200—440KB/S。</p><h3 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h3><p>在计算机科学中，bit是表示信息的最小单位，叫做二进制位；一般用0和1表示。Byte叫做字节，由8个位（8bit）组成一个字节(1Byte)，用于表示计算机中的一个字符。bit与Byte之间可以进行换算，其换算关系为：1Byte=8bit（或简写为：1B=8b）；在实际应用中一般用简称，即1bit简写为1b(注意是小写英文字母b)，1Byte简写为1B（注意是大写英文字母B）。</p><p>在计算机网络或者是网络运营商中，一般，宽带速率的单位用bps(或b/s)表示；bps表示比特每秒即表示每秒钟传输多少位信息，是bit per second的缩写。在实际所说的1M带宽的意思是1Mbps（是兆比特每秒Mbps不是兆字节每秒MBps）。</p><p>换算公式：<code>1B=8b 1B/s=8b/s(或1Bps=8bps)</code></p><p>规范提示：实际书写规范中B应表示Byte(字节)，b应表示bit(比特)，但在平时的实际书写中有的把bit和Byte都混写为b ，如把Mb/s和MB/s都混写为Mb/s，导致人们在实际计算中因单位的混淆而出错。</p><p>实例： 在我们实际上网应用中，下载软件时常常看到诸如下载速度显示为128KBps（KB/s），103KB/s等等宽带速率大小字样，因为ISP提供的线路带宽使用的单位是比特，而一般下载软件显示的是字节（1字节=8比特），所以要通过换算，才能得实际值。然而我们可以按照换算公式换算一下：</p><p><code>1Mb/s = 1024Kb/s = 128×8(Kb/s) = 128KB/s</code></p><p><code>即 1Mb/s = 128KB/s</code></p><h3 id="宽带速率对照表"><a href="#宽带速率对照表" class="headerlink" title="宽带速率对照表"></a>宽带速率对照表</h3><table><thead><tr><th>常见宽带</th><th>理论最高速率（Mbps）</th><th>理论最高速率（KB/S）</th><th>常见下载速率（供参考）</th></tr></thead><tbody><tr><td>1M</td><td>1 Mbps</td><td>128 KB/S</td><td>77~128 KB/S</td></tr><tr><td>2M</td><td>2 Mbps</td><td>256 KB/S</td><td>154~256 KB/S</td></tr><tr><td>3M</td><td>3 Mbps</td><td>384 KB/S</td><td>231~384 KB/S</td></tr><tr><td>4M</td><td>4 Mbps</td><td>512 KB/S</td><td>307~512 KB/S</td></tr><tr><td>6M</td><td>6 Mbps</td><td>620 KB/S</td><td>462~620 KB/S</td></tr><tr><td>8M</td><td>8 Mbps</td><td>1024 KB/S</td><td>614~1024 KB/S</td></tr><tr><td>10M</td><td>10 Mbps</td><td>1280 KB/S</td><td>768~1280 KB/S</td></tr><tr><td>12M</td><td>12 Mbps</td><td>1536 KB/S</td><td>922~1536 KB/S</td></tr><tr><td>20M</td><td>20 Mbps</td><td>2560 KB/S</td><td>1536~2560 KB/S</td></tr><tr><td>30M</td><td>30 Mbps</td><td>3840 KB/S</td><td>2560~3840 KB/S</td></tr><tr><td>50M</td><td>50 Mbps</td><td>6400 KB/S</td><td>3840~6400 KB/S</td></tr><tr><td>100M</td><td>100 Mbps</td><td>12800 KB/S</td><td>7680~12800 KB/S</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 其他篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NamedParameterJdbcTemplate 使用具名参数记录</title>
      <link href="/2018/07/30/Spring-NamedParameterJdbcTemplate/"/>
      <url>/2018/07/30/Spring-NamedParameterJdbcTemplate/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近维护了一个比较老的项目，操作数据库直接用的 Spring 的 JdbcTemplate，有很多地方我们传入的参数都是不确定的<br>简单的还好，复杂的 sql 语句在代码里用字符串拼接起来简直不能忍，<br>又不想对原来的项目有什么大的改动，就想这能不能在现在的基础上优化一下<br>还好有 NamedParameterJdbcTemplate</p><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>具名参数: SQL 按名称(以冒号开头)而不是按位置进行指定. 具名参数更易于维护, 也提升了可读性. 具名参数由框架类在运行时用占位符取代<br>具名参数只在 NamedParameterJdbcTemplate 中得到支持。NamedParameterJdbcTemplate可以使用全部jdbcTemplate方法</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><ol><li>该类位于 <code>org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate</code></li><li>有2个构造方法，参数分别是 DataSource 和 JdbcOperations</li></ol><pre><code class="java">    /**     * Create a new NamedParameterJdbcTemplate for the given {@link DataSource}.     * &lt;p&gt;Creates a classic Spring {@link org.springframework.jdbc.core.JdbcTemplate} and wraps it.     * @param dataSource the JDBC DataSource to access     */    public NamedParameterJdbcTemplate(DataSource dataSource) {        Assert.notNull(dataSource, &quot;DataSource must not be null&quot;);        this.classicJdbcTemplate = new JdbcTemplate(dataSource);    }    /**     * Create a new NamedParameterJdbcTemplate for the given classic     * Spring {@link org.springframework.jdbc.core.JdbcTemplate}.     * @param classicJdbcTemplate the classic Spring JdbcTemplate to wrap     */    public NamedParameterJdbcTemplate(JdbcOperations classicJdbcTemplate) {        Assert.notNull(classicJdbcTemplate, &quot;JdbcTemplate must not be null&quot;);        this.classicJdbcTemplate = classicJdbcTemplate;    }</code></pre><ol start="3"><li>实例化 bean 只要将 dataSource 或者 JdbcTemplate 传入到构造参数即可</li></ol><pre><code class="xml">    &lt;bean id=&quot;namedParameterJdbcTemplate&quot;          class=&quot;org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate&quot;&gt;        &lt;constructor-arg ref=&quot;dataSource&quot;/&gt;    &lt;/bean&gt;</code></pre><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><ol><li>注入 namedParameterJdbcTemplate</li></ol><h3 id="参数的传入"><a href="#参数的传入" class="headerlink" title="参数的传入"></a>参数的传入</h3><p>namedParameterJdbcTemplate 参数传入有 2 中方法：</p><ol><li><p><code>Map&lt;String, ?&gt; paramMap</code> 我们熟知的 map</p></li><li><p><code>SqlParameterSource paramSource</code><br> 该接口默认的实现有三个类：</p><p> <code>MapSqlParameterSource</code> 实现非常简单，只是封装了java.util.Map；<br> 当 Map&lt;String, ?&gt; paramMap 用吧 或者 new MapSqlParameterSource(paramMap) 参数为 map</p><p> <code>BeanPropertySqlParameterSource</code> 封装了一个JavaBean对象，通过JavaBean对象属性来决定命名参数的值。<br>  new BeanPropertySqlParameterSource(dto) new 出一个 BeanPropertySqlParameterSource 对象，构造方法传入实体类即可，绝大部分情况下我们都使用这种方式</p><p> <code>EmptySqlParameterSource</code> 一个空的SqlParameterSource ，常用来占位使用<br>  没用过</p></li></ol><h3 id="数据返回"><a href="#数据返回" class="headerlink" title="数据返回"></a>数据返回</h3><ol><li><p>返回 Map</p></li><li><p>返回 RowMapper 包装好的实体类，该类有2中实现<br> SingleColumnRowMapper ，sql结果为一个单列的数据，如List<String> , List<Integer>,String,Integer等</p><p> BeanPropertyRowMapper， sql结果匹配到对象 List&lt; XxxVO&gt; , XxxVO</p></li></ol><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre><code class="java">    KnowledgeInfo info = new KnowledgeInfo();    info.setAuditState(&quot;1&quot;);    List&lt;KnowledgeInfo&gt; infos = namedParameterJdbcTemplate.query(            sql,            new BeanPropertySqlParameterSource(info),            new BeanPropertyRowMapper&lt;&gt;(KnowledgeInfo.class)    );</code></pre><p>注意： sql 语句中的参数使用 <code>:参数名</code> 进行占位</p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle 里 number 类型对应 JdbcType bean 类型记录</title>
      <link href="/2018/07/29/OracleNubmer-JdbcType/"/>
      <url>/2018/07/29/OracleNubmer-JdbcType/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><table><thead><tr><th>number长度</th><th>Java类型</th></tr></thead><tbody><tr><td>1~4</td><td>Short</td></tr><tr><td>5~9</td><td>Integer</td></tr><tr><td>10~18</td><td>Long</td></tr><tr><td>18+</td><td>BigDecimal</td></tr></tbody></table><p>须指定number类型的大小。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DenyHosts 清除黑名单 IP 地址</title>
      <link href="/2018/07/19/Linux-Cancel-DenyHosts/"/>
      <url>/2018/07/19/Linux-Cancel-DenyHosts/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>今天连接远程服务器发生了以下的错误</p><pre><code class="bash">    ssh_exchange_identification: read: Connection reset</code></pre><p>我想应该是我当前的 IP 地址被 DenyHosts 加入了黑名单<br>本来想只要将当前的 ip 地址在黑名单中去掉就可以了<br>没想到事实并不是如此,为此还查资料花费了一点功夫<br>现记录下来</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><ol><li>停用 DenyHosts : <code>systemctl stop denyhosts.service</code></li><li>删除黑名单中当前的ip地址: <code>vim /etc/hosts.deny</code></li><li>进入  <code>/var/lib/denyhosts</code></li></ol><pre><code class="bash">      -rw-r--r-- 1 root root    39 2月  16 2015 allowed-hosts      -rw-r--r-- 1 root root 71451 7月  19 10:58 hosts      -rw-r--r-- 1 root root 71270 7月  19 10:58 hosts-restricted      -rw-r--r-- 1 root root 71433 7月  19 10:58 hosts-root      -rw-r--r-- 1 root root 71280 7月  19 10:58 hosts-valid      -rw-r--r-- 1 root root   105 7月  19 10:58 offset      -rw-r--r-- 1 root root     0 7月  19 10:58 suspicious-logins      -rw-r--r-- 1 root root 44731 7月  19 10:58 users-hosts      -rw-r--r-- 1 root root 50925 7月  19 10:58 users-invalid      -rw-r--r-- 1 root root   643 7月  19 10:58 users-valid</code></pre><ol start="4"><li>依次在上面各个文件中移除自己当前的IP地址</li><li>如果要将当前的IP地址添加到白名单中,可以在 /etc/hosts.allow 添加<br>sshd: ip地址<br>allowed-hosts 添加 IP地址</li><li>重启 DenyHosts</li></ol><blockquote><p>注意: 这些文件里有很多被拉入黑名单的IP地址,vim编辑的时候可以在命令行模式下使用 <code>/ip地址</code> 来查找, n 和 N 上下翻动,再在命令行模式下 <code>:noh</code> 取消查找</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 最佳编程字体 Monaco 的优化显示</title>
      <link href="/2018/07/13/Ubuntu-Fonts-Monaco/"/>
      <url>/2018/07/13/Ubuntu-Fonts-Monaco/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>自从入了 MBP 后就被其默认的字体显示效果吸引了，在编辑器里写代码更是舒服，于是想着把 Mac 下的字体也移植到 Ubuntu 下，但是显示效果并不是特别的好，尤其是粗体字的显示</p><h2 id="前后对比"><a href="#前后对比" class="headerlink" title="前后对比"></a>前后对比</h2><p>左侧使用前，右侧使用后</p><figure class="half"><img src="http://image.joylau.cn/blog/Monaco1.png" width="50%"/><img src="http://image.joylau.cn/blog/Monaco4.png" width="50%"/></figure><figure class="half"><img src="http://image.joylau.cn/blog/Monaco2.png" width="50%"/><img src="http://image.joylau.cn/blog/Monaco5.png" width="50%"/></figure><figure class="half"><img src="http://image.joylau.cn/blog/Monaco3.png" width="50%"/><img src="http://image.joylau.cn/blog/Monaco6.png" width="50%"/></figure><h2 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h2><ol><li>该字体为开源字体，字体地址： <a href="https://github.com/vjpr/monaco-bold" target="_blank" rel="noopener">https://github.com/vjpr/monaco-bold</a></li><li>复制到 <code>/usr/share/fonts</code></li><li><code>fc-cache -fv</code> 生成字体缓存</li></ol><p>我的 1080P 分辨率，我的配置如下：<br><img src="http://image.joylau.cn/blog/Monaco7.png" alt="MonacoB2"></p><h2 id="2018-07-18-14-22-05-更新"><a href="#2018-07-18-14-22-05-更新" class="headerlink" title="2018-07-18 14:22:05 更新"></a>2018-07-18 14:22:05 更新</h2><p>看到一篇关于 Ubuntu 字体渲染问题的文章: 修复 Ubuntu 中文字体渲染  <a href="https://i-meto.com/fix-chinese-font-display/" target="_blank" rel="noopener">https://i-meto.com/fix-chinese-font-display/</a></p>]]></content>
      
      
      <categories>
          
          <category> Ubuntu篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 使用阿里云个人专属加速器</title>
      <link href="/2018/07/12/Docker-AliAccelerator/"/>
      <url>/2018/07/12/Docker-AliAccelerator/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol start="0"><li><p>原来阿里云给每个账户都有分配专属的加速器地址</p></li><li><p>登录阿里云控制台</p></li><li><p>进入容器镜像服务，点击最下方的镜像加速器，会出现个人的专属加速器地址，我的是： <a href="https://0ppztvl0.mirror.aliyuncs.com" target="_blank" rel="noopener">https://0ppztvl0.mirror.aliyuncs.com</a></p></li><li><p>Docker客户端版本大于1.10.0的用户，创建 <code>/etc/docker/daemon.json</code><br> {<br>   “registry-mirrors”: [“<a href="https://0ppztvl0.mirror.aliyuncs.com&quot;]">https://0ppztvl0.mirror.aliyuncs.com&quot;]</a><br> }</p><p> sudo systemctl daemon-reload<br> sudo systemctl restart docker</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以非 root 用户身份管理 Docker</title>
      <link href="/2018/07/05/Docker-Manager-NonRoot/"/>
      <url>/2018/07/05/Docker-Manager-NonRoot/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>docker 安装完成后，其他用户只能使用 sudo 访问它。docker 守护进程始终以 root 用户身份运行，这样每次在使用命令时都需要在前面加上sudo,这很不方便。<br>有没有什么方式能够解决？<br>官方文档地址： <a href="https://docs.docker.com/install/linux/linux-postinstall/" target="_blank" rel="noopener">https://docs.docker.com/install/linux/linux-postinstall/</a></p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>docker 守护进程绑定至 Unix 套接字，而不是 TCP 端口。默认情况下，该 Unix 套接字由用户 root 所有，而其他用户只能使用 sudo 访问它。docker 守护进程始终以 root 用户身份运行。</p><p>在使用 docker 命令时，如果您不想使用 sudo，请创建名为 docker 的 Unix 组并向其中添加用户。docker 守护进程启动时，它将使 Unix 套接字的所有权可由 docker 组进行读取/写入。</p><blockquote><blockquote><blockquote><p>警告： docker 组将授予等同于 root 用户的特权。如需有关此操作如何影响系统安全性的详细信息，请参阅 Docker 守护进程攻击面。</p></blockquote></blockquote></blockquote><p>如需创建 docker 组并添加您的用户，请执行下列操作：</p><ol><li>创建 docker 组。</li></ol><pre><code class="shell">     $ sudo groupadd docker</code></pre><p>向 docker 组中添加您的用户。</p><pre><code class="shell">    $ sudo usermod -aG docker $USER</code></pre><p>注销并重新登录，以便对您的组成员资格进行重新评估。</p><p>如果在虚拟机上进行测试，可能必须重启此虚拟机才能使更改生效。</p><p>在桌面 Linux 环境（例如，X Windows）中，彻底从您的会话中注销，然后重新登录。</p><p>验证您是否可以在不使用 sudo 的情况下运行 docker 命令。</p><pre><code class="shell">    $ docker run hello-world</code></pre><p>此命令将下载一个测试镜像并在容器中运行它。容器运行时，它将输出一条参考消息并退出。</p><p>经过实测，Ubuntu通过源添加安装最新版 Docker 时，已经自动添加了 docker 组，只需要将 当前用户添加到组里面在重新登录就可以了。</p>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>office 套件的一系列研究记录</title>
      <link href="/2018/07/02/OfficeSuiteStudy/"/>
      <url>/2018/07/02/OfficeSuiteStudy/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="ElasticSearch-环境准备"><a href="#ElasticSearch-环境准备" class="headerlink" title="ElasticSearch 环境准备"></a>ElasticSearch 环境准备</h2><p>略</p><h2 id="中文分词实现"><a href="#中文分词实现" class="headerlink" title="中文分词实现"></a>中文分词实现</h2><ol><li><p>安装插件 <a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik</a></p></li><li><p>测试分词：</p><p>ik_max_word会将文本做最细粒度的拆分；<br>ik_smart 会做最粗粒度的拆分。</p></li></ol><pre><code class="json">    http://192.168.10.74:9200/_analyze/ POST        {          &quot;analyzer&quot;: &quot;ik_max_word&quot;,          &quot;text&quot;: &quot;绝地求生是最好玩的游戏&quot;        }        和        {          &quot;analyzer&quot;: &quot;ik_smart&quot;,          &quot;text&quot;: &quot;绝地求生是最好玩的游戏&quot;        }        和        {          &quot;analyzer&quot;: &quot;standard&quot;,          &quot;text&quot;: &quot;绝地求生是最好玩的游戏&quot;        }</code></pre><ol start="3"><li><p>创建索引</p><p> <a href="http://192.168.10.74:9200/ik-index" target="_blank" rel="noopener">http://192.168.10.74:9200/ik-index</a>  PUT<br> 指定使用 ik_max_word 分词器</p></li></ol><pre><code class="json">    {        &quot;settings&quot; : {            &quot;analysis&quot; : {                &quot;analyzer&quot; : {                    &quot;ik&quot; : {                        &quot;tokenizer&quot; : &quot;ik_max_word&quot;                    }                }            }        },        &quot;mappings&quot; : {            &quot;article&quot; : {                &quot;dynamic&quot; : true,                &quot;properties&quot; : {                    &quot;subject&quot; : {                        &quot;type&quot; : &quot;string&quot;,                        &quot;analyzer&quot; : &quot;ik_max_word&quot;                    },                    &quot;content&quot; : {                        &quot;type&quot; : &quot;string&quot;,                        &quot;analyzer&quot; : &quot;ik_max_word&quot;                    }                }            }        }    }</code></pre><p>​    </p><ol start="4"><li><p>添加数据<br> 略</p></li><li><p>查询：<br> <a href="http://192.168.10.74:9200/index/_search" target="_blank" rel="noopener">http://192.168.10.74:9200/index/_search</a>    POST</p><pre><code class="json"> {   &quot;query&quot;: {     &quot;match&quot;: {       &quot;subject&quot;: &quot;合肥送餐冲突&quot;     }   },   &quot;highlight&quot;: {     &quot;pre_tags&quot;: [&quot;&lt;span style = &#39;color:red&#39;&gt;&quot;],     &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;],     &quot;fields&quot;: {&quot;subject&quot;: {}}   } }</code></pre></li></ol><ol start="6"><li><p>热更新<br> IKAnalyzer.cfg.xml</p><p> <entry key="remote_ext_dict"><a href="http://localhost/hotload.dic" target="_blank" rel="noopener">http://localhost/hotload.dic</a></entry></p><p> 放入到 静态资源服务器下面</p></li></ol><ol start="7"><li>同义词配置<br> <a href="http://192.168.10.74:9200/synonyms-ik-index" target="_blank" rel="noopener">http://192.168.10.74:9200/synonyms-ik-index</a>  PUT</li></ol><pre><code class="json">    {          &quot;settings&quot;: {            &quot;analysis&quot;: {              &quot;analyzer&quot;: {                &quot;by_smart&quot;: {                  &quot;type&quot;: &quot;custom&quot;,                  &quot;tokenizer&quot;: &quot;ik_smart&quot;,                  &quot;filter&quot;: [                    &quot;by_tfr&quot;,                    &quot;by_sfr&quot;                  ],                  &quot;char_filter&quot;: [                    &quot;by_cfr&quot;                  ]                },                &quot;by_max_word&quot;: {                  &quot;type&quot;: &quot;custom&quot;,                  &quot;tokenizer&quot;: &quot;ik_max_word&quot;,                  &quot;filter&quot;: [                    &quot;by_tfr&quot;,                    &quot;by_sfr&quot;                  ],                  &quot;char_filter&quot;: [                    &quot;by_cfr&quot;                  ]                }              },              &quot;filter&quot;: {                &quot;by_tfr&quot;: {                  &quot;type&quot;: &quot;stop&quot;,                  &quot;stopwords&quot;: [                    &quot; &quot;                  ]                },                &quot;by_sfr&quot;: {                  &quot;type&quot;: &quot;synonym&quot;,                  &quot;synonyms_path&quot;: &quot;synonyms.dic&quot;                }              },              &quot;char_filter&quot;: {                &quot;by_cfr&quot;: {                  &quot;type&quot;: &quot;mapping&quot;,                  &quot;mappings&quot;: [                    &quot;| =&gt; |&quot;                  ]                }              }            }          },          &quot;mappings&quot;: {            &quot;article&quot;: {              &quot;dynamic&quot;: true,              &quot;properties&quot;: {                &quot;subject&quot;: {                  &quot;type&quot;: &quot;string&quot;,                  &quot;analyzer&quot;: &quot;by_max_word&quot;,                  &quot;search_analyzer&quot;: &quot;by_smart&quot;                },                &quot;content&quot;: {                  &quot;type&quot;: &quot;string&quot;,                  &quot;analyzer&quot;: &quot;by_max_word&quot;,                  &quot;search_analyzer&quot;: &quot;by_smart&quot;                }              }            }          }        }</code></pre><ol start="8"><li><p>测试同义词</p><p> <a href="http://192.168.10.74:9200/synonyms-ik-index/_analyze" target="_blank" rel="noopener">http://192.168.10.74:9200/synonyms-ik-index/_analyze</a>  POST</p></li></ol><pre><code class="json">    {      &quot;analyzer&quot;: &quot;by_smart&quot;,      &quot;text&quot;: &quot;绝地求生是最好玩的游戏&quot;    }</code></pre><ol start="9"><li>查询同义词<br> <a href="http://192.168.10.74:9200/synonyms-ik-index/_search" target="_blank" rel="noopener">http://192.168.10.74:9200/synonyms-ik-index/_search</a>  POST</li></ol><pre><code class="json">        {          &quot;query&quot;: {            &quot;match&quot;: {              &quot;subject&quot;: &quot;吃鸡&quot;            }          },          &quot;highlight&quot;: {            &quot;pre_tags&quot;: [              &quot;&lt;span style = &#39;color:red&#39;&gt;&quot;            ],            &quot;post_tags&quot;: [              &quot;&lt;/span&gt;&quot;            ],            &quot;fields&quot;: {              &quot;subject&quot;: {}            }          }        }</code></pre><p>数据导入/导出 ： <a href="https://github.com/taskrabbit/elasticsearch-dump" target="_blank" rel="noopener">elasticdump</a> </p><p>github 地址： <a href="https://github.com/taskrabbit/elasticsearch-dump" target="_blank" rel="noopener">https://github.com/taskrabbit/elasticsearch-dump</a></p><h2 id="文件搜索实现"><a href="#文件搜索实现" class="headerlink" title="文件搜索实现"></a>文件搜索实现</h2><ol><li><p>文档地址： <a href="https://www.elastic.co/guide/en/elasticsearch/plugins/5.3/using-ingest-attachment.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/plugins/5.3/using-ingest-attachment.html</a></p></li><li><p>安装插件<br>./bin/elasticsearch-plugin install ingest-attachment</p></li><li><p>创建管道single_attachment<br> <a href="http://192.168.10.74:9200/_ingest/pipeline/single_attachment" target="_blank" rel="noopener">http://192.168.10.74:9200/_ingest/pipeline/single_attachment</a>  PUT</p></li></ol><pre><code class="json">    {      &quot;description&quot;: &quot;Extract single attachment information&quot;,      &quot;processors&quot;: [        {          &quot;attachment&quot;: {            &quot;field&quot;: &quot;data&quot;,            &quot;indexed_chars&quot;: -1,            &quot;ignore_missing&quot;: true          }        },         {           &quot;remove&quot;: {             &quot;field&quot;: &quot;data&quot;           }         }      ]    }</code></pre><p>field  :  指定某个字段作为附件内容字段（需要用base64进行加密）</p><p>target_field：指定某个字段作为附件信息字段（作者、时间、类型）</p><p>indexed_chars : 指定解析文件管道流的最大大小，默认是100000。如果不想限制设置为-1（注意设置为-1的时候如果上传文件过大会而内存不够会导致文件上传不完全）</p><p>indexed_chars_field：指定某个字段能覆盖index_chars字段属性，这样子可以通过文件的大小去指定indexed_chars值。</p><p>properties:  选择需要存储附件的属性值可以为：content,title,name,author,keyword,date,content_type,content_length,language</p><p>ignore_missing： 默认为false，如果设置为true表示，如果上面指定的field字段不存在这不对附件进行解析，文档还能继续保留</p><p>新增了添加完附件数据后 删除 data 的 base64 的数据</p><p>多文件管道流</p><pre><code class="json">    {      &quot;description&quot;: &quot;多文件管道流&quot;,      &quot;processors&quot;: [         {          &quot;foreach&quot;: {            &quot;field&quot;: &quot;attachments&quot;,            &quot;processor&quot;: {              &quot;attachment&quot;: {                &quot;field&quot;: &quot;data&quot;,                &quot;indexed_chars&quot;: -1,                &quot;ignore_missing&quot;: true              }            }          }        }      ]    }</code></pre><ol start="3"><li>删除通道</li></ol><p><a href="http://192.168.10.74:9200/_ingest/pipeline/single_attachment" target="_blank" rel="noopener">http://192.168.10.74:9200/_ingest/pipeline/single_attachment</a>  DELETE</p><ol start="4"><li>创建索引<br> <a href="http://192.168.10.74:9200/file_attachment/" target="_blank" rel="noopener">http://192.168.10.74:9200/file_attachment/</a>  PUT</li></ol><pre><code class="json">    {      &quot;settings&quot;: {        &quot;analysis&quot;: {          &quot;analyzer&quot;: {            &quot;ik&quot;: {              &quot;tokenizer&quot;: &quot;ik_max_word&quot;            }          }        }      },      &quot;mappings&quot;: {        &quot;attachment&quot;: {          &quot;properties&quot;: {            &quot;filename&quot;: {              &quot;type&quot;: &quot;text&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            },            &quot;data&quot;: {              &quot;type&quot;: &quot;text&quot;            },            &quot;time&quot;: {              &quot;type&quot;: &quot;string&quot;            },            &quot;attachment.content&quot;: {              &quot;type&quot;: &quot;text&quot;,              &quot;analyzer&quot;: &quot;ik_max_word&quot;            }          }        }      }    }</code></pre><ol start="5"><li>添加数据<br> <a href="http://192.168.10.74:9200/file_attachment/attachment/1?pipeline=single_attachment&amp;refresh=true&amp;pretty=1/" target="_blank" rel="noopener">http://192.168.10.74:9200/file_attachment/attachment/1?pipeline=single_attachment&amp;refresh=true&amp;pretty=1/</a>  POST</li></ol><pre><code class="json">    {      &quot;filename&quot;: &quot;测试文档.txt&quot;,      &quot;time&quot;: &quot;2018-06-13 15:14:00&quot;,      &quot;data&quot;: &quot;6L+Z5piv56ys5LiA5Liq55So5LqO5rWL6K+V5paH5pys6ZmE5Lu255qE5YaF5a6577yb5paH5Lu25qC85byP5Li6dHh0LOaWh+acrOS4uuS4reaWhw==&quot;    }</code></pre><ol start="6"><li>文档查询<br> <a href="http://192.168.10.74:9200/file_attachment/_search" target="_blank" rel="noopener">http://192.168.10.74:9200/file_attachment/_search</a> POST</li></ol><pre><code class="json">    {      &quot;query&quot;: {        &quot;match&quot;: {          &quot;attachment.content&quot;: &quot;测试&quot;        }      },      &quot;highlight&quot;: {        &quot;pre_tags&quot;: [          &quot;&lt;span style = &#39;color:red&#39;&gt;&quot;        ],        &quot;post_tags&quot;: [          &quot;&lt;/span&gt;&quot;        ],        &quot;fields&quot;: {          &quot;attachment.content&quot;: {}        }      }    }</code></pre><p>注意： 使用 nginx 的静态资源目录作为 文件的存放，那么在下载文件时，想要 txt ,html ,pdf 等文件直接被下载而不被浏览器打开时，可在 nginx 的配置文件加入以下配置</p><pre><code class="bash">    server {            listen       80;            server_name  localhost;            #charset koi8-r;            #access_log  logs/host.access.log  main;            location / {                root   html;                if ($request_filename ~* ^.*?.(txt|doc|pdf|rar|gz|zip|docx|exe|xlsx|ppt|pptx|jpg|png|html|xml)$){                            add_header Content-Disposition attachment;                             add_header Content-Type &#39;APPLICATION/OCTET-STREAM&#39;;                                      }                 index  index.html index.htm;            }            #error_page  404              /404.html;            # redirect server error pages to the static page /50x.html            #            error_page   500 502 503 504  /50x.html;            location = /50x.html {                root   html;            }            # proxy the PHP scripts to Apache listening on 127.0.0.1:80            #            #location ~ \.php$ {            #    proxy_pass   http://127.0.0.1;            #}            # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000            #            #location ~ \.php$ {            #    root           html;            #    fastcgi_pass   127.0.0.1:9000;            #    fastcgi_index  index.php;            #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;            #    include        fastcgi_params;            #}            # deny access to .htaccess files, if Apache&#39;s document root            # concurs with nginx&#39;s one            #            #location ~ /\.ht {            #    deny  all;            #}        }</code></pre><p>重点是 :<br>if ($request_filename ~* ^.<em>?.(txt|doc|pdf|rar|gz|zip|docx|exe|xlsx|ppt|pptx|jpg|png|html|xml)$){<br>      add_header Content-Disposition attachment;<br>      add_header Content-Type ‘APPLICATION/OCTET-STREAM’;<br>   }<br>或者也可以这样处理：<br>if ($args ~</em> “target=download”) {<br>      add_header Content-Disposition ‘attachment’;<br>      add_header Content-Type ‘APPLICATION/OCTET-STREAM’;<br> }</p><p>这样的话只要在 get请求加上 target=download 参数就可以下载了。</p><h2 id="Office-套件研究"><a href="#Office-套件研究" class="headerlink" title="Office 套件研究"></a>Office 套件研究</h2><h3 id="OpenOffice-服务搭建"><a href="#OpenOffice-服务搭建" class="headerlink" title="OpenOffice 服务搭建"></a>OpenOffice 服务搭建</h3><h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><ol><li><p>下载 rpm 包 ： 官网： <a href="https://www.openoffice.org/download/" target="_blank" rel="noopener">https://www.openoffice.org/download/</a></p></li><li><p>解压，进入 /zh-CN/RPMS/ ， 安装 rpm 包： <code>rpm -ivh *.rpm</code></p></li><li><p>安装完成后，生成 desktop-integration 目录，进入，因为我的系统是 centos 的 ，我选择安装 <code>rpm -ivh openoffice4.1.5-redhat-menus-4.1.5-9789.noarch.rpm</code></p></li><li><p>安装完成后，目录在 /opt/openoffice4 下<br> 启动： <code>/opt/openoffice4/program/soffice -headless -accept=&quot;socket,host=0.0.0.0,port=8100;urp;&quot; -nofirststartwizard &amp;</code></p></li></ol><h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol><li><p>libXext.so.6: cannot open shared object file: No such file or directory<br> 解决 ： <code>yum install libXext.x86_64</code></p></li><li><p>no suitable windowing system found, exiting.<br> 解决： <code>yum groupinstall &quot;X Window System&quot;</code></p></li></ol><p>之后再启动，查看监听端口 <code>netstat -lnp |grep 8100</code><br>已经可以了。</p><h4 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h4><p>对很多中文字体的支持并不是很好，很多中文字符及特殊字符无法显示</p><h3 id="LibreOffice-服务搭建"><a href="#LibreOffice-服务搭建" class="headerlink" title="LibreOffice 服务搭建"></a>LibreOffice 服务搭建</h3><h4 id="安装步骤-1"><a href="#安装步骤-1" class="headerlink" title="安装步骤"></a>安装步骤</h4><ol><li><p>下载 Linux系统下的 rpm 安装包</p></li><li><p>将安装包解压缩到目录下</p></li><li><p>安装<br>$ sudo yum install ./RPMS/<em>.rpm  /</em> 安装主安装程序的所有rpm包 <em>/<br>$ sudo yum install ./RPMS/</em>.rpm  /* 安装中文语言包中的所有rpm包 <em>/<br>$ sudo yum install ./RPMS/</em>.rpm  /* 安装中文离线帮助文件中的所有rpm包 */</p></li><li><p>卸载<br> $ sudo apt-get remove –purge libreoffice6.x-*  /* 移除所有类似libreoffice6.x-*的包。–purge表示卸载的同时移除所有相关的配置文件 */</p></li></ol><h4 id="使用总结"><a href="#使用总结" class="headerlink" title="使用总结"></a>使用总结</h4><p>LibreOffice 的安装表示没有像 OpenOffice 那样遇到很多问题，且对中文字符的支持较为友好，官网也提供了相应的中文字体下载。</p><h3 id="Spring-Boot-连接并调用-Office-服务"><a href="#Spring-Boot-连接并调用-Office-服务" class="headerlink" title="Spring Boot 连接并调用 Office 服务"></a>Spring Boot 连接并调用 Office 服务</h3><pre><code class="java">    public Object preview(@PathVariable String fileName){        try {            Resource resource = new UrlResource(remoteAddr + fileName);            if (FilenameUtils.getExtension(resource.getFilename()).equalsIgnoreCase(&quot;pdf&quot;)) {                return &quot;Is the PDF file&quot;;            }            try (ByteArrayOutputStream baos = new ByteArrayOutputStream()) {                final DocumentFormat targetFormat =                        DefaultDocumentFormatRegistry.getFormatByExtension(&quot;pdf&quot;);                converter                        .convert(resource.getInputStream())                        .as(                                DefaultDocumentFormatRegistry.getFormatByExtension(                                        FilenameUtils.getExtension(resource.getFilename())))                        .to(baos)                        .as(targetFormat)                        .execute();                final HttpHeaders headers = new HttpHeaders();                headers.setContentType(MediaType.parseMediaType(targetFormat.getMediaType()));                return new ResponseEntity&lt;&gt;(baos.toByteArray(), headers, HttpStatus.OK);            } catch (OfficeException | IOException e) {                e.printStackTrace();                return &quot;convert error: &quot; + e.getMessage();            }        } catch (IOException e) {            e.printStackTrace();            return &quot;File does not exist;&quot;;        }    }</code></pre><h3 id="Collabora-Office-服务搭建"><a href="#Collabora-Office-服务搭建" class="headerlink" title="Collabora Office 服务搭建"></a>Collabora Office 服务搭建</h3><p>官方地址： <a href="https://www.collaboraoffice.com/solutions/collabora-office/" target="_blank" rel="noopener">https://www.collaboraoffice.com/solutions/collabora-office/</a></p><h4 id="Collabora-CODE-服务搭建"><a href="#Collabora-CODE-服务搭建" class="headerlink" title="Collabora CODE 服务搭建"></a>Collabora CODE 服务搭建</h4><p>官方建议采用docker来安装</p><h5 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h5><pre><code class="bash">$ docker pull collabora/code$ docker run -t -d -p 127.0.0.1:9980:9980 -e &quot;domain=&lt;your-dot-escaped-domain&gt;&quot; \        -e &quot;username=admin&quot; -e &quot;password=S3cRet&quot; --restart always --cap-add MKNOD collabora/code</code></pre><h5 id="Linux-packages"><a href="#Linux-packages" class="headerlink" title="Linux packages"></a>Linux packages</h5><pre><code class="shell"># import the signing keywget https://www.collaboraoffice.com/repos/CollaboraOnline/CODE-centos7/repodata/repomd.xml.key &amp;&amp; rpm --import repomd.xml.key# add the repository URL to yumyum-config-manager --add-repo https://www.collaboraoffice.com/repos/CollaboraOnline/CODE-centos7# perform the installationyum install loolwsd CODE-brand</code></pre><h3 id="Office-套件文档在线协作"><a href="#Office-套件文档在线协作" class="headerlink" title="Office 套件文档在线协作"></a>Office 套件文档在线协作</h3><p> 需要域名和SSL证书，尚未实际研究</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> OpenOffice </tag>
            
            <tag> LibreOffice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 自用配置记录</title>
      <link href="/2018/06/28/Ubuntu-SystemConfig/"/>
      <url>/2018/06/28/Ubuntu-SystemConfig/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="安装完系统后的一些配置"><a href="#安装完系统后的一些配置" class="headerlink" title="安装完系统后的一些配置"></a>安装完系统后的一些配置</h2><ol><li><p>关闭并禁用 swap 分区： sudo swapoff 并且 sudo vim /etc/fstab 注释掉 swap 那行</p></li><li><p>开启点击图标最小化： gsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ launcher-minimize-window true</p></li><li><p>开机开启小键盘： sudo apt-get install numlockx 然后 sudo vim /usr/share/lightdm/lightdm.conf.d/50-unity-greeter.conf 在最后添加：greeter-setup-script=/usr/bin/numlockx on</p></li><li><p>用久显示隐藏文件夹： Edit -&gt; Preferences -&gt; Views 勾选 Show hidden and backup files</p></li><li><p>禁用客人会话： <a href="https://blog.csdn.net/thuyx/article/details/78503870" target="_blank" rel="noopener">https://blog.csdn.net/thuyx/article/details/78503870</a></p></li><li><p>jdk 10 的配置？？<br> 分别下载 jdk10 和 jre 10 解压缩到 /usr/java目录下<br> 配置如下环境变量</p></li></ol><pre><code class="bash">    #set java environment    JAVA_HOME=/usr/java/jdk-10    JRE_HOME=/usr/java/jre-10    CLASS_PATH=.:$JAVA_HOME/lib:$JRE_HOME/lib    MAVEN_HOME=/usr/maven/apache-maven-3.5.3    NODE_HOME=/usr/nodejs/node-v8.11.2-linux-x64    PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:${NODE_HOME}/bin:$PATH    export JAVA_HOME JRE_HOME CLASS_PATH MAVEN_HOME NODE_HOME PATH</code></pre><ol start="7"><li><p>安装中文字体文泉译：sudo apt-get install fonts-wqy-microhei</p></li><li><p>防火墙配置<br> sudo ufw enable</p><p> sudo ufw default deny</p><p> 运行以上两条命令后，开启了防火墙，并在系统启动时自动开启。关闭所有外部对本机的访问，但本机访问外部正常</p><p> sudo ufw disable 关闭防火墙</p></li><li><p>鼠标移动速度调整<br> xset m N<br> 其中，N是速度，估计取值为0-10<br> 恢复默认 xset m default</p></li></ol><h2 id="apt-get-命令的记录"><a href="#apt-get-命令的记录" class="headerlink" title="apt-get 命令的记录"></a>apt-get 命令的记录</h2><ol><li>卸载软件： sudo apt-get purge docker-ce</li><li>查看软件版本： apt-cache madison docker-ce </li></ol><h2 id="2018年07月19日09-10-55-更新"><a href="#2018年07月19日09-10-55-更新" class="headerlink" title="2018年07月19日09:10:55 更新"></a>2018年07月19日09:10:55 更新</h2><p>indicator-sysmonitor 显示网速时,在状态栏会左右移动,解决方法是:<br>修改源代码</p><pre><code class="bash">    sudo vi  /usr/lib/indicator-sysmonitor/sensors.py   </code></pre><p>打开后，修改第29行的B_UNITS:</p><pre><code class="bash">    B_UNITS = [&#39;MB&#39;, &#39;GB&#39;, &#39;TB&#39;]</code></pre><p>接着修改下面的bytes_to_human函数：</p><pre><code class="python">    def bytes_to_human(bytes_):                     unit = 0        bytes_ = bytes_ / 1024 / 1024        while bytes_ &gt; 1024:            unit += 1            bytes_ /= 1024        # 做成00.00MB/s的形式，避免变化         return &#39;{:0&gt;5.2f}{:0&gt;2}&#39;.format(bytes_, B_UNITS[unit]) </code></pre><p>然后保存退出，重启就可以了。</p>]]></content>
      
      
      <categories>
          
          <category> Ubuntu篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IntelliJ IDEA 自用配置记录</title>
      <link href="/2018/06/25/IntelliJIDEA-MyConfigs/"/>
      <url>/2018/06/25/IntelliJIDEA-MyConfigs/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>我自己在多个系统中都有使用 IDEA， IDEA登录账户的话是支持配置同步的。但是由于每个系统的环境变量配置（JAVA_HOME,MAVEN_HOME,GIT,NODE,…..），文件目录结构，字体，快捷键等等不同,导致一套配置并不能很好的通用，于是我在此记录下我平时的一些配置，忘了的话翻出来看看，马上就能达到我要的配置</p><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><ol><li>UI 菜单字体</li><li>编辑器字体 注意：在 Ubuntu 系统下中文字体显得很难看，这时候设置支持中文的第二字体</li><li>控制台字体</li></ol><h3 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h3><p>插件我使用的是 IDEA 的自动同步功能，在一台客户端下载过的插件都会自动同步，这个不需担心</p><h3 id="编辑器变量颜色"><a href="#编辑器变量颜色" class="headerlink" title="编辑器变量颜色"></a>编辑器变量颜色</h3><p>进入设置： File | Settings | Editor | Color Scheme | Language Defaults， 开启 Semantic highlighting 功能</p><h3 id="代码改动后目录颜色"><a href="#代码改动后目录颜色" class="headerlink" title="代码改动后目录颜色"></a>代码改动后目录颜色</h3><p>File | Settings | Version Control， 开启 show directoris with ….</p><h3 id="自动导包优化"><a href="#自动导包优化" class="headerlink" title="自动导包优化"></a>自动导包优化</h3><p>File | Settings | Editor | General | Auto Import， 勾选 fly</p><h3 id="设置-alt"><a href="#设置-alt" class="headerlink" title="设置 alt + /"></a>设置 alt + /</h3><p>File | Settings | Keymap | main menu | code | completion | basic 设为 alt + /<br>同时 取消 cyclic expand word 的 快捷键</p><h3 id="自动提示忽略大小写"><a href="#自动提示忽略大小写" class="headerlink" title="自动提示忽略大小写"></a>自动提示忽略大小写</h3><p>File | Settings | Editor | General | Code Completion，将 case sensitive completion 修改为NONE</p><h3 id="编辑器设置多Tab页"><a href="#编辑器设置多Tab页" class="headerlink" title="编辑器设置多Tab页"></a>编辑器设置多Tab页</h3><p>File | Settings | Editor | General | Editor Tabs 去掉 show tabs in single row</p><h3 id="提示-serialVersionUID-的生成"><a href="#提示-serialVersionUID-的生成" class="headerlink" title="提示 serialVersionUID 的生成"></a>提示 serialVersionUID 的生成</h3><p>File | Settings | Editor | Inspections | Serialization issues | Serializable class without ’serialVersionUID’ </p><h3 id="显示内存占用"><a href="#显示内存占用" class="headerlink" title="显示内存占用"></a>显示内存占用</h3><p>Preferences | Appearance &amp; Behavior | Appearance | Show memory indicator</p><h3 id="idea64-vmoptions-配置"><a href="#idea64-vmoptions-配置" class="headerlink" title="idea64.vmoptions 配置"></a>idea64.vmoptions 配置</h3><p>16G 以上的机器：<br>    -Xms512m<br>    -Xmx1500m<br>    -XX:ReservedCodeCacheSize=500m<br>    -XX:SoftRefLRUPolicyMSPerMB=100<br>添加编码 ：<br>    -Dfile.encoding=UTF-8</p><h3 id="idea-properties-配置"><a href="#idea-properties-配置" class="headerlink" title="idea.properties 配置"></a>idea.properties 配置</h3><p>控制台打印日志的行数：默认为 1024，不限制的话：<br>    idea.cycle.buffer.size=disabled</p><h3 id="Mac-OS-下-IDEA-文件位置"><a href="#Mac-OS-下-IDEA-文件位置" class="headerlink" title="Mac OS 下 IDEA 文件位置"></a>Mac OS 下 IDEA 文件位置</h3><p>配置文件位置: /Users/joylau/Library/Preferences/IntelliJIdea201x.x<br>索引文件位置: /Users/joylau/Library/Caches/IntelliJIdea201x.x</p>]]></content>
      
      
      <categories>
          
          <category> IntelliJ IDEA篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IntelliJ IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 安装 OpenOffice 服务小记</title>
      <link href="/2018/06/22/Linux-OpenOffice/"/>
      <url>/2018/06/22/Linux-OpenOffice/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><ol><li><p>下载 rpm 包 ： 官网： <a href="https://www.openoffice.org/download/" target="_blank" rel="noopener">https://www.openoffice.org/download/</a></p></li><li><p>解压，进入 /zh-CN/RPMS/ ， 安装 rpm 包： <code>rpm -ivh *.rpm</code></p></li><li><p>安装完成后，生成 desktop-integration 目录，进入，因为我的系统是 centos 的 ，我选择安装 <code>rpm -ivh openoffice4.1.5-redhat-menus-4.1.5-9789.noarch.rpm</code></p></li><li><p>安装完成后，目录在 /opt/openoffice4 下<br> 启动： <code>/opt/openoffice4/program/soffice -headless -accept=&quot;socket,host=0.0.0.0,port=8100;urp;&quot; -nofirststartwizard &amp;</code></p></li></ol><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ol><li><p>libXext.so.6: cannot open shared object file: No such file or directory<br> 解决 ： <code>yum install libXext.x86_64</code></p></li><li><p>no suitable windowing system found, exiting.<br> 解决： <code>yum groupinstall &quot;X Window System&quot;</code></p></li></ol><p>之后再启动，查看监听端口 <code>netstat -lnp |grep 8100</code><br>已经可以了。</p>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> openoffice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 文档文本内容搜索</title>
      <link href="/2018/06/21/Elasticsearch-ingest-attachment/"/>
      <url>/2018/06/21/Elasticsearch-ingest-attachment/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="http://image.joylau.cn/blog/attachment.gif" alt="IdiomsDictionary"></p><p><a href="https://github.com/JoyLau/es-doc-node" target="_blank" rel="noopener">https://github.com/JoyLau/es-doc-node</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React 项目使用 IDEA 进行调试</title>
      <link href="/2018/06/19/React-DebugWithIDEA/"/>
      <url>/2018/06/19/React-DebugWithIDEA/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ol><li><p>You would need to have WebStorm and JetBrains IDE Support Chrome extension installed.<br> 需要安装 JetBrains IDE Support 的 chrome 插件</p></li><li><p>In the WebStorm menu Run select Edit Configurations…. Then click + and select JavaScript Debug. Paste <a href="http://localhost:3000" target="_blank" rel="noopener">http://localhost:3000</a> into the URL field and save the configuration.<br> 在 Edit Configurations 选项里添加一个 JavaScript Debug 的项目，并且地址写上 <a href="http://localhost:3000" target="_blank" rel="noopener">http://localhost:3000</a></p></li></ol><blockquote><blockquote><p>Note: the URL may be different if you’ve made adjustments via the HOST or PORT environment variables.<br>    地址根据配置环境而异</p></blockquote></blockquote><ol start="3"><li>Start your app by running npm start, then press ^D on macOS or F9 on Windows and Linux or click the green debug icon to start debugging in WebStorm.<br> 运行项目，点击 debug 按钮调试项目，注意在页面上开启插件的调试功能，此后就能像调式Java 一样调试 js 代码了。</li></ol>]]></content>
      
      
      <categories>
          
          <category> React篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> react </tag>
            
            <tag> nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS 修改 mac 地址</title>
      <link href="/2018/06/14/MacOS-ChangeMacAddr/"/>
      <url>/2018/06/14/MacOS-ChangeMacAddr/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>公司的网络接入是需要 ip 地址和 mac 地址绑定在一起的，笔记接入的 WiFi 没绑定就无法上网，公司那么多电脑不用，就使用他们已经绑定好的 静态 IP 地址和 mac 地址来上网</p><ol><li>随机生成一个全新的MAC网卡地址</li></ol><pre><code class="shell">    openssl rand -hex 6 | sed &#39;s/\(..\)/\1:/g; s/.$//&#39;</code></pre><ol start="2"><li>断开airport无线网卡连接</li></ol><pre><code class="shell">    sudo /System/Library/PrivateFrameworks/Apple80211.framework/Resources/airport -z</code></pre><ol start="3"><li>修改 mac 地址</li></ol><pre><code class="shell">    sudo ifconfig en0 ether xx:xx:xx:xx:xx:xx</code></pre><p>xx:xx:xx:xx:xx:xx ＝输入你想要修改成的MAC地址来代替。</p><p>en0 ＝ 输入你想要修改成的网卡代替。一般 en0 就为无线网卡</p><ol start="4"><li>重新打开网络</li></ol><pre><code class="shell">    networksetup -detectnewhardware</code></pre>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 分词插件的使用及 demo</title>
      <link href="/2018/06/12/Elasticsearch-Ik/"/>
      <url>/2018/06/12/Elasticsearch-Ik/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="http://image.joylau.cn/blog/idioms.gif" alt="IdiomsDictionary"></p><p><a href="https://github.com/JoyLau/es-doc-node" target="_blank" rel="noopener">https://github.com/JoyLau/es-doc-node</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mybatis 前后台时间传参格式化</title>
      <link href="/2018/05/23/MyBatis-DateFormat/"/>
      <url>/2018/05/23/MyBatis-DateFormat/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>好久不用 mybatis 了,今天突然遇到了一个时间参数的格式化问题…..<br>mysql 后台取出的时间格式的字段，传到前台变成了时间戳<br>一下就想到有一个注解进行格式化<br>可是半天想不到那个注解怎么写的了，于是一顿查</p><h2 id="记下来"><a href="#记下来" class="headerlink" title="记下来"></a>记下来</h2><p>以前经常使用的注解，现在都忘了，得记下来</p><ol><li>@JsonFormat(pattern=”yyyy-MM-dd HH:mm:ss”,timezone=”GMT+8”) ： 后台 Date 类型转时间字符串，注意时区 （后台 -&gt; 前台）</li><li>@DateTimeFormat(pattern=”yyyy-MM-dd HH:mm:ss”) ：前台时间格式参数转为 javabean 的 Date 类型 （前台 -&gt; 后台）</li><li>@JSONField(name=”end_time”, format=”yyyy-MM-dd HH:mm:ss”) ： fastjson 专用，定义json 的 key，还有时间的格式化，也可以分别在 get set 方法上注解</li></ol>]]></content>
      
      
      <categories>
          
          <category> MyBatis篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 集群安全控制</title>
      <link href="/2018/05/21/Elasticsearch-Security/"/>
      <url>/2018/05/21/Elasticsearch-Security/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一般我们搭建起来的 es 集群都可以通过默认的 9200 端口来进行 API 访问,这在局域网上没有什么大问题，如果说搭建的环境在公网上，这将埋下巨大的隐患，因为任何人都可以操作 API 来进行增删改查，这是多么的恐怖！！</p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>集群环境： elasticsearch 5.3.0；centos 7.2</li><li>集群公网环境</li></ol><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>elasticsearch 集群搭建完成后，通过制定的端口都可以访问，但是实际情况中，我们并不想这样。我们可能想只有固定的ip地址才能访问，或者需要用户名、密码才能访问<br>对于如何控制 Elasticsearch 的安全性，我详细查了下资料，现有如下解决方式</p><ol><li><p>官方的 x-pack 插件，收费的，一下子就觉得用不了了，截止现在（2018年5月21日16:23:19），有最新消息，在 ElasticON 2018 的开幕主题演讲中，x-pack 负责人在博客宣布将开放 X-Pack的代码，但是现在为止只是第一阶段完成，<br> 最后在博客中宣布在6.3版本，其中免费的X-Pack功能将包含在Elastic Stack的默认发行版中，所以说现在没戏</p></li><li><p>官方推荐的shield插件，再5.x的版本后已经集成到 x-pack里了，版本不适合，不用</p></li><li><p>elasticsearch-http-basic 插件， 已经不支持 5.x的版本了，没法用</p></li><li><p>ReadonlyREST : 官网地址： <a href="https://readonlyrest.com/download/" target="_blank" rel="noopener">https://readonlyrest.com/download/</a> elasticsearch 版的插件，是免费的， kibana 的插件是收费的，此法可用</p></li><li><p>使用 nginx 的 http-basic，可用</p></li></ol><h2 id="ReadonlyREST-插件的使用"><a href="#ReadonlyREST-插件的使用" class="headerlink" title="ReadonlyREST 插件的使用"></a>ReadonlyREST 插件的使用</h2><ol><li>官网选择 elasticsearch 的版本，填写邮箱地址，收到邮件后下载插件文件<br> 注意：只能通过官网填写邮箱的方式来进行下载，注意看的话，下载的地址后面有校验参数</li><li>运行 <code>bin/elasticsearch-plugin install file:///tmp/readonlyrest-1.16.19_es5.3.0.zip</code> 安装插件，注意是 file:// 再加上绝对路径<br> 卸载插件 <code>bin/elasticsearch-plugin remove readonlyrest</code></li><li>配置文件 readonlyrest.yml,这个比较坑，插件生成好之后，居然不生成 readonlyrest.yml，还需要我们自己配置，还不知道需要配置什么东西，没办法，只能去 github 上查看文档，<br>文档地址： <a href="https://github.com/beshu-tech/readonlyrest-docs/blob/master/elasticsearch.md" target="_blank" rel="noopener">https://github.com/beshu-tech/readonlyrest-docs/blob/master/elasticsearch.md</a> </li><li>文档说了很多，我找了半天才找到我需要的配置：</li></ol><pre><code class="yml">    readonlyrest:        prompt_for_basic_auth: true        access_control_rules:        - name: &quot;::ADMIN::&quot;          auth_key: admin:12333</code></pre><p>此时启动 elasticsearch， 再次访问 localhost:9200 就会弹出输入用户名和密码的窗口，此时输入 admin/12333 即可看到接口信息，请求成功后，在日志里会看到 ALLOWED by { name: ‘::PERSONAL_GRP::’, p。。。 的日志信息。<br>想要屏蔽这样的日志信息，只需再 <code>auth_key</code> 下面加上配置 <code>verbosity: error</code> 即可。默认为 info</p><p>这里吐槽一下，ReadonlyREST 插件的文档是真的难读，可能是国外人和我们的思维方式不一样吧。</p><p>至此 ReadonlyREST 插件的使用就完毕了。</p><h2 id="nginx-http-basic-的使用"><a href="#nginx-http-basic-的使用" class="headerlink" title="nginx  http-basic 的使用"></a>nginx  http-basic 的使用</h2><p>利用 nginx 的反向代理，分配一个二级域名来进行使用</p><ol><li>一个二级域名，比如xxxx.joylau.cn</li><li>添加 nginx 的配置文件:/etc/nginx/conf.d/elasticsearch.conf, nginx 会默认读取 <code>/etc/nginx/conf.d/</code> 目录下的 *.conf的文件</li></ol><pre><code class="bash">    upstream JoyElasticSearch {            server localhost:port  weight=1;        }    server {        listen       80;        server_name  xxxxx.joylau.cn;        location / {            # 提示信息            auth_basic &quot;请输入账号密码&quot;;            # 密码文件，最好写绝对路径            auth_basic_user_file /etc/nginx/conf.d/es-password;            autoindex on;            proxy_pass  http://JoyElasticSearch;        }    }</code></pre><p>在这里访问 xxxxx.joylau.cn 会被定向到 elasticsearch 的http端口<br><code>auth_basic_user_file</code> ：指的是密码文件，注意这里写绝对路径，防止出错</p><ol start="3"><li>用户名，密码文件 es-password</li></ol><pre><code class="bash">    # root:123    root:Hx53TyjMWNmLo</code></pre><p>这里假设 用户名是root，密码是123（实际上不是123），该加密方式为 httpd 加密，怎么获取明文加密后的密文，这个在网上有很多的在线工具可以直接使用，这里不再赘述</p><ol start="4"><li>保存并重新加载配置</li></ol><pre><code class="bash">    nginx -s reload</code></pre><p>访问 xxxxx.joylau.cn 就会提示输入用户名密码，输入正确即可。</p><p>至此，nginx  http-basic 就结束了</p><p>但是还有一个问题，就是直接访问 host + elasticsearch的端口也是可以访问的，解决这个问题，需要使用 iptables 来进行端口的限制访问。</p><h2 id="iptables-限制端口的访问"><a href="#iptables-限制端口的访问" class="headerlink" title="iptables 限制端口的访问"></a>iptables 限制端口的访问</h2><ol><li><p>禁用防火墙 <code>systemctl stop firewalld</code></p></li><li><p>禁用firewalld服务  <code>systemctl mask firewalld</code></p></li><li><p>安装iptables  <code>yum install -y iptables</code></p></li><li><p>开机自启 <code>systemctl enable iptables</code></p></li><li><p>启动 iptables <code>systemctl start iptables</code></p></li><li><p>查看现在的所有规则 <code>iptables -L -n</code></p></li><li><p>清空所有默认规则  <code>iptables -F</code></p></li><li><p>清空所有自定义规则  <code>iptables -X</code></p></li><li><p>添加限制规则 <code>iptables -A INPUT -p tcp --dport 9200 ! -s 127.0.0.1 -j DROP</code><br> 这句规则的意思是，除了本机，其他的地址都不允许 访问 9200 端口</p></li><li><p>保存：<code>service iptables save</code></p></li></ol><p>注： 后续想要删除这条规则的话<br>       直接修改 iptables.conf 文件后 <code>service iptables save</code><br>       或者 <code>iptables -L INPUT --line-numbers</code> 查看所有规则<br>       iptables -D INPUT 1 （注意，这个1是行号，num下面的数字）<br>       保存：<code>service iptables save</code></p><p>这样的话，其他机器就不能访问 elasticsearch 的http 服务的端口了，这能通过 配置好的二级域名来访问</p><p>至此配置结束</p><h2 id="集群环境下的配置"><a href="#集群环境下的配置" class="headerlink" title="集群环境下的配置"></a>集群环境下的配置</h2><p>在多个 elasticsearch 集群环境下，可配置一台机器作为负载均衡的机器，配置</p><pre><code class="yml">    node.master: false    node.data: false</code></pre><p>即可，其他机器的配置 <code>http.enabled: false</code> ，即对外不提供 http 服务<br>访问的时候只需访问那台负载均衡的节点。</p><p>至此，文章结束。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- systemctl 托管自定义程序</title>
      <link href="/2018/05/18/Linux-Systemctl/"/>
      <url>/2018/05/18/Linux-Systemctl/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>系统 centos 7</li><li>能够开机启动</li><li>能够一键开启，关闭，重启</li></ol><h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p>注意文件编码的问题</p><ul><li>service 文件</li></ul><pre><code class="shell">    [Unit]    Description=frp server Service    After=network.target    [Service]    ## 可以包含的值为simple、forking、oneshot、dbus、notify、idel其中之一。    ## Type=forking    ## 守护进程的PID文件，必须是绝对路径，强烈建议在Type=forking的情况下明确设置此选项    ## PIDFile=/project/frp_0.19.0_linux_amd64    ## 设置启动服务是要执行的命令（命令+参数）    ExecStart=/project/frp_0.19.0_linux_amd64/systemctl-frps start    ## ExecStop=    ## ExecReload=    ## 当服务进程正常退出、异常退出、被杀死、超时的时候，是否重启系统该服务。进程通过正常操作被停止则不会被执行重启。可选值为：    ## no：默认值，表示任何时候都不会被重启    ## always：表示会被无条件重启    ## no-success：表示仅在服务进程正常退出时重启    ## on-failure：表示仅在服务进程异常退出时重启    ## 所谓正常退出是指，退出码为“0”，或者到IGHUP, SIGINT, SIGTERM, SIGPIPE 信号之一，并且退出码符合 SuccessExitStatus= 的设置。    ## 所谓异常退出时指，退出码不为“0”，或者被强杀或者因为超时被杀死。    Restart=on-abort    [Install]    WantedBy=multi-user.target</code></pre><p>文件放到 /usr/lib/systemd/system/ 下</p><p>Service 部分的启动、重启、停止命令全部要求使用绝对路径</p><p>如果单独运行的是命令，这个就已经足够了，但是如果运行一些守护进程的话或者更复杂的情况的话，需要单独写一个脚本来运行</p><p>关于 service 里面的详细配置可以参考： <a href="http://blog.51cto.com/littledevil/1912570" target="_blank" rel="noopener">http://blog.51cto.com/littledevil/1912570</a> </p><ul><li>脚本文件</li></ul><pre><code class="bash">    #!/bin/bash    #set service name    SERVICE_NAME=frpServerService    BIN_FILE_NAME=frps    # set basic executable environment, do not modify those lines    BIN_HOME=$(dirname $0)    if [ &quot;${BIN_HOME}&quot; = &quot;.&quot; ]; then            BIN_HOME=$(pwd)    fi    cd ${BIN_HOME}    #the service pid    pid=`ps -ef|grep $SERVICE_NAME|grep -v grep|grep -v kill|awk &#39;{print $2}&#39;`    start() {       if [ -n &quot;$pid&quot; ]; then         echo &quot;service ${SERVICE_NAME} already start with PID :$pid&quot;         return 0       fi       nohup ./$BIN_FILE_NAME -c ./$BIN_FILE_NAME.ini &gt;/dev/null 2&gt;&amp;1 &amp;        echo &quot;Starting $SERVICE_NAME : &quot;       pid=`ps -ef|grep $SERVICE_NAME|grep -v grep|grep -v kill|awk &#39;{print $2}&#39;`       if [ ${pid} ]; then            echo &quot;start ${SERVICE_NAME} successfully with PID: ${pid}&quot;       else            echo &quot;start ${SERIVCE_NAME} failed&quot;       fi    }    debug() {       if [ ${pid} ]; then         kill -9 $pid       fi       ./${BIN_FILE_NAME} -c ./${BIN_FILE_NAME}.ini    }    stop() {       if [ -z ${pid} ]; then            echo &quot;service $SERVICE_NAME already stopped&quot;       else            kill -9 $pid            echo -n &quot;Shutting down $SERVICE_NAME : &quot;            check_pid=`jps | grep ${SERVICE_NAME}|grep -v grep|awk &#39;{print $1}&#39;`            while [ -n &quot;${check_pid}&quot; ]            do                    check_pid=`jps | grep ${SERVICE_NAME}|grep -v grep|awk &#39;{print $1}&#39;`                    if [ -z &quot;${check_pid}&quot; ];then                            break;                    fi            done            echo &quot;stop ${SERVICE_NAME} with PID: ${pid}&quot;       fi    }    status() {       pid=`jps | grep ${SERVICE_NAME}|grep -v grep|awk &#39;{print $1}&#39;`       if [ -n &quot;$pid&quot; ] ;then            echo &quot;service $SERVICE_NAME (pid $pid) is running ...&quot;       else            echo &quot;service $SERVICE_NAME is stopped&quot;       fi    }    # See how we were called.    case &quot;$1&quot; in      start)            start            ;;      stop)            stop            ;;      status)            status            ;;      restart)            stop            start            ;;      debug)            debug            ;;      *)            echo $&quot;Usage: $0 {start|stop|status|restart|debug}&quot;            exit 2    esac</code></pre><p>上面这个脚本是一个模板，包括了start，stop，status，restart，debug各个命令，是可以直接传参执行的<br>在一个文件上的 ExecStart= 就可以运行脚本文件 并传入 start 参数</p><p>注意： 如果运行的是守护进程的话，Type=forking 要配置上，意指 ExecStart 命令里面运行进程才是主进程</p><h2 id="使用命令"><a href="#使用命令" class="headerlink" title="使用命令"></a>使用命令</h2><ol><li>启动服务：systemctl start serviceName</li><li>停止服务：systemctl stop serviceName</li><li>服务状态：systemctl status serviceName</li><li>项目日志：journalctl -u serviceName</li><li>开机启动：systemctl enable serviceName</li><li>重新加载service文件：systemctl daemon-reload</li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CMD </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- 闲置笔记本安装 Centos</title>
      <link href="/2018/05/17/Linux-NoteBookPC/"/>
      <url>/2018/05/17/Linux-NoteBookPC/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>以前的笔记本是 windows7 的操作系统</li><li>6GB 内存</li><li>还剩 96G 硬盘</li><li>打算安装 Centos 7.2</li></ol><h2 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h2><ol><li>U 盘一个（&gt;= 8G）</li><li>centos 镜像文件</li><li>刻录软件 UltraISO （官网直接下载试用版的即可）</li></ol><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><ol><li>在 windows 系统下压缩出磁盘空间或者直接格式化一个盘出来用来装 centos ，注意盘的格式 要为fat32</li><li>UltraISO 烧录镜像到U盘，U盘会被磁盘格式会改变且会被格式化</li><li>重启系统，以U盘启动</li><li>指定U盘安装</li><li>安装配置</li><li>等待进入系统</li></ol><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol><li>在 U 盘启动的时候，在安装界面上会有三个选项，选择第一个 Install Centos，按tab键进行配置</li><li>找到U盘位置的方法： <code>vmlinuz initrd=initrd.img linux dd</code></li><li>这个时候很容易找到 U 的device，记下来(我当时U的device是 sdb4)，重启机器，在进入上一步的步骤</li><li>这时，将参数改为 ： <code>vmlinuz initrd=initrd.img inst.stage2=hd:/dev/sdb4</code> 接下来等待即可</li><li>选择安装位置，下方一定要选择自定义分区</li><li>分区策略就选默认的，创建新的分区，分区的大小就按照默认分配的就好，不需要改变</li></ol><h2 id="WiFi-问题"><a href="#WiFi-问题" class="headerlink" title="WiFi 问题"></a>WiFi 问题</h2><p>因为笔记本自带了 wifi 模块，想着不要用网线扯来扯去的，直接用wifi连接网络就好了啊<br>一切都没想象的那么简单….</p><p>因为我之前安装的时候选择了最小化安装，进去系统后什么都没有，一起都用通过命令行来解决<br>第一次我是根据这篇文章的步骤来的 <a href="http://www.jb51.net/article/100300.htm" target="_blank" rel="noopener">http://www.jb51.net/article/100300.htm</a><br>中间遇到了很多问题 network 服务不可用；systemctl restart network 也起不来，一直报错；ping 域名不通，ping ip 不通；ifconfig 命令不存在….总之一大堆问题<br>问题一个个解决，最后终于连上家里的wifi<br>后来重启了下，一切回到解放前<br>我去….<br>一顿惆怅<br>后来我装了个gnome图形界面，连上了wifi<br>在切换命令行使用，不使用图形界面，现在一切完好，而且内存占用空间大幅减少</p><h2 id="WiFi-连接命令"><a href="#WiFi-连接命令" class="headerlink" title="WiFi 连接命令"></a>WiFi 连接命令</h2><ol><li>设置NetworkManager自动启动<br> chkconfig NetworkManager on</li><li>安装NetworkManager-wifi<br> yum -y install NetworkManager-wifi</li><li>开启WiFi<br> nmcli r wifi on</li><li>测试（扫描信号）<br> nmcli dev wifi<br> 扫描不到可用 iw wlp8s0b1(网卡名称) scan | grep SSID 扫描一下</li><li>连接<br> nmcli dev wifi connect password</li></ol><p>注： 总结多次安装 centos 系统得出一个结论，如果在安装过程中选择打开 WiFi 并连接网络，系统安装完成后，会在 /etc/sysconfig/network-scripts/ 目录下生成一个 ifcfg-WiFi名称 文件和 keys-WiFi名称的密码文件，之后安装 NetworkManage-wifi 便可每次开机都能自动启动 WiFi，如果是装完系统在命令连接的话则每次重启后都需要自己手动连接 WiFi，这是扫描原因暂且不得而知</p><h2 id="切换命令行和图形界面"><a href="#切换命令行和图形界面" class="headerlink" title="切换命令行和图形界面"></a>切换命令行和图形界面</h2><pre><code class="shell">    systemctl set-default multi-user.target  //设置成命令模式    systemctl set-default graphical.target  //设置成图形模式</code></pre><h2 id="关闭盖子不睡眠"><a href="#关闭盖子不睡眠" class="headerlink" title="关闭盖子不睡眠"></a>关闭盖子不睡眠</h2><p>vim /etc/systemd/logind.conf  </p><p>HandlePowerKey　　　　  按下电源键后会触发的行为<br>HandleSleepKey　　 　　 按下挂起键后会触发的行为<br>HandleHibernateKey  　　按下休眠键后会触发的行为<br>HandleLidSwitch　　 　　关闭笔记本盖子后会触发的行为</p><p>只需要把HandleLidSwitch选项设置为 HandleLidSwitch=lock </p><p>设置完成保存后运行 systemctl restart systemd-logind 命令才生效</p><h2 id="恢复-Windows-启动项"><a href="#恢复-Windows-启动项" class="headerlink" title="恢复 Windows 启动项"></a>恢复 Windows 启动项</h2><p>windows 7、8/10 安装centos7双系统后，默认会将mbr改写成为grub2，而默认的centos7不识别windows 的ntfs分区，所以启动项没有windows。<br>可以用3条命令，即可将windows添加到grub2的启动项。</p><pre><code class="bash">    yum -y install epel-release    yum -y install ntfs-3g    grub2-mkconfig -o /boot/grub2/grub.cfg</code></pre><p>重启</p><h2 id="最小化安装时配置静态-IP-地址"><a href="#最小化安装时配置静态-IP-地址" class="headerlink" title="最小化安装时配置静态 IP 地址"></a>最小化安装时配置静态 IP 地址</h2><ol><li><p>vim /etc/sysconfig/network-scripts/ifcfg-网络接口名称,默认第一个是网络接口名称</p></li><li><p>修改以下红色标注的配置</p><p> TYPE=Ethernet</p><p> <font color=red size=3>BOOTPROTO=static</font></p><p> DEFROUTE=yes</p><p> IPV4_FAILURE_FATAL=no</p><p> IPV6INIT=yes</p><p> IPV6_AUTOCONF=yes</p><p> IPV6_DEFROUTE=yes</p><p> IPV6_FAILURE_FATAL=no</p><p> NAME=eno16777736</p><p> UUID=9e8d604f-d991-4aa2-88a3-4c679e6f139c</p><p> DEVICE=eno16777736</p><p> ONBOOT=yes</p><p> PEERDNS=yes</p><p> PEERROUTES=yes</p><p> IPV6_PEERDNS=yes</p><p> IPV6_PEERROUTES=yes</p><p> <font color=red size=3>HWADDR=B8:70:F4:24:61:A7</font>  #MAC地址</p><p> <font color=red size=3>IPADDR=192.168.10.29</font>     #静态IP</p><p> <font color=red size=3>GATEWAY=192.168.10.1</font>     #默认网关</p><p> <font color=red size=3>NETMASK=255.255.255.0</font>    #子网掩码</p><p> <font color=red size=3>DNS1=61.132.163.68</font>       #DNS配置</p></li><li><p>重启网络服务 ：service network restart</p></li></ol><h2 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h2><p>更新时间 2018-08-01 16:36:09<br>系统安装 ntpdate<br>查看本地时间： date<br>本地时间与服务器时间同步 ： ntpdate ntp1.aliyun.com<br>查看bois时间： hwclock<br>将本地时间写入到bois时间内： hwclock -w</p>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CMD </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lombok 注解小记</title>
      <link href="/2018/05/15/Lombok/"/>
      <url>/2018/05/15/Lombok/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ul><li>val可以将变量申明是final类型。</li><li>@NonNull注解能够为方法或构造函数的参数提供非空检查。</li><li>@Cleanup注解能够自动释放资源。</li><li>@Getter/@Setter注解可以针对类的属性字段自动生成Get/Set方法。</li><li>@ToString注解，为使用该注解的类生成一个toString方法，默认的toString格式为：ClassName(fieldName= fieleValue ,fieldName1=fieleValue)。</li><li>@EqualsAndHashCode注解，为使用该注解的类自动生成equals和hashCode方法。</li><li>@NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructor,这几个注解分别为类自动生成了无参构造器、指定参数的构造器和包含所有参数的构造器。</li><li>@Data注解作用比较全，其包含注解的集合 @ToString， @EqualsAndHashCode，所有字段的 @Getter和所有非final字段的 @Setter, @RequiredArgsConstructor。</li><li>@Builder注解提供了一种比较推崇的构建值对象的方式。</li><li>@Synchronized注解类似Java中的Synchronized 关键字，但是可以隐藏同步锁</li></ul><p>官网地址： <a href="https://www.projectlombok.org/features/all" target="_blank" rel="noopener">https://www.projectlombok.org/features/all</a></p>]]></content>
      
      
      <categories>
          
          <category> 工具类篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Lombok </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Filebeat 实时收集 Nginx 日志</title>
      <link href="/2018/05/08/Filebeat-Nginx/"/>
      <url>/2018/05/08/Filebeat-Nginx/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>Filebeat 版本为 5.3.0<br> 之所以使用 beats 家族的 Filebeat 来替代 Logstash 是因为 Logstash 实在太消耗资源了（服务器资源充足的土豪请无视）<br> 在官网下载 Logstash 有 89M，而 Filebeat 才8.4M，由此可见一斑<br> Logstash 可以配置 jvm 参数，经过我本身的调试，内存分配小了，启动很慢有时根本起不来，分配大了，其他服务就没有资源了<br> 所有说对于配置低的服务器，选择 Filebeat 是最好的选择了，而且现在 Filebeat 已经开始替代 Logstash 了</li><li>依然需要修改 nginx 的日志格式</li></ol><h2 id="nginx-config"><a href="#nginx-config" class="headerlink" title="nginx.config"></a>nginx.config</h2><p>更改日志记录的格式</p><pre><code class="bash">    log_format json &#39;{ &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &#39;                             &#39;&quot;time&quot;: &quot;$time_iso8601&quot;, &#39;                             &#39;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &#39;                             &#39;&quot;remote_user&quot;: &quot;$remote_user&quot;, &#39;                             &#39;&quot;body_bytes_sent&quot;: &quot;$body_bytes_sent&quot;, &#39;                             &#39;&quot;request_time&quot;: &quot;$request_time&quot;, &#39;                             &#39;&quot;status&quot;: &quot;$status&quot;, &#39;                             &#39;&quot;host&quot;: &quot;$host&quot;, &#39;                             &#39;&quot;request&quot;: &quot;$request&quot;, &#39;                             &#39;&quot;request_method&quot;: &quot;$request_method&quot;, &#39;                             &#39;&quot;uri&quot;: &quot;$uri&quot;, &#39;                             &#39;&quot;http_referrer&quot;: &quot;$http_referer&quot;, &#39;                             &#39;&quot;body_bytes_sent&quot;:&quot;$body_bytes_sent&quot;, &#39;                             &#39;&quot;http_x_forwarded_for&quot;: &quot;$http_x_forwarded_for&quot;, &#39;                             &#39;&quot;http_user_agent&quot;: &quot;$http_user_agent&quot; &#39;                        &#39;}&#39;;        access_log  /var/log/nginx/access.log  json;</code></pre><h2 id="filebeat-yml"><a href="#filebeat-yml" class="headerlink" title="filebeat.yml"></a>filebeat.yml</h2><pre><code class="bash">    #=========================== Filebeat prospectors =============================    filebeat.prospectors:    - input_type: log      # Paths that should be crawled and fetched. Glob based paths.      paths:        - /var/log/nginx/*access*.log      json.keys_under_root: true      json.overwrite_keys: true    #-------------------------- Elasticsearch output ------------------------------    output.elasticsearch:      # Array of hosts to connect to.      hosts: [&quot;ip:port&quot;,&quot;ip:port&quot;]      index: &quot;filebeat_server_nginx_%{+YYYY-MM}&quot;</code></pre><p>这里面需要注意的是<br>json.keys_under_root： 默认这个值是FALSE的，也就是我们的json日志解析后会被放在json键上。设为TRUE，所有的keys就会被放到根节点<br>json.overwrite_keys: 是否要覆盖原有的key，这是关键配置，将keys_under_root设为TRUE后，再将overwrite_keys也设为TRUE，就能把filebeat默认的key值给覆盖了</p><p>还有其他的配置<br>json.add_error_key：添加json_error key键记录json解析失败错误<br>json.message_key：指定json日志解析后放到哪个key上，默认是json，你也可以指定为log等。</p><p>说白了，差别就是，未配置前elasticsearch的数据是这样的：</p><pre><code class="json">    {        &quot;_index&quot;: &quot;filebeat_server_nginx_2018-05&quot;,        &quot;_type&quot;: &quot;log&quot;,        &quot;_id&quot;: &quot;AWM9sVOkCcRcg0IPg399&quot;,        &quot;_version&quot;: 1,        &quot;_score&quot;: 1,        &quot;_source&quot;: {            &quot;@timestamp&quot;: &quot;2018-05-08T03:00:17.544Z&quot;,            &quot;beat&quot;: {                &quot;hostname&quot;: &quot;VM_252_18_centos&quot;,                &quot;name&quot;: &quot;VM_252_18_centos&quot;,                &quot;version&quot;: &quot;5.3.0&quot;            },            &quot;input_type&quot;: &quot;log&quot;,            &quot;json&quot;: {},            &quot;message&quot;: &quot;{ &quot;@timestamp&quot;: &quot;2018-05-08T11:00:11+08:00&quot;, &quot;time&quot;: &quot;2018-05-08T11:00:11+08:00&quot;, &quot;remote_addr&quot;: &quot;113.16.251.67&quot;, &quot;remote_user&quot;: &quot;-&quot;, &quot;body_bytes_sent&quot;: &quot;403&quot;, &quot;request_time&quot;: &quot;0.000&quot;, &quot;status&quot;: &quot;200&quot;, &quot;host&quot;: &quot;blog.joylau.cn&quot;, &quot;request&quot;: &quot;GET /img/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90.png HTTP/1.1&quot;, &quot;request_method&quot;: &quot;GET&quot;, &quot;uri&quot;: &quot;/img/\xE7\xBD\x91\xE6\x98\x93\xE4\xBA\x91\xE9\x9F\xB3\xE4\xB9\x90.png&quot;, &quot;http_referrer&quot;: &quot;http://blog.joylau.cn/css/style.css&quot;, &quot;body_bytes_sent&quot;:&quot;403&quot;, &quot;http_x_forwarded_for&quot;: &quot;-&quot;, &quot;http_user_agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&quot; }&quot;,            &quot;offset&quot;: 7633,            &quot;source&quot;: &quot;/var/log/nginx/access.log&quot;,            &quot;type&quot;: &quot;log&quot;        }    }</code></pre><p>配置后，是这样的：</p><pre><code class="json">    {        &quot;_index&quot;: &quot;filebeat_server_nginx_2018-05&quot;,        &quot;_type&quot;: &quot;log&quot;,        &quot;_id&quot;: &quot;AWM9rjLd8mVZNgvhdnN9&quot;,        &quot;_version&quot;: 1,        &quot;_score&quot;: 1,        &quot;_source&quot;: {            &quot;@timestamp&quot;: &quot;2018-05-08T02:56:50.000Z&quot;,            &quot;beat&quot;: {                &quot;hostname&quot;: &quot;VM_252_18_centos&quot;,                &quot;name&quot;: &quot;VM_252_18_centos&quot;,                &quot;version&quot;: &quot;5.3.0&quot;            },            &quot;body_bytes_sent&quot;: &quot;12576&quot;,            &quot;host&quot;: &quot;blog.joylau.cn&quot;,            &quot;http_referrer&quot;: &quot;http://blog.joylau.cn/&quot;,            &quot;http_user_agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36&quot;,            &quot;http_x_forwarded_for&quot;: &quot;-&quot;,            &quot;input_type&quot;: &quot;log&quot;,            &quot;offset&quot;: 3916,            &quot;remote_addr&quot;: &quot;60.166.12.138&quot;,            &quot;remote_user&quot;: &quot;-&quot;,            &quot;request&quot;: &quot;GET /2018/03/01/JDK8-Stream-Distinct/ HTTP/1.1&quot;,            &quot;request_method&quot;: &quot;GET&quot;,            &quot;request_time&quot;: &quot;0.000&quot;,            &quot;source&quot;: &quot;/var/log/nginx/access.log&quot;,            &quot;status&quot;: &quot;200&quot;,            &quot;time&quot;: &quot;2018-05-08T10:56:50+08:00&quot;,            &quot;type&quot;: &quot;log&quot;,            &quot;uri&quot;: &quot;/2018/03/01/JDK8-Stream-Distinct/index.html&quot;        }    }</code></pre><p>这样看起来就很舒服了</p><h2 id="启动-FileBeat"><a href="#启动-FileBeat" class="headerlink" title="启动 FileBeat"></a>启动 FileBeat</h2><p>进入 Filebeat 目录</p><pre><code class="bash">    nohup sudo ./filebeat -e -c filebeat.yml &gt;/dev/null 2&gt;&amp;1 &amp; </code></pre><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>nginx 的日志里含有中文的话，会将中文转为 Unicode 编码，如果不转的话，加入 <code>escape=json</code> 参数就可以了</p><pre><code class="bash">    log_format json escape=json &#39;{ &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &#39;                                 &#39;&quot;time&quot;: &quot;$time_iso8601&quot;, &#39;                                 &#39;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &#39;                                 &#39;&quot;remote_user&quot;: &quot;$remote_user&quot;, &#39;                                 &#39;&quot;body_bytes_sent&quot;: &quot;$body_bytes_sent&quot;, &#39;                                 &#39;&quot;request_time&quot;: &quot;$request_time&quot;, &#39;                                 &#39;&quot;status&quot;: &quot;$status&quot;, &#39;                                 &#39;&quot;host&quot;: &quot;$host&quot;, &#39;                                 &#39;&quot;request&quot;: &quot;$request&quot;, &#39;                                 &#39;&quot;request_method&quot;: &quot;$request_method&quot;, &#39;                                 &#39;&quot;uri&quot;: &quot;$uri&quot;, &#39;                                 &#39;&quot;http_referrer&quot;: &quot;$http_referer&quot;, &#39;                                 &#39;&quot;body_bytes_sent&quot;:&quot;$body_bytes_sent&quot;, &#39;                                 &#39;&quot;http_x_forwarded_for&quot;: &quot;$http_x_forwarded_for&quot;, &#39;                                 &#39;&quot;http_user_agent&quot;: &quot;$http_user_agent&quot; &#39;                            &#39;}&#39;;            access_log  /var/log/nginx/access.log  json;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Filebeat </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logstash 实时收集 Nginx 日志</title>
      <link href="/2018/05/08/Logstash-Nginx/"/>
      <url>/2018/05/08/Logstash-Nginx/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>logstash 需要和 nginx 部署到一台机器<br>需要修改 nginx 的日志格式</p><h2 id="nginx-config"><a href="#nginx-config" class="headerlink" title="nginx.config"></a>nginx.config</h2><p>更改日志记录的格式</p><pre><code class="bash">    log_format json &#39;{ &quot;@timestamp&quot;: &quot;$time_iso8601&quot;, &#39;                             &#39;&quot;time&quot;: &quot;$time_iso8601&quot;, &#39;                             &#39;&quot;remote_addr&quot;: &quot;$remote_addr&quot;, &#39;                             &#39;&quot;remote_user&quot;: &quot;$remote_user&quot;, &#39;                             &#39;&quot;body_bytes_sent&quot;: &quot;$body_bytes_sent&quot;, &#39;                             &#39;&quot;request_time&quot;: &quot;$request_time&quot;, &#39;                             &#39;&quot;status&quot;: &quot;$status&quot;, &#39;                             &#39;&quot;host&quot;: &quot;$host&quot;, &#39;                             &#39;&quot;request&quot;: &quot;$request&quot;, &#39;                             &#39;&quot;request_method&quot;: &quot;$request_method&quot;, &#39;                             &#39;&quot;uri&quot;: &quot;$uri&quot;, &#39;                             &#39;&quot;http_referrer&quot;: &quot;$http_referer&quot;, &#39;                             &#39;&quot;body_bytes_sent&quot;:&quot;$body_bytes_sent&quot;, &#39;                             &#39;&quot;http_x_forwarded_for&quot;: &quot;$http_x_forwarded_for&quot;, &#39;                             &#39;&quot;http_user_agent&quot;: &quot;$http_user_agent&quot; &#39;                        &#39;}&#39;;        access_log  /var/log/nginx/access.log  json;</code></pre><h2 id="log-file-config"><a href="#log-file-config" class="headerlink" title="log-file.config"></a>log-file.config</h2><p>input 里添加 file 类型</p><pre><code class="bash">    input {        file {            path =&gt; &quot;/var/log/nginx/access.log&quot;            codec =&gt; &quot;json&quot;            start_position =&gt; &quot;beginning&quot;            type =&gt; &quot;server_nginx&quot;            tags =&gt; [&quot;nginx&quot;]        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
            <tag> Logstash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK(Elasticsearch + Logstash + Kibana) 日志分析平台搭建及 SpringBoot 如何实时发送日志存储到 ELK 平台</title>
      <link href="/2018/05/07/Elasticsearch-ELK/"/>
      <url>/2018/05/07/Elasticsearch-ELK/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>Elasticsearch， Logstash，Kibana 版本都是5.3.0</li><li>SpringBoot 集成 ELK，实际上指的就是 SpringBoot 与 Logstash 的整合</li><li>Elasticsearch 负责数据的存储，Logstash 负责数据的接受和数据的发送，相当于一个中转站，Kibana 负责数据的展示，查询</li><li>SpringBoot 项目是我们产生日志并且需要存储和分析的项目</li><li>SpringBoot 我还是使用的默认的 logback 日志系统，当然也可以采用 log4j,不过我还是比较喜欢 logback，性能好，配置少，有颜色</li></ol><h2 id="Elasticsearch-集群搭建"><a href="#Elasticsearch-集群搭建" class="headerlink" title="Elasticsearch 集群搭建"></a>Elasticsearch 集群搭建</h2><p>略</p><h2 id="Logstash-安装"><a href="#Logstash-安装" class="headerlink" title="Logstash 安装"></a>Logstash 安装</h2><ol><li>官网下载 Logstash</li><li>解压</li><li>添加配置文件 log.config</li></ol><pre><code class="bash">    input {        tcp {            host =&gt; &quot;192.168.10.78&quot;            type =&gt; &quot;dev&quot;            tags =&gt; [&quot;spring-boot&quot;]            port =&gt; 4560            codec =&gt; json_lines        }        tcp {            host =&gt; &quot;192.168.10.78&quot;            type =&gt; &quot;server&quot;            tags =&gt; [&quot;spring-boot&quot;]            port =&gt; 4561            codec =&gt; json_lines        }            tcp {            host =&gt; &quot;192.168.10.78&quot;            type =&gt; &quot;work_dev&quot;            tags =&gt; [&quot;boot&quot;]            port =&gt; 4568            codec =&gt; json_lines        }    }    filter {    }    output {            if[type] == &quot;work_dev&quot; {                    elasticsearch {                            hosts =&gt; [&quot;ip:9268&quot;]                            index =&gt; &quot;logstash_%{type}_%{+YYYY-MM}&quot;                    }            } else {                    elasticsearch {                            hosts =&gt; [&quot;http://192.168.10.232:9211&quot;]                            index =&gt; &quot;logstash_%{type}_%{+YYYY-MM}&quot;                    }            }     }</code></pre><p>总的来说，配置文件里由 input，filter，output，这里我没有特别复杂的需求，filter就没有配置<br>我这里有三个input，但是都是 tcp 类型的<br>意思配置了三个input,分别监听192.168.10.78（就是安装logstash的机器）的4560，4561，和4568端口，有数据发送过来的话就进行output处理<br>这里我配置了3个type,这个type也就是elasticsearch里索引的type，并且该type可作为参数在output里判断进行不同的处理<br>codec 是的对日志数据进行处理的插件，这里是 json_lines<br>所以需要安装插件</p><pre><code class="bash">    sh bin/logstash-plugin install logstash-codec-json_lines</code></pre><p>elasticsearch:hosts es的http地址和端口<br>index 是创建的索引名<br>如果要配置索引模板的话，可以添加以下配置<br>    manage_template =&gt; true<br>    template_name =&gt; “template_name”<br>    template_overwrite =&gt; true<br>    template =&gt; “/usr/local/path.json”</p><p>配置好了，我们检验下配置文件是否正确</p><pre><code class="bash">    sh /app/logstash-5.3.0/bin/logstash -f /app/logstash-5.3.0/config/log.config -t</code></pre><p>没有问题的话就可启动了,后台启动的就用 nohup</p><pre><code class="bash">    sh /app/logstash-5.3.0/bin/logstash -f /app/logstash-5.3.0/config/log.config</code></pre><p>启动成功的话，9600端口可以获取到 logstash 的相关信息</p><h2 id="SpringBoot-集成-Logstash"><a href="#SpringBoot-集成-Logstash" class="headerlink" title="SpringBoot 集成 Logstash"></a>SpringBoot 集成 Logstash</h2><ol><li>添加依赖：</li></ol><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;        &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;        &lt;version&gt;5.1&lt;/version&gt;    &lt;/dependency&gt;</code></pre><ol start="2"><li>添加配置 logstash 文件<br>在 resources 下直接添加 logback.xml 文件即可</li></ol><pre><code class="xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;!DOCTYPE configuration&gt;    &lt;configuration&gt;        &lt;appender name=&quot;LOGSTASH&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;            &lt;destination&gt;ip:4568&lt;/destination&gt;            &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt;        &lt;/appender&gt;        &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt;        &lt;root level=&quot;INFO&quot;&gt;            &lt;appender-ref ref=&quot;LOGSTASH&quot; /&gt;        &lt;/root&gt;    &lt;/configuration&gt;</code></pre><p>这里我是使用的是 SpringBoot 自带的 logback 日志<br>SpringBoot 默认会读取 resources 目录下的 logback.xml 作为配置文件，别问我怎么知道的（我特地查看了源码：org.springframework.boot.logging.logback.LogbackLoggingSystem，”logback-test.groovy”, “logback-test.xml”, “logback.groovy”, “logback.xml”这些文件检测到都会读取其中的配置的）<br>配置文件里我只配置了 一个Appender，就是net.logstash.logback.appender.LogstashTcpSocketAppender，用来输出日志到logstash的，并且级别是 INFO<br>destination 指的就是 logstash 的地址<br>encoder 就配置LogstashEncoder不要变<br>再把 SpringBoot默认的配置引入base.xml</p><p>好了，SpringBoot 集成 Logstash 完毕</p><p>注 ：后来我想用 javaConfig 去配置 SpringBoot和Logstash，不过没有成功，哪位大佬看到这个信息，可以给我留言下怎么配置<br>xml,也很方便，打包部署后可以作为配置文件修改</p><p>那么，这个时候启动项目，elasticsearch里面就会看到有新的索引数据了</p><h2 id="Kibana-安装"><a href="#Kibana-安装" class="headerlink" title="Kibana 安装"></a>Kibana 安装</h2><ol><li>其实 Kibana 非必须安装，只是用来统计数据和查询数据的，用来提供一个可视化的界面</li><li>下载 Kibana</li><li>修改配置文件 kibana.yml<br> server.port: 5668<br> server.host: “0.0.0.0”<br> elasticsearch.url: “<a href="http://localhost:9268&quot;">http://localhost:9268&quot;</a></li><li>后台启动</li><li>访问kibana的地址即可</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 集群搭建</title>
      <link href="/2018/05/07/Elasticsearch-Cluster/"/>
      <url>/2018/05/07/Elasticsearch-Cluster/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ol><li>机器三台</li><li>彼此间内网不同，公网可通（因为这个问题花费了很长时间,配置文件里有我的理解说明）</li><li>机器配置很低，需要调节jvm参数来优化</li><li>elasticsearch 版本为 5.3.0</li></ol><h2 id="elasticsearch-yml"><a href="#elasticsearch-yml" class="headerlink" title="elasticsearch.yml"></a>elasticsearch.yml</h2><pre><code class="bash">    cluster.name: joylau-es    node.name: joylau    # 有资格作为主节点    node.master: true    # 节点存储数据    node.data: true    # 绑定的ip地址    # 这里原来默认的是 network.host,如果配置了network.host，则一下2个配置的属性都为network.host的值    # 集群中各个节点内网不通，集群搭建不起来的原因就在这里，我也是查阅了大量资料，花费了好长时间，才搞明白    # 绑定地址，这里配置任何ip都能访问    network.bind_host: 0.0.0.0    # 这里配置该节点的公网IP地址，在集群启动时就不会使用默认内网地址寻找策略，就会以配置的公网地址来寻找该节点    network.publish_host: ip    #    # Set a custom port for HTTP:    #    http.port: 9268    transport.tcp.port: 9368    #    # For more information, consult the network module documentation.    # 集群的各个节点配置    discovery.zen.ping.unicast.hosts: [&quot;ip1:9368&quot;, &quot;ip2:9368&quot;, &quot;ip3:9368&quot;]    #    # Prevent the &quot;split brain&quot; by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):    # 上句话的意思是采取过半原则的策略配置节点数，为了防止“脑裂”情况，数量建议为 (节点总数/2) + 1    # 我的理解就是最少有多少个节点的时候开始选取主节点，这里我配置的1，比如说我现在有3个几点，其中一个节点的网络断了    # 如果配置的2 的话，那么有2个节点的会投票选取主节点，成为一个集群，剩下的那个节点无法选取主节点而挂了    # 如果配置的 1 的话，剩下的那个节点就会自己成为主节点而单独成为一个集群，这样就有2个集群了    # 说了这么多，大致的意思就是这样，我是这么理解的    #    discovery.zen.minimum_master_nodes: 1</code></pre><p>剩下没贴出配置的都是默认配置</p><p>依照改配置，在各个节点上修改节点名称及network.publish_host，要保证集群名称一样就可以了。</p><h2 id="jvm-options"><a href="#jvm-options" class="headerlink" title="jvm.options"></a>jvm.options</h2><p>主要配置<br>     -Xms1400m<br>     -Xmx1400m</p><p>我这里的机器是2G的运存，经过我的反复调试，能给出elasticsearch最大的内存空间就是1400m了，给多了跑步起来，给少了有不能完全发挥elasticsearch的性能优势<br>机器差，没办法<br>还有一点注意的是初始化内存大小个最大内存大小的配置数值要是一样的，否则会启动出错</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS 垃圾清理</title>
      <link href="/2018/04/01/MacOS-CleanMac/"/>
      <url>/2018/04/01/MacOS-CleanMac/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>GarageBand，这个是系统上的模拟乐器，一般都使用不到</p><pre><code class="bash">    rm -rf /Library/Application\ Support/GarageBand    rm -rf /Library/Application\ Support/Logic    rm -rf /Library/Audio/Apple\ Loops</code></pre><p>但是有些系统文件显示占用的空间很大，该怎么看呢</p><pre><code class="bash">    du -sh *</code></pre><p>这个命令用来查看根目录下，所有文件的大小分布</p><p>比如，我的电脑 Library 文件路径最大</p><p>那就在进入 Library 文件路径，再执行 du -sh *</p><p>直至找到占用内存最大的文件,然后结合实际情况,进行删减</p>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> MacBookPro </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringSecurity Session并发过期后会重定向到 /login (入口点问题)问题的解决</title>
      <link href="/2018/03/30/SpringBoot-SpringSecurity-EntryPoint/"/>
      <url>/2018/03/30/SpringBoot-SpringSecurity-EntryPoint/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在 SpringSecurity 中，我想配置一个关于session并发的控制，于是我是这样配置的</p><pre><code class="java">     @Override        protected void configure(HttpSecurity http) throws Exception {            http                    .sessionManagement()                    .invalidSessionStrategy(new InvalidSessionStrategyImpl())                    .maximumSessions(-1).expiredSessionStrategy(expiredSessionStrategy())//配置并发登录，-1表示不限制                    .sessionRegistry(sessionRegistry());        }</code></pre><p>上下文的配置我在此省略了</p><p>这里设置 maximumSessions 为 -1,表示不限制同一账号登录的客户端数</p><p>session过期后执行的逻辑是进入我自定义的类 expiredSessionStrategy() 中</p><p>因为我是构建的 rest 服务，所以我是返回的 http 状态码</p><pre><code class="java">    public class ExpiredSessionStrategyImpl implements SessionInformationExpiredStrategy {        @Override        public void onExpiredSessionDetected(SessionInformationExpiredEvent event) throws IOException {            event.getResponse().sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED,                    JSONObject.toJSONString(MessageBody.failure(405,&quot;not login or login has been expired&quot;)));        }    }</code></pre><p>在这里，问题就来了</p><p>我测试的时候，把 -1 改成了 1，之后登录同一个用户，后面登录的用户会把前面一个已经登录的用户挤下线，就是说之前登录的那个用户的session 会过期</p><p>就是说他所在的页面再发送任何请求的话会收到我返回的 405 状态码</p><p>在这里是没问题的</p><p>问题就在发完一个请求后，在发一个请求，在浏览器的 network 上会看到发出的请求会被重定向的 /login 请求上</p><p>后续再发任何请求都会被重定向到 /login 上</p><h2 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a>问题思考</h2><p>为什么会出现这样的情况呢？</p><p>为什么会第一个请求会收到405的状态码，后续的请求会被重定向到 /login 呢？</p><p>通过 debug 断点，我定位到过滤器的前置执行方法 beforeInvocation() 上</p><pre><code class="java">    protected InterceptorStatusToken beforeInvocation(Object object) {            Assert.notNull(object, &quot;Object was null&quot;);            final boolean debug = logger.isDebugEnabled();            if (!getSecureObjectClass().isAssignableFrom(object.getClass())) {                throw new IllegalArgumentException(                        &quot;Security invocation attempted for object &quot;                                + object.getClass().getName()                                + &quot; but AbstractSecurityInterceptor only configured to support secure objects of type: &quot;                                + getSecureObjectClass());            }            Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource()                    .getAttributes(object);            if (attributes == null || attributes.isEmpty()) {                if (rejectPublicInvocations) {                    throw new IllegalArgumentException(                            &quot;Secure object invocation &quot;                                    + object                                    + &quot; was denied as public invocations are not allowed via this interceptor. &quot;                                    + &quot;This indicates a configuration error because the &quot;                                    + &quot;rejectPublicInvocations property is set to &#39;true&#39;&quot;);                }                if (debug) {                    logger.debug(&quot;Public object - authentication not attempted&quot;);                }                publishEvent(new PublicInvocationEvent(object));                return null; // no further work post-invocation            }            if (debug) {                logger.debug(&quot;Secure object: &quot; + object + &quot;; Attributes: &quot; + attributes);            }            if (SecurityContextHolder.getContext().getAuthentication() == null) {                credentialsNotFound(messages.getMessage(                        &quot;AbstractSecurityInterceptor.authenticationNotFound&quot;,                        &quot;An Authentication object was not found in the SecurityContext&quot;),                        object, attributes);            }            Authentication authenticated = authenticateIfRequired();            // Attempt authorization            try {                this.accessDecisionManager.decide(authenticated, object, attributes);            }            catch (AccessDeniedException accessDeniedException) {                publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated,                        accessDeniedException));                throw accessDeniedException;            }            if (debug) {                logger.debug(&quot;Authorization successful&quot;);            }            if (publishAuthorizationSuccess) {                publishEvent(new AuthorizedEvent(object, attributes, authenticated));            }            // Attempt to run as a different user            Authentication runAs = this.runAsManager.buildRunAs(authenticated, object,                    attributes);            if (runAs == null) {                if (debug) {                    logger.debug(&quot;RunAsManager did not change Authentication object&quot;);                }                // no further work post-invocation                return new InterceptorStatusToken(SecurityContextHolder.getContext(), false,                        attributes, object);            }            else {                if (debug) {                    logger.debug(&quot;Switching to RunAs Authentication: &quot; + runAs);                }                SecurityContext origCtx = SecurityContextHolder.getContext();                SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext());                SecurityContextHolder.getContext().setAuthentication(runAs);                // need to revert to token.Authenticated post-invocation                return new InterceptorStatusToken(origCtx, true, attributes, object);            }        }</code></pre><p>问题出在了 SecurityContextHolder.getContext().getAuthentication() == null</p><p>getAuthentication() 为 null，于是进入了credentialsNotFound(),抛出了 AuthenticationCredentialsNotFoundException 异常</p><p>确实，在控制台上也能看到抛出的异常信息</p><h2 id="问题深入"><a href="#问题深入" class="headerlink" title="问题深入"></a>问题深入</h2><p>AuthenticationCredentialsNotFoundException 是 AuthenticationException 异常的子类</p><p>不仅仅是 AuthenticationCredentialsNotFoundException 还有其他很多异常都是异常的子类</p><p>既然抛出了异常，猜测肯定是被某个处理器给处理了而且处理的默认机制是重定向到 /login </p><p>于是继续搜索 SpringSecurity 异常处理器</p><p>我找到的答案是 ExceptionTranslationFilter </p><p>ExceptionTranslationFilter 是Spring Security的核心filter之一，用来处理AuthenticationException和AccessDeniedException两种异常（由FilterSecurityInterceptor认证请求返回的异常）</p><p>ExceptionTranslationFilter 对异常的处理是通过这两个处理类实现的，处理规则很简单：</p><p>规则1. 如果异常是 AuthenticationException，使用 AuthenticationEntryPoint 处理<br>规则2. 如果异常是 AccessDeniedException 且用户是匿名用户，使用 AuthenticationEntryPoint 处理<br>规则3. 如果异常是 AccessDeniedException 且用户不是匿名用户，如果否则交给 AccessDeniedHandler 处理。  </p><pre><code class="java">    private void handleSpringSecurityException(HttpServletRequest request,                HttpServletResponse response, FilterChain chain, RuntimeException exception)                throws IOException, ServletException {            if (exception instanceof AuthenticationException) {                logger.debug(                        &quot;Authentication exception occurred; redirecting to authentication entry point&quot;,                        exception);                sendStartAuthentication(request, response, chain,                        (AuthenticationException) exception);            }            else if (exception instanceof AccessDeniedException) {                Authentication authentication = SecurityContextHolder.getContext().getAuthentication();                if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) {                    logger.debug(                            &quot;Access is denied (user is &quot; + (authenticationTrustResolver.isAnonymous(authentication) ? &quot;anonymous&quot; : &quot;not fully authenticated&quot;) + &quot;); redirecting to authentication entry point&quot;,                            exception);                    sendStartAuthentication(                            request,                            response,                            chain,                            new InsufficientAuthenticationException(                                    &quot;Full authentication is required to access this resource&quot;));                }                else {                    logger.debug(                            &quot;Access is denied (user is not anonymous); delegating to AccessDeniedHandler&quot;,                            exception);                    accessDeniedHandler.handle(request, response,                            (AccessDeniedException) exception);                }            }        }</code></pre><p>我们这里的异常是 AuthenticationException ，紧接着就找 sendStartAuthentication() 方法</p><pre><code class="java">    protected void sendStartAuthentication(HttpServletRequest request,                HttpServletResponse response, FilterChain chain,                AuthenticationException reason) throws ServletException, IOException {            // SEC-112: Clear the SecurityContextHolder&#39;s Authentication, as the            // existing Authentication is no longer considered valid            SecurityContextHolder.getContext().setAuthentication(null);            requestCache.saveRequest(request, response);            logger.debug(&quot;Calling Authentication entry point.&quot;);            authenticationEntryPoint.commence(request, response, reason);        }</code></pre><p>上面的方法是先保存请求，之后执行 authenticationEntryPoint.commence(request, response, reason)， 再深入来看</p><p>默认实现 commence 接口的是 LoginUrlAuthenticationEntryPoint 类</p><pre><code class="java">    public void commence(HttpServletRequest request, HttpServletResponse response,                AuthenticationException authException) throws IOException, ServletException {            String redirectUrl = null;            if (useForward) {                if (forceHttps &amp;&amp; &quot;http&quot;.equals(request.getScheme())) {                    // First redirect the current request to HTTPS.                    // When that request is received, the forward to the login page will be                    // used.                    redirectUrl = buildHttpsRedirectUrlForRequest(request);                }                if (redirectUrl == null) {                    String loginForm = determineUrlToUseForThisRequest(request, response,                            authException);                    if (logger.isDebugEnabled()) {                        logger.debug(&quot;Server side forward to: &quot; + loginForm);                    }                    RequestDispatcher dispatcher = request.getRequestDispatcher(loginForm);                    dispatcher.forward(request, response);                    return;                }            }            else {                // redirect to login page. Use https if forceHttps true                redirectUrl = buildRedirectUrlToLoginPage(request, response, authException);            }            redirectStrategy.sendRedirect(request, response, redirectUrl);        }</code></pre><p>我们看到了 redirectUrl = buildRedirectUrlToLoginPage(request, response, authException)</p><p>这下总算是知道了为什么会重定向了 /login 请求了</p><h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>知道问题的原因了，解决问题就很简单了，重新实现 commence 接口，返回http 状态码就可以了，于是加上这样的配置</p><pre><code class="java">    @Override        protected void configure(HttpSecurity http) throws Exception {            http                    .sessionManagement()                    .invalidSessionStrategy(new InvalidSessionStrategyImpl())                    .maximumSessions(-1).expiredSessionStrategy(expiredSessionStrategy())//配置并发登录，-1表示不限制                    .sessionRegistry(sessionRegistry())                    .and()                    .and()                    .exceptionHandling()                    .authenticationEntryPoint(new UnauthenticatedEntryPoint())                    .accessDeniedHandler(new AuthorizationFailure());        }</code></pre><pre><code class="java">    public class UnauthenticatedEntryPoint implements AuthenticationEntryPoint {        @Override        public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException {            if (!response.isCommitted()) {                response.sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED,&quot;未认证的用户:&quot; + authException.getMessage());            }        }    }</code></pre><p>再次重试，发现会返回 405状态码了，不会在重定向到 /login 了</p><p>问题解决</p>]]></content>
      
      
      <categories>
          
          <category> SpringSecurity篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> SpringSecurity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 整合使用 SpringSecurity</title>
      <link href="/2018/03/28/SpringBoot-SpringSecurity/"/>
      <url>/2018/03/28/SpringBoot-SpringSecurity/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h2><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;        &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;</code></pre><h2 id="SpringSecurity-配置类"><a href="#SpringSecurity-配置类" class="headerlink" title="SpringSecurity 配置类"></a>SpringSecurity 配置类</h2><pre><code class="java">    @EqualsAndHashCode(callSuper = true)    @Data    @Configuration    @EnableWebSecurity    @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)    @ConfigurationProperties(prefix = &quot;spring.security.ignore&quot;)    public class WebSecurityConfig extends WebSecurityConfigurerAdapter {        private List&lt;String[]&gt; marchers;        @Bean        public UserService userService(){            return new UserService();        }        @Override        protected void configure(HttpSecurity http) throws Exception {            http                    .anonymous().disable()                    .csrf().disable()                    .authorizeRequests()    //                .requestMatchers(CorsUtils::isPreFlightRequest).permitAll() //解决PreFlight请求问题                    .anyRequest().authenticated()//其他请求必须授权后访问                    .and()                    .formLogin()    //                .loginPage(&quot;/login&quot;)                    .loginProcessingUrl(&quot;/login&quot;)                    .successHandler(authenticationSuccessHandler())                    .failureHandler(authenticationFailureHandler())                    .permitAll()//登录请求可以直接访问                    .and()                    .logout()                    .invalidateHttpSession(true)                    .deleteCookies(&quot;JSESSIONID&quot;)                    .logoutSuccessHandler(new LogoutSuccess())                    .permitAll()//注销请求可直接访问                    .and()                    .sessionManagement()                    .invalidSessionStrategy(new InvalidSessionStrategyImpl())                    .maximumSessions(-1).expiredSessionStrategy(expiredSessionStrategy())//配置并发登录，-1表示不限制                    .sessionRegistry(sessionRegistry())                    .and()                    .and()                    .exceptionHandling()                    .authenticationEntryPoint(new UnauthenticatedEntryPoint())                    .accessDeniedHandler(new AuthorizationFailure())                    .and()                    .addFilterBefore(new AuthorizationFilter(new AuthorizationMetadataSource(), new                    AuthorizationAccessDecisionManager()), FilterSecurityInterceptor.class);        }        @Override        public void configure(AuthenticationManagerBuilder auth) {            auth.authenticationProvider(authenticationProvider());        }        @Bean        public SessionRegistry sessionRegistry(){            return new SessionRegistryImpl();        }        @Bean        public ExpiredSessionStrategyImpl expiredSessionStrategy(){            return new ExpiredSessionStrategyImpl();        }        @Bean        public BCryptPasswordEncoder passwordEncoder() {            return SecurityUtils.getPasswordEncoder();        }        @Override        public void configure(WebSecurity web) {            for (String[] marcher : marchers) {                web.ignoring().antMatchers(marcher);            }        }        @Bean        public DaoAuthenticationProvider authenticationProvider() {            DaoAuthenticationProvider provider = new DaoAuthenticationProvider();            /*不将UserNotFoundExceptions转换为BadCredentialsException*/            provider.setHideUserNotFoundExceptions(false);            provider.setUserDetailsService(userService());            provider.setPasswordEncoder(passwordEncoder());            return provider;        }        @Bean        public AuthenticationSuccess authenticationSuccessHandler(){            return new AuthenticationSuccess();        }        @Bean        public AuthenticationFailureHandler authenticationFailureHandler(){            return new AuthenticationFailure();        }    }</code></pre><h2 id="自定义-userService"><a href="#自定义-userService" class="headerlink" title="自定义 userService"></a>自定义 userService</h2><pre><code class="java">    public class UserService implements UserDetailsService {        @Autowired        private WebSecurityConfig securityConfig;        @Autowired        private SysUserMapper userMapper;        @Override        public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {            if (StringUtils.isEmpty(username)) {                throw new UsernameNotFoundException(&quot;用户名不能为空!&quot;);            }            SysUser user = new SysUser();            user.setLoginName(username);            SysUser queryUser = userMapper.selectOne(user);            if (null == queryUser) {                throw new UsernameNotFoundException(&quot;用户  &quot; + username + &quot; 不存在!&quot;);            }            if (!queryUser.getPermissionIpList().contains(&quot;0.0.0.0&quot;) &amp;&amp; !queryUser.getPermissionIpList().contains                    (SecurityUtils.getRemoteAddress())) {                throw new InvalidIpAddrException(&quot;登录 IP 地址不合法&quot;);            }            return new SecurityUser(queryUser);        }        /**         * 重新授权         */        public void reAuthorization(){            SecurityUser user = SecurityUtils.currentUser();            assert user != null;            String username = user.getUsername();            user.setRoles(userMapper.findRolesByName(username));            user.setMenus(userMapper.findMenusByName(username));            user.setFunctions(userMapper.findFunctionsByName(username));            List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;();            for (Function function : user.getFunctions()) {                for (String url : function.getFunctionUrl().split(&quot;,&quot;)) {                    authorities.add(new SimpleGrantedAuthority(url));                }            }            user.setAuthorities(authorities.stream().distinct().collect(Collectors.toList()));            // 得到当前的认证信息            Authentication auth = SecurityUtils.getAuthentication();            // 生成新的认证信息            Authentication newAuth = new UsernamePasswordAuthenticationToken(auth.getPrincipal(), auth.getCredentials(), authorities);            // 重置认证信息            SecurityContextHolder.getContext().setAuthentication(newAuth);        }        /**         * 根据用户名 将该用户登录的所有账户踢下线         * @param userNames userNames         */        public void kickOutUser(String... userNames) {            SessionRegistry sessionRegistry = securityConfig.sessionRegistry();            for (Object o : sessionRegistry.getAllPrincipals()) {                SecurityUser user = (SecurityUser) o;                for (String username : userNames) {                    if (user.getLoginName().equals(username)) {                        for (SessionInformation sessionInformation : sessionRegistry.getAllSessions(user, false)) {                            sessionInformation.expireNow();                        }                    }                }            }        }    }</code></pre><h2 id="用户实体类-SecurityUser"><a href="#用户实体类-SecurityUser" class="headerlink" title="用户实体类 SecurityUser"></a>用户实体类 SecurityUser</h2><pre><code class="java">    @Data    public class SecurityUser extends SysUser implements UserDetails{        /*角色*/        private List&lt;SysRole&gt; roles;        /*菜单*/        private List&lt;Menu&gt; menus;        /*功能权限*/        private List&lt;Function&gt; functions;        private Collection&lt;? extends GrantedAuthority&gt; authorities;        SecurityUser(SysUser user) {            this.setUserId(user.getUserId());            this.setGlbm(user.getGlbm());            this.setXh(user.getXh());            this.setLoginName(user.getLoginName());            this.setLoginPassword(user.getLoginPassword());            this.setPermissionIpList(user.getPermissionIpList());            this.setLatestLoginTime(user.getLatestLoginTime());            this.setTotalLoginCounts(user.getTotalLoginCounts());            this.setName(user.getName());            this.setCreateTime(user.getCreateTime());            this.setUpdateTime(user.getUpdateTime());        }        @Override        public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() {            return authorities;        }        @Override        public boolean isAccountNonExpired() {            return true;        }        @Override        public boolean isAccountNonLocked() {            return true;        }        @Override        public boolean isCredentialsNonExpired() {            return true;        }        @Override        public boolean isEnabled() {            return true;        }        @Override        public String getPassword() {            return super.getLoginPassword();        }        @Override        public String getUsername() {            return super.getLoginName();        }        @Override        public int hashCode() {            return this.getLoginName().hashCode();        }        @Override        public boolean equals(Object obj) {            return obj instanceof SecurityUser &amp;&amp; ((SecurityUser) obj).getLoginName().equals(this.getLoginName());        }    }</code></pre><h2 id="授权Filter"><a href="#授权Filter" class="headerlink" title="授权Filter"></a>授权Filter</h2><pre><code class="java">    public class AuthorizationFilter extends AbstractSecurityInterceptor implements Filter {        private AuthorizationMetadataSource metadataSource;        public AuthorizationFilter(AuthorizationMetadataSource metadataSource, AuthorizationAccessDecisionManager                accessDecisionManager) {            this.metadataSource = metadataSource;            this.setAccessDecisionManager(accessDecisionManager);        }        @Override        public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)                throws IOException, ServletException {            FilterInvocation fi = new FilterInvocation(servletRequest, servletResponse, filterChain);            invoke(fi);        }        private void invoke(FilterInvocation fi) throws IOException, ServletException {            InterceptorStatusToken token = super.beforeInvocation(fi);            try {                fi.getChain().doFilter(fi.getRequest(), fi.getResponse());            } finally {                super.afterInvocation(token, null);            }        }        @Override        public Class&lt;?&gt; getSecureObjectClass() {            return FilterInvocation.class;        }        @Override        public SecurityMetadataSource obtainSecurityMetadataSource() {            return metadataSource;        }        @Override        public void destroy() {        }        @Override        public void init(FilterConfig filterConfig) {        }    }</code></pre><h2 id="授权访问决策器"><a href="#授权访问决策器" class="headerlink" title="授权访问决策器"></a>授权访问决策器</h2><pre><code class="java">    public class AuthorizationAccessDecisionManager implements AccessDecisionManager {        /**         * 认证用户是否具有权限访问该url地址         */        @Override        public void decide(Authentication authentication, Object object, Collection&lt;ConfigAttribute&gt; configAttributes)                throws AccessDeniedException, InsufficientAuthenticationException {            HttpServletRequest request = ((FilterInvocation) object).getRequest();            String url = ((FilterInvocation) object).getRequestUrl();            for (GrantedAuthority grantedAuthority : authentication.getAuthorities()) {                SimpleGrantedAuthority authority = (SimpleGrantedAuthority) grantedAuthority;                if (matches(authority.getAuthority(), request)) {                    return;                }            }            throw new AccessDeniedException(&quot;uri: &quot; + url + &quot;,无权限访问！&quot;);        }        /**         * 当前AccessDecisionManager是否支持对应的ConfigAttribute         */        @Override        public boolean supports(ConfigAttribute attribute) {            return true;        }        /**         * 当前AccessDecisionManager是否支持对应的受保护对象类型         */        @Override        public boolean supports(Class&lt;?&gt; clazz) {            return true;        }        private boolean matches(String url, HttpServletRequest request) {            AntPathRequestMatcher matcher = new AntPathRequestMatcher(url);            return matcher.matches(request);        }    }</code></pre><h2 id="授权元数据"><a href="#授权元数据" class="headerlink" title="授权元数据"></a>授权元数据</h2><pre><code class="java">    public class AuthorizationMetadataSource implements FilterInvocationSecurityMetadataSource {        /**         * 加载 请求的url资源所需的权限         * @param object object         * @return Collection         * @throws IllegalArgumentException Exception         */        @Override        public Collection&lt;ConfigAttribute&gt; getAttributes(Object object) throws IllegalArgumentException {            String url = ((FilterInvocation) object).getRequestUrl();            Collection&lt;ConfigAttribute&gt; configAttributes = new ArrayList&lt;&gt;();            configAttributes.add(new SecurityConfig(url));            return configAttributes;        }        /**         * 会在启动时加载所有 ConfigAttribute 集合         * @return Collection         */        @Override        public Collection&lt;ConfigAttribute&gt; getAllConfigAttributes() {            return null;        }        @Override        public boolean supports(Class&lt;?&gt; clazz) {            return true;        }    }</code></pre><h2 id="封装一些-Security-工具类"><a href="#封装一些-Security-工具类" class="headerlink" title="封装一些 Security 工具类"></a>封装一些 Security 工具类</h2><pre><code class="java">    public class SecurityUtils {        public static Authentication getAuthentication(){            return SecurityContextHolder.getContext().getAuthentication();        }        /**         * 用户是否登录         * @return boolean         */        public static boolean isAuthenticated(){            return getAuthentication() != null || !(getAuthentication() instanceof AnonymousAuthenticationToken);        }        /**         * 获取当前用户         * @return user         */        public static SecurityUser currentUser(){            if (isAuthenticated()) {                return (SecurityUser) getAuthentication().getPrincipal();            }            return null;        }        /**         * 获取 webAuthenticationDetails         */        private static WebAuthenticationDetails webAuthenticationDetails(){            return (WebAuthenticationDetails)getAuthentication().getDetails();        }        /**         * 获取session id         */        public static String getSessionId(){            return webAuthenticationDetails().getSessionId();        }        /**         * 获取远程访问地址         */        public static String getRemoteAddress(){            return webAuthenticationDetails().getRemoteAddress();        }        /**         * 获取密码编译器         * @return BCryptPasswordEncoder         */        public static BCryptPasswordEncoder getPasswordEncoder(){            return new BCryptPasswordEncoder(4);        }        /**         * 根据明文加密 返回密文         * @param rawPassword 明文         * @return 密文         */        public static String createPassword(String rawPassword){            return getPasswordEncoder().encode(rawPassword.trim());        }        /**         * 传入明文和密文 检查是否匹配         * @param rawPassword 明文         * @param encodedPassword 密文         * @return boolean         */        public static boolean isMatching(String rawPassword,String encodedPassword){            return getPasswordEncoder().matches(rawPassword,encodedPassword);        }    }</code></pre><p>主要的实现类都列举在内了，还有一些成功和失败的处理类，再次没有列举出来<br>因为该项目为构建纯restful风格的后台项目，这些成功或失败的处理类基本都是返回的http状态码</p>]]></content>
      
      
      <categories>
          
          <category> SpringSecurity篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> SpringSecurity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于通用 Mapper Example 使用记录</title>
      <link href="/2018/02/27/MyBatis-Example/"/>
      <url>/2018/02/27/MyBatis-Example/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>项目整合 通用 mapper 和 pagehelper 插件，这部分以前有写过，略</li><li>需要集成 mybatis 的 generator 插件，方便自动生成 实体类和 mapper 类，还可以生成xml，不过一般我们都不用 xml</li><li>baseMapper 需要继承 ExampleMapper<T> 不过只需要继承 Mapper<T> 就可以了，因为 Mapper<T> 已经继承了 ExampleMapper<T></li></ul><h2 id="Example-的用法"><a href="#Example-的用法" class="headerlink" title="Example  的用法"></a>Example  的用法</h2><p>首先需要说明一点 ，和 Example 使用相同的还有 Condition 类 该类继承自 Example，使用方法和 Example 完全一样，只是为了避免语义有歧义重命名的一个类，这里我们都用 Example 来说明</p><ul><li>创建 Example : </li></ul><pre><code class="java">    Example example = new Example(XXX.class);</code></pre><p>其中构造方法为生成的 model 实体类，还有 2 个构造方法</p><pre><code class="java">        /**         * 带exists参数的构造方法，默认notNull为false，允许为空         *         * @param entityClass         * @param exists      - true时，如果字段不存在就抛出异常，false时，如果不存在就不使用该字段的条件         */        public Example(Class&lt;?&gt; entityClass, boolean exists) {           ...        }        /**         * 带exists参数的构造方法         *         * @param entityClass         * @param exists      - true时，如果字段不存在就抛出异常，false时，如果不存在就不使用该字段的条件         * @param notNull     - true时，如果值为空，就会抛出异常，false时，如果为空就不使用该字段的条件         */        public Example(Class&lt;?&gt; entityClass, boolean exists, boolean notNull) {           ...        }</code></pre><p>然后可以对 example 的实体类的单表进行查询了</p><pre><code class="java">    Example example = new Example(XXX.class);    example.createCriteria().andGreaterThan(&quot;id&quot;, 100).andLessThan(&quot;id&quot;,151);    example.or().andLessThan(&quot;id&quot;, 41);    List&lt;XXX&gt; list = mapper.selectByExample(example);</code></pre><p>以上查询的条件是，查询 id 大于 100 并且小于 151 或者 id 小于 41 的记录</p><p>还可以写成 sql 的方式：</p><pre><code class="java">    Example example = new Example(XXX.class);    example.createCriteria().andCondition(&quot;id &gt; 100 and id &lt;151 or id &lt; 41&quot;);    // andCondition() 方法可以叠加使用，像这样    example.createCriteria().andCondition(&quot;id &gt; 100 and id &lt;151&quot;).orCondition(&quot;id &lt;41&quot;);</code></pre><p>andCondition() 有2中使用方法：<br>andCondition(String condition) ： 手写条件，例如 “length(name)&lt;5”<br>andCondition(String condition, Object value) : 手写左边条件，右边用value值,例如 “length(name)=” “5”<br>orCondition() 也是类似的</p><p>example 里有很多 mysql 常用的方法，使用方法和 elasticsearch 的 java api 很类似，这里列举几个</p><ul><li><code>Set&lt;String&gt; selectColumns</code> : 查询的字段</li><li><code>Set&lt;String&gt; excludeColumns</code> ： 排除的查询字段</li><li><code>Map&lt;String, EntityColumn&gt; propertyMap</code> ： 属性和列对应</li><li>andAllEqualTo ： 将此对象的所有字段参数作为相等查询条件，如果字段为 null，则为 is null</li><li>andGreaterThan ： and 条件 大于</li><li>andBetween : and 条件 between</li><li>andEqualTo : 将此对象的不为空的字段参数作为相等查询条件 还有一种有 value 参数的是 = 条件</li><li>andGreaterThanOrEqualTo ： and 条件 》=</li></ul><p>还有一些一看就知道意思的</p><ul><li>andIn</li><li>andIsNotNull</li><li>andIsNull</li><li>andLessThan</li><li>andLessThanOrEqualTo</li><li>andNotLike</li></ul><p>上面是以 and 条件举例 ，or的条件也是一样的</p><h2 id="集成分页功能"><a href="#集成分页功能" class="headerlink" title="集成分页功能"></a>集成分页功能</h2><p>我们知道 PageHelper.startPage(pageNum, pageSize); 可以对 后面的一个 select 进行分页<br>那么我们可以对 example 进行一个分页查询的封装</p><pre><code class="java">    // 在baseMapper 里封装一个接口    PageInfo selectPageByExample(int pageNum, int pageSize, Object example);    //这样实现上面的接口    @Override    public PageInfo selectPageByExample(int pageNum, int pageSize, Object example) {        PageHelper.startPage(pageNum, pageSize);        List&lt;T&gt; list = selectByExample(example);        return new PageInfo&lt;&gt;(list);    }    //java 8 的lamda 用法    @Override    public PageInfo selectPageByExample(int pageNum, int pageSize, Object example) {        return PageHelper.startPage(pageNum, pageSize).doSelectPageInfo(()-&gt;baseMapper.selectByExample(example));    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> MyBatis篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 自定义打包部署，暴露配置文件和静态资源文件</title>
      <link href="/2017/12/12/SpringBoot-Assembly-Package/"/>
      <url>/2017/12/12/SpringBoot-Assembly-Package/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>SpringBoot 默认有2种打包方式，一种是直接打成 jar 包，直接使用 java -jar 跑起来，另一种是打成 war 包，移除掉 web starter 里的容器依赖，然后丢到外部容器跑起来。</p><p>第一种方式的缺点是整个项目作为一个 jar，部署到生产环境中一旦有配置文件需要修改，则过程比较麻烦<br>linux 下可以使用 vim jar 包，找到配置文件修改后再保存<br>window 下需要使用 解压缩软件打开 jar 再找到配置文件，修改后替换更新</p><p>第二种方式的缺点是需要依赖外部容器，这无非多引入了一部分，很多时候我们很不情愿这么做</p><blockquote><blockquote><p>spring boot 项目启动时 指定配置有2种方式：一种是启动时修改配置参数，像 java -jar xxxx.jar –server.port=8081 这样；另外一种是 指定外部配置文件加载，像 java -jar xxxx.jar -Dspring.config.location=applixxx.yml这样</p></blockquote></blockquote><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>我们希望打包成 tomcat 或者 maven 那样的软件包结构，即</p><pre><code>--- bin    --- start.sh    --- stop.sh    --- restart.sh    --- start.bat    --- stop.bat    --- restart.bat--- boot    --- xxxx.jar--- lib--- conf--- logs--- README.md--- LICENSE</code></pre><p>就像这样<br><img src="http://image.joylau.cn/blog/Assembly-Package.png" alt="Assembly-Package"></p><ul><li><code>bin</code> 目录放一些我们程序的启动停止脚本</li><li><code>boot</code> 目录放我们自己的程序包</li><li><code>lib</code> 目录是我们程序的依赖包</li><li><code>conf</code> 目录是项目的配置文件</li><li><code>logs</code> 目录是程序运行时的日志文件</li><li><code>README.md</code> 使用说明</li><li><code>LICENSE</code> 许可说明</li></ul><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>maven-jar-plugin ： 打包我们写的程序包和所需的依赖包，并指定入口类，依赖包路径和classpath路径，其实就是在MANIFEST.MF这个文件写入相应的配置</li><li>maven-assembly-plugin ： 自定义我们打包的文件目录的格式</li></ul><h2 id="pom-xml-配置"><a href="#pom-xml-配置" class="headerlink" title="pom.xml 配置"></a>pom.xml 配置</h2><pre><code class="xml">    &lt;build&gt;        &lt;plugins&gt;            &lt;!--&lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;fork&gt;true&lt;/fork&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;--&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;                        &lt;manifest&gt;                            &lt;mainClass&gt;com.ahtsoft.AhtsoftBigdataWebApplication&lt;/mainClass&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;classpathPrefix&gt;../lib/&lt;/classpathPrefix&gt;                        &lt;/manifest&gt;                        &lt;manifestEntries&gt;                            &lt;Class-Path&gt;../conf/resources/&lt;/Class-Path&gt;                        &lt;/manifestEntries&gt;                    &lt;/archive&gt;                    &lt;excludes&gt;                        &lt;exclude&gt;static/**&lt;/exclude&gt;                        &lt;exclude&gt;*.yml&lt;/exclude&gt;                    &lt;/excludes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;descriptors&gt;                        &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt;                    &lt;/descriptors&gt;                &lt;/configuration&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;single&lt;/goal&gt;                        &lt;/goals&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><ol><li>将 spring boot 默认的打包方式 spring-boot-maven-plugin 去掉，使用现在的打包方式</li><li>maven-jar-plugin 配置中，制定了入口类，addClasspath 配置将所需的依赖包单独打包，依赖包打的位置在lib目录底下，在MANIFEST.MF这个文件写入相应的配置</li><li>配置了 classpath 在 /conf/resources/ ,这个和后面的 assembly.xml 要相对应</li><li>我单独把spring boot 的配置文件 yml文件 和 静态资源目录 static 单独拎了出来，在我们的源码包中并没有打进去，而是交给 assembly.xml 来单独打到一个独立的文件 conf文件下</li><li>这也是照应了 前面为什么要设置 classpath 为 /conf/resources/</li></ol><p>下面重要的是 assembly.xml 配置文件了，这个文件才是把我们的程序打成标准的目录结构</p><h2 id="assembly-xml"><a href="#assembly-xml" class="headerlink" title="assembly.xml"></a>assembly.xml</h2><pre><code class="xml">    &lt;assembly&gt;        &lt;id&gt;assembly&lt;/id&gt;        &lt;formats&gt;            &lt;format&gt;tar.gz&lt;/format&gt;        &lt;/formats&gt;        &lt;baseDirectory&gt;${project.artifactId}-${project.version}/&lt;/baseDirectory&gt;        &lt;files&gt;            &lt;file&gt;                &lt;source&gt;target/${project.artifactId}-${project.version}.jar&lt;/source&gt;                &lt;outputDirectory&gt;boot/&lt;/outputDirectory&gt;                &lt;destName&gt;${project.artifactId}-${project.version}.jar&lt;/destName&gt;            &lt;/file&gt;        &lt;/files&gt;        &lt;fileSets&gt;            &lt;fileSet&gt;                &lt;directory&gt;./&lt;/directory&gt;                &lt;outputDirectory&gt;./&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;*.txt&lt;/include&gt;                    &lt;include&gt;*.md&lt;/include&gt;                &lt;/includes&gt;            &lt;/fileSet&gt;            &lt;fileSet&gt;                &lt;directory&gt;src/main/bin&lt;/directory&gt;                &lt;outputDirectory&gt;bin/&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;*.sh&lt;/include&gt;                    &lt;include&gt;*.cmd&lt;/include&gt;                &lt;/includes&gt;                &lt;fileMode&gt;0755&lt;/fileMode&gt;            &lt;/fileSet&gt;            &lt;fileSet&gt;                &lt;directory&gt;src/main/resources/static&lt;/directory&gt;                &lt;outputDirectory&gt;conf/resources/static/&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;*&lt;/include&gt;                &lt;/includes&gt;            &lt;/fileSet&gt;            &lt;fileSet&gt;                &lt;directory&gt;src/main/resources&lt;/directory&gt;                &lt;outputDirectory&gt;conf/resources&lt;/outputDirectory&gt;                &lt;includes&gt;                    &lt;include&gt;*.properties&lt;/include&gt;                    &lt;include&gt;*.conf&lt;/include&gt;                    &lt;include&gt;*.yml&lt;/include&gt;                &lt;/includes&gt;            &lt;/fileSet&gt;        &lt;/fileSets&gt;        &lt;dependencySets&gt;            &lt;dependencySet&gt;                &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt;                &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt;                &lt;scope&gt;runtime&lt;/scope&gt;                &lt;includes&gt;                    &lt;include&gt;*:*&lt;/include&gt;                &lt;/includes&gt;                &lt;excludes&gt;                    &lt;exclude&gt;${groupId}:${artifactId}&lt;/exclude&gt;                    &lt;exclude&gt;org.springframework.boot:spring-boot-devtools&lt;/exclude&gt;                &lt;/excludes&gt;            &lt;/dependencySet&gt;        &lt;/dependencySets&gt;    &lt;/assembly&gt;</code></pre><ul><li>将最终的程序包打成 tar.gz ,当然也可以打成其他的格式如zip,rar等，fileSets 里面指定我们源码里的文件和路径打成标准包相对应的目录</li><li>需要注意的是，在最终的依赖库 lib 下 去掉我们的程序和开发时spring boot的热部署依赖 spring-boot-devtools，否则的会出问题</li><li>代码里的启动和停止脚本要赋予权限，否则在执行的时候可能提示权限的问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 最新版 SpringBoot 整合 Druid,MyBatis,通用 Mapper,PageHelper的脚手架</title>
      <link href="/2017/11/29/SpringBoot-Druid-MyBatis-Mapper-PageHelper/"/>
      <url>/2017/11/29/SpringBoot-Druid-MyBatis-Mapper-PageHelper/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>上次自己写这篇文章 已经是今年初了,一年过去了, Spring Boot 项目在不停的更新着,与此同时其他的 stater项目也在不停的更新着,今天就来重新整合下Druid,MyBatis,通用 Mapper,PageHelper,打算在企业级项目中使用</p><p>当前 SpringBoot 最新的发布版是 1.5.9.RELEASE<br>昨天还是 1.5.8,今天发现就是1.5.9.RELEASE了<br>本篇文章搭建的脚手架就是基于 1.5.9.RELEASE</p><p>年初我自己搭建这个脚手架使用的时候,那时 Druid,MyBatis,Mapper,PageHelper,这几个开源项目都没有集成 SpringBoot,我自己还是使用 JavaConfig 配置的<br>现在不一样了,一年过去了,这些项目的作者也开发了对 SpringBoot 支持的 starter 版本</p><p>本篇文章就来整合这些开源框架制作一个脚手架</p><p>另外是有打算将它应用到企业级项目中的</p><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>SpringBoot: 1.5.9.RELEASE<br>SpringBoot-mybatis : 1.3.1<br>mapper-spring-boot-starter : 1.1.5<br>pagehelper-spring-boot-starter: 1.2.3<br>druid-spring-boot-starter: 1.1.5</p><h3 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h3><pre><code class="xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;        xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;com.ahtsoft&lt;/groupId&gt;        &lt;artifactId&gt;ahtsoft-bigdata-web&lt;/artifactId&gt;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;packaging&gt;jar&lt;/packaging&gt;        &lt;name&gt;ahtsoft-bigdata-web&lt;/name&gt;        &lt;description&gt;ahtsoft bigData Web Project&lt;/description&gt;        &lt;developers&gt;            &lt;developer&gt;                &lt;name&gt;LiuFa&lt;/name&gt;                &lt;email&gt;liuf@ahtsoft.com&lt;/email&gt;            &lt;/developer&gt;        &lt;/developers&gt;        &lt;parent&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;            &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;            &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;        &lt;/parent&gt;        &lt;properties&gt;            &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;            &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;            &lt;java.version&gt;1.8&lt;/java.version&gt;        &lt;/properties&gt;        &lt;dependencies&gt;            &lt;!--&lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;            &lt;/dependency&gt;--&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;                &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;                &lt;version&gt;1.3.1&lt;/version&gt;            &lt;/dependency&gt;            &lt;!--mapper--&gt;            &lt;dependency&gt;                &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;                &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;                &lt;version&gt;1.1.5&lt;/version&gt;            &lt;/dependency&gt;            &lt;!--pagehelper--&gt;            &lt;dependency&gt;                &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;                &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;                &lt;version&gt;1.2.3&lt;/version&gt;            &lt;/dependency&gt;            &lt;!--druid--&gt;            &lt;dependency&gt;                &lt;groupId&gt;com.alibaba&lt;/groupId&gt;                &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;                &lt;version&gt;1.1.5&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;mysql&lt;/groupId&gt;                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;                &lt;scope&gt;runtime&lt;/scope&gt;            &lt;/dependency&gt;            &lt;!--&lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;            &lt;/dependency&gt;--&gt;            &lt;!--&lt;dependency&gt;                &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;                &lt;artifactId&gt;spring-session&lt;/artifactId&gt;            &lt;/dependency&gt;--&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;                &lt;exclusions&gt;                    &lt;exclusion&gt;                        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                        &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;                    &lt;/exclusion&gt;                &lt;/exclusions&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;            &lt;/dependency&gt;            &lt;!--&lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;            &lt;/dependency&gt;--&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;                &lt;scope&gt;runtime&lt;/scope&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;                &lt;artifactId&gt;lombok&lt;/artifactId&gt;                &lt;optional&gt;true&lt;/optional&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;                &lt;scope&gt;test&lt;/scope&gt;            &lt;/dependency&gt;            &lt;!--&lt;dependency&gt;                &lt;groupId&gt;org.springframework.security&lt;/groupId&gt;                &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt;                &lt;scope&gt;test&lt;/scope&gt;            &lt;/dependency&gt;--&gt;            &lt;dependency&gt;                &lt;groupId&gt;com.alibaba&lt;/groupId&gt;                &lt;artifactId&gt;fastjson&lt;/artifactId&gt;                &lt;version&gt;1.2.33&lt;/version&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;                &lt;optional&gt;true&lt;/optional&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;        &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                    &lt;configuration&gt;                        &lt;fork&gt;true&lt;/fork&gt;                    &lt;/configuration&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/build&gt;    &lt;/project&gt;</code></pre><p>说明:<br>pom 中除了应用了必要的依赖,还引入了SpringSecurity, 打算做脚手架的安全认证<br>caffeine cache 打算做 restapi 的 cache 的</p><p>使用 devtools 开发时热部署<br>lombok 简化代码配置<br>websocket 全双工通信<br>集群的话 spring-session 做到 session 共享</p><h3 id="application-yml"><a href="#application-yml" class="headerlink" title="application,yml"></a>application,yml</h3><pre><code class="properties">    spring:      datasource:        druid:          url: jdbc:mysql://lfdevelopment.cn:3333/boot-security?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false          username: root          password: q1pE3gb8+1Q9DkE27wjl0Q1xhiYJJC0w5+TJIZXjEW9fKv9W2h4VOSWOajAVtNXRjaDhtXZlyWN8SAJPqzNFqg==          driver-class-name: com.mysql.jdbc.Driver          public-key: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAK9HqNyD1g+vgwITT4x5EcaWKGJQ7/HCl1C0Uwc8AHPr2y7heJBLGdWtvIKtRKGsn4LCCkyKfVFs87nKKFpJbPECAwEAAQ==          connection-properties: config.decrypt=true;config.decrypt.key=${spring.datasource.druid.public-key}          filter:            config:              enabled: true    mybatis:      type-aliases-package: com.ahtsoft.**.model      configuration:        map-underscore-to-camel-case: true    #    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl    mapper:      mappers[0]: com.ahtsoft.config.basemapper.BaseMapper      not-empty: false      identity: MYSQL    pagehelper:      helper-dialect: mysql      reasonable: true      supportMethodsArguments: true      params: count=countSql    logging:      level:        com:          ahtsoft: debug</code></pre><p>正常配置了druid 的连接配置,其中使用 ConfigTool 的密码加密功能,提供加密后的密文个公钥,在连接数据库时会自动解密</p><p>mybatis 配置了各个 model 的位置,配置开启驼峰命名转换,SQL 语句的打印使用的 springboot 的日志功能,将实现的 StdOutImpl给注释了<br>配置的分页插件 pagehelper 参数</p><p>最后在@ SpringBoot 注解下加入<br><code>@MapperScan(basePackages = &quot;com.ahtsoft.**.mapper&quot;)</code><br>用来扫描 mapper自动注入为 bean</p><p>项目地址: <a href="https://github.com/JoyLau/ahtsoft-bigdata-web.git" target="_blank" rel="noopener">https://github.com/JoyLau/ahtsoft-bigdata-web.git</a></p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Druid </tag>
            
            <tag> MyBatis </tag>
            
            <tag> Mapper </tag>
            
            <tag> PageHelper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript 数组的一些常用的方法整理</title>
      <link href="/2017/11/24/JavaScript-Array-Method/"/>
      <url>/2017/11/24/JavaScript-Array-Method/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="push-添加最后一项"><a href="#push-添加最后一项" class="headerlink" title="push 添加最后一项"></a>push 添加最后一项</h3><p>在数组末尾添加一项，并返回数组的长度, 可以添加任意类型的值作为数组的一项。</p><pre><code class="javascript">    var arr = [1,2];    arr.push(6)     // arr: [1,2,6]    arr.push(&#39;aa&#39;)  // arr: [1,2,6,&quot;aa&quot;]    arr.push(undefined)  // arr: [1,2,6,&quot;aa&quot;,undefined]    arr.push({a: &quot;A&quot;, b: &quot;B&quot;})  // [1,2,6,&quot;aa&quot;,undefined,{a: &quot;A&quot;, b: &quot;B&quot;}]</code></pre><h3 id="unshift-在最前面添加一项"><a href="#unshift-在最前面添加一项" class="headerlink" title="unshift 在最前面添加一项"></a>unshift 在最前面添加一项</h3><pre><code class="javascript">    var arr = [1,2];    arr.unshift(9)      // [9, 1, 2]    arr.unshift(&#39;aa&#39;)   // [&#39;aa&#39;,9, 1, 2]</code></pre><h3 id="pop-删除最后一项"><a href="#pop-删除最后一项" class="headerlink" title="pop 删除最后一项"></a>pop 删除最后一项</h3><p>删除最后一项,并返回删除元素的值；如果数组为空则返回undefine。对数组本身操作</p><pre><code class="javascript">    var arr = [1,2,3,4,5];    arr.pop()       // arr: [1, 2, 3, 4]    arr.pop()       // arr: [1, 2, 3]</code></pre><h3 id="shift-删除最前面一项"><a href="#shift-删除最前面一项" class="headerlink" title="shift 删除最前面一项"></a>shift 删除最前面一项</h3><pre><code class="javascript">    var arr = [1,2,3,4,5];    arr.shift()     // [2, 3, 4, 5]    arr.shift()     // [3, 4, 5]</code></pre><h3 id="slice截取-切片-数组-得到截取的数组"><a href="#slice截取-切片-数组-得到截取的数组" class="headerlink" title="slice截取(切片)数组 得到截取的数组"></a>slice截取(切片)数组 得到截取的数组</h3><p>不改变原始数组，得到新的数组</p><p>slice(start,end)</p><pre><code class="javascript">    var arr = [1,2,3,4,5];    var a = arr.slice(1)        // a: [2,3,4,5]    var a = arr.slice(1,3)      // a: [2,3]    var a = arr.slice(3,4)      // a: [5]</code></pre><h3 id="splice剪接数组"><a href="#splice剪接数组" class="headerlink" title="splice剪接数组"></a>splice剪接数组</h3><p>改变原数组，可以实现shift前删除，pop后删除,unshift前增加,同push后增加一样的效果。索引从0开始</p><p>splice(index,howmany,item1,…..,itemX)</p><pre><code class="javascript">    var arr = [1,2,3,4,5];    push: arr.splice(arr.length, 0, 6)  //  [1, 2, 3, 4, 5, 6]    unshift: arr.splice(0, 0, 6)        // [6, 1, 2, 3, 4, 5]    pop: arr.splice(arr.length-1, 1)    // [1, 2, 3, 4]    shift: arr.splice(0, 1)             // [2, 3, 4, 5]    arr.splice(1)   // [1]    arr.splice(1, 2)    // [1, 4, 5]    arr.splice(1, 0, &#39;A&#39;)   // [1, &quot;A&quot;,2,3, 4, 5]    arr.splice(1, 2, &#39;A&#39;, &#39;B&#39;)   // [1, &quot;A&quot;, &quot;B&quot;, 4, 5]</code></pre><h3 id="concat-数组合并"><a href="#concat-数组合并" class="headerlink" title="concat 数组合并"></a>concat 数组合并</h3><p>合并后得到新数组，原始数组不改变</p><pre><code class="javascript">    var arr1 = [1,2];    var arr2 = [3,4,5];    var arr = arr1.concat(arr2)     // [1,2,3,4,5]</code></pre><h3 id="indexOf-数组元素索引"><a href="#indexOf-数组元素索引" class="headerlink" title="indexOf 数组元素索引"></a>indexOf 数组元素索引</h3><p>并返回元素索引，不存在返回-1,索引从0开始</p><pre><code class="javascript">    var arr = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;];     arr.indexOf(&#39;a&#39;);       //0    arr.indexOf(a);         //-1    arr.indexOf(&#39;f&#39;);       //-1    arr.indexOf(&#39;e&#39;);       //4</code></pre><h3 id="join-数组转字符串"><a href="#join-数组转字符串" class="headerlink" title="join 数组转字符串"></a>join 数组转字符串</h3><pre><code class="javascript">    var a, b;    a = [0, 1, 2, 3, 4];    b = a.join(&quot;-&quot;);    // 0-1-2-3-4</code></pre><h3 id="reverse-数组翻转"><a href="#reverse-数组翻转" class="headerlink" title="reverse 数组翻转"></a>reverse 数组翻转</h3><p>并返回翻转后的原数组，原数组翻转了</p><pre><code class="javascript">    var a = [1,2,3,4,5];     a.reverse()//a：[5, 4, 3, 2, 1] 返回[5, 4, 3, 2, 1]</code></pre><h3 id="数组里面的对象去重复"><a href="#数组里面的对象去重复" class="headerlink" title="数组里面的对象去重复"></a>数组里面的对象去重复</h3><pre><code class="javascript">    unique(arr){            let hash = {};            arr = arr.reduce(function(item, next) {                if (!hash[next.name]) {                    item.push(next);                    hash[next.name] = true;                }                return item            }, []);            return arr;        }</code></pre><h3 id="arr-forEach-callback"><a href="#arr-forEach-callback" class="headerlink" title="arr.forEach(callback)"></a>arr.forEach(callback)</h3><p>遍历数组,无return<br>callback的参数：<br>value –当前索引的值<br>index –索引<br>array –原数组</p><h3 id="arr-map-callback"><a href="#arr-map-callback" class="headerlink" title="arr.map(callback)"></a>arr.map(callback)</h3><p>映射数组(遍历数组),有return 返回一个新数组<br>callback的参数：<br>value –当前索引的值<br>index –索引<br>array –原数组</p><p>注意: arr.forEach()和arr.map()的区别 </p><ol><li>arr.forEach()是和for循环一样，是代替for。arr.map()是修改数组其中的数据，并返回新的数据。</li><li>arr.forEach() 没有return  arr.map() 有return</li></ol><h3 id="arr-filter-callback"><a href="#arr-filter-callback" class="headerlink" title="arr.filter(callback)"></a>arr.filter(callback)</h3><p>过滤数组，返回一个满足要求的数组</p><h3 id="arr-every-callback"><a href="#arr-every-callback" class="headerlink" title="arr.every(callback)"></a>arr.every(callback)</h3><p>依据判断条件，数组的元素是否全满足，若满足则返回ture</p><pre><code class="js">    let arr = [1,2,3,4,5]    let arr1 = arr.every( (i, v) =&gt; i &lt; 3)    console.log(arr1)    // false    let arr2 = arr.every( (i, v) =&gt; i &lt; 10)    console.log(arr2)    // true</code></pre><h3 id="arr-some"><a href="#arr-some" class="headerlink" title="arr.some()"></a>arr.some()</h3><p>依据判断条件，数组的元素是否有一个满足，若有一个满足则返回ture</p><pre><code class="js">    let arr = [1,2,3,4,5]    let arr1 = arr.some( (i, v) =&gt; i &lt; 3)    console.log(arr1)    // true    let arr2 = arr.some( (i, v) =&gt; i &gt; 10)    console.log(arr2)    // false</code></pre><h3 id="arr-reduce-callback-initialValue"><a href="#arr-reduce-callback-initialValue" class="headerlink" title="arr.reduce(callback, initialValue)"></a>arr.reduce(callback, initialValue)</h3><p>迭代数组的所有项，累加器，数组中的每个值（从左到右）合并，最终计算为一个值</p><p>参数： </p><ol><li><p>callback:<br>previousValue 必选 –上一次调用回调返回的值，或者是提供的初始值（initialValue）<br>currentValue 必选 –数组中当前被处理的数组项<br>index 可选 –当前数组项在数组中的索引值<br>array 可选 –原数组</p></li><li><p>initialValue: 可选 –初始值<br>实行方法：回调函数第一次执行时，preValue 和 curValue 可以是一个值，如果 initialValue 在调用 reduce() 时被提供，那么第一个 preValue 等于 initialValue ，并且curValue 等于数组中的第一个值；如果initialValue 未被提供，那么preValue 等于数组中的第一个值.</p></li></ol><pre><code class="js">    let arr = [0,1,2,3,4]    let arr1 = arr.reduce((preValue, curValue) =&gt;         preValue + curValue    )    console.log(arr1)    // 10</code></pre><h3 id="arr-find-callback"><a href="#arr-find-callback" class="headerlink" title="arr.find(callback)"></a>arr.find(callback)</h3><p>find的参数为回调函数，回调函数可以接收3个参数，值x、所以i、数组arr，回调函数默认返回值x。</p><pre><code class="js">    let arr=[1,2,234,&#39;sdf&#39;,-2];    arr.find(function(x){        return x&lt;=2;    })//结果：1，返回第一个符合条件的x值    arr.find(function(x,i,arr){        if(x&lt;2){console.log(x,i,arr)}    })//结果：1 0 [1, 2, 234, &quot;sdf&quot;, -2]，-2 4 [1, 2, 234, &quot;sdf&quot;, -2]</code></pre><h3 id="arr-findIndex-callback"><a href="#arr-findIndex-callback" class="headerlink" title="arr.findIndex(callback)"></a>arr.findIndex(callback)</h3><p>findIndex和find差不多，不过默认返回的是索引。</p><h3 id="arr-includes"><a href="#arr-includes" class="headerlink" title="arr.includes()"></a>arr.includes()</h3><p>includes函数与string的includes一样，接收2参数，查询的项以及查询起始位置。</p><pre><code class="js">    let arr=[1,2,234,&#39;sdf&#39;,-2];    arr.includes(2);// 结果true，返回布尔值    arr.includes(20);// 结果：false，返回布尔值    arr.includes(2,3)//结果：false，返回布尔值</code></pre><h3 id="arr-keys"><a href="#arr-keys" class="headerlink" title="arr.keys()"></a>arr.keys()</h3><p>keys，对数组索引的遍历</p><pre><code class="js">    let arr=[1,2,234,&#39;sdf&#39;,-2];    for(let a of arr.keys()){        console.log(a)    }//结果：0,1,2,3,4  遍历了数组arr的索引</code></pre><h3 id="arr-values"><a href="#arr-values" class="headerlink" title="arr.values()"></a>arr.values()</h3><p>values, 对数组项的遍历</p><pre><code class="js">    let arr=[1,2,234,&#39;sdf&#39;,-2];    for(let a of arr.values()){        console.log(a)    }//结果：1,2,234,sdf,-2 遍历了数组arr的值</code></pre><h3 id="arr-entries"><a href="#arr-entries" class="headerlink" title="arr.entries()"></a>arr.entries()</h3><p>entries，对数组键值对的遍历。</p><pre><code class="js">    let arr=[&#39;w&#39;,&#39;b&#39;];    for(let a of arr.entries()){        console.log(a)    }//结果：[0,w],[1,b]    for(let [i,v] of arr.entries()){        console.log(i,v)    }//结果：0 w,1 b</code></pre><h3 id="arr-fill"><a href="#arr-fill" class="headerlink" title="arr.fill()"></a>arr.fill()</h3><p>fill方法改变原数组，当第三个参数大于数组长度时候，以最后一位为结束位置。</p><pre><code class="js">    let arr=[&#39;w&#39;,&#39;b&#39;];    arr.fill(&#39;i&#39;)//结果：[&#39;i&#39;,&#39;i&#39;]，改变原数组    arr.fill(&#39;o&#39;,1)//结果：[&#39;i&#39;,&#39;o&#39;]改变原数组,第二个参数表示填充起始位置    new Array(3).fill(&#39;k&#39;).fill(&#39;r&#39;,1,2)//结果：[&#39;k&#39;,&#39;r&#39;,&#39;k&#39;]，第三个数组表示填充的结束位置</code></pre><h3 id="Array-of"><a href="#Array-of" class="headerlink" title="Array.of()"></a>Array.of()</h3><p>Array.of()方法永远返回一个数组，参数不分类型，只分数量，数量为0返回空数组。</p><pre><code class="js">    Array.of(&#39;w&#39;,&#39;i&#39;,&#39;r&#39;)//[&quot;w&quot;, &quot;i&quot;, &quot;r&quot;]返回数组    Array.of([&#39;w&#39;,&#39;o&#39;])//[[&#39;w&#39;,&#39;o&#39;]]返回嵌套数组    Array.of(undefined)//[undefined]依然返回数组    Array.of()//[]返回一个空数组</code></pre><h3 id="arr-copyWithin"><a href="#arr-copyWithin" class="headerlink" title="arr.copyWithin"></a>arr.copyWithin</h3><p>copyWithin方法接收三个参数，被替换数据的开始处、替换块的开始处、替换块的结束处(不包括);copyWithin(s,m,n).</p><pre><code class="js">    [&quot;w&quot;, &quot;i&quot;, &quot;r&quot;].copyWithin(0)//此时数组不变    [&quot;w&quot;, &quot;i&quot;, &quot;r&quot;].copyWithin(1)//[&quot;w&quot;, &quot;w&quot;, &quot;i&quot;],数组从位置1开始被原数组覆盖，只有1之前的项0保持不变    [&quot;w&quot;, &quot;i&quot;, &quot;r&quot;,&quot;b&quot;].copyWithin(1,2)//[&quot;w&quot;, &quot;r&quot;, &quot;b&quot;, &quot;b&quot;],索引2到最后的r,b两项分别替换到原数组1开始的各项，当数量不够，变终止    [&quot;w&quot;, &quot;i&quot;, &quot;r&quot;,&#39;b&#39;].copyWithin(1,2,3)//[&quot;w&quot;, &quot;r&quot;, &quot;r&quot;, &quot;b&quot;]，强第1项的i替换为第2项的r</code></pre><h3 id="Array-from"><a href="#Array-from" class="headerlink" title="Array.from()"></a>Array.from()</h3><p>Array.from可以把带有lenght属性类似数组的对象转换为数组，也可以把字符串等可以遍历的对象转换为数组，它接收2个参数，转换对象与回调函数</p><pre><code class="js">    Array.from({&#39;0&#39;:&#39;w&#39;,&#39;1&#39;:&#39;b&#39;,length:2})//[&quot;w&quot;, &quot;b&quot;],返回数组的长度取决于对象中的length，故此项必须有！    Array.from({&#39;0&#39;:&#39;w&#39;,&#39;1&#39;:&#39;b&#39;,length:4})//[&quot;w&quot;, &quot;b&quot;, undefined, undefined],数组后2项没有属性去赋值，故undefined    Array.from({&#39;0&#39;:&#39;w&#39;,&#39;1&#39;:&#39;b&#39;,length:1})//[&quot;w&quot;],length小于key的数目，按序添加数组    //////////////////////////////    let divs=document.getElementsByTagName(&#39;div&#39;);    Array.from(divs)//返回div元素数组    Array.from(&#39;wbiokr&#39;)//[&quot;w&quot;, &quot;b&quot;, &quot;i&quot;, &quot;o&quot;, &quot;k&quot;, &quot;r&quot;]    Array.from([1,2,3],function(x){            return x+1})//[2, 3, 4],第二个参数为回调函数</code></pre><h3 id="arr-sort-callback"><a href="#arr-sort-callback" class="headerlink" title="arr.sort(callback)"></a>arr.sort(callback)</h3><p>如果方法没有使用参数，那么将按照字母顺序对数组元素进行排序</p><pre><code class="js">    var arr = [        {name:&#39;zopp&#39;,age:0},        {name:&#39;gpp&#39;,age:18},        {name:&#39;yjj&#39;,age:8}    ];    var compare = age =&gt; {       return (a,b) =&gt; {           return a[age] - b[age];       }    }    arr.sort(compare(age))</code></pre><h3 id="arr-indexOf"><a href="#arr-indexOf" class="headerlink" title="arr.indexOf()"></a>arr.indexOf()</h3><p>从前往后遍历，返回item在数组中的索引位，如果没有返回-1；通常用来判断数组中有没有某个元素。可以接收两个参数，第一个参数是要查找的项，第二个参数是查找起点位置的索引</p><h3 id="arr-lastIndexOf"><a href="#arr-lastIndexOf" class="headerlink" title="arr.lastIndexOf()"></a>arr.lastIndexOf()</h3><p>与indexOf一样，区别是从后往前找。</p><h3 id="arr-flat"><a href="#arr-flat" class="headerlink" title="arr.flat()"></a>arr.flat()</h3><p>数组的成员有时还是数组，Array.prototype.flat()用于将嵌套的数组“拉平”，变成一维数组。该方法返回一个新数组，对原数据没有影响<br>flat()默认只会“拉平”一层，如果想要“拉平”多层的嵌套数组，可以将flat()方法的参数写成一个整数，表示想要拉平的层数，默认为1</p><pre><code class="js">    [1, 2, [3, 4]].flat()    // [1, 2, 3, 4]    [1, 2, [3, [4, 5]]].flat()    // [1, 2, 3, [4, 5]]    [1, 2, [3, [4, 5]]].flat(2)    // [1, 2, 3, 4, 5]</code></pre><h3 id="arr-flatMap"><a href="#arr-flatMap" class="headerlink" title="arr.flatMap()"></a>arr.flatMap()</h3><p>flatMap()方法对原数组的每个成员执行一个函数，相当于执行Array.prototype.map(),然后对返回值组成的数组执行flat()方法。该方法返回一个新数组，不改变原数组。</p><pre><code class="js">    // 相当于 [[2, 4], [3, 6], [4, 8]].flat()    [2, 3, 4].flatMap((x) =&gt; [x, x * 2])    // [2, 4, 3, 6, 4, 8]</code></pre><p>发现一个比较好的js组件，地址： <a href="https://www.lodashjs.com/" target="_blank" rel="noopener">https://www.lodashjs.com/</a>  里面有很多关于对数组的操作</p>]]></content>
      
      
      <categories>
          
          <category> JavaScript篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据之路 Spark 环境搭建</title>
      <link href="/2017/11/23/Spark-Integrate-Build/"/>
      <url>/2017/11/23/Spark-Integrate-Build/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="首先"><a href="#首先" class="headerlink" title="首先"></a>首先</h3><p>首先要说明的是,本篇文章用的  Spark 的版本都是目前最新版,直接在官网上下载就可以了,有注意的,下面详细说<br>有些命令可能已经不适应之前的旧版本了,以最新的版的为准<br>以下操作命令均是在服务的根目录下,使用的是相对目录</p><h3 id="当前版本说明"><a href="#当前版本说明" class="headerlink" title="当前版本说明"></a>当前版本说明</h3><ul><li>jdk 1.8.0</li><li>Hadoop 版本2.8.2</li><li>操作系统版本 centos 7.2</li><li>Spark 2.2.0</li></ul><h3 id="首先需要做的"><a href="#首先需要做的" class="headerlink" title="首先需要做的"></a>首先需要做的</h3><p>安装 jdk 环境,再此不做详细叙述了,需要注意的是 jdk 的环境变量的配置<br>安装 Hadoop 环境,必须安装 Hadoop 才能使用 Spark，但如果使用 Spark 过程中没用到 HDFS，不启动 Hadoop 也是可以的</p><h2 id="安装-Spark"><a href="#安装-Spark" class="headerlink" title="安装 Spark"></a>安装 Spark</h2><p>打开官网下载的地址: <a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">http://spark.apache.org/downloads.html</a><br>需要注意的是,在选择下载包类型 <code>Choose a package type</code> 这个需要根据安装的 Hadoop 的版本来定的,或者直接选择  <code>Pre-build with user-provided Apache Hadoop</code><br>这样我们可以自己配置 Hadoop 的版本</p><p>下载后,解压</p><p>进入 conf目录拷贝一份配置文件</p><pre><code class="bash">    cp ./conf/spark-env.sh.template ./conf/spark-env.sh</code></pre><p>加入环境变量</p><pre><code class="bash">    export SPARK_DIST_CLASSPATH=$(/home/hadoop-2.8.2/bin/hadoop classpath)</code></pre><p>我们运行 </p><pre><code class="bash">    # ./sbin/start-all.sh</code></pre><p>Spark 便会运行起来,查看地址 : <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a>  可查看到集群情况</p><h2 id="运行-Spark-示例程序"><a href="#运行-Spark-示例程序" class="headerlink" title="运行 Spark 示例程序"></a>运行 Spark 示例程序</h2><p>正如前面的 Hadoop 一样, Spark 自带有很多示例程序,目录在 ./example 下面,有 Java 的 Python,Scala ,R 语言的,<br>这里我们选个最熟悉的 Java 版的来跑下</p><p>我们找到 Java 的目录里也能看到里面有很多程序,能看到我们熟悉的 wordcount</p><p>这里我们跑个 计算π的值</p><pre><code class="bash">    # ./bin/run-example SparkPi</code></pre><p>运行后控制台打印很多信息,但是能看到这么一行:</p><p><em><strong>Pi is roughly 3.1432557162785812</strong></em></p><p>这就可以了</p><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><blockquote><blockquote><p>RDD : Spark 的分布式的元素集合（distributed collection of items），称为RDD（Resilient Distributed Dataset，弹性分布式数据集），它可被分发到集群各个节点上，进行并行操作。RDDs 可以通过 Hadoop InputFormats 创建（如 HDFS），或者从其他 RDDs 转化而来</p></blockquote></blockquote><p>我就简单的理解为 类比 Hadoop 的 MapReduce</p><p>RDDs 支持两种类型的操作</p><ul><li>actions: 在数据集上运行计算后返回值</li><li>transformations: 转换, 从现有数据集创建一个新的数据集</li></ul><h2 id="Spark-Shell"><a href="#Spark-Shell" class="headerlink" title="Spark-Shell"></a>Spark-Shell</h2><p>Spark-shell 支持 Scala 和 Python 2中语言,这里我们就用 Scala 来做,关于 Scala 的使用和语法我打算新写一篇文章来记录下,<br>在之前我也写过 在 maven 中集成使用 Scala 来编程,这里我先用下</p><p>执行 shell </p><pre><code class="bash">    # ./bin/spark-shell    To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).    17/11/24 09:33:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable    17/11/24 09:33:37 WARN util.Utils: Your hostname, JoyLinux resolves to a loopback address: 127.0.0.1; using 10.0.2.15 instead (on interface enp0s3)    17/11/24 09:33:37 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address    Spark context Web UI available at http://10.0.2.15:4040    Spark context available as &#39;sc&#39; (master = local[*], app id = local-1511487218050).    Spark session available as &#39;spark&#39;.    Welcome to          ____              __         / __/__  ___ _____/ /__        _\ \/ _ \/ _ `/ __/  &#39;_/       /___/ .__/\_,_/_/ /_/\_\   version 2.2.0          /_/    Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_151)    Type in expressions to have them evaluated.    Type :help for more information.    scala&gt;</code></pre><p>来执行一个文本统计</p><pre><code class="bash">    scala&gt; val textFile = sc.textFile(&quot;file:///home/hadoop-2.8.2/input/test.txt&quot;).count()    textFile: Long = 4</code></pre><p>默认读取的文件是 Hadoop HDFS 上的,上面的示例是从本地文件读取</p><p>来一个从 HDFS 上读取的,在这里我们之前在 HDFS 上传了个 tets.txt 的文档,在这里就可以直接使用了</p><pre><code class="bash">    scala&gt; val textFile = sc.textFile(&quot;test2.txt&quot;);textFile.count()    textFile: org.apache.spark.rdd.RDD[String] = test2.txt MapPartitionsRDD[19] at textFile at &lt;console&gt;:26    res7: Long = 4</code></pre><p>可以看到结果是一样的</p><h2 id="Spark-SQL-和-DataFrames"><a href="#Spark-SQL-和-DataFrames" class="headerlink" title="Spark SQL 和 DataFrames"></a>Spark SQL 和 DataFrames</h2><p>Spark SQL 是 Spark 内嵌的模块，用于结构化数据。在 Spark 程序中可以使用 SQL 查询语句或 DataFrame API。DataFrames 和 SQL 提供了通用的方式来连接多种数据源，支持 Hive、Avro、Parquet、ORC、JSON、和 JDBC，并且可以在多种数据源之间执行 join 操作。</p><p>下面仍在 Spark shell 中演示一下 Spark SQL 的基本操作，该部分内容主要参考了 Spark SQL、DataFrames 和 Datasets 指南。</p><p>Spark SQL 的功能是通过 SQLContext 类来使用的，而创建 SQLContext 是通过 SparkContext 创建的。</p><pre><code class="bash">    scala&gt; var df = spark.read.json(&quot;file:///home/spark-2.2.0-bin-without-hadoop/examples/src/main/resources/employees.json&quot;)    df: org.apache.spark.sql.DataFrame = [name: string, salary: bigint]    scala&gt; df.show()    +-------+------+    |   name|salary|    +-------+------+    |Michael|  3000|    |   Andy|  4500|    | Justin|  3500|    |  Berta|  4000|    +-------+------+    scala&gt;</code></pre><p>再来执行2条查询语句<br><code>df.select(&quot;name&quot;).show()</code><br><code>df.filter(df(&quot;salary&quot;)&gt;=4000).show()</code></p><pre><code class="bash">    scala&gt; df.select(&quot;name&quot;).show()    +-------+    |   name|    +-------+    |Michael|    |   Andy|    | Justin|    |  Berta|    +-------+    scala&gt; df.filter(df(&quot;salary&quot;)&gt;=4000).show()    +-----+------+    | name|salary|    +-----+------+    | Andy|  4500|    |Berta|  4000|    +-----+------+</code></pre><p>执行一条 sql 语句试试</p><pre><code class="bash">    scala&gt; df.registerTempTable(&quot;employees&quot;)    warning: there was one deprecation warning; re-run with -deprecation for details    scala&gt; spark.sql(&quot;select * from employees&quot;).show()    +-------+------+    |   name|salary|    +-------+------+    |Michael|  3000|    |   Andy|  4500|    | Justin|  3500|    |  Berta|  4000|    +-------+------+    scala&gt; spark.sql(&quot;select * from employees where salary &gt;= 4000&quot;).show()    +-----+------+    | name|salary|    +-----+------+    | Andy|  4500|    |Berta|  4000|    +-----+------+</code></pre><p>其实还有很多功能呢, <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame</a> ,这里先写2个试试,后续再细节学习</p><p>这篇文章暂时先写到这,还有后续的 Spark Streaming ,想先学学看流式计算Storm,之后对比下看看写一篇文章</p><p>接下来,熟悉 Scala 语法写一个 JavaScala 应用程序来通过 SparkAPI 单独部署一下试试</p><h3 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h3><p>这篇文章写下来等于将当时搭建 Spark 环境重复了一遍, 也是一遍敲命令,一遍记录下来,温故而知新,自己也学到不少东西,棒棒哒💯</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据之路 Hadoop 环境搭建</title>
      <link href="/2017/11/22/Hadoop-Integrate-Build/"/>
      <url>/2017/11/22/Hadoop-Integrate-Build/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="首先"><a href="#首先" class="headerlink" title="首先"></a>首先</h2><p>首先要说明的是,本篇文章用的 Hadoop 的版本都是目前最新版,直接在官网上下载就可以了<br>有些命令可能已经不适应之前的旧版本了,以最新的版的为准<br>以下操作命令均是在服务的根目录下,使用的是相对目录</p><h3 id="当前版本说明"><a href="#当前版本说明" class="headerlink" title="当前版本说明"></a>当前版本说明</h3><ul><li>Hadoop 版本2.8.2</li><li>操作系统版本 centos 7.2</li></ul><h2 id="首先需要做的"><a href="#首先需要做的" class="headerlink" title="首先需要做的"></a>首先需要做的</h2><p>安装 jdk 环境,再此不做详细叙述了,需要注意的是 jdk 的环境变量的配置</p><p><code>yum install openjdk1.8xxxxx</code> 这个安装的是 jre环境,并不是 jdk,安装 jdk</p><pre><code class="bash">    sudo yum install java-1.7.0-openjdk java-1.8.0-openjdk-devel</code></pre><p>配置环境变量</p><pre><code class="bash">    vim ~/.bashrc</code></pre><p>最后一行添加</p><pre><code class="bash">    export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk</code></pre><p>紧接着,让环境变量生效</p><pre><code class="bash">    source ~/.bashrc    # 使变量设置生效</code></pre><p>设置好之后,再看下是否生效了</p><pre><code class="bash">    echo $JAVA_HOME     # 检验变量值    java -version    $JAVA_HOME/bin/java -version  # 与直接执行 java -version 一样就没什么问题了</code></pre><h2 id="Hadoop-单机环境搭建及测试运行"><a href="#Hadoop-单机环境搭建及测试运行" class="headerlink" title="Hadoop 单机环境搭建及测试运行"></a>Hadoop 单机环境搭建及测试运行</h2><p>官网下载 Hadoop 包</p><p>上传到服务器上,解压 tar -zxf hadoop-2.8.2.tar.gz<br>解压完了,我们可以查看下版本信息</p><pre><code class="bash">    bin/hadoop version    Hadoop 2.8.2    Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb    Compiled by jdu on 2017-10-19T20:39Z    Compiled with protoc 2.5.0    From source with checksum dce55e5afe30c210816b39b631a53b1d    This command was run using /home/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar</code></pre><p>出现上述信息就没有什么问题</p><p>接下来,就可以运行 Hadoop 自带的列子了,例子的目录在 /share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar</p><pre><code class="bash">    // 创建1个输入目录,输出目录不用创建,在命令中会自动创建,如果创建了,会提示目录已经存在,再次运行示例程序化,删除输出目录即可    mkdir ./input    // 看看都有哪些例子    ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar    An example program must be given as the first argument.    Valid program names are:      aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.      aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.      bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.      dbcount: An example job that count the pageview counts from a database.      distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.      grep: A map/reduce program that counts the matches of a regex in the input.      join: A job that effects a join over sorted, equally partitioned datasets      multifilewc: A job that counts words from several files.      pentomino: A map/reduce tile laying program to find solutions to pentomino problems.      pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.      randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.      randomwriter: A map/reduce program that writes 10GB of random data per node.      secondarysort: An example defining a secondary sort to the reduce.      sort: A map/reduce program that sorts the data written by the random writer.      sudoku: A sudoku solver.      teragen: Generate data for the terasort      terasort: Run the terasort      teravalidate: Checking results of terasort      wordcount: A map/reduce program that counts the words in the input files.      wordmean: A map/reduce program that counts the average length of the words in the input files.      wordmedian: A map/reduce program that counts the median length of the words in the input files.      wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.</code></pre><p>接下来,跑一个经典的 wordcount ,再次之前,我们创建一个文本以供程序统计</p><pre><code class="bash">    cat input/test.txt    vi input/test.txt    插入一些字符</code></pre><p>开始记录</p><pre><code class="bash">    ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar wordcount ./input/test.txt ./output/</code></pre><p>截取部分输出</p><pre><code class="txt">    17/11/22 11:30:08 INFO mapred.LocalJobRunner: reduce &gt; reduce    17/11/22 11:30:08 INFO mapred.Task: Task &#39;attempt_local1247748922_0001_r_000000_0&#39; done.    17/11/22 11:30:08 INFO mapred.LocalJobRunner: Finishing task: attempt_local1247748922_0001_r_000000_0    17/11/22 11:30:08 INFO mapred.LocalJobRunner: reduce task executor complete.    17/11/22 11:30:08 INFO mapreduce.Job: Job job_local1247748922_0001 running in uber mode : false    17/11/22 11:30:08 INFO mapreduce.Job:  map 100% reduce 100%    17/11/22 11:30:08 INFO mapreduce.Job: Job job_local1247748922_0001 completed successfully    17/11/22 11:30:08 INFO mapreduce.Job: Counters: 30        File System Counters            FILE: Number of bytes read=605002            FILE: Number of bytes written=1267054            FILE: Number of read operations=0            FILE: Number of large read operations=0            FILE: Number of write operations=0        Map-Reduce Framework            Map input records=38            Map output records=35            Map output bytes=277            Map output materialized bytes=251            Input split bytes=103            Combine input records=35            Combine output records=23            Reduce input groups=23            Reduce shuffle bytes=251            Reduce input records=23            Reduce output records=23            Spilled Records=46            Shuffled Maps =1            Failed Shuffles=0            Merged Map outputs=1            GC time elapsed (ms)=21            Total committed heap usage (bytes)=461250560        Shuffle Errors            BAD_ID=0            CONNECTION=0            IO_ERROR=0            WRONG_LENGTH=0            WRONG_MAP=0            WRONG_REDUCE=0        File Input Format Counters            Bytes Read=140        File Output Format Counters            Bytes Written=165</code></pre><p>看下输出情况</p><pre><code class="xml">    # cat output/*    hello    1    jjjjj    1    joylau    2    world    1</code></pre><p>可以看到每个单词出现的次数</p><h2 id="Hadoop-伪分布式环境搭建"><a href="#Hadoop-伪分布式环境搭建" class="headerlink" title="Hadoop 伪分布式环境搭建"></a>Hadoop 伪分布式环境搭建</h2><p>我们需要设置 HADOOP 环境变量</p><pre><code class="bash">    gedit ~/.bashrc    export HADOOP_HOME=/home/hadoop-2.8.2    export HADOOP_INSTALL=$HADOOP_HOME    export HADOOP_MAPRED_HOME=$HADOOP_HOME    export HADOOP_COMMON_HOME=$HADOOP_HOME    export HADOOP_HDFS_HOME=$HADOOP_HOME    export YARN_HOME=$HADOOP_HOME    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin    source ~/.bashrc</code></pre><p>修改配置文件</p><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><pre><code class="xml">    &lt;configuration&gt;      &lt;property&gt;            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;            &lt;value&gt;file:/home/temp&lt;/value&gt;            &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;fs.defaultFS&lt;/name&gt;            &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;        &lt;/property&gt;    &lt;/configuration&gt;</code></pre><h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><pre><code class="xml">    &lt;configuration&gt;     &lt;property&gt;            &lt;name&gt;dfs.replication&lt;/name&gt;            &lt;value&gt;1&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;            &lt;value&gt;file:/home/temp/hdfs/namenode&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;            &lt;value&gt;file:/home/temp/hdfs/datanode&lt;/value&gt;        &lt;/property&gt;    &lt;/configuration&gt;</code></pre><p>配置完成后，执行 NameNode 和 DataNode 的格式化:</p><pre><code class="bash">    ./bin/hdfs namenode -format    ./bin/hdfs datanode -format</code></pre><p>现在启动 Hadoop 伪分布式服务器</p><pre><code class="bash">    ./sbin/start-dfs.sh     ./sbin/start-yarn.sh</code></pre><p>以前版本的命令是</p><pre><code class="bash">    ./sbin/start-all.sh</code></pre><p>jps查看启动是否成功启动</p><pre><code class="bash">    jps    5360 Jps    4935 ResourceManager    5225 NodeManager    4494 NameNode    4782 SecondaryNameNode</code></pre><p>成功启动后，可以访问 Web 界面 <a href="http://localhost:50070" target="_blank" rel="noopener">http://localhost:50070</a> 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件<br>运行 stop-all.sh 来关闭所有进程</p><h2 id="伪分布式环境实例运行"><a href="#伪分布式环境实例运行" class="headerlink" title="伪分布式环境实例运行"></a>伪分布式环境实例运行</h2><p>上面实例的运行时单机版的,伪分布式的实例的运行的不同之处在于,读取文件是在 HDFS 上的</p><p>按照常规的尿性,我们先创建个用户目录 ,以后就可以以相对目录来进行文件的操作了</p><p>这里得说下 hdfs 的常用 shell</p><ul><li>创建目录 <code>./bin/hdfs dfs -mkdir -p /user/root</code></li><li>上传文档 <code>./bin/hdfs dfs -put ./input/test.txt input</code></li><li>删除文档 <code>./bin/hdfs dfs -rmr input</code></li><li>产看文档 <code>./bin/hdfs dfs -cat input/*</code></li><li>查看列表 <code>./bin/hdfs dfs -ls input</code></li><li>拉取文档 <code>./bin/hdfs dfs -get output/* ./output</code></li></ul><p>有了这些简单的命令,现在就可以运行实例</p><p>先创建用户目录 <code>./bin/hdfs dfs -mkdir -p /user/root</code><br>在新建一个目录 <code>./bin/hdfs dfs -mkdir input</code><br>将之前的文件上传 <code>./bin/hdfs dfs -put ./input/test.txt input</code><br>上传成功后还可以查看下时候有文件 <code>./bin/hdfs dfs -ls input</code><br>运行实例  <code>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar wordcount input/ output/</code><br>查看运行结果 <code>./bin/hdfs dfs -cat output/*</code></p><p>其实这些命令都是类 linux 命令,熟悉 linux 命令,这些都很好操作</p><p>可以看到统计结果和单机版是一致的</p><p>将结果导出 <code>./bin/hdfs dfs -get output ./output</code></p><p>其实 在 <a href="http://host:50070/explorer.html#/user/root" target="_blank" rel="noopener">http://host:50070/explorer.html#/user/root</a> 可以看到上传和输出的文件目录</p><h3 id="YARN-启动"><a href="#YARN-启动" class="headerlink" title="YARN 启动"></a>YARN 启动</h3><p>伪分布式不启动 YARN 也可以，一般不会影响程序执行<br>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性</p><p>首先修改配置文件 mapred-site.xml，这边需要先进行重命名：</p><pre><code class="bash">    mv ./etc/hadoop/mapred-site.xml.template ./etc/hadoop/mapred-site.xml</code></pre><p>增加配置</p><pre><code class="xml">    &lt;configuration&gt;        &lt;property&gt;            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;            &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;    &lt;/configuration&gt;</code></pre><p>配置文件 yarn-site.xml：</p><pre><code class="xml">    &lt;configuration&gt;        &lt;property&gt;            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;            &lt;/property&gt;    &lt;/configuration&gt;</code></pre><pre><code class="bash">    ./sbin/start-yarn.sh      $ 启动YARN    ./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况</code></pre><p>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。<br>观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，<br>启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。<br>启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：<a href="http://localhost:8088/cluster" target="_blank" rel="noopener">http://localhost:8088/cluster</a></p><h2 id="踩坑记录"><a href="#踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录</h2><ul><li>内存不足:一开始虚拟机只开了2G 内存,出现了很多错误,后来将虚拟机内存开到8G, 就没有问题了</li><li>hosts 配置,一开始启动的时候会报不识别 localhost 的域名的错误,更改下 hosts文件即可,加一行</li></ul><pre><code class="xml">    127.0.0.1   localhost HostName</code></pre><ul><li>put 上传文档时报错:There are 0 datanode(s) running and no node(s) are excluded in this operation<br>这可能由于之前在目录下有操作,有一些其他的文档,只要清空指定的目录,然后再格式化 namenode 和 datanode 就可以了</li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>《Hadoop 权威指南 : 第四版》 –Tom White 著</p><h3 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h3><p>这篇文章写下来等于将当时搭建 Hadoop 环境重复了一遍,花了不少功夫的,一遍敲命令,一遍记录下来,温故而知新,自己也学到不少东西,棒棒哒💯</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据之路 Hadoop 的学习流程</title>
      <link href="/2017/11/17/Hadoop-Study-Way/"/>
      <url>/2017/11/17/Hadoop-Study-Way/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="首先"><a href="#首先" class="headerlink" title="首先"></a>首先</h2><p>首先记录,在这篇文章书写前,自己并不是刚刚上手 Hadoop, 其实学了有一段时间了<br>在这段时间内,由最开始的对 Hadoop 的懵懂无知到渐渐的熟悉 Hadoop 大致的开发流程<br>整个过程越来越清晰<br>于是就想着,把自己接下来在 Hadoop 上的学习计划记录下来</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol><li>了解 Hadoop 背景,开发作用</li><li>然后搭建Hadoop集群，先让它在自己电脑上运行。</li><li>学习分布式文件系统HDFS。</li><li>学习分布式计算框架MapReduce</li><li>学习流式计算Storm</li><li>学习分布式协作服务Zookeeper</li><li>学习Hive—数据仓库工具</li><li>学习Hbase—分布式存储系统</li><li>学习Spark</li><li>学习Scala</li><li>学习Spark开发技术</li></ol><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>这些技术在工作中是远远不够的,但也不是工作中每项都有用到了<br>就自己现在公司的大数据环境来说,还有像 impala,zookeeper,spark,kafka…等等<br>等有新的学习计划再补充吧</p>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 使用 Elasticsearch 进行更复杂的查询</title>
      <link href="/2017/11/16/SpringBoot-Elasticsearch-Complex/"/>
      <url>/2017/11/16/SpringBoot-Elasticsearch-Complex/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="首先要说"><a href="#首先要说" class="headerlink" title="首先要说"></a>首先要说</h2><p>java 操作 elasticsearch 有四种方式</p><ol><li>调用 elasticsearch 的 restapis 接口</li><li>调用 java elasticsearch client 的接口</li><li>整合 spring data 使用 ElasticsearchTemplate 封装的方法</li><li>继承 ElasticsearchRepository 接口调用方法</li></ol><h2 id="测试准备"><a href="#测试准备" class="headerlink" title="测试准备"></a>测试准备</h2><p>我们先来准备一些数据,写了一个之前的获取JoyMusic 的音乐数据的项目来说,项目的结构是这样的:<br><img src="http://image.joylau.cn/blog/elasticsearch-test-project.png" alt="elasticsearch-test-project"><br>获取数据的主要代码如下,只是为了增加数据</p><pre><code class="java">    @RunWith(SpringJUnit4ClassRunner.class)    @SpringBootTest(classes = JoylauElasticsearchApplication.class,webEnvironment = SpringBootTest.WebEnvironment.MOCK)    public class JoylauElasticsearchApplicationTests {        @Autowired        private RestTemplate restTemplate;        @Autowired        private PlaylistDAO playlistDAO;        @Autowired        private SongDAO songDAO;        @Autowired        private CommentDAO commentDAO;        @Test        public void createData() {            String personalizeds = restTemplate.getForObject(&quot;http://localhost:3003/apis/v1&quot;+&quot;/personalized&quot;,String.class);            JSONObject perJSON = JSONObject.parseObject(personalizeds);            JSONArray perArr = perJSON.getJSONArray(&quot;result&quot;);            List&lt;Playlist&gt; list = new ArrayList&lt;&gt;();            List&lt;Integer&gt; playListIds = new ArrayList&lt;&gt;();            for (Object o : perArr) {                JSONObject playListJSON = JSONObject.parseObject(o.toString());                Playlist playlist = new Playlist();                playlist.setId(playListJSON.getIntValue(&quot;id&quot;));                playListIds.add(playlist.getId());                playlist.setName(playListJSON.getString(&quot;name&quot;));                playlist.setPicURL(playListJSON.getString(&quot;picUrl&quot;));                playlist.setPlayCount(playListJSON.getIntValue(&quot;playCount&quot;));                playlist.setBookCount(playListJSON.getIntValue(&quot;bookCount&quot;));                playlist.setTrackCount(playListJSON.getIntValue(&quot;trackCount&quot;));                list.add(playlist);            }            playlistDAO.saveAll(list);            /*存储歌曲*/            List&lt;Integer&gt; songIds = new ArrayList&lt;&gt;();            List&lt;Song&gt; songList = new ArrayList&lt;&gt;();            for (Integer playListId : playListIds) {                String res = restTemplate.getForObject(&quot;http://localhost:3003/apis/v1&quot;+&quot;/playlist/detail?id=&quot;+playListId,String.class);                JSONArray songJSONArr = JSONObject.parseObject(res).getJSONObject(&quot;playlist&quot;).getJSONArray(&quot;tracks&quot;);                for (Object o : songJSONArr) {                    JSONObject songJSON = JSONObject.parseObject(o.toString());                    Song song = new Song();                    song.setId(songJSON.getIntValue(&quot;id&quot;));                    songIds.add(song.getId());                    song.setName(songJSON.getString(&quot;name&quot;));                    song.setAuthor(getSongAuthor(songJSON.getJSONArray(&quot;ar&quot;)));                    song.setTime(songJSON.getLong(&quot;dt&quot;));                    song.setPlaylistId(playListId);                    song.setPicURL(songJSON.getJSONObject(&quot;al&quot;).getString(&quot;picUrl&quot;));                    song.setAlbum(songJSON.getJSONObject(&quot;al&quot;).getString(&quot;name&quot;));                    songList.add(song);                }            }            songDAO.saveAll(songList);            /*存储评论*/            List&lt;Comment&gt; commentList = new ArrayList&lt;&gt;();            for (Integer songId : songIds) {                String res = restTemplate.getForObject(&quot;http://localhost:3003/apis/v1&quot;+&quot;/comment/music?id=&quot;+songId+&quot;&amp;offset=&quot;+300,String.class);                JSONArray commentArr = JSONObject.parseObject(res).getJSONArray(&quot;comments&quot;);                for (Object o : commentArr) {                    JSONObject commentJSON = JSONObject.parseObject(o.toString());                    Comment comment = new Comment();                    comment.setId(commentJSON.getIntValue(&quot;commentId&quot;));                    comment.setSongId(songId);                    comment.setContent(commentJSON.getString(&quot;content&quot;));                    comment.setAuthor(commentJSON.getJSONObject(&quot;user&quot;).getString(&quot;nickname&quot;));                    comment.setPicUrl(commentJSON.getJSONObject(&quot;user&quot;).getString(&quot;avatarUrl&quot;));                    comment.setTime(commentJSON.getLong(&quot;time&quot;));                    comment.setSupport(commentJSON.getIntValue(&quot;likedCount&quot;));                    commentList.add(comment);                }            }            commentDAO.saveAll(commentList);        }        /**         * 获取歌曲作者名         * @param arr arr         * @return String         */        private String getSongAuthor(JSONArray arr){            StringBuilder author = new StringBuilder();            for (Object o : arr) {                JSONObject json = JSONObject.parseObject(o.toString());                author.append(json.getString(&quot;name&quot;));                if (arr.size() &gt; 1){                    author.append(&quot;,&quot;);                }            }            return author.toString();        }    }</code></pre><p>跑了起来之后, elasticsearch 增加的数据如下:<br><img src="http://image.joylau.cn/blog/elasticsearch-test-guide.png" alt="elasticsearch-test-guide"><br><img src="http://image.joylau.cn/blog/elasticsearch-test-data.png" alt="elasticsearch-test-data"></p><p>现在数据有了,接下来就是使用各种方法了</p><h2 id="ElasticSearchTemplate-和-ElasticsearchRepository-的关系"><a href="#ElasticSearchTemplate-和-ElasticsearchRepository-的关系" class="headerlink" title="ElasticSearchTemplate 和 ElasticsearchRepository 的关系"></a>ElasticSearchTemplate 和 ElasticsearchRepository 的关系</h2><p>ElasticSearchTemplate 是 spring date 对 elasticsearch 客户端 Java API 的封装,而 ElasticsearchRepository,是ElasticSearchTemplate更深层次的封装,可以使用注解,很类似以前 mybatis 的使用<br>ElasticSearchTemplate提供的方法更多,ElasticsearchRepository能用的方法其实全部都在而 ElasticSearchTemplate 都有实现<br>我们只要能熟悉调用的 ElasticSearchTemplate 里面的方法操作<br>ElasticsearchRepository都能够会操作</p><h2 id="ElasticSearchTemplate"><a href="#ElasticSearchTemplate" class="headerlink" title="ElasticSearchTemplate"></a>ElasticSearchTemplate</h2><p>一些很底层的方法，我们最常用的就是elasticsearchTemplate.queryForList(searchQuery, class);<br>而这里面最主要的就是构建searchQuery，一下总结几个最常用的searchQuery以备忘<br>searchQuery能构建好,其他的就很简单了</p><h3 id="queryStringQuery"><a href="#queryStringQuery" class="headerlink" title="queryStringQuery"></a>queryStringQuery</h3><p>单字符串全文查询</p><pre><code class="java">    /**     * 单字符串模糊查询，默认排序。将从所有字段中查找包含传来的word分词后字符串的数据集     */    @Test    public void queryStringQuerySong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(queryStringQuery(&quot;Time&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>返回的结果如下</p><pre><code class="text">    {      &quot;query_string&quot; : {        &quot;query&quot; : &quot;Time&quot;,        &quot;fields&quot; : [ ],        &quot;use_dis_max&quot; : true,        &quot;tie_breaker&quot; : 0.0,        &quot;default_operator&quot; : &quot;or&quot;,        &quot;auto_generate_phrase_queries&quot; : false,        &quot;max_determinized_states&quot; : 10000,        &quot;enable_position_increments&quot; : true,        &quot;fuzziness&quot; : &quot;AUTO&quot;,        &quot;fuzzy_prefix_length&quot; : 0,        &quot;fuzzy_max_expansions&quot; : 50,        &quot;phrase_slop&quot; : 0,        &quot;escape&quot; : false,        &quot;split_on_whitespace&quot; : true,        &quot;boost&quot; : 1.0      }    }    {&quot;album&quot;:&quot;Time&quot;,&quot;author&quot;:&quot;Cat naps&quot;,&quot;id&quot;:459733590,&quot;name&quot;:&quot;Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/9DmApLeDwutb4HpuhD_E-Q==/18624627464667106.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:86465}    {&quot;album&quot;:&quot;Go Time&quot;,&quot;author&quot;:&quot;Mark Petrie&quot;,&quot;id&quot;:29717271,&quot;name&quot;:&quot;Go Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/TJe468hZr_0ndQRfTAKdqA==/3233663697760186.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:136071}    {&quot;album&quot;:&quot;Out of Time&quot;,&quot;author&quot;:&quot;R.E.M.&quot;,&quot;id&quot;:20282663,&quot;name&quot;:&quot;Losing My Religion&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/wYtpqN8Yu2jamQwdM6ugGg==/6638851209090428.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:269270}    {&quot;album&quot;:&quot;Time Flies... 1994-2009&quot;,&quot;author&quot;:&quot;Oasis&quot;,&quot;id&quot;:17822660,&quot;name&quot;:&quot;Cigarettes &amp; Alcohol&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/qDgXElJRtSsuqNwsTzW8lw==/667403558069001.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:291853}    {&quot;album&quot;:&quot;Electric Warrior&quot;,&quot;author&quot;:&quot;T. Rex&quot;,&quot;id&quot;:29848501,&quot;name&quot;:&quot;There Was A Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/dn1MwEBfBcL4l6isrnEwDw==/3246857839528733.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:60577}    {&quot;album&quot;:&quot;Ride On Time&quot;,&quot;author&quot;:&quot;山下達郎&quot;,&quot;id&quot;:22693846,&quot;name&quot;:&quot;DAYDREAM&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/GaQVveQiyTIqecs7hhoYpA==/749866930165154.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:273476}    {&quot;album&quot;:&quot;The Blossom Chronicles&quot;,&quot;author&quot;:&quot;Philter&quot;,&quot;id&quot;:21375446,&quot;name&quot;:&quot;Adventure Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/YjMS5_kM3u9PCUU0lcRK8g==/6657542907248762.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:207412}    {&quot;album&quot;:&quot;Decimus&quot;,&quot;author&quot;:&quot;Audio Machine&quot;,&quot;id&quot;:36586631,&quot;name&quot;:&quot;Ashes of Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/7InBepjNDGCzpzH8Feyw9A==/3395291908535260.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:190826}    {&quot;album&quot;:&quot;In Time: The Best Of R.E.M. 1988-2003&quot;,&quot;author&quot;:&quot;R.E.M.&quot;,&quot;id&quot;:20283068,&quot;name&quot;:&quot;Bad Day&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/aZXu5ulRJvH4dnoWPjxb3A==/18277181789089107.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:248111}    {&quot;album&quot;:&quot;It&#39;s a Poppin&#39; Time&quot;,&quot;author&quot;:&quot;山下達郎&quot;,&quot;id&quot;:22693864,&quot;name&quot;:&quot;HEY THERE LONELY GIRL&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/PGZlyXk20_-5d6E3pDEKpg==/815837627833461.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:325956}    {&quot;album&quot;:&quot;Shire Music Annual Selection - Myth&quot;,&quot;author&quot;:&quot;Shire Music,Songs To Your Eyes,&quot;,&quot;id&quot;:34916751,&quot;name&quot;:&quot;Between Space And Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/CCqLd2ly2XuuSPz0IW0u-g==/3284241233077333.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:222456}    {&quot;album&quot;:&quot;Double Live Doggie Style I&quot;,&quot;author&quot;:&quot;X-Ray Dog&quot;,&quot;id&quot;:26246058,&quot;name&quot;:&quot;Time Will Tell&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/oYEIMWnAvpuRDTk4g_l-lg==/2503587976473913.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:202133}    {&quot;album&quot;:&quot;The Ghost Of Tom Joad&quot;,&quot;author&quot;:&quot;Bruce Springsteen&quot;,&quot;id&quot;:16657852,&quot;name&quot;:&quot;Straight Time (Album Version)&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/yK0V-aD3Myh4xorvwUtCrw==/17889054184179160.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:210651}    {&quot;album&quot;:&quot;Epic Action &amp; Adventure Vol. 6&quot;,&quot;author&quot;:&quot;Epic Score&quot;,&quot;id&quot;:4054121,&quot;name&quot;:&quot;Time Will Remember Us&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/uN8AYI3sQEgoECuSYmi9Eg==/658607465082090.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:165000}</code></pre><p>我们修改一下排序方式，按照id从大到小排序</p><pre><code class="java">    /**      * 单字符串模糊查询，单字段排序。      */      @Test    public void queryStringQueryWeightSong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(queryStringQuery(&quot;Time&quot;)).withPageable(of(0,100,new Sort(Sort.Direction.DESC,&quot;id&quot;))).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>也可以使用注解,这么写</p><pre><code class="java">    public void queryStringQueryWeightSong(@PageableDefault(sort = &quot;id&quot;, direction = Sort.Direction.DESC) Pageable pageable){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(queryStringQuery(&quot;Time&quot;)).withPageable(pageable).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>返回的结果</p><pre><code class="text">    {      &quot;query_string&quot; : {        &quot;query&quot; : &quot;Time&quot;,        &quot;fields&quot; : [ ],        &quot;use_dis_max&quot; : true,        &quot;tie_breaker&quot; : 0.0,        &quot;default_operator&quot; : &quot;or&quot;,        &quot;auto_generate_phrase_queries&quot; : false,        &quot;max_determinized_states&quot; : 10000,        &quot;enable_position_increments&quot; : true,        &quot;fuzziness&quot; : &quot;AUTO&quot;,        &quot;fuzzy_prefix_length&quot; : 0,        &quot;fuzzy_max_expansions&quot; : 50,        &quot;phrase_slop&quot; : 0,        &quot;escape&quot; : false,        &quot;split_on_whitespace&quot; : true,        &quot;boost&quot; : 1.0      }    }    {&quot;album&quot;:&quot;Time&quot;,&quot;author&quot;:&quot;Cat naps&quot;,&quot;id&quot;:459733590,&quot;name&quot;:&quot;Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/9DmApLeDwutb4HpuhD_E-Q==/18624627464667106.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:86465}    {&quot;album&quot;:&quot;Decimus&quot;,&quot;author&quot;:&quot;Audio Machine&quot;,&quot;id&quot;:36586631,&quot;name&quot;:&quot;Ashes of Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/7InBepjNDGCzpzH8Feyw9A==/3395291908535260.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:190826}    {&quot;album&quot;:&quot;Shire Music Annual Selection - Myth&quot;,&quot;author&quot;:&quot;Shire Music,Songs To Your Eyes,&quot;,&quot;id&quot;:34916751,&quot;name&quot;:&quot;Between Space And Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/CCqLd2ly2XuuSPz0IW0u-g==/3284241233077333.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:222456}    {&quot;album&quot;:&quot;Electric Warrior&quot;,&quot;author&quot;:&quot;T. Rex&quot;,&quot;id&quot;:29848501,&quot;name&quot;:&quot;There Was A Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/dn1MwEBfBcL4l6isrnEwDw==/3246857839528733.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:60577}    {&quot;album&quot;:&quot;Go Time&quot;,&quot;author&quot;:&quot;Mark Petrie&quot;,&quot;id&quot;:29717271,&quot;name&quot;:&quot;Go Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/TJe468hZr_0ndQRfTAKdqA==/3233663697760186.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:136071}    {&quot;album&quot;:&quot;Double Live Doggie Style I&quot;,&quot;author&quot;:&quot;X-Ray Dog&quot;,&quot;id&quot;:26246058,&quot;name&quot;:&quot;Time Will Tell&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/oYEIMWnAvpuRDTk4g_l-lg==/2503587976473913.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:202133}    {&quot;album&quot;:&quot;It&#39;s a Poppin&#39; Time&quot;,&quot;author&quot;:&quot;山下達郎&quot;,&quot;id&quot;:22693864,&quot;name&quot;:&quot;HEY THERE LONELY GIRL&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/PGZlyXk20_-5d6E3pDEKpg==/815837627833461.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:325956}    {&quot;album&quot;:&quot;Ride On Time&quot;,&quot;author&quot;:&quot;山下達郎&quot;,&quot;id&quot;:22693846,&quot;name&quot;:&quot;DAYDREAM&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/GaQVveQiyTIqecs7hhoYpA==/749866930165154.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:273476}    {&quot;album&quot;:&quot;The Blossom Chronicles&quot;,&quot;author&quot;:&quot;Philter&quot;,&quot;id&quot;:21375446,&quot;name&quot;:&quot;Adventure Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/YjMS5_kM3u9PCUU0lcRK8g==/6657542907248762.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:207412}    {&quot;album&quot;:&quot;In Time: The Best Of R.E.M. 1988-2003&quot;,&quot;author&quot;:&quot;R.E.M.&quot;,&quot;id&quot;:20283068,&quot;name&quot;:&quot;Bad Day&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/aZXu5ulRJvH4dnoWPjxb3A==/18277181789089107.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:248111}    {&quot;album&quot;:&quot;Out of Time&quot;,&quot;author&quot;:&quot;R.E.M.&quot;,&quot;id&quot;:20282663,&quot;name&quot;:&quot;Losing My Religion&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/wYtpqN8Yu2jamQwdM6ugGg==/6638851209090428.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:269270}    {&quot;album&quot;:&quot;Time Flies... 1994-2009&quot;,&quot;author&quot;:&quot;Oasis&quot;,&quot;id&quot;:17822660,&quot;name&quot;:&quot;Cigarettes &amp; Alcohol&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/qDgXElJRtSsuqNwsTzW8lw==/667403558069001.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:291853}    {&quot;album&quot;:&quot;The Ghost Of Tom Joad&quot;,&quot;author&quot;:&quot;Bruce Springsteen&quot;,&quot;id&quot;:16657852,&quot;name&quot;:&quot;Straight Time (Album Version)&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/yK0V-aD3Myh4xorvwUtCrw==/17889054184179160.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:210651}    {&quot;album&quot;:&quot;Epic Action &amp; Adventure Vol. 6&quot;,&quot;author&quot;:&quot;Epic Score&quot;,&quot;id&quot;:4054121,&quot;name&quot;:&quot;Time Will Remember Us&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/uN8AYI3sQEgoECuSYmi9Eg==/658607465082090.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:165000}</code></pre><h3 id="matchQuery"><a href="#matchQuery" class="headerlink" title="matchQuery"></a>matchQuery</h3><p>查询某个字段中模糊包含目标字符串，使用matchQuery</p><pre><code class="java">    /**      * 单字段对某字符串模糊查询      */      @Test    public void matchQuerySong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(matchQuery(&quot;name&quot;,&quot;Time&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>返回结果</p><pre><code class="text">    {      &quot;match&quot; : {        &quot;name&quot; : {          &quot;query&quot; : &quot;Time&quot;,          &quot;operator&quot; : &quot;OR&quot;,          &quot;prefix_length&quot; : 0,          &quot;max_expansions&quot; : 50,          &quot;fuzzy_transpositions&quot; : true,          &quot;lenient&quot; : false,          &quot;zero_terms_query&quot; : &quot;NONE&quot;,          &quot;boost&quot; : 1.0        }      }    }    {&quot;album&quot;:&quot;Time&quot;,&quot;author&quot;:&quot;Cat naps&quot;,&quot;id&quot;:459733590,&quot;name&quot;:&quot;Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/9DmApLeDwutb4HpuhD_E-Q==/18624627464667106.jpg&quot;,&quot;playlistId&quot;:900228548,&quot;time&quot;:86465}    {&quot;album&quot;:&quot;Go Time&quot;,&quot;author&quot;:&quot;Mark Petrie&quot;,&quot;id&quot;:29717271,&quot;name&quot;:&quot;Go Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/TJe468hZr_0ndQRfTAKdqA==/3233663697760186.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:136071}    {&quot;album&quot;:&quot;The Blossom Chronicles&quot;,&quot;author&quot;:&quot;Philter&quot;,&quot;id&quot;:21375446,&quot;name&quot;:&quot;Adventure Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/YjMS5_kM3u9PCUU0lcRK8g==/6657542907248762.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:207412}    {&quot;album&quot;:&quot;Shire Music Annual Selection - Myth&quot;,&quot;author&quot;:&quot;Shire Music,Songs To Your Eyes,&quot;,&quot;id&quot;:34916751,&quot;name&quot;:&quot;Between Space And Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/CCqLd2ly2XuuSPz0IW0u-g==/3284241233077333.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:222456}    {&quot;album&quot;:&quot;Electric Warrior&quot;,&quot;author&quot;:&quot;T. Rex&quot;,&quot;id&quot;:29848501,&quot;name&quot;:&quot;There Was A Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/dn1MwEBfBcL4l6isrnEwDw==/3246857839528733.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:60577}    {&quot;album&quot;:&quot;Double Live Doggie Style I&quot;,&quot;author&quot;:&quot;X-Ray Dog&quot;,&quot;id&quot;:26246058,&quot;name&quot;:&quot;Time Will Tell&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/oYEIMWnAvpuRDTk4g_l-lg==/2503587976473913.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:202133}    {&quot;album&quot;:&quot;Decimus&quot;,&quot;author&quot;:&quot;Audio Machine&quot;,&quot;id&quot;:36586631,&quot;name&quot;:&quot;Ashes of Time&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/7InBepjNDGCzpzH8Feyw9A==/3395291908535260.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:190826}    {&quot;album&quot;:&quot;The Ghost Of Tom Joad&quot;,&quot;author&quot;:&quot;Bruce Springsteen&quot;,&quot;id&quot;:16657852,&quot;name&quot;:&quot;Straight Time (Album Version)&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/yK0V-aD3Myh4xorvwUtCrw==/17889054184179160.jpg&quot;,&quot;playlistId&quot;:772430182,&quot;time&quot;:210651}    {&quot;album&quot;:&quot;Epic Action &amp; Adventure Vol. 6&quot;,&quot;author&quot;:&quot;Epic Score&quot;,&quot;id&quot;:4054121,&quot;name&quot;:&quot;Time Will Remember Us&quot;,&quot;picURL&quot;:&quot;http://p1.music.126.net/uN8AYI3sQEgoECuSYmi9Eg==/658607465082090.jpg&quot;,&quot;playlistId&quot;:636015704,&quot;time&quot;:165000}</code></pre><h3 id="matchPhraseQuery"><a href="#matchPhraseQuery" class="headerlink" title="matchPhraseQuery"></a>matchPhraseQuery</h3><p>PhraseMatch查询，短语匹配</p><pre><code class="java">    /**      * 单字段对某短语进行匹配查询，短语分词的顺序会影响结果      */      @Test    public void phraseMatchSong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(matchPhraseQuery(&quot;name&quot;,&quot;Time&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><h3 id="termQuery"><a href="#termQuery" class="headerlink" title="termQuery"></a>termQuery</h3><p>这个是最严格的匹配，属于低级查询，不进行分词的，参考这篇文章 <a href="http://www.cnblogs.com/muniaofeiyu/p/5616316.html" target="_blank" rel="noopener">http://www.cnblogs.com/muniaofeiyu/p/5616316.html</a></p><pre><code class="java">    /**      * term匹配，即不分词匹配，你传来什么值就会拿你传的值去做完全匹配      */      @Test    public void termQuerySong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(termQuery(&quot;name&quot;,&quot;Time&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><h3 id="multiMatchQuery"><a href="#multiMatchQuery" class="headerlink" title="multiMatchQuery"></a>multiMatchQuery</h3><p>多个字段匹配某字符串,如果我们希望name，author两个字段去匹配某个字符串，只要任何一个字段包括该字符串即可，就可以使用multiMatchQuery。</p><pre><code class="java">    /**      * 多字段匹配      */      @Test    public void multiMatchQuerySong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(multiMatchQuery(&quot;time&quot;,&quot;name&quot;,&quot;author&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><h3 id="完全包含查询"><a href="#完全包含查询" class="headerlink" title="完全包含查询"></a>完全包含查询</h3><p>之前的查询中，当我们输入“我天”时，ES会把分词后所有包含“我”和“天”的都查询出来，如果我们希望必须是包含了两个字的才能被查询出来，那么我们就需要设置一下Operator。</p><pre><code class="java">    /**      * 单字段包含所有输入      */      @Test    public void matchQueryOperatorSong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(matchQuery(&quot;name&quot;,&quot;真的&quot;).operator(Operator.AND)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>无论是matchQuery，multiMatchQuery，queryStringQuery等，都可以设置operator。默认为Or，设置为And后，就会把符合包含所有输入的才查出来。<br>如果是and的话，譬如用户输入了5个词，但包含了4个，也是显示不出来的。我们可以通过设置精度来控制。</p><pre><code class="java">    /**      * 单字段包含所有输入(按比例包含)      */      @Test    public void matchQueryOperatorWithMinimumShouldMatchSong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(matchQuery(&quot;name&quot;,&quot;time&quot;).operator(Operator.AND).minimumShouldMatch(&quot;80%&quot;)).withPageable(of(0,100)).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>minimumShouldMatch可以用在match查询中，设置最少匹配了多少百分比的能查询出来。</p><h3 id="合并查询"><a href="#合并查询" class="headerlink" title="合并查询"></a>合并查询</h3><p>即boolQuery，可以设置多个条件的查询方式。它的作用是用来组合多个Query，有四种方式来组合，must，mustnot，filter，should。<br>must代表返回的文档必须满足must子句的条件，会参与计算分值；<br>filter代表返回的文档必须满足filter子句的条件，但不会参与计算分值；<br>should代表返回的文档可能满足should子句的条件，也可能不满足，有多个should时满足任何一个就可以，通过minimum_should_match设置至少满足几个。<br>mustnot代表必须不满足子句的条件。<br>譬如我想查询name包含“XXX”，且userId=“2345098”，且time最好小于165000的结果。那么就可以使用boolQuery来组合。</p><pre><code class="java">    /**      * 多字段合并查询      */      @Test    public void boolQuerySong(){        SearchQuery searchQuery = new NativeSearchQueryBuilder().withQuery(boolQuery().must(termQuery(&quot;userId&quot;, &quot;2345098&quot;))                .should(rangeQuery(&quot;time&quot;).lt(165000)).must(matchQuery(&quot;name&quot;, &quot;time&quot;))).build();        System.out.println(searchQuery.getQuery().toString());        List&lt;Song&gt; songList = songDAO.search(searchQuery).getContent();        for (Song song : songList) {            System.out.println(JSONObject.toJSONString(song));        }    }</code></pre><p>详细点的看这篇 <a href="http://blog.csdn.net/dm_vincent/article/details/41743955" target="_blank" rel="noopener">http://blog.csdn.net/dm_vincent/article/details/41743955</a><br>boolQuery使用场景非常广泛，应该是主要学习的知识之一。</p><h3 id="Query和Filter的区别"><a href="#Query和Filter的区别" class="headerlink" title="Query和Filter的区别"></a>Query和Filter的区别</h3><p>query和Filter都是QueryBuilder，也就是说在使用时，你把Filter的条件放到withQuery里也行，反过来也行。那么它们两个区别在哪？<br>查询在Query查询上下文和Filter过滤器上下文中，执行的操作是不一样的：</p><p>1、查询：是在使用query进行查询时的执行环境，比如使用search的时候。<br>在查询上下文中，查询会回答这个问题——“这个文档是否匹配这个查询，它的相关度高么？”<br>ES中索引的数据都会存储一个_score分值，分值越高就代表越匹配。即使lucene使用倒排索引，对于某个搜索的分值计算还是需要一定的时间消耗。</p><p>2、过滤器：在使用filter参数时候的执行环境，比如在bool查询中使用Must_not或者filter<br>在过滤器上下文中，查询会回答这个问题——“这个文档是否匹配？”<br>它不会去计算任何分值，也不会关心返回的排序问题，因此效率会高一点。<br>另外，经常使用过滤器，ES会自动的缓存过滤器的内容，这对于查询来说，会提高很多性能。</p><h2 id="ElasticsearchRepository"><a href="#ElasticsearchRepository" class="headerlink" title="ElasticsearchRepository"></a>ElasticsearchRepository</h2><p>ElasticsearchRepository接口的方法有</p><pre><code class="java">    @NoRepositoryBean    public interface ElasticsearchRepository&lt;T, ID extends Serializable&gt; extends ElasticsearchCrudRepository&lt;T, ID&gt; {        &lt;S extends T&gt; S index(S var1);        Iterable&lt;T&gt; search(QueryBuilder var1);        FacetedPage&lt;T&gt; search(QueryBuilder var1, Pageable var2);        FacetedPage&lt;T&gt; search(SearchQuery var1);        Page&lt;T&gt; searchSimilar(T var1, String[] var2, Pageable var3);    }</code></pre><p>执行复杂查询最常用的就是 FacetedPage<T> search(SearchQuery var1); 这个方法了，需要的参数是 SearchQuery<br>主要是看QueryBuilder和SearchQuery两个参数，要完成一些特殊查询就主要看构建这两个参数。<br>我们先来看看它们之间的类关系<br><img src="http://img.blog.csdn.net/20170726163702583?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdGlhbnlhbGVpeGlhb3d1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="image"></p><p>实际使用中，我们的主要任务就是构建NativeSearchQuery来完成一些复杂的查询的。</p><pre><code class="java">    public NativeSearchQuery(QueryBuilder query, QueryBuilder filter, List&lt;SortBuilder&gt; sorts, Field[] highlightFields) {              this.query = query;              this.filter = filter;              this.sorts = sorts;              this.highlightFields = highlightFields;          }  </code></pre><p>我们可以看到要构建NativeSearchQuery，主要是需要几个构造参数</p><p>当然了，我们没必要实现所有的参数。<br>可以看出来，大概是需要QueryBuilder，filter，和排序的SortBuilder，和高亮的字段。<br>一般情况下，我们不是直接是new NativeSearchQuery，而是使用NativeSearchQueryBuilder。<br>通过NativeSearchQueryBuilder.withQuery(QueryBuilder1).withFilter(QueryBuilder2).withSort(SortBuilder1).withXXXX().build();这样的方式来完成NativeSearchQuery的构建。<br>从名字就能看出来，QueryBuilder主要用来构建查询条件、过滤条件，SortBuilder主要是构建排序。</p><p>很幸运的 ElasticsearchRepository 里的 SearchQuery 也就是上述描述的 temple 的 SearchQuery，2 者可以共用</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FastJSON 还有这样的用法 涨姿势了</title>
      <link href="/2017/11/15/FastJson-JSONPath/"/>
      <url>/2017/11/15/FastJson-JSONPath/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>JSONPath。这是一个很强大的功能，可以在java框架中当作对象查询语言（OQL）来使用</p><h3 id="语法说明"><a href="#语法说明" class="headerlink" title="语法说明"></a>语法说明</h3><table><thead><tr><th align="left">JSONPATH</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">$</td><td align="left">根对象，例如$.name</td></tr><tr><td align="left">[num]</td><td align="left">数组访问，其中num是数字，可以是负数。例如$[0].leader.departments[-1].name</td></tr><tr><td align="left">[num0,num1,num2…]</td><td align="left">数组多个元素访问，其中num是数字，可以是负数，返回数组中的多个元素。例如$[0,3,-2,5]</td></tr><tr><td align="left">[start:end]</td><td align="left">数组范围访问，其中start和end是开始小表和结束下标，可以是负数，返回数组中的多个元素。例如$[0:5]</td></tr><tr><td align="left">[start:end :step]</td><td align="left">数组范围访问，其中start和end是开始小表和结束下标，可以是负数；step是步长，返回数组中的多个元素。例如$[0:5:2]</td></tr><tr><td align="left">[?(key)]</td><td align="left">对象属性非空过滤，例如$.departs[?(name)]</td></tr><tr><td align="left">[key &gt; 123]</td><td align="left">数值类型对象属性比较过滤，例如$.departs[id &gt;= 123]，比较操作符支持=,!=,&gt;,&gt;=,&lt;,&lt;=</td></tr><tr><td align="left">[key = ‘123’]</td><td align="left">字符串类型对象属性比较过滤，例如$.departs[name = ‘123’]，比较操作符支持=,!=,&gt;,&gt;=,&lt;,&lt;=</td></tr><tr><td align="left">[key like ‘aa%’]</td><td align="left">字符串类型like过滤，例如$.departs[name like ‘sz*’]，通配符只支持% 支持not like</td></tr><tr><td align="left">[key rlike ‘regexpr’]</td><td align="left">字符串类型正则匹配过滤，例如departs[name like ‘aa(.)*’]，正则语法为jdk的正则语法，支持not rlike</td></tr><tr><td align="left">[key in (‘v0’, ‘v1’)]</td><td align="left">IN过滤, 支持字符串和数值类型 例如: $.departs[name in (‘wenshao’,’Yako’)] $.departs[id not in (101,102)]</td></tr><tr><td align="left">[key between 234 and 456]</td><td align="left">BETWEEN过滤, 支持数值类型，支持not between 例如: $.departs[id between 101 and 201]$.departs[id not between 101 and 201]length() 或者 size()    数组长度。例如$.values.size() 支持类型java.util.Map和java.util.Collection和数组</td></tr><tr><td align="left">.</td><td align="left">属性访问，例如$.name</td></tr><tr><td align="left">..</td><td align="left">deepScan属性访问，例如$..name</td></tr><tr><td align="left">*</td><td align="left">对象的所有属性，例如$.leader.*</td></tr><tr><td align="left">[‘key’]</td><td align="left">属性访问。例如$[‘name’]</td></tr><tr><td align="left">[‘key0’,’key1’]</td><td align="left">多个属性访问。例如$[‘id’,’name’]</td></tr></tbody></table><h3 id="语法示例"><a href="#语法示例" class="headerlink" title="语法示例"></a>语法示例</h3><table><thead><tr><th align="left">JSONPath</th><th align="left">语义</th></tr></thead><tbody><tr><td align="left">$</td><td align="left">根对象</td></tr><tr><td align="left">$[-1]</td><td align="left">最后元素</td></tr><tr><td align="left">$[:-2]</td><td align="left">第1个至倒数第2个</td></tr><tr><td align="left">$[1:]</td><td align="left">第2个之后所有元素</td></tr><tr><td align="left">$[1,2,3]</td><td align="left">集合中1,2,3个元素</td></tr></tbody></table><h3 id="java-示例"><a href="#java-示例" class="headerlink" title="java 示例"></a>java 示例</h3><pre><code class="json">    { &quot;store&quot;: {        &quot;book&quot;: [           { &quot;category&quot;: &quot;reference&quot;,            &quot;author&quot;: &quot;Nigel Rees&quot;,            &quot;title&quot;: &quot;Sayings of the Century&quot;,            &quot;price&quot;: 8.95          },          { &quot;category&quot;: &quot;fiction&quot;,            &quot;author&quot;: &quot;Evelyn Waugh&quot;,            &quot;title&quot;: &quot;Sword of Honour&quot;,            &quot;price&quot;: 12.99,            &quot;isbn&quot;: &quot;0-553-21311-3&quot;          }        ],        &quot;bicycle&quot;: {          &quot;color&quot;: &quot;red&quot;,          &quot;price&quot;: 19.95        }      }    }</code></pre><pre><code class="java">    private static void jsonPathTest() {        JSONObject json = jsonTest();//调用自定义的jsonTest()方法获得json对象，生成上面的json        //输出book[0]的author值        String author = JsonPath.read(json, &quot;$.store.book[0].author&quot;);        //输出全部author的值，使用Iterator迭代        List&lt;String&gt; authors = JsonPath.read(json, &quot;$.store.book[*].author&quot;);        //输出book[*]中category == &#39;reference&#39;的book        List&lt;Object&gt; books = JsonPath.read(json, &quot;$.store.book[?(@.category == &#39;reference&#39;)]&quot;);                       //输出book[*]中price&gt;10的book        List&lt;Object&gt; books = JsonPath.read(json, &quot;$.store.book[?(@.price&gt;10)]&quot;);        //输出book[*]中含有isbn元素的book        List&lt;Object&gt; books = JsonPath.read(json, &quot;$.store.book[?(@.isbn)]&quot;);        //输出该json中所有price的值        List&lt;Double&gt; prices = JsonPath.read(json, &quot;$..price&quot;);        //可以提前编辑一个路径，并多次使用它        JsonPath path = JsonPath.compile(&quot;$.store.book[*]&quot;);         List&lt;Object&gt; books = path.read(json);     }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具类篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JSON </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>npm install 居然出错了</title>
      <link href="/2017/11/07/Node-Install-Error/"/>
      <url>/2017/11/07/Node-Install-Error/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>今天在安装完nodejs后执行 npm install 居然出错了</p><p>npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.</p><p>npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.so.10 with link time reference”, “rc”: 127, “stderr”: “npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.so.10 with link time reference\n”, “stderr_lines”: [“npm: relocation error: npm: symbol SSL_set_cert_cb, version libssl.so.10 not defined in file libssl.so.10 with link time reference</p><p>解决办法：</p><p>  yum -y install openssl</p><p>  如果已经安装，就更新一下</p><p>  yum -y update openssl</p>]]></content>
      
      
      <categories>
          
          <category> Node篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot 整合 Kafka 踩坑记录</title>
      <link href="/2017/11/02/SpringBoot-Kafka/"/>
      <url>/2017/11/02/SpringBoot-Kafka/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="第一个坑"><a href="#第一个坑" class="headerlink" title="第一个坑"></a>第一个坑</h3><p>SpringBoot 在1.5版本后就有了 starter， 但是在依赖列表中却没有找到相应的依赖，原因是名字不叫starter，傻傻的我还用JavaConfig 配置了一遍<br>现在看下整合 starter 之后的是怎么样的吧！</p><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;        &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;    &lt;/dependency&gt;</code></pre><p>上面这个依赖其实就是starter， 不需要些版本，SpringBoot会自己选择版本</p><p>yml配置文件</p><pre><code class="xml">    spring      kafka:        bootstrap-servers: 192.168.10.192:9092        consumer:          group-id: secondary-identification        producer:          batch-size: 65536          buffer-memory: 524288</code></pre><p>默认只需要 bootstrap-servers 和 group-id 即可</p><p>接下来 生产者 和 消费者</p><pre><code class="java">    @Component    public class MsgProducer {        @Autowired        private KafkaTemplate kafkaTemplate;        public void sendMessage() {            kafkaTemplate.send(&quot;index-vehicle&quot;,&quot;key&quot;,&quot;hello,kafka&quot;  + LocalDateTime.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss.SSS&quot;)));        }    }</code></pre><pre><code class="java">    @Component    public class MsgConsumer {        @KafkaListener(topics = {&quot;index-vehicle&quot;})        public void processMessage(String content) {            System.out.println(content);        }    }</code></pre><h3 id="第二个坑"><a href="#第二个坑" class="headerlink" title="第二个坑"></a>第二个坑</h3><p>可以发消息，但是SpringBoot始终收不到，我用Kafka自带的工具却可以收到，很气愤，搞了好长时间都没有解决<br>后来遍访Google和官方文档，终于找到原因了，只要修改下配置文件的一个配置即可：</p><pre><code class="properties">    # The address the socket server listens on. It will get the value returned from     # java.net.InetAddress.getCanonicalHostName() if not configured.    #   FORMAT:    #     listeners = listener_name://host_name:port    #   EXAMPLE:    #     listeners = PLAINTEXT://your.host.name:9092    listeners=PLAINTEXT://0.0.0.0:9092</code></pre><p>上面的额这个 listeners，因为我的程序是加了@KafkaListener 来监听消息的，需要开启一个这样的配置项</p><p>这项配置项的含义在此也备注下：</p><blockquote><blockquote><p>监听列表(以逗号分隔 不同的协议(如plaintext,trace,ssl、不同的IP和端口)),hostname如果设置为0.0.0.0则绑定所有的网卡地址；如果hostname为空则绑定默认的网卡。如果没有配置则默认为java.net.InetAddress.getCanonicalHostName()</p></blockquote></blockquote><p>这2个坑在此记录下</p><h2 id="一些常用命令在此记录下"><a href="#一些常用命令在此记录下" class="headerlink" title="一些常用命令在此记录下"></a>一些常用命令在此记录下</h2><p>zookeeper-server-start.bat ../../config/zookeeper.properties   : 开启自带的zookeeper<br>kafka-server-start.bat ../../config.properties   ： 开启kafka<br>kafka-console-consumer.bat –bootstrap-server localhost:9092 –topic myTopic  –from-beginning : 控制台接受指定topic消息<br>kafka-console-producer.bat –broker-list localhost:9092 –topic myTopic  :   指定topic发送消息</p><p>注意的是用命令行创建的producer绑定的主题topic需要用命令行先创建topic，已经创建的就直接发送就好了</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IDEA 中 SpringBoot 项目热部署</title>
      <link href="/2017/11/01/SpringBoot-IDEA-DevTools/"/>
      <url>/2017/11/01/SpringBoot-IDEA-DevTools/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>本文转自：<a href="http://blog.csdn.net/jsshaojinjie/article/details/64125458" target="_blank" rel="noopener">http://blog.csdn.net/jsshaojinjie/article/details/64125458</a></p><p>maven dependencies增加</p><pre><code class="xml">    &lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;          &lt;optional&gt;true&lt;/optional&gt;      &lt;/dependency&gt; </code></pre><p>project增加</p><pre><code class="xml">    &lt;build&gt;          &lt;plugins&gt;              &lt;plugin&gt;                  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                  &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                  &lt;configuration&gt;                  &lt;!--fork :  如果没有该项配置，devtools不会起作用，即应用不会restart --&gt;                  &lt;fork&gt;true&lt;/fork&gt;                  &lt;/configuration&gt;              &lt;/plugin&gt;          &lt;/plugins&gt;      &lt;/build&gt;  </code></pre><p>idea设置</p><p><img src="http://img.blog.csdn.net/20170320144352296?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanNzaGFvamluamll/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image"></p><p>ctrl+shift+alt+/</p><p><img src="http://img.blog.csdn.net/20170320144426734?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanNzaGFvamluamll/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image"><br><img src="http://img.blog.csdn.net/20170320144446687?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanNzaGFvamluamll/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="image"></p><p>重启项目即可。</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot 读取 JSON 文件并转化为 JSON 对象</title>
      <link href="/2017/10/30/SpringBoot-ReadJSONFile/"/>
      <url>/2017/10/30/SpringBoot-ReadJSONFile/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="通过注解读取文件"><a href="#通过注解读取文件" class="headerlink" title="通过注解读取文件"></a>通过注解读取文件</h3><pre><code class="java">    @Value(&quot;classpath:static/json/addTask.json&quot;)    Resource addTaskJson;</code></pre><h3 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h3><table><thead><tr><th align="left">前缀</th><th align="left">例子</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">classpath:</td><td align="left">classpath:com/myapp/config.xml</td><td align="left">从classpath中加载</td></tr><tr><td align="left">file:</td><td align="left">file:/data/config.xml</td><td align="left">作为 URL 从文件系统中加载</td></tr><tr><td align="left">http:</td><td align="left"><a href="http://myserver/logo.png" target="_blank" rel="noopener">http://myserver/logo.png</a></td><td align="left">作为 URL 加载</td></tr><tr><td align="left">(none)</td><td align="left">/data/config.xml</td><td align="left">根据 ApplicationContext 进行判断</td></tr></tbody></table><p>摘自于Spring Framework参考手册</p><h3 id="转化为-字符串-转化为-JSON-对象"><a href="#转化为-字符串-转化为-JSON-对象" class="headerlink" title="转化为 字符串 转化为 JSON 对象"></a>转化为 字符串 转化为 JSON 对象</h3><pre><code class="java">    String jsonStr = new String(IOUtils.readFully(addTaskJson.getInputStream(), -1,true));    JSONObject json = JSONObject.parseObject(jsonStr);</code></pre><p>注意： 该方法需要 jdk1.8的环境</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> JSON </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot 连接 Oracle 及 Navicat for Oracle 绿色版下载</title>
      <link href="/2017/10/26/SpringBoot-Oracle/"/>
      <url>/2017/10/26/SpringBoot-Oracle/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="SpringBoot-连接-Oracle"><a href="#SpringBoot-连接-Oracle" class="headerlink" title="SpringBoot 连接 Oracle"></a>SpringBoot 连接 Oracle</h2><h3 id="pom-文件配置"><a href="#pom-文件配置" class="headerlink" title="pom 文件配置"></a>pom 文件配置</h3><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.oracle&lt;/groupId&gt;        &lt;artifactId&gt;ojdbc6&lt;/artifactId&gt;        &lt;version&gt;12.1.0.2&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p>注意： com.oracle.ojdbc6.12.1.0.2 在中央仓库没有，需要单独下载下来，再安装到本地仓库</p><h3 id="yml文件配置"><a href="#yml文件配置" class="headerlink" title="yml文件配置"></a>yml文件配置</h3><pre><code class="yml">    spring:      datasource:        driver-class-name: oracle.jdbc.OracleDriver        url: jdbc:oracle:thin:@192.168.10.240:1522:orcl12c        username: C##itmscz        password: itmscz      jpa:        hibernate:          ddl-auto: update        show-sql: true</code></pre><p>接下来的套路都一样了，写好model实体类，注册个接口，然后就可以直接增删改查了</p><p>model ：</p><pre><code class="java">    @Entity(name = &quot;t_samp_recog&quot;)    @Data    public class SampRecog {        @Id        @GeneratedValue        private int id; //主键        private String batch; // 批次        private String img_url; // 图片路径        private String plate_nbr; // 车辆号牌        private boolean plate_nbr_right; // 车辆号牌是否正确        private String brand; // 品牌        private boolean brand_right; // 品牌是否正确        private String veh_type; // 车辆类型        private boolean veh_type_right; // 车辆类型是否正确        private String veh_color; // 车身颜色        private boolean veh_color_right; // 车身颜色是否正确        private String sticker_pos; // 车标位置        private boolean sticker_pos_right; // 车标位置是否全部正确        private boolean is_right; // 是否全部正确        private int check_status; //核对状态 1.未核对，2，正在核对，3、已经核对    }</code></pre><p>dao :</p><pre><code class="java">    public interface SampRecogDAO extends JpaRepository&lt;SampRecog,Integer&gt; {    }</code></pre><p>看来 SpringBoot 整合数据源的套路都一样，下次整合其他的猜都知道怎么做了</p><h2 id="Navicat-for-Oracle"><a href="#Navicat-for-Oracle" class="headerlink" title="Navicat for Oracle"></a>Navicat for Oracle</h2><p>以前一直用的 Navicat Premiun,里面虽然支持 Oracle ，但是支持 Oracle 版本都比较老啦，新一点的根本连接不上去，今天在网上找到个绿色版的 Navicat for Oracle，赶紧记下来，mark一下</p><h3 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h3><p>百度云盘：链接: <a href="https://pan.baidu.com/s/1mhPS9wW" target="_blank" rel="noopener">https://pan.baidu.com/s/1mhPS9wW</a> 密码: gtq4</p><p>7z的是我替换操作后的</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>下载 3个文件 ：<br>Navicat for Oracle.zip</p><p>instantclient-basic-nt-12.1.0.2.0.zip</p><p>instantclient-sqlplus-nt-12.1.0.2.0.zip </p><p>直接把 instantclient-basic-nt-12.1.0.2.0.zip 解压到 Navicat for Oracle 的解压目录的instantclient_10_2目录下</p><p>然后这个目录下多了instantclient_12_1 这个目录 </p><p>然后再把instantclient-sqlplus-nt-12.1.0.2.0.zip 解压到 instantclient_12_1下</p><p>完成</p><p>最后打开Navicat for Oracle 单击   工具-&gt;选项-&gt; OCI </p><p>2个路径分别选：</p><p>\instantclient_12_1.oci.dll</p><p>\instantclient_12_1.sqlplus.exe</p><p>然后就可以连接使用了</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 配置说明 &amp;&amp; 遇坑记录</title>
      <link href="/2017/10/25/Elasticsearch-Config/"/>
      <url>/2017/10/25/Elasticsearch-Config/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h2><pre><code>配置Elasticsearch的集群名称，默认是elasticsearch，Elasticsearch会自动发现在同一网段下的Elasticsearch 节点，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。cluster.name: elasticsearch节点名，默认随机指定一个name列表中名字，不能重复。node.name: &quot;node1&quot;指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。node.master: true指定该节点是否存储索引数据，默认为true。node.data: true设置默认索引分片个数，默认为5片。index.number_of_shards: 5设置默认索引副本个数，默认为1个副本。index.number_of_replicas: 1设置配置文件的存储路径，默认是es根目录下的config文件夹。path.conf: /path/to/conf设置索引数据的存储路径，默认是es根目录下的data文件夹path.data: /path/to/data可以设置多个存储路径，用逗号（半角）隔开，如下面这种配置方式：path.data: /path/to/data1,/path/to/data2设置临时文件的存储路径，默认是es根目录下的work文件夹。path.work: /path/to/work设置日志文件的存储路径，默认是es根目录下的logs文件夹path.logs: /path/to/logs设置插件的存放路径，默认是es根目录下的plugins文件夹path.plugins: /path/to/plugins设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。bootstrap.mlockall: true设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。network.bind_host: 192.168.0.1设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。network.publish_host: 192.168.0.1这个参数是用来同时设置bind_host和publish_host上面两个参数。network.host: 192.168.0.1设置节点间交互的tcp端口，默认是9300，（集群的时候，注意端口区分）。transport.tcp.port: 9300设置是否压缩tcp传输时的数据，默认为false，不压缩。transport.tcp.compress: true设置对外服务的http端口，默认为9200（集群的时候，同台机器，注意端口区分）。http.port: 9200设置内容的最大容量，默认100mbhttp.max_content_length: 100mb是否使用http协议对外提供服务，默认为true，开启。http.enabled: falsegateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器。gateway.type: local设置集群中N个节点启动时进行数据恢复，默认为1。gateway.recover_after_nodes: 1设置初始化数据恢复进程的超时时间，默认是5分钟。gateway.recover_after_time: 5m设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。gateway.expected_nodes: 2初始化数据恢复时，并发恢复线程的个数，默认为4。cluster.routing.allocation.node_initial_primaries_recoveries: 4添加删除节点或负载均衡时并发恢复线程的个数，默认为4。cluster.routing.allocation.node_concurrent_recoveries: 2设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。indices.recovery.max_size_per_sec: 0设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。indices.recovery.concurrent_streams: 5设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）discovery.zen.minimum_master_nodes: 1设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。discovery.zen.ping.timeout: 3s设置是否打开多播发现节点，默认是true。discovery.zen.ping.multicast.enabled: false设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;, &quot;host3[portX-portY]&quot;]</code></pre><p>低配置云服务器上安装遇到的坑：</p><ol><li><p>启动elasticsearch直接退出，并返回killed，这里一般是由于内存不足导致的<br>修改es_home/config/jvm.options<br>-Xms2g<br>-Xmx2g</p></li><li><p>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]解决办法是手动修改/etc/sysctl.conf文件，最后面加上一行代码。<br>vm.max_map_count=655360<br>修改/etc/sysctl.conf，修改完成之后，参数可以使用sysctl -p命令来让参数生效</p></li><li><p>initial heap size [536870912] not equal to maximum heap size [1073741824]; this can cause resize pauses and prevents mlockall from locking the entire heap<br> vi config/jvm.options<br> -Xms 和 -Xmx需要配置的相等，不然无法启动成功</p></li></ol><p>【更新一下内容 2018年4月28日】</p><ol start="4"><li><p>elasticsearch 5 版本以上不能以  root 用户启动，需要新建一个用户<br> useradd elasticsearch<br> passwd elasticsearch<br> chown elasticsearch path -R</p></li><li><p>elasticsearch 在 linux 下以后台启动的命令<br> sh elasticsearch -d<br> 确认日志没有报错，然后head插件可以连接的上就可以了</p></li></ol><h3 id="2018-06-21-更新"><a href="#2018-06-21-更新" class="headerlink" title="2018-06-21 更新"></a>2018-06-21 更新</h3><ol><li><p>ElasticSearch 允许跨域<br> http.cors.enabled: true #开启跨域访问支持，默认为false<br> http.cors.allow-origin: /.*/ #跨域访问允许的域名地址，(允许所有域名)以上使用正则</p></li><li><p>rpm 安装的 elasticsearch 可以自动以系统服务启动和以root用户启动</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 的第一天</title>
      <link href="/2017/10/25/Hadoop-FristDay/"/>
      <url>/2017/10/25/Hadoop-FristDay/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>第一天学习 Hadoop 看了不少资料和文档，在这里想总结一下这一天的所学</p><h2 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h2><p>以前一直以为 JavaWeb 和大数据这是2条路子，学了大数据之后就要放下 JavaWeb，就像在项目中使用 Struts2 和 SpringMVC，2者只能选一个使用，在看了一些资料之后，我发现我的认识错了，其实 JavaWeb 和大数据技术就像 SpringMVC 和Spring Boot<br>2者是并行不悖的。大数据技术囊括很多技术，JavaWeb只是其中的一部分，要学习大数据需要学习的技术还有很多。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="Hadoop是干什么的"><a href="#Hadoop是干什么的" class="headerlink" title="Hadoop是干什么的"></a>Hadoop是干什么的</h3><p>一句话概括：适合大数据的分布式存储与计算平台</p><h3 id="Hadoop的2个重要部分"><a href="#Hadoop的2个重要部分" class="headerlink" title="Hadoop的2个重要部分"></a>Hadoop的2个重要部分</h3><ul><li>HDFS ： 分布式文件系统</li><li>MapReduce ： 并行计算框架</li></ul><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>主从结构：</p><pre><code>主节点： 只有一个 namedode从节点： 多个 datanode</code></pre><p>namenode:</p><pre><code>负责接收用户请求维护文件系统的目录结构管理文件与 block 之间的关系，block 与 datanode 之间的关系</code></pre><p>datanode:</p><pre><code>存储文件文件被分成若干 Block 存储在磁盘上为保证数据安全，文件会被备份成多个副本</code></pre><h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>主从结构：</p><pre><code>主节点： 只有一个 JobTracker从节点： 有多个 TaskTracker</code></pre><p>JobTracker：</p><pre><code>接受用户提交的任务把计算任务分配给 TaskTracker 执行监控 TaskTracker 的执行情况</code></pre><p>TaskTracker：</p><pre><code>执行 JobTracker 分配的任务</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 整合使用 Elasticsearch</title>
      <link href="/2017/10/23/SpringBoot-Elasticsearch/"/>
      <url>/2017/10/23/SpringBoot-Elasticsearch/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt;        &lt;artifactId&gt;jna&lt;/artifactId&gt;        &lt;version&gt;3.0.9&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p>这里需要注意的是：<br>    SpringBoot 的版本和 elasticsearch 的版本问题，在springboot 1.3.5 版本之前支持elasticsearch2.0 以下的版本，springboot1.3.5之后的版本支持elasticsearch5.0以下的版本<br>    net.java.dev.jna 这个依赖是因为启动后报类不存在，加个jna依赖加上后就好了</p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code class="yaml">    spring:      data:        elasticsearch:          cluster-name: elasticsearch          cluster-nodes: localhost:9300</code></pre><p>这里需要注意的是：<br>    elasticsearch对外提供的api的端口的是9200，提供各个集群间和客户端通信的是9300<br>    配置文件里 cluster-nodes 配置项如果不填写的话，springboot应用启动时会自动创建内部的 elasticsearch 客户端，你会发现即是本地没开 elasticsearch 服务也能跑起来<br>    配置多个集群的话 cluster-nodes 就配置多条信息，用逗号隔开</p><h3 id="在-SpringBoot-项目中使用"><a href="#在-SpringBoot-项目中使用" class="headerlink" title="在 SpringBoot 项目中使用"></a>在 SpringBoot 项目中使用</h3><ul><li>主要的一个接口<code>ElasticsearchRepository&lt;T,ID&gt;</code>,第一个是要存储的实体类,第二个参数是 ID 类型</li><li>还有个 <code>ElasticsearchCrudRepository</code>，顾名思义就是增删改查</li><li>自定义一个接口实现上述接口</li><li>定义实体类</li><li>自定义实现类可直接注入使用</li><li>默认的已经存在了增删改查的方法了,可以直接使用</li><li>想要更多的功能可以在接口中实现更多的自定义</li></ul><p>自定义一个 DAO :</p><pre><code class="java">    public interface SongDao extends ElasticsearchRepository&lt;Song,Integer&gt; {    }</code></pre><p>定义一个实体类 :</p><pre><code class="java">    @Data    @NoArgsConstructor    @Document(indexName = &quot;songdb&quot;,type = &quot;song&quot;)    public class Song {        @Id        private int id;        private String name;        private String author;        private long time;        private String commentKeyId;        private String mp3URL;        /*歌曲封面地址*/        private String picURL;        /*歌曲描述*/        private String describe;        /*专辑*/        private String album;        /*歌词*/        private String lyric;        /*mvid*/        private int mvId;    }</code></pre><p>注意：<br>    @Document注解里面的几个属性，类比mysql的话是这样：<br>    index –&gt; DB<br>    type –&gt; Table<br>    Document –&gt; row<br>    @Id注解加上后，在Elasticsearch里相应于该列就是主键了，在查询时就可以直接用主键查询，后面一篇会讲到。其实和mysql非常类似，基本就是一个数据库<br>    indexName在上述注解中需要小写</p><p>使用的话 注入SongDAO ，之后就可以看到相应的方法了<br>使用起来就是如此简单,感觉使用起来很像MongoDB配置</p><h2 id="有一些注解的配置"><a href="#有一些注解的配置" class="headerlink" title="有一些注解的配置"></a>有一些注解的配置</h2><h3 id="有时候使用起来会有一些问题"><a href="#有时候使用起来会有一些问题" class="headerlink" title="有时候使用起来会有一些问题"></a>有时候使用起来会有一些问题</h3><ul><li>在默认策略下, Java 实体类叫什么名字,生成后的表名就叫什么,但我们可能并不想这样</li><li>同样的道理,有时属性名和字段也并不想一样的<h3 id="注解解决这些问题"><a href="#注解解决这些问题" class="headerlink" title="注解解决这些问题"></a>注解解决这些问题</h3></li><li><code>@Id</code> : 标明表的 ID , 自带索引,无需维护</li><li><code>@Document</code> : 解决第一个问题</li><li><code>@Field</code> : 解决第二个问题，默认不加@Field 有一写默认配置，一旦添加了@Filed注解，所有的默认值都不再生效。此外，如果添加了@Filed注解，那么type字段必须指定</li></ul><p>入门使用就写到这</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elasticsearch </tag>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开源许可证</title>
      <link href="/2017/10/20/Open-Source-License/"/>
      <url>/2017/10/20/Open-Source-License/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><blockquote><blockquote><p>本文转自 <a href="http://www.ruanyifeng.com/blog/2017/10/open-source-license-tutorial.html" target="_blank" rel="noopener">阮一峰- 开源许可证教程</a></p></blockquote></blockquote><h2 id="开源许可证教程"><a href="#开源许可证教程" class="headerlink" title="开源许可证教程"></a>开源许可证教程</h2><p>作为一个开发者，如果你打算开源自己的代码，千万不要忘记，选择一种开源许可证（license）。</p><p>许多开发者对开源许可证了解很少，不清楚有哪些许可证，应该怎么选择。本文介绍开源许可证的基本知识，主要参考了 OpenSource.com （<a href="https://opensource.com/article/17/9/9-open-source-software-rules-startups" target="_blank" rel="noopener">1</a>，<a href="https://opensource.com/article/17/9/open-source-licensing" target="_blank" rel="noopener">2</a>）。</p><p><img src="http://www.ruanyifeng.com/blogimg/asset/2017/bg2017101101.jpg" alt=""></p><h2 id="一、什么是开源许可证"><a href="#一、什么是开源许可证" class="headerlink" title="一、什么是开源许可证"></a>一、什么是开源许可证</h2><p>开源许可证是一种法律许可。通过它，版权拥有人明确允许，用户可以免费地使用、修改、共享版权软件。</p><p>版权法默认禁止共享，也就是说，没有许可证的软件，就等同于保留版权，虽然开源了，用户只能看看源码，不能用，一用就会侵犯版权。所以软件开源的话，必须明确地授予用户开源许可证。</p><h2 id="二、开源许可证的种类"><a href="#二、开源许可证的种类" class="headerlink" title="二、开源许可证的种类"></a>二、开源许可证的种类</h2><p>目前，国际公认的开源许可证共有<a href="https://opensource.org/licenses/alphabetical" target="_blank" rel="noopener">80多种</a>。它们的共同特征是，都允许用户免费地使用、修改、共享源码，但是都有各自的使用条件。</p><p>如果一种开源许可证没有任何使用条件，连保留作者信息都不需要，那么就等同于放弃版权了。这时，软件可以直接声明进入“公共领域”（public domain）。</p><p>根据使用条件的不同，开源许可证分成两大类。</p><blockquote><ul><li>宽松式（permissive）许可证</li><li>Copyleft 许可证</li></ul></blockquote><h2 id="三、宽松式许可证"><a href="#三、宽松式许可证" class="headerlink" title="三、宽松式许可证"></a>三、宽松式许可证</h2><h3 id="3-1-特点"><a href="#3-1-特点" class="headerlink" title="3.1 特点"></a>3.1 特点</h3><p>宽松式许可证（permissive license）是最基本的类型，对用户几乎没有限制。用户可以修改代码后闭源。</p><p>它有三个基本特点。</p><p><strong>（1）没有使用限制</strong></p><p>用户可以使用代码，做任何想做的事情。</p><p><strong>（2）没有担保</strong></p><p>不保证代码质量，用户自担风险。</p><p><strong>（3）披露要求（notice requirement）</strong></p><p>用户必须披露原始作者。</p><h3 id="3-2-常见许可证"><a href="#3-2-常见许可证" class="headerlink" title="3.2 常见许可证"></a>3.2 常见许可证</h3><p>常见的宽松式许可证有四种。它们都允许用户任意使用代码，区别在于要求用户遵守的条件不同。</p><p><strong>（1）BSD（二条款版）</strong></p><p>分发软件时，必须保留原始的许可证声明。</p><p><strong>（2） BSD（三条款版）</strong></p><p>分发软件时，必须保留原始的许可证声明。不得使用原始作者的名字为软件促销。</p><p><strong>（3）MIT</strong></p><p>分发软件时，必须保留原始的许可证声明，与 BSD（二条款版）基本一致。</p><p><strong>（4）Apache 2</strong></p><p>分发软件时，必须保留原始的许可证声明。凡是修改过的文件，必须向用户说明该文件修改过；没有修改过的文件，必须保持许可证不变。</p><h2 id="四、Copyleft-许可证"><a href="#四、Copyleft-许可证" class="headerlink" title="四、Copyleft 许可证"></a>四、Copyleft 许可证</h2><h3 id="4-1-Copyleft-的含义"><a href="#4-1-Copyleft-的含义" class="headerlink" title="4.1 Copyleft 的含义"></a>4.1 Copyleft 的含义</h3><p>Copyleft 是<a href="http://www.ruanyifeng.com/blog/2005/03/post_112.html" target="_blank" rel="noopener">理查德·斯托曼</a>发明的一个词，作为 Copyright （版权）的反义词。</p><p>Copyright 直译是“复制权”，这是版权制度的核心，意为不经许可，用户无权复制。作为反义词，Copyleft 的含义是不经许可，用户可以随意复制。</p><p>但是，它带有前提条件，比宽松式许可证的限制要多。</p><blockquote><ul><li>如果分发二进制格式，必须提供源码</li><li>修改后的源码，必须与修改前保持许可证一致</li><li>不得在原始许可证以外，附加其他限制</li></ul></blockquote><p>上面三个条件的核心就是：修改后的 Copyleft 代码不得闭源。 </p><h3 id="4-2-常见许可证"><a href="#4-2-常见许可证" class="headerlink" title="4.2 常见许可证"></a>4.2 常见许可证</h3><p>常见的 Copyleft 许可证也有四种（对用户的限制从最强到最弱排序）。</p><p><strong>（1）Affero GPL (AGPL)</strong></p><p>如果云服务（即 SAAS）用到的代码是该许可证，那么云服务的代码也必须开源。</p><p><strong>（2）GPL</strong></p><p>如果项目包含了 GPL 许可证的代码，那么整个项目都必须使用 GPL 许可证。</p><p><strong>（3）LGPL</strong></p><p>如果项目采用动态链接调用该许可证的库，项目可以不用开源。</p><p><strong>（4）Mozilla（MPL）</strong></p><p>只要该许可证的代码在单独的文件中，新增的其他文件可以不用开源。</p><h2 id="五、常见问题"><a href="#五、常见问题" class="headerlink" title="五、常见问题"></a>五、常见问题</h2><p>本节回答一些开源许可证的常见问题。</p><h3 id="5-1-什么叫分发（distribution）？"><a href="#5-1-什么叫分发（distribution）？" class="headerlink" title="5.1 什么叫分发（distribution）？"></a>5.1 什么叫分发（distribution）？</h3><p>除了 Affero GPL (AGPL) ，其他许可证都规定只有在“分发”时，才需要遵守许可证。换言之，如果不“分发”，就不需要遵守。</p><p>简单说，分发就是指将版权作品从一个人转移到另一个人。这意味着，如果你是自己使用，不提供给他人，就没有分发。另外，这里的“人”也指“法人”，因此如果使用方是公司，且只在公司内部使用，也不需要遵守许可证。</p><p>云服务（SaaS）是否构成“分发”呢？答案是不构成。所以你使用开源软件提供云服务，不必提供源码。但是，Affero GPL (AGPL) 许可证除外，它规定云服务也必须提供源码。</p><h3 id="5-2-开源软件的专利如何处理？"><a href="#5-2-开源软件的专利如何处理？" class="headerlink" title="5.2 开源软件的专利如何处理？"></a>5.2 开源软件的专利如何处理？</h3><p>某些许可证（Apache 2 和 GPL v3）包含明确的条款，授予用户许可，使用软件所包含的所有专利。</p><p>另一些许可证（BSD、MIT 和 GPL v2）根本没提到专利。但是一般认为，它们默认给予用户专利许可，不构成侵犯专利。</p><p>总得来说，除非有明确的“保留专利”的条款，使用开源软件都不会构成侵犯专利。</p><h3 id="5-3-什么是披露要求？"><a href="#5-3-什么是披露要求？" class="headerlink" title="5.3 什么是披露要求？"></a>5.3 什么是披露要求？</h3><p>所有的开源许可证都带有“披露要求”（notice requirement），即要求软件的分发者必须向用户披露，软件里面有开源代码。</p><p>一般来说，你只要在软件里面提供完整的原始许可证文本，并且披露原始作者，就满足了“披露要求”。</p><h3 id="5-4-GPL-病毒是真的吗？"><a href="#5-4-GPL-病毒是真的吗？" class="headerlink" title="5.4  GPL 病毒是真的吗？"></a>5.4  GPL 病毒是真的吗？</h3><p>GPL 许可证规定，只要你的项目包含了 GPL 代码，整个项目就都变成了 GPL。有人把这种传染性比喻成“GPL 病毒”。</p><p>很多公司希望避开这个条款，既使用 GPL 软件，又不把自己的专有代码开源。理论上，这是做不到的。因为 GPL 的设计目的，就是为了防止出现这种情况。</p><p>但是实际上，不遵守 GPL，最坏情况就是被起诉。如果你向法院表示无法履行 GPL 的条件，法官只会判决你停止使用 GPL 代码（法律上叫做“停止侵害”），而不会强制要求你将源码开源，因为《版权法》里面没有相应的规定。</p>]]></content>
      
      
      <categories>
          
          <category> 开源篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> license </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven --- 一款打包压缩 js css html 的Maven插件</title>
      <link href="/2017/10/16/Maven-ResourceCompressor/"/>
      <url>/2017/10/16/Maven-ResourceCompressor/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="怎么使用？"><a href="#怎么使用？" class="headerlink" title="怎么使用？"></a>怎么使用？</h2><p>pom 中引入插件：</p><pre><code class="xml">    &lt;plugin&gt;        &lt;groupId&gt;cn.joylau.code&lt;/groupId&gt;        &lt;artifactId&gt;joylau-compressor-plugins&lt;/artifactId&gt;        &lt;version&gt;1.2.RELEASE&lt;/version&gt;        &lt;executions&gt;            &lt;execution&gt;                &lt;id&gt;resource-compressor&lt;/id&gt;                &lt;phase&gt;compile&lt;/phase&gt;                &lt;goals&gt;                    &lt;goal&gt;resource-compressor&lt;/goal&gt;                &lt;/goals&gt;            &lt;/execution&gt;        &lt;/executions&gt;        &lt;configuration&gt;            &lt;cssConfigs&gt;                &lt;cssConfig&gt;                    &lt;dir&gt;/static/css&lt;/dir&gt;                    &lt;include&gt;*.css&lt;/include&gt;                    &lt;exclude&gt;*.min.css&lt;/exclude&gt;                &lt;/cssConfig&gt;            &lt;/cssConfigs&gt;            &lt;jsConfigs&gt;                &lt;jsConfig&gt;                    &lt;dir&gt;/static/js&lt;/dir&gt;                    &lt;include&gt;*.js&lt;/include&gt;                    &lt;exclude&gt;*.min.js&lt;/exclude&gt;                    &lt;munge&gt;true&lt;/munge&gt;                &lt;/jsConfig&gt;            &lt;/jsConfigs&gt;            &lt;htmlConfigs&gt;                &lt;htmlConfig&gt;                    &lt;dir&gt;/templates&lt;/dir&gt;                    &lt;include&gt;*.html&lt;/include&gt;                    &lt;removeIntertagSpaces&gt;true&lt;/removeIntertagSpaces&gt;                    &lt;compressJavaScript&gt;false&lt;/compressJavaScript&gt;                    &lt;compressCss&gt;true&lt;/compressCss&gt;                &lt;/htmlConfig&gt;            &lt;/htmlConfigs&gt;        &lt;/configuration&gt;    &lt;/plugin&gt;</code></pre><h2 id="配置解释"><a href="#配置解释" class="headerlink" title="配置解释"></a>配置解释</h2><ul><li><code>phase</code> : compile 表明该插件在 compile 时调用</li><li><code>goal</code> ： 固定为 resource-compressor 不需要改变</li><li><code>cssConfigs</code> , 可配置多个 cssConfig<ul><li>cssConfig <ul><li>dir： css文件目录</li><li>include：包含的css文件，支持通配符</li><li>exclude：排除的css文件，支持通配符</li></ul></li></ul></li></ul><ul><li><code>jsConfigs</code> , 可配置多个 jsConfig<ul><li>jsConfig <ul><li>dir： js文件目录</li><li>include：包含的js文件，支持通配符</li><li>exclude：排除的js文件，支持通配符</li><li>munge: 是否进行代码混淆，缺省值为 false</li><li>preserveAllSemiColons : 保留所有的分号，缺省值为 false</li><li>disableOptimizations : 禁用自带的所有优化措施，缺省值为 false</li></ul></li></ul></li></ul><ul><li><code>htmlConfigs</code> , 可配置多个 htmlConfig<ul><li>htmlConfig <ul><li>dir： js文件目录</li><li>include：包含的js文件，支持通配符</li><li>exclude：排除的js文件，支持通配符</li><li>removeComments: 是否移除注释，缺省值为 true</li><li>removeIntertagSpaces : 是否移除标签之间的空格，缺省值为 false</li><li>compressJavaScript : 是否对html里的js代码进行压缩，缺省值为 false</li><li>compressCss : 是否对html里的css代码进行压缩，缺省值为 false</li></ul></li></ul></li></ul><h2 id="压缩信息"><a href="#压缩信息" class="headerlink" title="压缩信息"></a>压缩信息</h2><p>当看到以下图片所示的信息后，则压缩成功</p><p><img src="http://image.joylau.cn/blog/resource-compressor.png" alt="joylau-compressor-plugins"></p><p>例如 ：[INFO] common.js(8.71KB==&gt;4.58KB,47.39%)</p><p>表示 ：common.js 源文件大小8.71KB，压缩后大小 4.58KB，压缩率47.39%</p><h2 id="GitHub-地址"><a href="#GitHub-地址" class="headerlink" title="GitHub 地址"></a>GitHub 地址</h2><p>源码已开源，地址 ： <a href="https://github.com/JoyLau/joylau-compressor-plugins" target="_blank" rel="noopener">https://github.com/JoyLau/joylau-compressor-plugins</a></p>]]></content>
      
      
      <categories>
          
          <category> Maven篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当鼠标移入图片上慢慢放大的效果</title>
      <link href="/2017/10/13/CSS3-Image-Scale/"/>
      <url>/2017/10/13/CSS3-Image-Scale/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><ul><li>今天在浏览网站时，<a href="http://ai.baidu.com/" target="_blank" rel="noopener">http://ai.baidu.com/</a> ，看到一个CSS3的效果:将鼠标放到图片上，图片会稍稍方大一点，当时很好奇是怎么做的</li><li>当即百度了一下，有人用js做的，有人用css做的，首先js做的肯定不够好，一看效果就是css3的效果</li><li>于是自己查看了下 这块 div 的效果</li><li>将压缩的css展开来</li><li>原来是这样的：</li></ul><pre><code class="css">    # 鼠标移上去各浏览器的延时效果    .solution-img {        height: 100%;        -webkit-transform-origin: 50% 50%;        -moz-transform-origin: 50% 50%;        -ms-transform-origin: 50% 50%;        transform-origin: 50% 50%;        -webkit-transition: -webkit-transform .2s;        transition: -webkit-transform .2s;        -moz-transition: transform .2s,-moz-transform .2s;        transition: transform .2s;        transition: transform .2s,-webkit-transform .2s,-moz-transform .2s    }    # 鼠标移上去各浏览器的放大倍数    .solution-item:hover .solution-img {        -webkit-transform: scale(1.1);        -moz-transform: scale(1.1);        -ms-transform: scale(1.1);        transform: scale(1.1)    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CSS3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 代码中使用 Scala</title>
      <link href="/2017/09/26/Java-Scala/"/>
      <url>/2017/09/26/Java-Scala/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>将 Scala 依赖 scala-library 和插件 scala-maven-plugin 添加到 Maven 项目中</p><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;        &lt;artifactId&gt;scala-library&lt;/artifactId&gt;        &lt;version&gt;2.11.7&lt;/version&gt;    &lt;/dependency&gt;    &lt;plugin&gt;    &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;    &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;scala-compile-first&lt;/id&gt;            &lt;phase&gt;process-resources&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;add-source&lt;/goal&gt;                &lt;goal&gt;compile&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;        &lt;execution&gt;            &lt;id&gt;scala-test-compile&lt;/id&gt;            &lt;phase&gt;process-test-resources&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;testCompile&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;</code></pre><p>更新完上面的内容之后，你需要等待Maven下载完所有的依赖。</p><p>安装IDEA插件 <code>Scala</code><br>现在可以在Java工程中使用Scala代码了<br>创建新的文件夹src/main/scala；<br>Scala Maven插件将会识别这些目录，并且编译其中的Scala文件：</p><pre><code class="java">    object BooksProcessor {      def filterByAuthor(author: String)(implicit books: util.ArrayList[Book]) = {        books.filter(book =&gt; book.getAuthor == author)      }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> Scala篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 推荐使用CaffeineCache</title>
      <link href="/2017/09/19/SpringBoot-CaffeineCache/"/>
      <url>/2017/09/19/SpringBoot-CaffeineCache/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="今天没有图片"><a href="#今天没有图片" class="headerlink" title="今天没有图片"></a>今天没有图片</h2><p>在做单系统的情况下，我还是比较喜欢使用Google 的 Guava 来做缓存的，结合 SpringBoot 使用非常简单 ：</p><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;com.google.guava&lt;/groupId&gt;        &lt;artifactId&gt;guava&lt;/artifactId&gt;        &lt;version&gt;23.0&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p>再配置 yml ：</p><pre><code class="xml">    spirng:        cache:            type: guava            cache-names: api_cache            guava:              spec: maximumSize=300,expireAfterWrite=2m</code></pre><p>上述配置了一个 缓存名为 api_cache 的缓存 ，最大数量为300，超时时间为2分钟</p><p>接下来，在类中使用注解 @CacheConfig(cacheNames = “api_cache”) 来配置整个类的配置<br>@Cacheable() 注解在方法上来 开启方法的注解</p><p>使用很透明</p><p>今天再次使用时发现guava.spec提示过期了，查了下文档,文档原话是这样说的：</p><blockquote><blockquote><p>@Deprecated<br>           @DeprecatedConfigurationProperty(<br>               reason = “Caffeine will supersede the Guava support in Spring Boot 2.0”,<br>               replacement = “spring.cache.caffeine.spec”<br>           )</p></blockquote></blockquote><p>原来，在SpringBoot2.0中推荐使用Caffeine，表达式就是spring.cache.caffeine.spec</p><p>更改的方法很简单，改下依赖包，换个配置名，又可以愉快的额使用了：</p><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt;        &lt;artifactId&gt;caffeine&lt;/artifactId&gt;    &lt;/dependency&gt;</code></pre><p>更新配置：</p><pre><code class="bash">    spirng:        cache:            type: caffeine            cache-names: api_cache            caffeine:              spec: maximumSize=300,expireAfterWrite=2m</code></pre><p>通常SpringBoot默认的keyGenerator 是SimpleKeyGenerator，这个策略是以参数作为key值，如果参数为空的，就会返回SimpleKey[]字符串，这对于很多无参的方法的就有问题了<br>我们需要重新这个keyGenerator，实现 <code>org.springframework.cache.interceptor.keyGenerator</code> 这个接口即可，将key值设置为类名+方法名+参数名，这样就不会冲突了</p><pre><code class="java">    @Bean    public KeyGenerator caffeineKeyGenerator() {        return (target, method, params) -&gt; {            StringBuilder sb = new StringBuilder();            sb.append(target.getClass().getName());            sb.append(method.getName());            for (Object obj : params) {                sb.append(obj.toString());            }            return sb.toString();        };    }</code></pre><p>感觉无缝切换，继续使用吧！！！</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JoyGame --- 一个情怀游戏平台</title>
      <link href="/2017/09/11/JoyGame/"/>
      <url>/2017/09/11/JoyGame/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="制作背景"><a href="#制作背景" class="headerlink" title="制作背景"></a>制作背景</h2><ul><li>有时候宅在家里实在不知道玩什么游戏</li><li>英雄联盟都玩烂了</li><li>哥们提议玩红警</li><li>红警是单机啊，一个人玩另一个人怎么办，一个人打电脑有啥意思 =_=|</li><li>找对战平台啊，首先下载安装了红警玩家自制的战网对战平台</li><li>我个人电脑从来不安装杀毒软件，Windows Defender 一直报毒搞个不停</li><li>战网的平台体验也很不好，消息弹个不停，感觉像广告软件</li><li>后来换了腾讯对战平台，进入红警起个名字老说含有敏感信息，结果起了半个小时，MDZZ</li><li>决定自己了解下对战平台的原理，打算自己写个简单好用的玩</li></ul><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>通过socket hook + udp，针对war3来说，支持tcp，先在本地通过hook模拟建立tcp连接，然后将tcp的数据转成外网udp数据发给外网服务器转发给其他客户端，客户端接收到后通过本地tcp模拟连接转发到游戏进程。这个过程中通过中转服务器协助进行p2p。</p><center>![JoyGame-zhihu](//image.joylau.cn/blog/JoyGame-zhihu.jpg)</center><p>上面是知乎上的回答<br>用我自己的话说就是</p><blockquote><blockquote><p>使用JoyGameClient客户端，在本地创建了一个虚拟的IP地址，每一个客户端通过连接远程服务器形成了一个虚拟局域网，这样在游戏的【局域网】选择项中就能找到彼此，这样自然一方创建一个游戏，其他人都可以加入进来了就能愉快的玩耍了。底层通信使用的就是TCP和UDP连接，在同一个房间的玩家都会向服务器发送和下载游戏的实时数据。服务器会向房间里的玩家的客户端上转发数据包，这样就间接形成了一个局域网，就能在一起玩游戏啦。</p></blockquote></blockquote><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><ul><li>解压，打开JoyGameClient.exe</li><li>选择中间的网络服务器,因为你本地肯定是没有服务端的，只能连接远程部署好的服务器<center>![JoyGame-Login](//image.joylau.cn/blog/JoyGame-login.png)</center></li><li>没有账号，就注册一个账号，注册成功后登录平台<center>![JoyGame-Login](//image.joylau.cn/blog/JoyGame-main.png)</center></li><li>这是主界面</li><li>接下来进入一个你想玩的游戏的房间</li><li>设置你的游戏启动主程序<center>![JoyGame-Login](//image.joylau.cn/blog/JoyGame-setGamePath.png)</center></li><li>下面可以设置启动时游戏的参数，比如玩红警时，加入参数 -win，可以窗口启动</li><li>之后点启动，进入游戏就可找到在一个房间的小伙伴了</li><li>使用都很简单，看一遍就会</li></ul><h2 id="特色"><a href="#特色" class="headerlink" title="特色"></a>特色</h2><ul><li>可以聊天，发表情，可以加好友。。。额，这些好像没有什么特色</li><li><strong><code>可以作弊</code></strong>！！！ 该平台只实现了虚拟局域网的互通，并没有考虑游戏的平衡性，因此你可以在网上下载相应的修改器进行作弊，哥们跟我玩红警，到现在他都不知道为什么盘盘都输给我，<center>![JoyGame-Login](//image.joylau.cn/aodamiao/02.jpg)</center></li></ul><h2 id="我想说"><a href="#我想说" class="headerlink" title="我想说"></a>我想说</h2><p>如果你想玩玩以前的一些怀旧游戏，或者你想看看该平台是如何操作实现联机的，还等什么，跟着Joy一起来玩吧<br>私聊我可以给你开个 VIP 、等级直接升到将军哦！虽然没什么用，纯粹装*</p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><ul><li>JoyGame平台下载： <a href="http://image.joylau.cn/blog/JoyGameClient.rar" target="_blank" rel="noopener">JoyGameClient.rar</a></li><li>魔兽争霸3冰封王座v1.26绿色版： <a href="https://pan.baidu.com/share/link?shareid=3779529435&uk=1077172855" target="_blank" rel="noopener">百度网盘</a></li><li>红警2共和国之辉：<a href="https://pan.baidu.com/s/1pKQ0aaJ" target="_blank" rel="noopener">百度网盘</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 程序员篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技能 </tag>
            
            <tag> 程序员 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven --- 将 SpringBoot 项目做成Windows服务(Windows Service)</title>
      <link href="/2017/09/03/Maven-MakeWinServiceForJar/"/>
      <url>/2017/09/03/Maven-MakeWinServiceForJar/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h1 id="一款将-SpringBoot-项目做成Windows-Service-的-Maven-插件"><a href="#一款将-SpringBoot-项目做成Windows-Service-的-Maven-插件" class="headerlink" title="一款将 SpringBoot 项目做成Windows Service 的 Maven 插件"></a>一款将 SpringBoot 项目做成Windows Service 的 Maven 插件</h1><blockquote><blockquote><p>包括但不限于 SpringBoot ,任何打成 java jar 包运行的 Maven 项目都可以使用</p></blockquote></blockquote><h2 id="编写初衷"><a href="#编写初衷" class="headerlink" title="编写初衷"></a>编写初衷</h2><ul><li>公司有个项目</li><li>Java 部分的全部使用的是SpringBoot</li><li>该项目的部署环境是 Windows</li><li>公司想把 各个 SpringBoot 的模块托管一下</li><li>托管的使用方式要简单，易用，测试在打包部署的时候要很容易上手</li><li>期间尝试过 Spring Boot Admin 和 Jenkins,都说不好用…</li><li>于是就想着 将Spring Boot 的服务制作成 Windows 服务，这样基本上会操作电脑的人都会使用了，够简单易用的了吧</li><li>花了一上午时间将其中一个 Spring Boot 模块制作成了 Windows Service</li><li>发现再做其他的模块的时候，很多工作都是重复的，心想着能够将这个功能提取出来就好了</li><li>于是就写了这个 Maven 插件</li></ul><h2 id="使用演示地址："><a href="#使用演示地址：" class="headerlink" title="使用演示地址："></a>使用演示地址：</h2><center><video src="http://image.joylau.cn/blog/joylau-springboot-daemon-service-video.mp4" loop="true" controls="controls">您的浏览器版本太低，无法观看本视频</video></center><h2 id="怎么使用？"><a href="#怎么使用？" class="headerlink" title="怎么使用？"></a>怎么使用？</h2><ul><li>使用方法很简单，和普通的 Maven 插件一样使用就可以了，如下<pre><code class="xml">  &lt;plugins&gt;      &lt;plugin&gt;          &lt;groupId&gt;cn.joylau.code&lt;/groupId&gt;          &lt;artifactId&gt;joylau-springboot-daemon-windows&lt;/artifactId&gt;          &lt;version&gt;1.0.RELEASE&lt;/version&gt;          &lt;executions&gt;              &lt;execution&gt;                  &lt;id&gt;make-win-service&lt;/id&gt;                  &lt;phase&gt;package&lt;/phase&gt;                  &lt;goals&gt;                      &lt;goal&gt;make-win-service&lt;/goal&gt;                  &lt;/goals&gt;              &lt;/execution&gt;          &lt;/executions&gt;      &lt;/plugin&gt;  &lt;/plugins&gt;</code></pre></li></ul><p>注意：</p><ol><li>这里的 phase 写的是 package,意思是该插件在 mvn package 的时候调用,你也可以根据不同的需求来更改，比如 install, test等等</li><li>goal 写 make-win-service 就可以了，不需要改动</li><li>一般情况下我们的SpringBoot项目会有其他父项目，这时打包会使用 spring-boot-maven-plugin 插件的 repackage,这样的情况的话，请将该插件放置最后面,否则服务运行的话将提示没有主属性</li></ol><ul><li>在你的项目中按照以上的方式引入插件后，现在可以 打包了<pre><code>  mvn package</code></pre></li></ul><p>打包过程中，看到如下日志信息，便制作成功了：<br><img src="http://image.joylau.cn/blog/joylau-springboot-daemon-windows-package-info.jpg" alt="joylau-springboot-daemon-windows-package-info"></p><p>此时，在你项目的target目录下会生成一个 jar 包名字 一样的压缩包<br>进入文件夹，解压这个压缩包，你会看见如下内容的文件<br><img src="http://image.joylau.cn/blog/joylau-springboot-daemon-windows-package-file.jpg" alt="joylau-springboot-daemon-windows-package-file"><br>注意：</p><ol><li>5个 bat 文件，请右键以管理员的身份运行</li><li>各文件的文件名无特殊情况，不需要修改</li><li>一旦安装成了 Windows 服务，目录下的文件就不要移动了</li><li>命令运行时，可能会提示安装.NET,安装完成就可运行命令了，不过现在大部分的 Windows 服务器或者个人电脑都会默认安装了.NET,没有的话启用一下就好了，如下图：<br><img src="http://image.joylau.cn/blog/joylau-springboot-daemon-windows-.net.jpg" alt="joylau-springboot-daemon-windows-.NET"></li><li>运行各个命令是注意提示信息，例如卸载完服务都的状态为NonExistent，刚安装完服务后的状态为Stopped，服务成功启动的状态为Started…等等<br><img src="http://image.joylau.cn/blog/joylau-springboot-daemon-service-status.jpg" alt="joylau-springboot-daemon-windows-service-status"></li></ol><h2 id="扩展参数"><a href="#扩展参数" class="headerlink" title="扩展参数"></a>扩展参数</h2><p>想要在服务启动时添加自定义参数,如 SpringBoot 的配置参数或者 JMV 参数？<br>像如下配置即可：</p><pre><code class="xml">    &lt;plugin&gt;        &lt;groupId&gt;cn.joylau.code&lt;/groupId&gt;        &lt;artifactId&gt;joylau-springboot-daemon-windows&lt;/artifactId&gt;        &lt;version&gt;1.0.RELEASE&lt;/version&gt;        &lt;executions&gt;            &lt;execution&gt;                &lt;id&gt;make-win-service&lt;/id&gt;                &lt;phase&gt;package&lt;/phase&gt;                &lt;goals&gt;                    &lt;goal&gt;make-win-service&lt;/goal&gt;                &lt;/goals&gt;            &lt;/execution&gt;        &lt;/executions&gt;        &lt;configuration&gt;            &lt;arguments&gt;                &lt;argument&gt;--server.port=9090&lt;/argument&gt;            &lt;/arguments&gt;        &lt;/configuration&gt;    &lt;/plugin&gt;</code></pre><p>上面配置了一个 Spring Boot 应用的启动端口9090</p><h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><ul><li>打包使用过程中需要联网</li><li>文档中有些图片可能看不到，再次刷新下页面就可以</li><li>服务的id为artifactId，服务的名称为artifactId+version，服务的描述为description</li></ul><h2 id="GitHub-地址"><a href="#GitHub-地址" class="headerlink" title="GitHub 地址"></a>GitHub 地址</h2><p>源码已开源，地址 ： <a href="https://github.com/JoyLau/joylau-springboot-daemon-windows" target="_blank" rel="noopener">https://github.com/JoyLau/joylau-springboot-daemon-windows</a></p>]]></content>
      
      
      <categories>
          
          <category> Maven篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 实战项目 JoyMedia （ NoReferer篇 ）</title>
      <link href="/2017/08/29/SpringBoot-JoyMedia-NoReferer/"/>
      <url>/2017/08/29/SpringBoot-JoyMedia-NoReferer/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h3><center>![JoyMusic-NoReferer](//image.joylau.cn/blog/joymusic-mv-noreferer.png)![JoyMusic-NoReferer](//image.joylau.cn/blog/joymusic-mv-video-small.gif)![JoyMusic-NoReferer](//image.joylau.cn/blog/joymusic-mv-video-url.gif)</center><h3 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h3><ul><li><a href="//music.joylau.cn" target="_blank" rel="noopener">JoyMusic</a></li></ul><h3 id="问题说明"><a href="#问题说明" class="headerlink" title="问题说明"></a>问题说明</h3><ul><li>为什么解析的 MV 地址无法直接播放，在上一篇文章上我也说明了</li><li>相应的解决办法我在上一篇文章上也说明了</li><li>这样的方法有很明显的缺点，在上一篇文章也说明了</li><li>这个方法只能实现播放的功能，但是距离完美或者说好的展示效果来说，并不满意</li><li>我自己就很不满意</li></ul><h2 id="开始动手"><a href="#开始动手" class="headerlink" title="开始动手"></a>开始动手</h2><h3 id="先说下我是怎么解决的"><a href="#先说下我是怎么解决的" class="headerlink" title="先说下我是怎么解决的"></a>先说下我是怎么解决的</h3><ul><li>解决的方法还是一样：去除referer</li><li>同时去除了原来使用的jPlayer播放器，因为这个播放器在移动设备下的表现并不是很好，现在改为浏览器自带的视频播放空控件</li><li>这个东西就没有什么兼容性了，只要IE10 以上支持HTML5 的都可以观看</li><li>正如上面我截图所示的那样，我使用的是 Safari 浏览器，表现效果还是很好的</li><li>同时也加入了一些比较棒的小功能：比如下滑看评论的时候，会出现小视频框在右下角</li><li>我个人是比较喜欢看评论的，一些音乐或者 MV 页面打开后并不是先听或者先看，都是翻到下面看看评论</li><li>这也正是我喜欢网易云音乐的原因之一，网易云音乐的评论大部分都很精彩，有时候听歌不如看评论</li></ul><h3 id="现在是怎么在页面上去除referer的？"><a href="#现在是怎么在页面上去除referer的？" class="headerlink" title="现在是怎么在页面上去除referer的？"></a>现在是怎么在页面上去除referer的？</h3><ul><li>动态生成一个iframe,我本身是比较反对使用iframe的，因为以前使用的extjs使用的多了，都用吐了，而且性能还不是很好</li><li>但是在这里它可就起了大作用了</li><li>iframe 里的页面就放一个<code>&lt;video&gt;</code></li><li>iframe 的宽度高度及video的宽度高度都要调节好，其实这一步花了我不少时间，因为并不是所有的MV宽高的比例是一样的</li><li>iframe 的src不能直接写MV的MP4地址，因为那样的话就没有作用了</li><li>在src里写js脚本动态生成html页面，页面里面包括的之前提到的video</li><li>使用这种方法就可将网站的referer去除掉</li><li>这就类似于直接在浏览器的地址栏上输入MP4的地址然后播放</li><li>在前一篇的文章分析中，我们知道，这种方法是可以播放的</li></ul><h2 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h2><h3 id="动态渲染iframe："><a href="#动态渲染iframe：" class="headerlink" title="动态渲染iframe："></a>动态渲染iframe：</h3><pre><code class="javascript">    return &#39;&lt;iframe \                    style=&quot;border 1px solid #ff0000&quot; \                    scrolling=&quot;no&quot; \                    frameborder=&quot;no&quot; \                    allowtransparency=&quot;true&quot; &#39; +                /*-- Adding style attribute --*/                objectToHtmlAttributes( iframeAttributes ) +                &#39;id=&quot;&#39; + id + &#39;&quot; &#39; +                &#39;    src=&quot;javascript:\&#39;\                &lt;!doctype html&gt;\                &lt;html&gt;\                &lt;head&gt;\                &lt;meta http-equiv=\\\&#39;Content-Type\\\&#39;; content=\\\&#39;text/html\\\&#39;; charset=\\\&#39;utf-8\\\&#39;&gt;\                &lt;style&gt;*{margin:0;padding:0;border:0;}&lt;/style&gt;\                &lt;/head&gt;&#39; +                /*-- Function to adapt iframe&#39;s size to content&#39;s size --*/                &#39;&lt;script&gt;\                     function resizeWindow() {\                        var elems  = document.getElementsByTagName(\\\&#39;*\\\&#39;),\                            width  = parent.document.getElementById(\\\&#39;panel-c\\\&#39;).offsetWidth-7,\                            height = 0,\                            first  = document.body.firstChild,\                            elem;\                        if (first.offsetHeight &amp;&amp; first.offsetWidth) {\                            width = first.offsetWidth;\                            height = first.offsetHeight;\                        } else {\                            for (var i in elems) {\                                                elem = elems[i];\                                                if (!elem.offsetWidth) {\                                                    continue;\                                                }\                                                width  = Math.max(elem.offsetWidth, width);\                                                height = Math.max(elem.offsetHeight, height);\                            }\                        }\                        var ifr = parent.document.getElementById(\\\&#39;&#39; + id + &#39;\\\&#39;);\                        ifr.height = height;\                        ifr.width  = width;\                    };\                 &lt;/script&gt;&#39; +                &#39;&lt;body onload=\\\&#39;resizeWindow()\\\&#39;&gt;\&#39; + decodeURIComponent(\&#39;&#39; +                /*-- Content --*/                encodeURIComponent(html) +            &#39;\&#39;) +\&#39;&lt;/body&gt;&lt;/html&gt;\&#39;&quot;&gt;&lt;/iframe&gt;&#39;;</code></pre><p>注意这里的反斜杠不要去掉，是用来转义的，代码的样式虽然丑了点，但是并不影响使用</p><ul><li>这里面有个方法是<code>encodeURIComponent(html)</code>，这个是转义了video里面的url链接</li><li>在iframe的body加载完成后会调用<code>resizeWindow()</code>函数自适应下iframe的宽高</li><li><code>html</code>里面写的就是要放入iframe的body里的代码，这里我们放的肯定是video</li><li>于是，可以将上述代码封装成一个函数，在父页面是直接调用</li><li>封装的时候我们还可以传一些参数，比如上面的iframe的初始的宽高，style，scrolling，frameborder等等</li></ul><h3 id="扩展一下"><a href="#扩展一下" class="headerlink" title="扩展一下"></a>扩展一下</h3><ul><li>这个方式使用的是video</li><li>那么<code>&lt;img&gt;</code>呢？现在有些网站的图片也是经过了防盗链处理，这种方法也是可以实现去掉referer，直接访问图片的额</li></ul><blockquote><blockquote><p>欢迎大家来看看试试看!😘 <a href="http://music.joylau.cn" target="_blank" rel="noopener">http://music.joylau.cn</a>  (当前版本 v1.5)</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Node.js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 实战项目 JoyMedia （ MV篇 ）</title>
      <link href="/2017/08/20/SpringBoot-JoyMedia-MV/"/>
      <url>/2017/08/20/SpringBoot-JoyMedia-MV/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h3><center><video src="//image.joylau.cn/blog/joymusic-mv.mp4" loop="true" controls="controls" poster="//image.joylau.cn/blog/joymusic-mv-poster.png">您的浏览器版本太低，无法观看本视频</video></center><h3 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h3><ul><li><a href="//music.joylau.cn" target="_blank" rel="noopener">JoyMusic</a></li></ul><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h3 id="需要准备"><a href="#需要准备" class="headerlink" title="需要准备"></a>需要准备</h3><ul><li>这次要解析的是 网易云音乐的 MV</li><li>需要准备的解析的有</li><li>获取 MV 信息列表</li><li>获取 MV 详细信息</li><li>获取 MV 播放地址</li><li>在线播放 MV</li><li>获取 MV 排行榜</li><li>获取最新 MV</li></ul><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li>大部分解析提供的接口都和我以前2篇文章类似,之前的文章有分析过,这里就不再多说了</li><li>这里重点说明下 MV 的播放问题</li></ul><h3 id="关于-MV-的播放"><a href="#关于-MV-的播放" class="headerlink" title="关于 MV 的播放"></a>关于 MV 的播放</h3><ul><li>解析 MV 详细信息,可获得 MV 的真实播放的 MP4 的地址</li><li>但是这个地址,网易云做了防盗链处理</li><li>什么是防盗链?</li><li>一般情况下,我的资源文件,比如 图片, css,js,视频,我们自己放到服务器上可以直接引用</li><li>同样的道理,别人可以访问你的服务器,也可以直接引用</li><li>那么,不想被别人引用怎么办呢?</li><li>这就引申出了防盗链的操作</li><li>最常见的防盗链的处理就是加上 referer识别,就是来源网址信息</li><li>referer 其实是个错误的拼写,这个就是有历史原因了,以前的开发人员在定义这个属性的时候,把这个单词写错了,后来没有人注意到,一直使用到他作为标准</li><li>后来,也没有人去特意改他了,就这么用着吧</li><li>这个是简单防盗链处理</li><li>还有更复杂的,比如 js 加密路径信息,每次请求路径都会变化,这个就复杂了</li><li>很幸运,网易云的 MV 采用的就是 referer 的识别方式</li><li>那么就有相应的破解方法了</li></ul><h3 id="关于-referer"><a href="#关于-referer" class="headerlink" title="关于 referer"></a>关于 referer</h3><ul><li>MP4 的地址在浏览器地址栏直接粘过去是可以播放的,但是由其他网站跳进去的则不能访问,因为带进了 rerferer</li><li>那么,要做的就是去除 请求的 rerferer </li><li>我找了很多资料也尝试了很多次,想在浏览器端把 rerferer 去除掉,基本是实现不了的,如果你实现在页面里单独请求 mp4 地址时不带referer, 请联系我</li><li>那么要做的就是在服务端操作了</li><li>在服务端操作很简单,就是伪造头信息进行请求</li></ul><p>这个是带 referer 的请求,被网易云直接拒绝了</p><p><img src="http://image.joylau.cn/blog/joymusic-mv-referer.png" alt="joymusic-mv-referer"></p><p>这个是复制地址到地址栏,则可以直接播放</p><p><img src="http://image.joylau.cn/blog/joymusic-mv-no-referer.png" alt="joymusic-mv-no-referer"></p><h2 id="服务单去除-referer"><a href="#服务单去除-referer" class="headerlink" title="服务单去除 referer"></a>服务单去除 referer</h2><ul><li>严格来说不能说去除 refere,我们需要将原本我们自己服务器的 referer 修改为网易云服务器的 referer<h3 id="Java-版"><a href="#Java-版" class="headerlink" title="Java 版"></a>Java 版</h3><pre><code class="java">  public void playMV(HttpServletResponse res, String mvurl) throws IOException {          if (StringUtils.isEmpty(mvurl)){              return;          }          res.setContentType(&quot;video/mpeg4; charset=utf-8&quot;);          URLConnection connection = new URL(mvurl).openConnection();          connection.setRequestProperty(&quot;referer&quot;, &quot;http://music.163.com/&quot;);          connection.setRequestProperty(&quot;cookie&quot;, &quot;appver=1.5.0.75771;&quot;);          connection.connect();          InputStream is = connection.getInputStream();          OutputStream os = res.getOutputStream();          byte bf[] = new byte[2048];          int length;          try {              while ((length = is.read(bf)) &gt; 0) {                  os.write(bf, 0, length);              }          } catch (IOException e) {              is.close();              os.close();              return;          }          is.close();          os.close();      }</code></pre></li></ul><p>解释: </p><ol><li>首先我们请求的资源不是本地的资源,是存储在其他服务器上的,这里用到的是URL</li><li>这里我们需要设置 referer 和 cookie,结合前面使用的 URL, 这里使用的是URLConnection</li><li>后面的就很好理解了,相当于做了一个管道,将读取的文件流原封不动的通过Response返回给调用者</li><li>不要忘了设置 setContentType 为 MP4 的格式</li></ol><h3 id="nodejs-版"><a href="#nodejs-版" class="headerlink" title="nodejs 版"></a>nodejs 版</h3><pre><code class="javascript">    const express = require(&quot;express&quot;);    const router = express();    const request = require(&quot;request&quot;);    router.get(&quot;/&quot;, (req, res) =&gt; {      const url = req.query.url;      const headers = {        &quot;Referer&quot;: &quot;http://music.163.com/&quot;,        &quot;Cookie&quot;: &quot;appver=1.5.0.75771;&quot;,        &#39;Content-Type&#39;: &#39;video/mp4&#39;,        &#39;Location&#39;: url      };      const options = {        header: headers,        url: url      };      request(options).on(&#39;error&#39;, err =&gt; {          res.send({ err })        }).pipe(res)    });    module.exports = router;</code></pre><p>解释:<br>和上面的 Java 版代码是一个意思,主要是 pipe 流管道将文件流返回给调用者</p><h3 id="功能完成"><a href="#功能完成" class="headerlink" title="功能完成"></a>功能完成</h3><ul><li>那么这样解决了 MP4 地址防盗链的问题</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>不足之处也暴露了</li><li>首先这段代码必须部署到服务端</li><li>部署到服务端就需要服务器去拉去 MV 的流信息,这无疑给服务器增加过多的流量压力</li><li>其次,由于使用的流传输,这个 MP4 的播放是不支持快进操作的</li></ul><h2 id="有个简单的解决方式"><a href="#有个简单的解决方式" class="headerlink" title="有个简单的解决方式"></a>有个简单的解决方式</h2><ul><li>在 html5 之后,想去除 referer 信息, a标签有个属性 rel </li><li>将 <code>rel=&quot;noreferrer&quot;</code> 即可在 a 标签的 href 的链接上去除 referer信息</li><li>这一属性已被我使用在播放器的右下角的一个小飞机的按钮上</li><li>点击小飞机按钮就可以直接看 MV 视频了,流量走的是网易云的CDN,不再试自己的服务器</li></ul><p><img src="http://image.joylau.cn/blog/joymusic-mv-no-referer-href.png" alt="joymusic-mv-no-referer-href"></p><h2 id="不完美"><a href="#不完美" class="headerlink" title="不完美"></a>不完美</h2><ul><li>总感觉这个解决不够完美</li><li>如果你看到这篇文章能有更好的解决办法,请联系我</li></ul><blockquote><blockquote><p>欢迎大家来看看试试看!😘 <a href="http://music.joylau.cn" target="_blank" rel="noopener">http://music.joylau.cn</a>  (当前版本 v1.4)</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Node.js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 实战项目 JoyMedia （ 搜索篇 ）</title>
      <link href="/2017/08/06/SpringBoot-JoyMedia-Search/"/>
      <url>/2017/08/06/SpringBoot-JoyMedia-Search/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h3><p><img src="//image.joylau.cn/blog/jquery-autocomplate.gif" alt="JoyMedia - Search"></p><h3 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h3><ul><li><a href="//music.joylau.cn" target="_blank" rel="noopener">JoyMusic</a><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3></li><li>正如文章图片那样,在搜索框中输入想听的音乐/歌手/专辑</li><li>在输入过程中及输入完成后,显示搜索结果的列表供用户选择<h3 id="材料"><a href="#材料" class="headerlink" title="材料"></a>材料</h3></li><li>REST 接口</li><li>jquery-autocomplete插件</li></ul><h2 id="优美的开始"><a href="#优美的开始" class="headerlink" title="优美的开始"></a>优美的开始</h2><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ul><li>引入插件 css: jquery.autocomplete.css</li><li>引入插件 js : jquery.autocomplete.min.js</li><li>写一个数据返回的 REST 接口<h3 id="开始操作"><a href="#开始操作" class="headerlink" title="开始操作"></a>开始操作</h3></li><li>定义搜索的 input 的 id 值</li></ul><pre><code class="html">    &lt;div class=&quot;navbar-form navbar-left input-s-lg m-t m-l-n-xs hidden-xs&quot;&gt;            &lt;div class=&quot;form-group&quot; style=&quot;display: inline&quot;&gt;                &lt;div class=&quot;input-group&quot;&gt;                &lt;span class=&quot;input-group-btn&quot;&gt;                  &lt;button class=&quot;btn btn-sm bg-white btn-icon rounded&quot;&gt;&lt;i class=&quot;fa fa-search&quot;&gt;&lt;/i&gt;&lt;/button&gt;                &lt;/span&gt;                    &lt;input id=&quot;keywords&quot; type=&quot;text&quot; class=&quot;form-control input-sm no-border rounded&quot; placeholder=&quot;搜索  单曲/歌手/专辑...&quot;&gt;                &lt;/div&gt;            &lt;/div&gt;    &lt;/div&gt;</code></pre><ul><li>这里我定义的是 keywords</li><li>接下来在我们的 js 文件里调用 : $(“#keywords”).autocomplete</li></ul><pre><code class="javascript">    $(&quot;#keywords&quot;).autocomplete(&quot;/music/neteaseCloud/search&quot;, {            width : 350, // 提示的宽度，溢出隐藏            max : 30,// 显示数量            scrollHeight: 600,            resultsClass: &quot;ac_results animated fadeInUpBig&quot;,            autoFill : false,//自动填充            highlight : false,            highlightItem: true,            scroll : true,            matchContains : true,            multiple :false,            matchSubset: false,            dataType: &quot;json&quot;,            formatItem: function(row, i, max) {                //自定义样式            },            formatMatch: function(row, i, max) {                return row.name + row.id;            },            formatResult: function(row) {                return row.id;            },            parse:function(data) {                //解释返回的数据，把其存在数组里                if (data.data.length === 0) {                    return [];                }else {                    return $.map(data.data, function(row) {                        return {                            data: row                        }                    });                }            }        }).result(function(event, row, formatted) {            jQuery(this).val(row.name + &#39; &#39; + row.author);            addSearchResult(row.id);        });</code></pre><h3 id="接下来重点解释这个配置项"><a href="#接下来重点解释这个配置项" class="headerlink" title="接下来重点解释这个配置项"></a>接下来重点解释这个配置项</h3><ul><li>autocomplete 的第一个参数是url, 值得注意的是,这个 url 我们返回的结果数据是 JSON</li><li>后面要专门针对返回的 JSON 数据进行解析</li><li>再往后面来,看到的是一些配置项参数,一些简单的我就不在这多解释了,我这边主要说下我觉得比较重要的</li><li>resultsClass : 这个参数是生成的候选项的父 DIV,如下图所示:</li></ul><p><img src="//image.joylau.cn/blog/jquery-autocomplate-div.png" alt="JoyMedia - AutoComplate-Div"></p><ul><li>默认提供的样式很不好看,默认提供的样式都写在 jquery.autocomplete.css 里面</li><li>在这里面,能看到刚才截图的 div : ac_results</li><li>那么我们要美化的就是 这个 div 和其子元素 li 的样式了</li><li>为了跟契合本站的主题,我采用的黑色主题风格</li><li>给ac_results添加了黑色背景色:background-color: #232c32</li><li>在js文件里搜索ac_results,添加动画效果,并将这个配置写到配置项里:resultsClass: “ac_results animated fadeInUpBig”</li><li>ul 里的 li 是交替的样式的,class 分别为ac_odd和 ac_even,鼠标滑上去的效果为 ac_over,这几个地方自定义下样式</li><li>还有一个配置: matchSubset,设置为 false ,可以避免输入大小写转换的js错误</li><li>formatItem : 返回的每一个结果都会再次处理,这里要做的事是以自己想要的样式显示出来</li><li>formatMatch : 匹配自己在结果集中想要的属性</li><li>formatResult : 自己最终要取的数据是什么</li><li>parse : 针对返回的JSON 数据进行转换,这里通过$. map 转化为 数组</li><li>result : 点击了列表项以后要做什么事情</li></ul><h2 id="完美的结束"><a href="#完美的结束" class="headerlink" title="完美的结束"></a>完美的结束</h2><blockquote><blockquote><p>欢迎大家来听听试试看!😘 <a href="http://music.joylau.cn" target="_blank" rel="noopener">http://music.joylau.cn</a>  (当前版本 v1.3)</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Jquery </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 实战项目 JoyMedia （ Node篇 ）</title>
      <link href="/2017/07/29/SpringBoot-JoyMedia-Node/"/>
      <url>/2017/07/29/SpringBoot-JoyMedia-Node/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h3><ul><li><a href="//music.joylau.cn" target="_blank" rel="noopener">JoyMusic</a><h3 id="Node-js-的学习"><a href="#Node-js-的学习" class="headerlink" title="Node.js 的学习"></a>Node.js 的学习</h3></li><li>入门是从这本书上开始的</li><li>结合Node中文网的文档开始探索开发</li></ul><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ul><li>利用 Node 来解析网易云音乐,其实质就是 跨站请求伪造 (CSRF),通过自己在本地代码中伪造网易云的请求头,来调用网易云的接口</li></ul><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="以获取歌曲评论来分析"><a href="#以获取歌曲评论来分析" class="headerlink" title="以获取歌曲评论来分析"></a>以获取歌曲评论来分析</h3><ul><li>我们打开其中一首音乐,抓包看一下</li></ul><p><img src="//image.joylau.cn/blog/joylau-media-node-1.png" alt="JoyMedia - Node"></p><ul><li>绝大部分的请求都是 POST 的</li><li>我们找到其中关于评论的请求,如上图所示</li><li>链接中间的部分是歌曲的 id 值</li><li>在返回的 JSON 数据中包含了热评和最新评论</li><li>评论过多的话是分页来展示的</li><li>通过参数 limit 来显示评论数量, offset 来控制分页</li></ul><p><img src="//image.joylau.cn/blog/joylau-media-node-2.png" alt="JoyMedia - Node"></p><ul><li>再来看,这是我本地浏览器中的 cookies 值,现在为止知道有个 csrf 值用来加密</li></ul><p><img src="//image.joylau.cn/blog/joylau-media-node-3.png" alt="JoyMedia - Node"></p><ul><li>每个请求后面都会跟上csrf_token 值,其他的参数还有params 和 encSecKey</li><li>这些值的加密算法无非是2种,一种是前台 js 加密生成的,另一种是将参数传往后台,由后台加密完再传回来</li><li>想要测试一下很简单,将里面的值复制一下在 xhr 里找一下就知道了</li><li>推测是是 js 加密的,加密的 js 简直不能看,如下图</li></ul><p><img src="//image.joylau.cn/blog/joylau-media-node-4.png" alt="JoyMedia - Node"></p><ul><li>看到很多请求后面都返回了 md5 那么 md5 加密是肯定有的</li><li>其实仔细看加密的参数,很多都能靠猜出来</li><li>本地需要创建一个私钥secKey，十六位，之后aes加密生成，在通过rsa吧secKey加密作为参数一起传回</li><li>那么下面贴出加密代码</li></ul><pre><code class="javascript">    const modulus = &#39;00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7&#39;;    const nonce = &#39;0CoJUm6Qyw8W8jud&#39;;    const pubKey = &#39;010001&#39;;    function createSecretKey(size) {      const keys = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;;      let key = &quot;&quot;;      for (let i = 0; i &lt; size; i++) {          let pos = Math.random() * keys.length;          pos = Math.floor(pos);          key = key + keys.charAt(pos)      }      return key    }    function aesEncrypt(text, secKey) {      const _text = text;      const lv = new Buffer(&#39;0102030405060708&#39;, &quot;binary&quot;);      const _secKey = new Buffer(secKey, &quot;binary&quot;);      const cipher = crypto.createCipheriv(&#39;AES-128-CBC&#39;, _secKey, lv);      let encrypted = cipher.update(_text, &#39;utf8&#39;, &#39;base64&#39;);      encrypted += cipher.final(&#39;base64&#39;);      return encrypted    }    function zfill(str, size) {        while (str.length &lt; size) str = &quot;0&quot; + str;        return str    }    function rsaEncrypt(text, pubKey, modulus) {      const _text = text.split(&#39;&#39;).reverse().join(&#39;&#39;);      const biText = bigInt(new Buffer(_text).toString(&#39;hex&#39;), 16),          biEx = bigInt(pubKey, 16),          biMod = bigInt(modulus, 16),          biRet = biText.modPow(biEx, biMod);      return zfill(biRet.toString(16), 256)    }    function Encrypt(obj) {      const text = JSON.stringify(obj);      const secKey = createSecretKey(16);      const encText = aesEncrypt(aesEncrypt(text, nonce), secKey);      const encSecKey = rsaEncrypt(secKey, pubKey, modulus);      return {        params: encText,        encSecKey: encSecKey      }    }</code></pre><ul><li>挺复杂的,很多我也是参考网络上其他人的加密方式</li></ul><h3 id="伪造网易云头部请求"><a href="#伪造网易云头部请求" class="headerlink" title="伪造网易云头部请求"></a>伪造网易云头部请求</h3><ul><li>这一步就很简单了,主要需要注意的就是 referer 的地址一定要是网易云的地址</li><li>其他的想 cookie 和 User-Agent 直接复制浏览器的即可</li><li>那我们构造一个 POST 的请求</li><li>需要都回到函数和错误返回回调函数</li><li>贴下代码</li></ul><pre><code class="javascript">    const Encrypt = require(&#39;./crypto.js&#39;);    const http = require(&#39;http&#39;);    function createWebAPIRequest(host, path, method, data, cookie, callback, errorcallback) {        let music_req = &#39;&#39;;        const cryptoreq = Encrypt(data);        const http_client = http.request({            hostname: host,            method: method,            path: path,            headers: {                &#39;Accept&#39;: &#39;*/*&#39;,                &#39;Accept-Language&#39;: &#39;zh-CN,zh;q=0.8,gl;q=0.6,zh-TW;q=0.4&#39;,                &#39;Connection&#39;: &#39;keep-alive&#39;,                &#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39;,                &#39;Referer&#39;: &#39;http://music.163.com&#39;,                &#39;Host&#39;: &#39;music.163.com&#39;,                &#39;Cookie&#39;: cookie,                &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36&#39;,            },        }, function (res) {            res.on(&#39;error&#39;, function (err) {                errorcallback(err)            });            res.setEncoding(&#39;utf8&#39;);            if (res.statusCode !== 200) {                createWebAPIRequest(host, path, method, data, cookie, callback);            } else {                res.on(&#39;data&#39;, function (chunk) {                    music_req += chunk                });                res.on(&#39;end&#39;, function () {                    if (music_req === &#39;&#39;) {                        createWebAPIRequest(host, path, method, data, cookie, callback);                        return                    }                    if (res.headers[&#39;set-cookie&#39;]) {                        callback(music_req, res.headers[&#39;set-cookie&#39;])                    } else {                        callback(music_req)                    }                })            }        });        http_client.write(&#39;params=&#39; + cryptoreq.params + &#39;&amp;encSecKey=&#39; + cryptoreq.encSecKey);        http_client.end()    }</code></pre><ul><li>那么再结合我们刚才分析的评论API, 发出该请求</li></ul><pre><code class="javascript">    const express = require(&quot;express&quot;);    const router = express();    const { createWebAPIRequest } = require(&quot;../common&quot;);    router.get(&quot;/&quot;, (req, res) =&gt; {        const rid=req.query.id;        const cookie = req.get(&#39;Cookie&#39;) ? req.get(&#39;Cookie&#39;) : &#39;&#39;;        const data = {            &quot;offset&quot;: req.query.offset || 0,            &quot;rid&quot;: rid,            &quot;limit&quot;: req.query.limit || 20,            &quot;csrf_token&quot;: &quot;&quot;        };        createWebAPIRequest(            &#39;music.163.com&#39;,            `/weapi/v1/resource/comments/R_SO_4_${rid}/?csrf_token=`,            &#39;POST&#39;,            data,            cookie,            music_req =&gt; {                res.send(music_req)            },            err =&gt; res.status(502).send(&#39;fetch error&#39;)        )    });    module.exports = router;</code></pre><ul><li>值得注意的是,这里我的 node 模板选择的 EJS 所使用的 js 语法格式也比较新,你需要将你 WebStorm 的 js 编译器的版本提升到ECMAScript 6,否则的话会报错,如下图所示:<br><img src="//image.joylau.cn/blog/joylau-media-node-5.png" alt="JoyMedia - Node"></li></ul><h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><ul><li>我们写一个入口文件,可以直接运行期容器,以及提供 APIs</li><li>那么,这个就跟简单了</li></ul><pre><code class="javascript">    const express = require(&#39;express&#39;);    const http = require(&#39;http&#39;);    const app = express();    const port = 3000;    const v = &#39;/apis/v1&#39;;    app.listen(port, () =&gt; {        console.log(`server starting ${port}`)    });    /*APIs 列表*/    app.use(express.static(&#39;public&#39;));    //推荐歌单    app.use(v + &quot;/personalized&quot;, require(&quot;./apis/personalized&quot;));    //歌单评论    app.use(v + &#39;/comment/playlist&#39;, require(&#39;./apis/comment_playlist&#39;));    //获取歌单内列表    app.use(v + &#39;/playlist/detail&#39;, require(&#39;./apis/playlist_detail&#39;));    //获取音乐详情    app.use(v + &#39;/song/detail&#39;, require(&#39;./apis/song_detail&#39;));    //单曲评论    app.use(v + &#39;/comment/music&#39;, require(&#39;./apis/comment_music&#39;));    //获取音乐 url    app.use(v + &#39;/music/url&#39;, require(&#39;./apis/musicUrl&#39;));    // 获取歌词    app.use(v + &#39;/lyric&#39;, require(&#39;./apis/lyric&#39;))    process.on(&#39;uncaughtException&#39;, function (err) {        //打印出错误的调用栈方便调试        console.log(err.stack);    });    module.exports = app;</code></pre><ul><li>引用 http 模块,开启 node 的默认3000 端口 </li><li>目前提供了上述注释里所写的 APIs</li><li>每一个 API 都会单独写一个模块,以在此调用</li><li>有一个地方值得注意的事</li><li>node 是单线程的异步 IO,这使得他在高并发方面得到很快相应速度,但是也有缺点</li><li>当其中一个操作出错异常了,就会导致整个服务挂掉</li><li>我在此的处理方式是:监听全局异常,捕到异常后将错误的堆栈信息打印出来,这样使得后续的操作不得进行以至于使整个服务挂掉</li><li>当然,还有其他的方式来处理,可以通过引用相应的模块,来守护 node 的进程,简单的来说就是挂掉我就给你重启</li><li>我觉得第二种方式不是我想要的,我是采取的第一种方式</li><li>况且我还真想看看是什么错误引起的</li><li>最后发现都是网络原因引起的错误 🤣🤣🤣🤣😂😂😂😂😂</li></ul><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><ul><li>npm install</li><li>node app.js</li></ul><h2 id="查看效果"><a href="#查看效果" class="headerlink" title="查看效果"></a>查看效果</h2><p><img src="//image.joylau.cn/blog/joylau-media-node-7.png" alt="JoyMedia - Node"></p><p><img src="//image.joylau.cn/blog/joylau-media-node-6.png" alt="JoyMedia - Node"></p><blockquote><blockquote><p>欢迎大家来听听试试看!😘 <a href="http://music.joylau.cn" target="_blank" rel="noopener">http://music.joylau.cn</a>  (当前版本 v1.3)</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Node.js </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 实战项目 JoyMedia （ 分析篇 ）</title>
      <link href="/2017/07/24/SpringBoot-JoyMedia/"/>
      <url>/2017/07/24/SpringBoot-JoyMedia/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><center><p><img src="//image.joylau.cn/blog/JoyMedia.gif" alt="JoyMedia - Beta - 预览图"><br><img src="//image.joylau.cn/blog/JoyMedia.png" alt="JoyMedia - Beta - 系统结构"></p></center><h2 id="在线地址"><a href="#在线地址" class="headerlink" title="在线地址"></a>在线地址</h2><p><a href="http://media.joylau.cn" target="_blank" rel="noopener">JoyMedia - Beta 预览版</a></p><h2 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h2><h3 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a>实现目的</h3><ul><li>本人经常在写代码或者没事的时候会听一些音乐</li><li>以前大部分会选择本地安装客户端</li><li>其中最喜欢的认为做的比较好的音乐客户端实属网易云音乐了</li><li>无论是从 Mac 版的客户端,还是 IOS 版的客户端,界面都非常优美,简直是极客和码农的必备</li><li>最主要是的网易云的歌曲推荐功能,很强大,我一度认为2个人的歌单相似度超过90%,就可以在一起了,这样再也不怕找不到对象了,😆</li><li>但也有些问题,网易云有一些版权音乐,是无法听到的,有时候昨天还在听得音乐,今天就听不了了</li><li>这就很烦了</li></ul><h3 id="自己的想法"><a href="#自己的想法" class="headerlink" title="自己的想法"></a>自己的想法</h3><ul><li>最初想把这个版权音乐的 mp3 地址解析出来,这样就可以直接听了</li><li>恩,想法很 nice</li><li>那么,照着这个想法做吧</li></ul><h2 id="项目实现"><a href="#项目实现" class="headerlink" title="项目实现"></a>项目实现</h2><h3 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h3><ul><li>正如上述系统结构所示</li><li>我自己有2台云服务器,一台阿里云的,另一台是腾讯云的</li><li>这2台服务器,我是这样分配的: 阿里云只提供 WEB 服务,腾讯云为 WEB 访问提供各种服务</li><li>当然服务器上我还跑了其他服务</li></ul><h3 id="阿里云服务器"><a href="#阿里云服务器" class="headerlink" title="阿里云服务器"></a>阿里云服务器</h3><ul><li>Nginx 主要负责了 JoyMedia 的 负载均衡,在该台服务器上,我用 部署了2个 spring-boot 项目,以权重的方式配置了负载均衡,这样我在更新项目的时候可以保证另一个服务的可用性</li><li>当然 Nginx 还有个反向代理的作用, upstream 配置了其他项目的访问</li><li>还有台 Redis 服务了,爬到的数据会存到 Redis 了,以供 WEB 服务迅速读取,当然在有些地方不会读取 Redis ,比如单曲歌曲播放的 mp3地址的获取</li><li>在最开始的时候我会先在后台解析出来再存到 Redis 里,但是发现网易云的歌曲 mp3 地址失效太快了,有时会导致播放异常,不如实时解析来的实在</li><li>在比如单首歌曲的评论的获取,这个得是实时解析的</li></ul><h3 id="腾讯云服务器"><a href="#腾讯云服务器" class="headerlink" title="腾讯云服务器"></a>腾讯云服务器</h3><ul><li>提供网易云音乐解析的是一个 Node 服务，这个 Node 服务是如何解析地址的，这个需要单独再写一篇文章，先知道这个 Node 服务是干嘛的就好</li><li>然后部署了3个spring-boot服务，分别提供了各自的服务，有定时爬去网易云音乐的推荐歌单，爬取歌单的歌曲列表，爬取歌单评论</li><li>由于爬到的音乐信息很快就会失效，这个服务都要定时的爬取</li><li>爬取到的数据的落地存储，我是存到的MongoDB中，在这篇文章中：<a href="http://blog.joylau.cn/2017/07/18/SpringBoot-MongoDB/">重剑无锋,大巧不工 SpringBoot — 整合使用MongoDB</a> , 我说明了为什么要选择 MongoDB</li><li>这3个服务爬到的数据会实时存到 Redis 中,另一方面,会异步存到 MongoDB 中,我想着这些数据或许还能做什么数据分析之类的,😄</li></ul><h2 id="初版完成后"><a href="#初版完成后" class="headerlink" title="初版完成后"></a>初版完成后</h2><h3 id="等我搭建完这个服务后-发现了问题"><a href="#等我搭建完这个服务后-发现了问题" class="headerlink" title="等我搭建完这个服务后,发现了问题"></a>等我搭建完这个服务后,发现了问题</h3><ul><li>有版权控制的音乐根本解析不到 mp3 的实际地址</li><li>那么我想听的音乐,听不到还是听不到,突然变得很尴尬</li></ul><h3 id="又有了想法"><a href="#又有了想法" class="headerlink" title="又有了想法"></a>又有了想法</h3><ul><li>一般情况下,我们在一家音乐网站上找不到自己想要的音乐,就回去其他音乐网站上找</li><li>恩,就这么干</li><li>网易云找不到的音乐,我就去虾米音乐,去 QQ 音乐找</li><li>这2个网站的音乐我都小试了下,都是可以的</li><li>于是我现在把这些功能集中在页面的搜索框中,搜索这3个音乐网站的结果,然后实施解析来播放</li><li>这是我下步要做的事情</li></ul><h3 id="有些地方还有-BUG"><a href="#有些地方还有-BUG" class="headerlink" title="有些地方还有 BUG"></a>有些地方还有 BUG</h3><ul><li>有些地方还是有 BUG 的,需要修复</li></ul><h3 id="有些地方功能还没写好"><a href="#有些地方功能还没写好" class="headerlink" title="有些地方功能还没写好"></a>有些地方功能还没写好</h3><ul><li>比如右上角的用户登录,现在的想法是使用第三方登录,比如 QQ, 微信…,但是是登录网易云音乐呢,还是登录网站呢?</li><li>要是登录网易云音乐的话,估计账号安全是个问题,而且登录接口不能频繁调用</li><li>要是登录网站的,好像没什么卵用</li><li>再比如左下角的歌词界面,虽然能获取到歌词,但是怎么做到歌词随着歌曲的播放实时滚动,这个现在还没有头绪…</li></ul><blockquote><blockquote><p>还在继续开发中…</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 整合使用MongoDB</title>
      <link href="/2017/07/18/SpringBoot-MongoDB/"/>
      <url>/2017/07/18/SpringBoot-MongoDB/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="MongoDB-安装"><a href="#MongoDB-安装" class="headerlink" title="MongoDB 安装"></a>MongoDB 安装</h3><ul><li><code>yum install mongodb-server  mongodb</code></li><li><code>systemctl start mongod</code></li><li><code>whereis mongo</code></li></ul><h3 id="MongoDB-配置文件"><a href="#MongoDB-配置文件" class="headerlink" title="MongoDB 配置文件"></a>MongoDB 配置文件</h3><ul><li>修改 bind_ip为 0.0.0.0 即可外网可访问</li><li>修改 fork 为 true 即可后台运行</li><li>修改 auth为 true 即访问连接时需要认证</li><li>修改 port 修改端口号</li></ul><h2 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;    &lt;/dependency&gt;</code></pre><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p><img src="//image.joylau.cn/blog/springboot-mongodb-config.png" alt="mongoDB配置"><br>还有种配置url方式: <code>spring.data.mongodb.uri=mongodb://name:pass@host:port/db_name</code></p><p>相比这种方式,我觉得第一种截图的方式要更直观一些</p><h3 id="在-SpringBoot-项目中使用"><a href="#在-SpringBoot-项目中使用" class="headerlink" title="在 SpringBoot 项目中使用"></a>在 SpringBoot 项目中使用</h3><ul><li>主要的一个接口<code>MongoRepository&lt;T,ID&gt;</code>,第一个是要存储的实体类,第二个参数是 ID 类型</li><li>自定义一个接口实现上述接口</li><li>定义实体类</li><li>自定义实现类可直接注入使用</li><li>默认的已经存在了增删改查的方法了,可以直接使用</li><li>想要更多的功能可以在接口中实现更多的自定义</li><li>下面截图所示:</li></ul><p>自定义一个 DAO :<br><img src="//image.joylau.cn/blog/springboot-mongodb-dao.png" alt="mongoDB-DAO"></p><p>查看如何使用 :<br><img src="//image.joylau.cn/blog/springboot-mongodb-method.png" alt="mongoDB-method"><br>有个 username 忘了配置了,得加上的</p><p>使用起来就是如此简单,感觉使用起来很像 mybatis 的 mapper 配置</p><h2 id="有一些注解的配置"><a href="#有一些注解的配置" class="headerlink" title="有一些注解的配置"></a>有一些注解的配置</h2><h3 id="有时候使用起来会有一些问题"><a href="#有时候使用起来会有一些问题" class="headerlink" title="有时候使用起来会有一些问题"></a>有时候使用起来会有一些问题</h3><ul><li>在默认策略下, Java 实体类叫什么名字,生成后的表名就叫什么,但我们可能并不想这样</li><li>同样的道理,有时属性名和字段也并不想一样的</li><li>有时一些属性我们也并不想存到 MongoDB<h3 id="注解解决这些问题"><a href="#注解解决这些问题" class="headerlink" title="注解解决这些问题"></a>注解解决这些问题</h3></li><li><code>@Id</code> : 标明表的 ID , 自带索引,无需维护</li><li><code>@Document</code> : 解决第一个问题</li><li><code>@Field</code> : 解决第二个问题</li><li><code>@Transient</code> : 解决第三个问题<h3 id="此外-还有其他的注解"><a href="#此外-还有其他的注解" class="headerlink" title="此外,还有其他的注解"></a>此外,还有其他的注解</h3>可能并不常用,在此也说明下</li><li><code>@Indexed(unique = true)</code> : 加在属性上,标明添加唯一索引</li><li><code>@CompoundIndex</code> : 复合索引</li></ul><h2 id="预览"><a href="#预览" class="headerlink" title="预览"></a>预览</h2><p>查看下刚爬的网易云官网的歌曲信息吧</p><center> ![歌曲信息](//image.joylau.cn/blog/springboot-mongoDB-preview.gif) <center>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ZeroC Ice --- 高性能RPC技术王者</title>
      <link href="/2017/07/10/ZeroC-Ice/"/>
      <url>/2017/07/10/ZeroC-Ice/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul><li>ZeroC Ice 的背景我就不介绍了</li><li>ZeroC Ice 环境安装搭建，概念原理，技术基础，这些网络上都有，再介绍的话就是copy过来了，没有多大意义，不再赘述了</li><li>下面我们开始实战</li></ul><h3 id="开始动手"><a href="#开始动手" class="headerlink" title="开始动手"></a>开始动手</h3><ul><li>首先我们需要几个ice接口文件,比如说这几个：<br><img src="//image.joylau.cn/blog/ZeroC-Ice-1.png" alt="Ice 文件展示"></li><li>我们来看一下其中一个ice文件定义的接口说明<br><img src="//image.joylau.cn/blog/ZeroC-Ice-2.png" alt="Ice接口文件说明"><br>文件里定义了5个接口，可以很明显的的看到是区间的增删改查接口<br>刚好很适合我们对外提供增删改查的RESTFul API 接口<br>这里在对外提供 RESTFul API 是可以很清楚的 使用 POST GET PUT DELETE<br>可以说这里很好的提供了这样一个例子</li><li>命令 <code>slice2java xxx.ice</code> 生成 java 的 client，server类<br><img src="//image.joylau.cn/blog/ZeroC-Ice-3.png" alt="生成的Java类"><br>生成的Java文件很多，这个不用管，更不必更改里面的代码内容<br>你要是有兴趣的话，也可以将这些文件分为 client 和 server 分门别类的归纳好<br>打开看一下，里面的代码很混乱，无论是代码风格，样式，变量命名，对于我来说，简直不忍直视<br><img src="//image.joylau.cn/blog/ZeroC-Ice-5.png" alt="生成的Java代码"></li><li>编写client类<br><img src="//image.joylau.cn/blog/ZeroC-Ice-4.png" alt="client类"><br>代码如下：</li></ul><pre><code class="java">    @Data    @Component    @ConfigurationProperties(prefix = &quot;ice&quot;)    public class Client {        private String adapterName;        private String host;        private int port;        private Logger _logger = LoggerFactory.getLogger(Client.class);        /**         * 执行操作         *         * @param command 命令体         * @return Result         */        public Result execute(CommandBody command) {            Ice.Communicator ic = null;            try {                //初使化通信器                ic = Ice.Util.initialize();                //传入远程服务单元的名称、网络协议、IP及端口，获取接口的远程代理，这里使用的stringToProxy方式                Ice.ObjectPrx base = ic.stringToProxy(getStringProxy());                //通过checkedCast向下转换，获取接口的远程，并同时检测根据传入的名称获取的服务单元是否代理接口，如果不是则返回null对象                ZKRoadRangeAdminPrx interfacePrx = ZKRoadRangeAdminPrxHelper.checkedCast(base);                if (interfacePrx == null) {                    return new Result(false, &quot;Invalid proxy&quot;);                }                //把接口的方法传给服务端，让服务端执行                Result result = executeCommand(command, interfacePrx);                if (result == null) {                    return new Result(false, &quot;暂无此操作命令&quot;);                }                return result;            } catch (Exception e) {                _logger.info(e.getMessage(), e);                return new Result(false, &quot;连接错误！&quot; + e);            } finally {                if (ic != null) {                    ic.destroy();                }            }        }        /**         * 执行操作命令         *         * @param command      命令体         * @param interfacePrx 接口         * @return ProgramResponse         */        private Result executeCommand(CommandBody command, ZKRoadRangeAdminPrx interfacePrx) {            CommandType type = command.getCommandType();            if (type.equals(CommandType.addRange)) {                return returnMessage(interfacePrx.AddRange(command.getZkRoadRange()));            } else if (type.equals(CommandType.updateRange)) {                return returnMessage(interfacePrx.UpdateRange(command.getZkRoadRange()));            } else if (type.equals(CommandType.removeRange)) {                return returnMessage(interfacePrx.RemoveRange(command.getZkRoadRange().code));            } else if (type.equals(CommandType.getRange)) {                return new Result(true, JSONObject.toJSONString(interfacePrx.GetRange(command.getZkRoadRange().code)));            } else if (type.equals(CommandType.listRanges)) {                return new Result(true, JSONObject.toJSONString(interfacePrx.ListRanges()));            }            return null;        }        /**         * 获取配置的地址信息         *         * @return String         */        private String getStringProxy() {            return adapterName + &quot;:tcp -h &quot; + host + &quot; -p &quot; + port;        }        private Result returnMessage(boolean result) {            return result ? new Result(true, &quot;success&quot;) : new Result(false, &quot;failure&quot;);        }    }</code></pre><ul><li>需要三个配置： 适配器名，IP地址，端口号，配置在SpringBoot项目里，如下：<br><img src="//image.joylau.cn/blog/ZeroC-Ice-6.png" alt="ICE配置信息"></li></ul><h3 id="再封装一下"><a href="#再封装一下" class="headerlink" title="再封装一下"></a>再封装一下</h3><ul><li>封装返回消息体<br><img src="//image.joylau.cn/blog/ZeroC-Ice-8.png" alt="ICE配置信息"></li><li>封装执行命令体<br><img src="//image.joylau.cn/blog/ZeroC-Ice-7.png" alt="ICE配置信息"></li></ul><h3 id="重要"><a href="#重要" class="headerlink" title="重要"></a>重要</h3><ul><li>调用 ice 里的接口方法：获取远程代理的 checkedCast </li><li>获取远程接口的 interfacePrx 可直接调用 ice 文件里的方法</li><li>服务端的 Ice 版本最好和 客户端的版本相同</li><li>服务端提供服务时需要创建一个 servant ，一般的我们会在接口名后面加一个I，以此命名作为Java文件类名</li><li>该servant继承 接口文件的Disp类，并重写接口中定义的方法，实现具体的业务逻辑</li><li>Server端创建一个适配器 adapter，将servant 放进去</li><li>服务退出前，一直对请求持续监听</li></ul><h3 id="听首歌回忆下"><a href="#听首歌回忆下" class="headerlink" title="听首歌回忆下"></a>听首歌回忆下</h3><center><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=250 height=86 src="//music.163.com/outchain/player?type=2&id=135728&auto=1&height=66"></iframe></center>]]></content>
      
      
      <categories>
          
          <category> ZeroC Ice篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZeroC Ice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一次Git多仓库提交</title>
      <link href="/2017/07/03/Git-Multi-Repo-Push/"/>
      <url>/2017/07/03/Git-Multi-Repo-Push/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h2><ul><li>新建一个项目</li><li>可先分别在码云和 GitHub 上建好仓库&lt;可选&gt;</li><li>将项目提交的码云上</li><li>项目提交到另一个仓库的时候重新 define remote &lt;可选&gt;</li><li>之后每次先提交到本地仓库，可以根据每次提交到本地仓库的不同，来选择定义的 remote 来分别提交</li><li>每次 pull 也可以选择仓库</li></ul><h2 id="遇到个问题"><a href="#遇到个问题" class="headerlink" title="遇到个问题"></a>遇到个问题</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ul><li>在我新建好码云的仓库后，提交项目，遇到  Git Pull Failed: fatal: refusing to merge unrelated histories</li></ul><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul><li>原因：git拒绝合并两个不相干的东西</li></ul><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ul><li>此时在命令行输入 ： git pull origin master –allow-unrelated-histories</li><li>要求我输入提交信息</li><li>输入完成后，按一下Esc,再输入:wq,然后回车就OK了</li><li>再回来提交就可以了</li></ul>]]></content>
      
      
      <categories>
          
          <category> Git篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS常用开发使用APP</title>
      <link href="/2017/06/29/MacOS-Dev-App/"/>
      <url>/2017/06/29/MacOS-Dev-App/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="系统工具"><a href="#系统工具" class="headerlink" title="系统工具"></a>系统工具</h2><ul><li><strong>BetterZip</strong> : mac上面的最好的解压工具</li><li><strong>CHM View</strong> : 查看chm类型的开发文档</li><li><strong>Easy New File Free</strong> : 右击桌面，可以像win一样新建文件</li><li><strong>Bartender 2</strong> : 任务栏menu图标整理</li><li><strong>iStat Menus</strong> : 系统网速、cpu、内存监控工具</li><li><strong>SwitchResX</strong> : 外接显示器，调节DPI</li><li><strong>Go2Shell</strong> : 在finder的任意文件夹下打开终端</li><li><strong>Aria2GUI</strong> : 突破百度限速</li><li><strong>Alfred 3</strong> : 效率神器,谁用谁知道</li><li><strong>PDF Expert</strong> : 查看pdf</li><li><strong>远程桌面连接</strong> : mac电脑上远程连接windows,网址: <a href="https://rink.hockeyapp.net/apps/5e0c144289a51fca2d3bfa39ce7f2b06" target="_blank" rel="noopener">https://rink.hockeyapp.net/apps/5e0c144289a51fca2d3bfa39ce7f2b06</a> (2017年10月26日加)</li></ul><h2 id="播放器"><a href="#播放器" class="headerlink" title="播放器"></a>播放器</h2><ul><li><strong>网易云音乐</strong> ：这个必备啊</li><li><strong>优酷</strong> ：这个可以免费看1080P视频，没广告，有时候出抽风的时候还可以看会员视频</li><li><strong>OBS</strong> : 视频直播、录制软件</li><li><strong>Movist</strong> : 视频播放器,支持的格式很多</li></ul><h2 id="小工具"><a href="#小工具" class="headerlink" title="小工具"></a>小工具</h2><ul><li><strong>CleanMyMac 3</strong> : 清理mac电脑垃圾</li><li><strong>ShadowsocksX</strong> : 翻墙必备</li><li><strong>TeamView</strong> : 桌面远程软件</li><li><strong>MacDown</strong> : 开源的markdown编辑器</li><li><strong>Path Finder</strong> : Finder增强版</li><li><strong>Parallels Desktop</strong> : 虚拟机</li><li><strong>FileZilla</strong> : ftp工具</li><li><strong>Foxmail</strong> : 邮箱客户端</li><li><strong>Folx</strong> : 下载工具</li></ul><h2 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h2><ul><li><strong>FireFox</strong> : 火狐</li><li><strong>Google Chrome</strong> : 必备</li><li><strong>IntelliJ IDEA</strong> : 必备IDE</li><li><strong>WebStorm</strong> : web开发必备</li><li><strong>DataGrip</strong> : 数据库管理软件</li><li><strong>Navicat Premium</strong> : 已经使用习惯的MySQL连接工具，也支持其他数据库</li><li><strong>XShell</strong> : SSH远程连接工具,我还是比较喜欢终端下的ssh命令连接，虽然有一个家族的系列产品</li><li><strong>Sublime Text3</strong> : 文本编辑器</li><li><strong>Beyond Compare</strong> : 文本比较工具</li><li><strong>GitHub Desktop</strong> : github GUI客户端</li><li><strong>rdm</strong> : redis可视化GUI界面</li><li><strong>HBuilder</strong> : h5开发工具</li><li><strong>iTerm</strong> : 终端</li></ul><blockquote><blockquote><p>自己暂时使用的工具都已归纳出来，以后有新的好用的工具，会加上的，Mac下大部分工具都是收费的，你可以偷偷点一下 <a href="http://xclient.info/s/" target="_blank" rel="noopener">xclient.info</a></p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> MacBookPro </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacBook Pro 2017 --- 不行！我要开箱</title>
      <link href="/2017/06/24/MacBookPro-Unboxing/"/>
      <url>/2017/06/24/MacBookPro-Unboxing/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="官方视频"><a href="#官方视频" class="headerlink" title="官方视频"></a>官方视频</h2><center><video src="//image.joylau.cn/blog/macbook-pro-design.mp4" loop="true" controls="controls" poster="//image.joylau.cn/blog/MacBookPro-unboxing-video.png">您的浏览器版本太低，无法观看本视频</video></center><h2 id="开始拆箱"><a href="#开始拆箱" class="headerlink" title="开始拆箱"></a>开始拆箱</h2><center>![MacBook Pro](http://image.joylau.cn/blog/macbookpro/IMG_2180.JPG)<p>先来看一下刚拿到手的包装是什么样的</p><p>一台主机</p><p>我在官网订购了一个 USB-typeC 转 USB 的转接口</p><p>那个小盒子就是</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2181.JPG" alt="MacBook Pro"></p><p>打开主机纸盒</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2182.JPG" alt="MacBook Pro"></p><p>掰开这个直接就可以把里面的主机盒抽出来,很方便</p><p>两边都是这样设计的</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2183.JPG" alt="MacBook Pro"></p><p>就2样东西</p><p>都摆放好了</p><p>准备拿剪刀拆开</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2184.JPG" alt="MacBook Pro"></p><p>来一张侧面照</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2185.JPG" alt="MacBook Pro"></p><p>拆开盒子保护膜</p><p>打开镂空设计的上盖，看到我们的主机真容</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2186.JPG" alt="MacBook Pro"></p><p>这样一看，真的很薄，起码比我以前用过得笔记本都要薄多了</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2187.JPG" alt="MacBook Pro"></p><p>2端都是 USB-C 接口的充电线</p><p>适配器感觉好大啊</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2188.JPG" alt="MacBook Pro"></p><p>靠近点看下USB-C的充电线</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2189.JPG" alt="MacBook Pro"></p><p>然后就什么都没有了</p><p>底下的盒子也打不开</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2190.JPG" alt="MacBook Pro"></p><p>苹果的LOGO贴纸</p><p>说明书</p><p>三包凭证</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2191.JPG" alt="MacBook Pro"></p><p>开始正式拆开主机的包装纸</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2192.JPG" alt="MacBook Pro"></p><p>一睹真容<br>15.6寸的</p></center><h2 id="进入系统"><a href="#进入系统" class="headerlink" title="进入系统"></a>进入系统</h2><center>![MacBook Pro](http://image.joylau.cn/blog/macbookpro/IMG_2193.JPG)<p>盖子一打开就开机了</p><p>屏幕与键盘之间隔了一张纸</p><p>让我们拿开他</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2194.JPG" alt="MacBook Pro"></p><p>很快就进入了系统</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2195.JPG" alt="MacBook Pro"></p><p>重新设计的蝴蝶键盘</p><p>键程很短</p><p>按键很紧凑</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2196.JPG" alt="MacBook Pro"></p><p>来一张键盘的整体照</p><p>上面是全新的 Multi-Touch Bar ，替换了以前的一排功能按键，许多mac内置的应用在Touch Bar上都有支持</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2197.JPG" alt="MacBook Pro"></p><p>触摸板的占比实在是太大了</p><p>看我一只手放上去，刚好差不多</p><p>手有点丑，请忽略</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2198.JPG" alt="MacBook Pro"></p><p>迫不及待的想进入系统尝试一下了</p><p>先来连接家里的WIFI</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2199.JPG" alt="MacBook Pro"></p><p>老套路了</p><p>都是下一步</p><p>再下一步</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2200.JPG" alt="MacBook Pro"></p><p>在电源键上提供了和iPhone上一个的指纹支持</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2201.JPG" alt="MacBook Pro"></p><p>来录入我自己的指纹</p><p>不知道用的是什么材料，在这个TouchBar上面滑来滑去很舒服，很有感觉</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2202.JPG" alt="MacBook Pro"></p><p>正在设置指纹</p><p>稍等一下</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2203.JPG" alt="MacBook Pro"></p><p>终于正式进入系统了</p><p>屏幕的显示效果很震撼</p><p>特效动画的帧数很高，给人感觉很流畅</p></center><h2 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h2><center>![MacBook Pro](http://image.joylau.cn/blog/macbookpro/IMG_2204.JPG)<p>看一下系统信息</p><p><img src="http://image.joylau.cn/blog/macbookpro/IMG_2205.JPG" alt="MacBook Pro"></p><p>显示器信息</p><p>2G独立显存</p></center><h2 id="个人感受"><a href="#个人感受" class="headerlink" title="个人感受"></a>个人感受</h2><h3 id="使用它也有一周多了，说一下自己的整体感受吧"><a href="#使用它也有一周多了，说一下自己的整体感受吧" class="headerlink" title="使用它也有一周多了，说一下自己的整体感受吧"></a>使用它也有一周多了，说一下自己的整体感受吧</h3><ul><li>Retina显示器的显示效果真的很好，真是惯坏了眼睛，现在再去看普通的显示器，就感觉有很强的颗粒感</li><li>macOS High Sierra字体渲染的很棒，系统中有很多适合编程的字体，在 IntelliJ IDEA 中编码很爽</li><li>更大的分辨率能看到更多的内容</li><li>系统安装软件什么的很方便，没有想Windows下那么碎片化</li><li>Multi-Touch Bar 有很多有意思的功能，除了官方宣传的和MacOS本身自带的，想滑动查看照片，添加emoji小表情，控制亮度。。。之类的，大量第三方的软件也进行了适配，网易云音乐，搜狗输入法就适配的很不错</li><li>系统触摸板真的是Windows平台无法比拟的，有很多手势，编码什么的，完全可以不用鼠标</li><li>键盘旁边2个喇叭的音质效果很震撼，而且声音特别大，看电影，听音乐很有感觉</li><li>耗电也比Windows系统的笔记本少多了，充满电的话，就拿我平时工作情况来说，开多个IDEA，起多个服务，多个浏览器，多个编辑器。。。什么什么的，大概能撑个8，9个小时，上班一天不充电….</li><li>颜值好，很符合现代化审美</li></ul><h3 id="缺点也还是有的"><a href="#缺点也还是有的" class="headerlink" title="缺点也还是有的"></a>缺点也还是有的</h3><ul><li>太贵</li></ul>]]></content>
      
      
      <categories>
          
          <category> MacOS篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> MacBookPro </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- RESTful API</title>
      <link href="/2017/06/18/SpringBoot-RESTfulAPI/"/>
      <url>/2017/06/18/SpringBoot-RESTfulAPI/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul><li>使用很简单</li><li>关注业务开发</li><li>熟悉提供的注解</li></ul><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;        &lt;version&gt;2.7.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;        &lt;version&gt;2.7.0&lt;/version&gt;    &lt;/dependency&gt;</code></pre><h3 id="配置启动"><a href="#配置启动" class="headerlink" title="配置启动"></a>配置启动</h3><pre><code class="java">    @SpringBootApplication    @EnableSwagger2    public class JoylauSwagger2Application {        public static void main(String[] args) {            SpringApplication.run(JoylauSwagger2Application.class, args);        }        @Bean        public Docket createRestApi() {            return new Docket(DocumentationType.SWAGGER_2)                    .apiInfo(apiInfo())                    .select()                    .apis(RequestHandlerSelectors.basePackage(&quot;cn.joylau.code&quot;))                    .paths(PathSelectors.any())                    .build();        }        private ApiInfo apiInfo() {            return new ApiInfoBuilder()                    .title(&quot;Spring Boot构建RESTful APIs&quot;)                    .description(&quot;将每一个注解的@RestController和@ResponseBody的类和方法生成API，点击即可展开&quot;)                    .termsOfServiceUrl(&quot;http://blog.joylau.cn&quot;)                    .contact(new Contact(&quot;joylau&quot;,&quot;http://blog.joylau.cn&quot;,&quot;2587038142@qq.com&quot;))                    .license(&quot;The Apache License, Version 2.0&quot;)                    .licenseUrl(&quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;)                    .version(&quot;1.0&quot;)                    .build();        }    }</code></pre><h3 id="注解说明"><a href="#注解说明" class="headerlink" title="注解说明"></a>注解说明</h3><pre><code class="java">    @RestController    @RequestMapping(value=&quot;/users&quot;)     // 通过这里配置使下面的映射都在/users下，可去除    public class UserController {        static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;());        @ApiOperation(value=&quot;获取用户列表&quot;, notes=&quot;&quot;)        @RequestMapping(value={&quot;&quot;}, method= RequestMethod.GET)        public List&lt;User&gt; getUserList() {            List&lt;User&gt; r = new ArrayList&lt;User&gt;(users.values());            return r;        }        @ApiOperation(value=&quot;创建用户&quot;, notes=&quot;根据User对象创建用户&quot;)        @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;)        @RequestMapping(value=&quot;&quot;, method=RequestMethod.POST)        public String postUser(@RequestBody User user) {            users.put(user.getId(), user);            return &quot;success&quot;;        }        @ApiOperation(value=&quot;获取用户详细信息&quot;, notes=&quot;根据url的id来获取用户详细信息&quot;)        @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;)        @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.GET)        public User getUser(@PathVariable Long id) {            return users.get(id);        }        @ApiOperation(value=&quot;更新用户详细信息&quot;, notes=&quot;根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息&quot;)        @ApiImplicitParams({                @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;),                @ApiImplicitParam(name = &quot;user&quot;, value = &quot;用户详细实体user&quot;, required = true, dataType = &quot;User&quot;)        })        @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.PUT)        public String putUser(@PathVariable Long id, @RequestBody User user) {            User u = users.get(id);            u.setName(user.getName());            u.setAge(user.getAge());            users.put(id, u);            return &quot;success&quot;;        }        @ApiOperation(value=&quot;删除用户&quot;, notes=&quot;根据url的id来指定删除对象&quot;)        @ApiImplicitParam(name = &quot;id&quot;, value = &quot;用户ID&quot;, required = true, dataType = &quot;Long&quot;)        @RequestMapping(value=&quot;/{id}&quot;, method=RequestMethod.DELETE)        public String deleteUser(@PathVariable Long id) {            users.remove(id);            return &quot;success&quot;;        }    }</code></pre><h3 id="常见注解"><a href="#常见注解" class="headerlink" title="常见注解"></a>常见注解</h3><ul><li><code>@Api</code>：修饰整个类，描述Controller的作用</li><li><code>@ApiOperation</code>：描述一个类的一个方法，或者说一个接口</li><li><code>@ApiParam</code>：单个参数描述</li><li><code>@ApiModel</code>：用对象来接收参数</li><li><code>@ApiProperty</code>：用对象接收参数时，描述对象的一个字段</li><li><code>@ApiResponse</code>：HTTP响应其中1个描述</li><li><code>@ApiResponses</code>：HTTP响应整体描述</li><li><code>@ApiIgnore</code>：使用该注解忽略这个API </li><li><code>@ApiClass</code></li><li><code>@ApiError</code></li><li><code>@ApiErrors</code></li><li><code>@ApiParamImplicit</code></li><li><code>@ApiParamsImplicit</code></li></ul><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ul><li>Swagger2默认将所有的Controller中的RequestMapping方法都会暴露，然而在实际开发中，我们并不一定需要把所有API都提现在文档中查看，这种情况下，使用注解@ApiIgnore来解决，如果应用在Controller范围上，则当前Controller中的所有方法都会被忽略，如果应用在方法上，则对应用的方法忽略暴露API</li></ul><p>或者重写方法</p><pre><code class="java">    public Docket createRestApi() {            Predicate&lt;RequestHandler&gt; predicate = new Predicate&lt;RequestHandler&gt;() {                @Override                public boolean apply(RequestHandler input) {                    Class&lt;?&gt; declaringClass = input.declaringClass();                    if (declaringClass == BasicErrorController.class)// 排除                        return false;                    if(declaringClass.isAnnotationPresent(RestController.class)) // 被注解的类                        return true;                    if(input.isAnnotatedWith(ResponseBody.class)) // 被注解的方法                        return true;                    return false;                }            };</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
            <tag> Swagger2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 整合RabbitMQ</title>
      <link href="/2017/06/16/SpringBoot-RabbitMQ/"/>
      <url>/2017/06/16/SpringBoot-RabbitMQ/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="本文说明"><a href="#本文说明" class="headerlink" title="本文说明"></a>本文说明</h3><ul><li>使用之前<code>rabbitMQ</code>的介绍我就不说了，我认为你已经了解了</li><li><code>rabbitMQ</code>和<code>activeMQ</code>的对比区别我也不说了，我认为你已经查过资料了</li><li><code>rabbitMQ</code>的安装，我也不说了，我认为你下载的时候已经看到了官网的安装说明，给一个Windows安装的链接：<a href="http://www.rabbitmq.com/install-windows.html" target="_blank" rel="noopener">http://www.rabbitmq.com/install-windows.html</a></li><li><code>rabbitMQ</code>web插件的启用，我也不说，我认为你已经会了</li><li>那我们开始吧</li></ul><h2 id="入门使用"><a href="#入门使用" class="headerlink" title="入门使用"></a>入门使用</h2><h3 id="在使用之前先看一下rabbitMQ-client的使用"><a href="#在使用之前先看一下rabbitMQ-client的使用" class="headerlink" title="在使用之前先看一下rabbitMQ-client的使用"></a>在使用之前先看一下rabbitMQ-client的使用</h3><p>先引入依赖：</p><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;        &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;        &lt;version&gt;3.6.0&lt;/version&gt;    &lt;/dependency&gt;</code></pre><p>在看代码：</p><pre><code class="java">    public void product() throws IOException, TimeoutException {            // 创建连接工厂            ConnectionFactory factory = new ConnectionFactory();            //设置RabbitMQ地址            factory.setHost(&quot;localhost&quot;);            factory.setPort(5672);            factory.setUsername(&quot;guest&quot;);            factory.setPassword(&quot;guest&quot;);            //创建一个新的连接            Connection connection = factory.newConnection();            //创建一个频道            Channel channel = connection.createChannel();            //声明一个队列 -- 在RabbitMQ中，队列声明是幂等性的（一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同），也就是说，如果不存在，就创建，如果存在，不会对已经存在的队列产生任何影响。            channel.queueDeclare(QUEUE_NAME, false, false, false, null);            String message = &quot;Hello World!&quot;;            //发送消息到队列中            channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes(&quot;UTF-8&quot;));            System.out.println(&quot;P [x] Sent &#39;&quot; + message + &quot;&#39;&quot;);            //关闭频道和连接            channel.close();            connection.close();        }        public void consumer() throws IOException, TimeoutException {            // 创建连接工厂            ConnectionFactory factory = new ConnectionFactory();            //设置RabbitMQ地址            factory.setHost(&quot;localhost&quot;);            factory.setPort(5672);            factory.setUsername(&quot;guest&quot;);            factory.setPassword(&quot;guest&quot;);            //创建一个新的连接            Connection connection = factory.newConnection();            //创建一个频道            Channel channel = connection.createChannel();            //声明要关注的队列 -- 在RabbitMQ中，队列声明是幂等性的（一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同），也就是说，如果不存在，就创建，如果存在，不会对已经存在的队列产生任何影响。            channel.queueDeclare(QUEUE_NAME, false, false, false, null);            System.out.println(&quot;C [*] Waiting for messages. To exit press CTRL+C&quot;);            //DefaultConsumer类实现了Consumer接口，通过传入一个频道，告诉服务器我们需要那个频道的消息，如果频道中有消息，就会执行回调函数handleDelivery            Consumer consumer = new DefaultConsumer(channel) {                @Override                public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {                    String message = new String(body, &quot;UTF-8&quot;);                    System.out.println(&quot;C [x] Received &#39;&quot; + message + &quot;&#39;&quot;);                }            };            //自动回复队列应答 -- RabbitMQ中的消息确认机制            channel.basicConsume(QUEUE_NAME, true, consumer);        }</code></pre><p>代码的注释很详细</p><h2 id="SpringBoot中的使用"><a href="#SpringBoot中的使用" class="headerlink" title="SpringBoot中的使用"></a>SpringBoot中的使用</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><pre><code class="xml">    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code class="yml">    spring:      rabbitmq:        host: localhost        port: 5672        username: guest        password: guest      output:        ansi:          enabled: always</code></pre><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><pre><code class="java">    @Component    public class Product {        @Autowired        private AmqpTemplate rabbitTemplate;        public void send() {            String context = &quot;hello &quot; + new Date();            System.out.println(&quot;生产者发送信息 : &quot; + context);            new Queue(&quot;hello&quot;);            this.rabbitTemplate.convertAndSend(&quot;hello&quot;, context);        }    }</code></pre><p>创建消息生产者Product。通过注入AmqpTemplate接口的实例来实现消息的发送，AmqpTemplate接口定义了一套针对AMQP协议的基础操作。在Spring Boot中会根据配置来注入其具体实现。在该生产者，我们会产生一个字符串，并发送到名为hello的队列中</p><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><pre><code class="java">    @Component    @RabbitListener(queues = &quot;hello&quot;)    public class Consumer {        @RabbitHandler        public void process(String hello) {            System.out.println(&quot;消费者接受信息 : &quot; + hello);        }    }</code></pre><p>创建消息消费者Consumer。通过@RabbitListener注解定义该类对hello队列的监听，并用@RabbitHandler注解来指定对消息的处理方法。所以，该消费者实现了对hello队列的消费，消费操作为输出消息的字符串内容。</p><h3 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h3><pre><code class="java">    @RunWith(SpringRunner.class)    @SpringBootTest    public class JoylauSpringBootRabbitmqApplicationTests {        @Autowired        private Product product;        @Test        public void test() throws Exception {            product.send();        }    }</code></pre><h3 id="再来一张图"><a href="#再来一张图" class="headerlink" title="再来一张图"></a>再来一张图</h3><p><img src="//image.joylau.cn/blog/spring-boot-rabbitmq-test.png" alt="示例截图"></p><h2 id="exchange-多个消费者"><a href="#exchange-多个消费者" class="headerlink" title="exchange 多个消费者"></a>exchange 多个消费者</h2><p>当Exchange和RoutingKey相同、queue不同时，所有消费者都能消费同样的信息<br>Exchange和RoutingKey、queue都相同时，消费者中只有一个能消费信息，其他消费者都不能消费该信息。</p><p>下面示例的队列名称可以随意写个,启动时 @RabbitListener 的 bindings 会自动使用 key 绑定队列到exchange</p><pre><code class="java">    @RabbitHandler    @RabbitListener(            bindings = @QueueBinding(                    value = @Queue(value = &quot;${spring.application.name}&quot;),                    exchange = @Exchange(value = &quot;${spring.rabbitmq.template.exchange}&quot;),                    key = &quot;${spring.rabbitmq.template.routing-key}&quot;)    )    public void listenerTrafficMessage(Message message){        System.out.println(message.getClass().getName());    }</code></pre><h2 id="消息返回队列"><a href="#消息返回队列" class="headerlink" title="消息返回队列"></a>消息返回队列</h2><p>需要处理完消息后在将消息返回队列的话需要配置 spring.rabbitmq.listener.simple.acknowledge-mode: manual<br>之后注解@RabbitListener 到方法上<br>Channel channel 进行返回</p><pre><code class="java">    @RabbitHandler    @RabbitListener(            bindings = @QueueBinding(                    value = @Queue(value = &quot;${spring.application.name}&quot;),                    exchange = @Exchange(value = &quot;${spring.rabbitmq.template.exchange}&quot;),                    key = &quot;${spring.rabbitmq.template.routing-key}&quot;)    )    public void listenerTrafficMessage(Message message, Channel channel){        System.out.println(message.getClass().getName());        try {            channel.basicNack(message.getMessageProperties().getDeliveryTag(),false,true);        } catch (IOException e) {            e.printStackTrace();        }    }</code></pre><pre><code class="yaml">    spring:      rabbitmq:        host: 192.168.10.224        port: 35672        username: guest        password: guest        virtual-host: /        listener:          simple:            acknowledge-mode: manual #设置消费端手动 ack            concurrency: 1 #消费者最小数量            max-concurrency: 1 #消费者最大数量            prefetch: 1 #在单个请求中处理的消息个数，他应该大于等于事务数量(unack的最大数量)        template:          exchange: SURVEY_CENTER          routing-key: trafficCongestionSituationBD</code></pre><p>在属性配置文件里面开启了ACK确认 所以如果代码没有执行ACK确认 你在RabbitMQ的后台会看到消息会一直留在队列里面未消费掉 只要程序一启动开始接受该队列消息的时候 又会收到</p><pre><code class="java">    // 告诉服务器收到这条消息 已经被我消费了 可以在队列删掉 这样以后就不会再发了    // 否则消息服务器以为这条消息没处理掉 后续还会在发，true确认所有消费者获得的消息    channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);</code></pre><p>丢弃消息</p><pre><code class="java">    //最后一个参数是：是否重回队列    channel.basicNack(message.getMessageProperties().getDeliveryTag(), false,false);    //拒绝消息    //channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);    //消息被丢失    //channel.basicReject(message.getMessageProperties().getDeliveryTag(), false);    //消息被重新发送    //channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);    //多条消息被重新发送    //channel.basicNack(message.getMessageProperties().getDeliveryTag(), true, true);</code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>让你的Windows控制台窗口更优美</title>
      <link href="/2017/06/16/Console-Better/"/>
      <url>/2017/06/16/Console-Better/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>Windows下最适合编程的字体要数<code>Consolas</code>字体了，那么如何将命令提示符换成Consolas字体呢？我们只需要注册以下信息即可:</p><pre><code class="bash">    Windows Registry Editor Version 5.00    [HKEY_CURRENT_USER\Console\%SystemRoot%_system32_cmd.exe]    &quot;WindowSize&quot;=dword:00170058    &quot;ScreenBufferSize&quot;=dword:01170058    &quot;WindowPosition&quot;=dword:0079004b    &quot;ColorTable01&quot;=dword:00235600    &quot;FontSize&quot;=dword:00120000    &quot;FontWeight&quot;=dword:00000190    &quot;FaceName&quot;=&quot;Consolas&quot;    &quot;FontFamily&quot;=dword:00000036</code></pre><p>新建一个文本文件，将信息保存到此文本文件中<br>然后将文本文件重命名为*.reg<br>双击此文件将其注册</p>]]></content>
      
      
      <categories>
          
          <category> 其他篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CMD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 属性注入</title>
      <link href="/2017/06/13/SpringBoot-ConfigurationProperties/"/>
      <url>/2017/06/13/SpringBoot-ConfigurationProperties/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="通常的属性注入"><a href="#通常的属性注入" class="headerlink" title="通常的属性注入"></a>通常的属性注入</h2><p>一般情况下我们使用<strong>Spring</strong>或者<strong>SpringMVC</strong>的时候会使用<code>@Value()</code>注入</p><p>使用<strong>SpringBoot</strong>的时候会使用<code>@ConfigurationProperties(prefix = &quot;xxxx&quot;)</code></p><p>注入自定义的呢？这样：<code>@ConfigurationProperties(prefix = &quot;xxx&quot;,locations = &quot;classpath:config/xxxx.properties&quot;)</code></p><h2 id="更复杂一点的注入"><a href="#更复杂一点的注入" class="headerlink" title="更复杂一点的注入"></a>更复杂一点的注入</h2><p>如上图所示我注入了一个<code>List&lt;String&gt;</code></p><h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><p>那么同样的方式，是否可以注入Map<String>,String[]….呢？</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p><code>properties</code>的文件被读取的时候使用的就是Map,那么我们知道Map是无序了，这样就会导致我们原先要求的一致性可能达不到</p><h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p><code>properties</code>文件改成采用<code>yml</code>文件，或者升级<strong>SpringBoot</strong>的版本，貌似新版本采用的<code>LinkedHashMap</code></p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 项目问题汇总及解决</title>
      <link href="/2017/06/12/SpringBoot-Question-Tips/"/>
      <url>/2017/06/12/SpringBoot-Question-Tips/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="引用本地包并打包部署的问题"><a href="#引用本地包并打包部署的问题" class="headerlink" title="引用本地包并打包部署的问题"></a>引用本地包并打包部署的问题</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>在最近的开发中需要对接C++服务提供的<code>ZeroC Ice</code>接口，客户机环境安装了和服务环境相同的Ice，服务端的Ice比较老，是3.4.0的版本<br>在maven的中央仓库中没有找到<strong>ice-3.4.0</strong>的jar包，只能引用安装路径下提供的jar了</li></ul><p>那么常用的写法是这样的：（包括但不限于SpringBoot）</p><pre><code class="xml">        &lt;!--Ice--&gt;            &lt;dependency&gt;                &lt;groupId&gt;Ice&lt;/groupId&gt;                &lt;artifactId&gt;Ice&lt;/artifactId&gt;                &lt;version&gt;3.4.0&lt;/version&gt;                &lt;scope&gt;system&lt;/scope&gt;                &lt;systemPath&gt;${basedir}/src/lib/Ice.jar&lt;/systemPath&gt;            &lt;/dependency&gt;</code></pre><p>我是在src下新建的lib目录，在开发编译的是没有问题的。</p><p>在进行打包的时候发现Ice.jar没有被打进去</p><p>相对于这个应用来说，打成jar包是最合适的做法了</p><blockquote><blockquote><p>这里说一下，用package打包，不要用SpringBoot插件的jar打包</p></blockquote></blockquote><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>在<em>build</em>里加上这一段：</p><pre><code class="xml">    &lt;build&gt;                ..............            &lt;resources&gt;                &lt;resource&gt;                    &lt;directory&gt;src/lib&lt;/directory&gt;                    &lt;targetPath&gt;BOOT-INF/lib/&lt;/targetPath&gt;                    &lt;includes&gt;                        &lt;include&gt;**/*.jar&lt;/include&gt;                    &lt;/includes&gt;                &lt;/resource&gt;                &lt;resource&gt;                    &lt;directory&gt;src/main/resources&lt;/directory&gt;                    &lt;targetPath&gt;BOOT-INF/classes/&lt;/targetPath&gt;                &lt;/resource&gt;            &lt;/resources&gt;        &lt;/build&gt;</code></pre><p>之后，再打包，再解压一看，果然是打进去了，完美~</p><p>然后，遇到了新问题……..</p><h3 id="以jar运行时没有主清单属性"><a href="#以jar运行时没有主清单属性" class="headerlink" title="以jar运行时没有主清单属性"></a>以jar运行时没有主清单属性</h3><p>之后便很愉快的使用 <code>java -jar  xxxxx.jar</code></p><p>提示：没有主清单属性</p><p>再解压一看，有Application.java类，但是jar包的大小明显不对，光SpringBoot父项目依赖的jar至少也有10+M了，这个大小明显不对</p><p>在结合没有主属性的错误，知道了错误的原因在这：</p><pre><code class="xml">        &lt;dependencyManagement&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;!-- Import dependency management from Spring Boot --&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                    &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;                    &lt;type&gt;pom&lt;/type&gt;                    &lt;scope&gt;import&lt;/scope&gt;                &lt;/dependency&gt;        &lt;dependencyManagement&gt;</code></pre><p>我用的项目是多模块依赖</p><p>解决的方式是：</p><pre><code class="xml">        &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                    &lt;version&gt;${spring-boot-dependencies.version}&lt;/version&gt;                    &lt;executions&gt;                        &lt;execution&gt;                            &lt;goals&gt;                                &lt;goal&gt;repackage&lt;/goal&gt;                            &lt;/goals&gt;                        &lt;/execution&gt;                    &lt;/executions&gt;                &lt;/plugin&gt;        &lt;/build&gt;</code></pre><p>正如我文章截图的那样，解决问题！</p><h3 id="父项目依赖-打包成jar"><a href="#父项目依赖-打包成jar" class="headerlink" title="父项目依赖,打包成jar"></a>父项目依赖,打包成jar</h3><p>同时加入以下代码</p><pre><code class="xml">    &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;configuration&gt;                        &lt;source&gt;1.8&lt;/source&gt;                        &lt;target&gt;1.8&lt;/target&gt;                    &lt;/configuration&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                    &lt;version&gt;${spring-boot.version}&lt;/version&gt;                    &lt;executions&gt;                        &lt;execution&gt;                            &lt;goals&gt;                                &lt;goal&gt;repackage&lt;/goal&gt;                            &lt;/goals&gt;                        &lt;/execution&gt;                    &lt;/executions&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/build&gt;</code></pre><h2 id="2017年9月19日更新"><a href="#2017年9月19日更新" class="headerlink" title="2017年9月19日更新"></a>2017年9月19日更新</h2><h3 id="SpringBoot-项目打包时修改-MANIFEST-MF-文件"><a href="#SpringBoot-项目打包时修改-MANIFEST-MF-文件" class="headerlink" title="SpringBoot 项目打包时修改 MANIFEST.MF 文件"></a>SpringBoot 项目打包时修改 MANIFEST.MF 文件</h3><p>一般情况下我们的 MANIFEST.MF内容如下：</p><pre><code class="bash">    Manifest-Version: 1.0    Implementation-Title: joylau-media    Implementation-Version: 1.7-RELEASE    Archiver-Version: Plexus Archiver    Built-By: JoyLau    Implementation-Vendor-Id: cn.joylau.code    Spring-Boot-Version: 1.5.4.RELEASE    Implementation-Vendor: Pivotal Software, Inc.    Main-Class: org.springframework.boot.loader.JarLauncher    Start-Class: cn.joylau.code.JoylauMediaApplication    Spring-Boot-Classes: BOOT-INF/classes/    Spring-Boot-Lib: BOOT-INF/lib/    Created-By: Apache Maven 3.5.0    Build-Jdk: 1.8.0_45    Implementation-URL: http://projects.spring.io/spring-boot/joylau-media     /</code></pre><p>解决：</p><pre><code class="xml">    &lt;plugin&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;configuration&gt;            &lt;!--fork :  如果没有该项配置，肯呢个devtools不会起作用，即应用不会restart --&gt;            &lt;fork&gt;true&lt;/fork&gt;        &lt;/configuration&gt;    &lt;/plugin&gt;    //修改版本号，一般为pom文件的版本    &lt;plugin&gt;        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;        &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;        &lt;version&gt;3.0.2&lt;/version&gt;        &lt;configuration&gt;            &lt;archive&gt;                &lt;manifestEntries&gt;                    &lt;Manifest-Version&gt;${version}&lt;/Manifest-Version&gt;                &lt;/manifestEntries&gt;            &lt;/archive&gt;        &lt;/configuration&gt;    &lt;/plugin&gt;</code></pre><h3 id="SpringBoot-项目中引入缓存"><a href="#SpringBoot-项目中引入缓存" class="headerlink" title="SpringBoot 项目中引入缓存"></a>SpringBoot 项目中引入缓存</h3><ul><li>引入依赖</li></ul><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;    &lt;/dependency&gt;</code></pre><p>@EnableCaching 开启缓存</p><p>@CacheConfig(cacheNames = “api_cache”) 配置一个缓存类的公共信息</p><p>@Cacheable() 注解到方法上开启缓存</p><p>@CachePut() 根据使用的条件来执行具体的方法</p><p>@CacheEvict() 根据配置的参数删除缓存</p><p>SpringBoot默认支持很多缓存，spring.cache.type就可以知道，默认的是实现的是SimpleCacheManage，这里我记一下怎么设置缓存的超时时间</p><pre><code class="java">    @Configuration    @EnableCaching    @EnableScheduling    public class CachingConfig {        public static final String CACHENAME = &quot;api_cache&quot;;        @Bean        public CacheManager cacheManager() {            return new ConcurrentMapCacheManager(CACHENAME);        }        @CacheEvict(allEntries = true, value = {CACHENAME})        @Scheduled(fixedDelay = 120 * 1000 ,  initialDelay = 500)        public void reportCacheEvict() {            System.out.println(&quot;Flush Cache &quot; + dateFormat.format(new Date()));        }    }</code></pre><p>这里巧妙的使用了 定时任务，再其加上注解CacheEvict来清除所有cache name 为 api——cache 的缓存，超时时间是120s</p><h3 id="在说说我比较喜欢的使用方式"><a href="#在说说我比较喜欢的使用方式" class="headerlink" title="在说说我比较喜欢的使用方式"></a>在说说我比较喜欢的使用方式</h3><p>单独写了篇文章，戳下面：</p><ul><li><a href="/2017/09/19/SpringBoot-CaffeineCache/">重剑无锋,大巧不工 SpringBoot — 推荐使用CaffeineCache</a></li></ul><blockquote><blockquote><p>持续更新中…</p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- @RequestBody JSON参数处理</title>
      <link href="/2017/06/12/SpringBoot-RequestBody/"/>
      <url>/2017/06/12/SpringBoot-RequestBody/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li>用jackson 作为json转换器的时候，如果传入的json的key 比接收对象多的话，就会报错</li></ul><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><h3 id="先看下SpringMVC原来的配置"><a href="#先看下SpringMVC原来的配置" class="headerlink" title="先看下SpringMVC原来的配置"></a>先看下SpringMVC原来的配置</h3><pre><code class="xml">            &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt;                &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt;                    &lt;property name=&quot;supportedMediaTypes&quot; value=&quot;application/json&quot; /&gt;                    &lt;property name=&quot;objectMapper&quot; ref=&quot;jacksonObjectMapper&quot; /&gt;                            &lt;/bean&gt;                &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;                    &lt;property name=&quot;supportedMediaTypes&quot;&gt;                          &lt;list&gt;                                &lt;value&gt;text/plain;charset=UTF-8&lt;/value&gt;                            &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;                            &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt;                          &lt;/list&gt;                      &lt;/property&gt;                        &lt;/bean&gt;            &lt;/mvc:message-converters&gt;</code></pre><p>这里的json转换器配置的是:<code>org.springframework.http.converter.json.MappingJackson2HttpMessageConverter</code></p><p>我们进入到这个类中发现，这个类是继承的 <code>AbstractJackson2HttpMessageConverter</code></p><p>而 <code>AbstractJackson2HttpMessageConverter</code> 继承的是 <code>AbstractHttpMessageConverter&lt;Object&gt;</code><br>找到这个包下面 有一个类 <code>GsonHttpMessageConverter</code> 同样继承的 <code>AbstractHttpMessageConverter&lt;Object&gt;</code><br>OK，就是他了 </p><pre><code class="xml">            &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt;                &lt;bean class=&quot;org.springframework.http.converter.json.GsonHttpMessageConverter&quot;&gt;&lt;/bean&gt;                &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;                    &lt;property name=&quot;supportedMediaTypes&quot;&gt;                          &lt;list&gt;                                &lt;value&gt;text/plain;charset=UTF-8&lt;/value&gt;                            &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt;                            &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt;                          &lt;/list&gt;                      &lt;/property&gt;                        &lt;/bean&gt;            &lt;/mvc:message-converters&gt;</code></pre><p>这样，参数就随便你整吧，多点少点杜无所谓，完全匹配不上就返回个{}给你</p><h3 id="来看下fastjson"><a href="#来看下fastjson" class="headerlink" title="来看下fastjson"></a>来看下fastjson</h3><p>fastjson下面有这个一个 package : <code>com.alibaba.fastjson.support.spring</code></p><p>根据字面意思可知，这里是对spring的支持</p><p>找到下面这个class <code>FastJsonHttpMessageConverter</code></p><pre><code class="java">    public class FastJsonHttpMessageConverter extends AbstractHttpMessageConverter&lt;Object&gt;</code></pre><p>OK，这个类同样也是继承了 AbstractHttpMessageConverter<Object> </p><p>只要把这个类注入进去就可以了</p><h3 id="SpringBoot使用FastJSON解析数据"><a href="#SpringBoot使用FastJSON解析数据" class="headerlink" title="SpringBoot使用FastJSON解析数据"></a>SpringBoot使用FastJSON解析数据</h3><ul><li>第一种继承WebMvcConfigurerAdapter，重写configureMessageConverters方法：</li></ul><pre><code class="java">    @Override    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {        super.configureMessageConverters(converters);        FastJsonHttpMessageConverter converter=new FastJsonHttpMessageConverter();        FastJsonConfig fastJsonConfig= new FastJsonConfig();        fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat);        converter.setFastJsonConfig(fastJsonConfig);        converters.add(converter);    }</code></pre><ul><li>第二种方式bean注入HttpMessageConverters：</li></ul><pre><code class="java">    @Bean      public HttpMessageConverters fastJsonHttpMessageConverters() {      FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter();      FastJsonConfig fastJsonConfig = new FastJsonConfig();      fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat);      fastConverter.setFastJsonConfig(fastJsonConfig);      HttpMessageConverter&lt;?&gt; converter = fastConverter;      return new HttpMessageConverters(converter);      } </code></pre>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> JSON </tag>
            
            <tag> Spring </tag>
            
            <tag> SpringMVC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2017年程序员高考试卷</title>
      <link href="/2017/06/09/College-Entrance-Examination-of-2017-for-Progarmmer/"/>
      <url>/2017/06/09/College-Entrance-Examination-of-2017-for-Progarmmer/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="2017年普通高等学校招生全国统一考试"><a href="#2017年普通高等学校招生全国统一考试" class="headerlink" title="2017年普通高等学校招生全国统一考试"></a>2017年普通高等学校招生全国统一考试</h2><blockquote><blockquote><center>程序员的高考试卷（A卷）    `考生类别：码农`</center></blockquote></blockquote><h3 id="1、程序员A：借我1000元吧。程序员B：给你凑个整数。程序员B借给程序员A多少钱？（）"><a href="#1、程序员A：借我1000元吧。程序员B：给你凑个整数。程序员B借给程序员A多少钱？（）" class="headerlink" title="1、程序员A：借我1000元吧。程序员B：给你凑个整数。程序员B借给程序员A多少钱？（）"></a>1、程序员A：借我1000元吧。程序员B：给你凑个整数。程序员B借给程序员A多少钱？（）</h3><p>&emsp;&emsp;&emsp;A. 1000元<br>&emsp;&emsp;&emsp;B. 1024元<br>&emsp;&emsp;&emsp;C. 1111元</p><h3 id="2、程序员A：嘿-是什么意思啊？程序员B：嘿-程序员A：呃-我问你-是什么意思？程序员B：问吧-程序员A：我刚才不是问了么？程序员B：啊？程序员A到底问了程序员B什么问题？（）"><a href="#2、程序员A：嘿-是什么意思啊？程序员B：嘿-程序员A：呃-我问你-是什么意思？程序员B：问吧-程序员A：我刚才不是问了么？程序员B：啊？程序员A到底问了程序员B什么问题？（）" class="headerlink" title="2、程序员A：嘿 //是什么意思啊？程序员B：嘿.程序员A：呃 我问你//是什么意思？程序员B：问吧.程序员A：我刚才不是问了么？程序员B：啊？程序员A到底问了程序员B什么问题？（）"></a><strong>2、程序员A：嘿 //是什么意思啊？程序员B：嘿.程序员A：呃 我问你//是什么意思？程序员B：问吧.程序员A：我刚才不是问了么？程序员B：啊？程序员A到底问了程序员B什么问题？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 嘿<br>&emsp;&emsp;&emsp;B. 呃 我问你<br>&emsp;&emsp;&emsp;C. //是什么意思</p><h3 id="3、为什么程序员分不清万圣节和圣诞节？（）"><a href="#3、为什么程序员分不清万圣节和圣诞节？（）" class="headerlink" title="3、为什么程序员分不清万圣节和圣诞节？（）"></a><strong>3、为什么程序员分不清万圣节和圣诞节？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 因为 31 OCT == 25 DEC<br>&emsp;&emsp;&emsp;B. 程序员只有加班/不加班，不过节<br>&emsp;&emsp;&emsp;C. 程序员没有女朋友，不过节</p><h3 id="4、程序员最怕弹出的窗口是（）"><a href="#4、程序员最怕弹出的窗口是（）" class="headerlink" title="4、程序员最怕弹出的窗口是（）"></a><strong>4、程序员最怕弹出的窗口是（）</strong></h3><p>&emsp;&emsp;&emsp;A.&emsp;&emsp;&emsp;<img src="//image.joylau.cn/blog/gaokao-a.jpg" alt="选项A"></p><p>&emsp;&emsp;&emsp;B.&emsp;&emsp;&emsp;<img src="//image.joylau.cn/blog/gaokao-b.jpg" alt="选项B"></p><p>&emsp;&emsp;&emsp;C.&emsp;&emsp;&emsp;<img src="//image.joylau.cn/blog/gaokao-c.jpg" alt="选项C"></p><h3 id="5、程序员：哎，太累了日子没法过了，怎么才能换行啊？（）"><a href="#5、程序员：哎，太累了日子没法过了，怎么才能换行啊？（）" class="headerlink" title="5、程序员：哎，太累了日子没法过了，怎么才能换行啊？（）"></a><strong>5、程序员：哎，太累了日子没法过了，怎么才能换行啊？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 打回车<br>&emsp;&emsp;&emsp;B. 不换行，日子不过了<br>&emsp;&emsp;&emsp;C. 除了敲代码，都不会，换行还是敲代码啊</p><h3 id="6、程序员会给自己的孩子起什么名字？（）"><a href="#6、程序员会给自己的孩子起什么名字？（）" class="headerlink" title="6、程序员会给自己的孩子起什么名字？（）"></a><strong>6、程序员会给自己的孩子起什么名字？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 依依、灵灵、依灵、灵依、依初<br>&emsp;&emsp;&emsp;B. Ctrl、Alt 、Delete<br>&emsp;&emsp;&emsp;C. 程序员怎么会有女朋友？</p><h3 id="7、如何快速挣到一百万？（）"><a href="#7、如何快速挣到一百万？（）" class="headerlink" title="7、如何快速挣到一百万？（）"></a><strong>7、如何快速挣到一百万？（）</strong></h3><p>&emsp;&emsp;&emsp;A. while<br>&emsp;&emsp;&emsp;B. 买彩票<br>&emsp;&emsp;&emsp;C. 当乞丐</p><h3 id="8、程序员下班前给老婆打电话：老婆，晚饭我带回来吃，你说买些啥？老婆：买1斤包子吧，如果遇到卖西瓜的，就买一个。程序员买包子时，看到旁边有人在卖西瓜。那么，程序员带了什么晚饭回家？（）"><a href="#8、程序员下班前给老婆打电话：老婆，晚饭我带回来吃，你说买些啥？老婆：买1斤包子吧，如果遇到卖西瓜的，就买一个。程序员买包子时，看到旁边有人在卖西瓜。那么，程序员带了什么晚饭回家？（）" class="headerlink" title="8、程序员下班前给老婆打电话：老婆，晚饭我带回来吃，你说买些啥？老婆：买1斤包子吧，如果遇到卖西瓜的，就买一个。程序员买包子时，看到旁边有人在卖西瓜。那么，程序员带了什么晚饭回家？（）"></a><strong>8、程序员下班前给老婆打电话：老婆，晚饭我带回来吃，你说买些啥？老婆：买1斤包子吧，如果遇到卖西瓜的，就买一个。程序员买包子时，看到旁边有人在卖西瓜。那么，程序员带了什么晚饭回家？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 1斤包子<br>&emsp;&emsp;&emsp;B. 1个包子<br>&emsp;&emsp;&emsp;C. 1个西瓜</p><h3 id="9、我GET不到你的笑点，怎么办？（）"><a href="#9、我GET不到你的笑点，怎么办？（）" class="headerlink" title="9、我GET不到你的笑点，怎么办？（）"></a><strong>9、我GET不到你的笑点，怎么办？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 智商不在一条线<br>&emsp;&emsp;&emsp;B. 太矮了，踩凳子上<br>&emsp;&emsp;&emsp;C. 用Post试试</p><h3 id="10、为什么吸烟的程序员不在乎香烟盒上的那个警告？（）"><a href="#10、为什么吸烟的程序员不在乎香烟盒上的那个警告？（）" class="headerlink" title="10、为什么吸烟的程序员不在乎香烟盒上的那个警告？（）"></a><strong>10、为什么吸烟的程序员不在乎香烟盒上的那个警告？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 字太小<br>&emsp;&emsp;&emsp;B. 程序员眼中只有程序<br>&emsp;&emsp;&emsp;C. 不关心Warning，只关心Error</p><h3 id="11、一对程序员恋人面对面坐着，他们在做什么？（）"><a href="#11、一对程序员恋人面对面坐着，他们在做什么？（）" class="headerlink" title="11、一对程序员恋人面对面坐着，他们在做什么？（）"></a><strong>11、一对程序员恋人面对面坐着，他们在做什么？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 面向对象编程<br>&emsp;&emsp;&emsp;B. 喝咖啡<br>&emsp;&emsp;&emsp;C. 抱怨产品经理</p><h3 id="12、老板：小程，下班前新版本一定要上线！小程：好的。第二天，老板上班，问小程：新版本怎么还没上线？-小程怎么回答的？（）"><a href="#12、老板：小程，下班前新版本一定要上线！小程：好的。第二天，老板上班，问小程：新版本怎么还没上线？-小程怎么回答的？（）" class="headerlink" title="12、老板：小程，下班前新版本一定要上线！小程：好的。第二天，老板上班，问小程：新版本怎么还没上线？  小程怎么回答的？（）"></a><strong>12、老板：小程，下班前新版本一定要上线！小程：好的。第二天，老板上班，问小程：新版本怎么还没上线？  小程怎么回答的？（）</strong></h3><p>&emsp;&emsp;&emsp;A. 版本出问题了<br>&emsp;&emsp;&emsp;B. 版本上线前需求又改了<br>&emsp;&emsp;&emsp;C. 我还没下班呢</p><center> ![Title](//image.joylau.cn/blog/gaokao-title.jpg)</center ><h2 id="2017年普通高等学校招生全国统一考试-1"><a href="#2017年普通高等学校招生全国统一考试-1" class="headerlink" title="2017年普通高等学校招生全国统一考试"></a>2017年普通高等学校招生全国统一考试</h2><blockquote><blockquote><center>程序员的高考试卷（B卷） `考生类别：码神`<center></blockquote></blockquote><h3 id="1、以下哪个概念和公孙龙的《指物论》中的“指”字含义相近？（）"><a href="#1、以下哪个概念和公孙龙的《指物论》中的“指”字含义相近？（）" class="headerlink" title="1、以下哪个概念和公孙龙的《指物论》中的“指”字含义相近？（）"></a>1、以下哪个概念和公孙龙的《指物论》中的“指”字含义相近？（）</h3><p>&emsp;&emsp;&emsp;A. 变量<br>&emsp;&emsp;&emsp;B. 数组<br>&emsp;&emsp;&emsp;C. 对象<br>&emsp;&emsp;&emsp;D. 指针 </p><h3 id="2、蔺相如，司马相如；魏无忌，长孙无忌。下列哪一组对应关系与此类似（-）"><a href="#2、蔺相如，司马相如；魏无忌，长孙无忌。下列哪一组对应关系与此类似（-）" class="headerlink" title="2、蔺相如，司马相如；魏无忌，长孙无忌。下列哪一组对应关系与此类似（ ）"></a>2、蔺相如，司马相如；魏无忌，长孙无忌。下列哪一组对应关系与此类似（ ）</h3><p>&emsp;&emsp;&emsp;A.  PHP，Python<br>&emsp;&emsp;&emsp;B.  JSP，servlet<br>&emsp;&emsp;&emsp;C.  java，java script<br>&emsp;&emsp;&emsp;D. C，C++</p><h3 id="3、秦始皇吞并六国采用了以下哪种算法思想？（-）"><a href="#3、秦始皇吞并六国采用了以下哪种算法思想？（-）" class="headerlink" title="3、秦始皇吞并六国采用了以下哪种算法思想？（ ）"></a>3、秦始皇吞并六国采用了以下哪种算法思想？（ ）</h3><p>&emsp;&emsp;&emsp;A. 递归<br>&emsp;&emsp;&emsp;B. 分治<br>&emsp;&emsp;&emsp;C. 迭代<br>&emsp;&emsp;&emsp;D. 模拟</p><h3 id="4、雅典王子忒修斯勇闯克里特岛斩杀米诺牛的时候采用了以下哪种算法？（-）"><a href="#4、雅典王子忒修斯勇闯克里特岛斩杀米诺牛的时候采用了以下哪种算法？（-）" class="headerlink" title="4、雅典王子忒修斯勇闯克里特岛斩杀米诺牛的时候采用了以下哪种算法？（  ）"></a>4、雅典王子忒修斯勇闯克里特岛斩杀米诺牛的时候采用了以下哪种算法？（  ）</h3><p>&emsp;&emsp;&emsp;A. 动态规划<br>&emsp;&emsp;&emsp;B. 穷举<br>&emsp;&emsp;&emsp;C. 记忆化搜索<br>&emsp;&emsp;&emsp;D. Dijkstra算法</p><h3 id="5、众里寻他千百度，蓦然回首，那人却在灯火阑珊处（辛弃疾《青玉案》）。所体现的算法是：（-）"><a href="#5、众里寻他千百度，蓦然回首，那人却在灯火阑珊处（辛弃疾《青玉案》）。所体现的算法是：（-）" class="headerlink" title="5、众里寻他千百度，蓦然回首，那人却在灯火阑珊处（辛弃疾《青玉案》）。所体现的算法是：（  ）"></a>5、众里寻他千百度，蓦然回首，那人却在灯火阑珊处（辛弃疾《青玉案》）。所体现的算法是：（  ）</h3><p>&emsp;&emsp;&emsp;A. 贪心<br>&emsp;&emsp;&emsp;B. 回溯<br>&emsp;&emsp;&emsp;C. 穷举<br>&emsp;&emsp;&emsp;D. 分治          </p><h3 id="6、《公孙龙子》记载：“齐王之谓尹文曰：‘寡人甚好士，以齐国无士，何也？’尹文曰：‘愿闻大王之所谓士者。’齐王无以应。”这说明了齐王：（-）"><a href="#6、《公孙龙子》记载：“齐王之谓尹文曰：‘寡人甚好士，以齐国无士，何也？’尹文曰：‘愿闻大王之所谓士者。’齐王无以应。”这说明了齐王：（-）" class="headerlink" title="6、《公孙龙子》记载：“齐王之谓尹文曰：‘寡人甚好士，以齐国无士，何也？’尹文曰：‘愿闻大王之所谓士者。’齐王无以应。”这说明了齐王：（  ）"></a>6、《公孙龙子》记载：“齐王之谓尹文曰：‘寡人甚好士，以齐国无士，何也？’尹文曰：‘愿闻大王之所谓士者。’齐王无以应。”这说明了齐王：（  ）</h3><p>&emsp;&emsp;&emsp;A. 昏庸无道<br>&emsp;&emsp;&emsp;B. 是个结巴<br>&emsp;&emsp;&emsp;C. 不会下定义<br>&emsp;&emsp;&emsp;D. 不会定义自己的需求 </p><h3 id="7、惠施曾提出过“卵有毛”的命题，以下哪一项是导致这个错误命题的原因：（-）"><a href="#7、惠施曾提出过“卵有毛”的命题，以下哪一项是导致这个错误命题的原因：（-）" class="headerlink" title="7、惠施曾提出过“卵有毛”的命题，以下哪一项是导致这个错误命题的原因：（  ）"></a>7、惠施曾提出过“卵有毛”的命题，以下哪一项是导致这个错误命题的原因：（  ）</h3><p>&emsp;&emsp;&emsp;A. 混淆了命名空间<br>&emsp;&emsp;&emsp;B. 引入了错误的包<br>&emsp;&emsp;&emsp;C. 衍生类未重载<br>&emsp;&emsp;&emsp;D. 调用了危险的指针</p><h3 id="8、下面哪种面向对象的方法可以让你变得富有？（-）"><a href="#8、下面哪种面向对象的方法可以让你变得富有？（-）" class="headerlink" title="8、下面哪种面向对象的方法可以让你变得富有？（   ）"></a>8、下面哪种面向对象的方法可以让你变得富有？（   ）</h3><p>&emsp;&emsp;&emsp;A. 继承<br>&emsp;&emsp;&emsp;B. 封装<br>&emsp;&emsp;&emsp;C. 多态<br>&emsp;&emsp;&emsp;D. 抽象</p><blockquote><blockquote><p>那么你能答对几题呢? 下期发布标准答案 <img src='//tb2.bdstatic.com/tb/editor/images/face/i_f25.png?t=20140803' alt='滑稽'></p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> 其他篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 程序员 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>收集整理一些JAVA学习的技能树</title>
      <link href="/2017/06/05/Skill-Tree-Of-Java/"/>
      <url>/2017/06/05/Skill-Tree-Of-Java/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="先来一张集合的"><a href="#先来一张集合的" class="headerlink" title="先来一张集合的"></a>先来一张集合的</h2><p><img src="//image.joylau.cn/blog/java-skill-tree1.png" alt="java-skill-tree1"></p><h2 id="Java核心技术总结"><a href="#Java核心技术总结" class="headerlink" title="Java核心技术总结"></a>Java核心技术总结</h2><p><img src="//image.joylau.cn/blog/java-skill-tree2.gif" alt="java-skill-tree2"></p><h2 id="J2EE技术总结"><a href="#J2EE技术总结" class="headerlink" title="J2EE技术总结"></a>J2EE技术总结</h2><p><img src="//image.joylau.cn/blog/java-skill-tree3.gif" alt="java-skill-tree3"></p><h2 id="工作学习总结"><a href="#工作学习总结" class="headerlink" title="工作学习总结"></a>工作学习总结</h2><p><img src="//image.joylau.cn/blog/java-skill-tree4.gif" alt="java-skill-tree4"></p><h2 id="大数据相关技术总结"><a href="#大数据相关技术总结" class="headerlink" title="大数据相关技术总结"></a>大数据相关技术总结</h2><p><img src="//image.joylau.cn/blog/java-skill-tree5.gif" alt="java-skill-tree5"></p><h2 id="来看看Java工程师技能表"><a href="#来看看Java工程师技能表" class="headerlink" title="来看看Java工程师技能表"></a>来看看Java工程师技能表</h2><p><img src="//image.joylau.cn/blog/java-skill-tree6.png" alt="java-skill-tree6"><br><img src="//image.joylau.cn/blog/java-skill-tree8.png" alt="java-skill-tree8"><br><img src="//image.joylau.cn/blog/java-skill-tree9.png" alt="java-skill-tree9"></p><h2 id="恐怖的Linux大法"><a href="#恐怖的Linux大法" class="headerlink" title="恐怖的Linux大法"></a>恐怖的Linux大法</h2><p><img src="//image.joylau.cn/blog/java-skill-tree7.png" alt="java-skill-tree7"></p>]]></content>
      
      
      <categories>
          
          <category> 其他篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决一道智力题</title>
      <link href="/2017/06/02/SolveBrainAndPuzzles/"/>
      <url>/2017/06/02/SolveBrainAndPuzzles/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/imback.jpg" alt="Im Back"></p><p>今天被问了一道题，是这样的：</p><blockquote><blockquote><p>求解：一筐鸡蛋：<br>1个1个拿，正好拿完<br>2个2个拿，还剩1个<br>3个3个拿，正好拿完<br>4个4个拿，还剩1个<br>5个5个拿，还差1个<br>6个6个拿，还剩3个<br>7个7个拿，正好拿完<br>8个8个拿，还剩1个<br>9个9个拿，正好拿完<br>问筐里最少有多少鸡蛋</p></blockquote></blockquote><p>能算出这道题的智商不一般！求答案？有高手没，算算吧！</p><p>”5个5个拿，是还差1个“，也就是还剩下4个，这是这个题目的一个小陷阱…</p><p>我第一反应想到的是这个数一定是63的倍数，但是后来就没有什么想法了。</p><p>再后来，我想到了一个残暴的方法，<code>穷举法</code>：</p><pre><code class="java">            int i = 1;            while (true) {                System.out.println(i);                if (i % 2 == 1 &amp;&amp; i % 3 == 0 &amp;&amp; i % 4 == 1 &amp;&amp; i % 5 == 4 &amp;&amp; i % 6 == 3 &amp;&amp; i % 7 == 0                        &amp;&amp; i % 8 == 1 &amp;&amp; i % 9 == 0) {                    System.out.println(&quot;鸡蛋数=&quot; + i);                    break;                }                i++;            }</code></pre><p>执行后正确答案是1449;</p><p>能被7整除，能被9整除，所以肯定是63的倍数<br>如果利用63的倍数来做写的话：</p><pre><code class="java">            int i = 1;                while (true) {                    int num = 63 *i;                    if (num%5==4&amp;&amp;num%6==3&amp;&amp;num%8==1) {                        System.out.println(&quot;鸡蛋数=&quot; + num);                        break;                    }                    i++;                }</code></pre><p>答案依旧是1449，稍微显得动了点头脑，但还是穷举法，有什么高大上的解法么？？？在下默默献上膝盖！</p>]]></content>
      
      
      <categories>
          
          <category> 其他篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IntelliJ IDEA 插件开发</title>
      <link href="/2017/04/28/IntelliJIDEA-Plugins/"/>
      <url>/2017/04/28/IntelliJIDEA-Plugins/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/IntelliJIDEA-Plugins.png" alt="IntelliJIDEA-Plugins"></p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>我现在用的这个插件时ECTranslation,是用于做中英文翻译的，可以在看文档和注释的是方便的使用，然而近期变得不好用了</p><ul><li>翻译的内容有时能出来，有时出不来，有时甚至没有反应</li><li><strong>查看了该款插件的源代码，发现是调用的有道翻译的API接口，而且在代码里写死了APIkey和KeyFrom</strong></li><li>调用了有道的API，加上上面作者提供的Key，再传入翻译的文本内容，发现返回值居然是请求次数过多，被封禁了…..</li><li>明白了，很多使用这个插件的开发者都是用的作者提供的默认Key，默认情况下1小时请求的限制次数是1000次</li><li>肯定是次数超了</li><li><strong>但是他的配置信息是写在代码里的，能配置到IDEA的面板上供使用者自己配置就好了</strong></li><li>于是我有了自己动手的想法</li></ul><h2 id="开始项目"><a href="#开始项目" class="headerlink" title="开始项目"></a>开始项目</h2><p>第一步创建IDEA插件项目：<br><img src="//image.joylau.cn/blog/IntelliJIDEA-Build.png" alt="IntelliJIDEA-Build"><br>第二步目录结构如下图所示：<br><img src="//image.joylau.cn/blog/IntelliJIDEA-folder.png" alt="IntelliJIDEA-Folder"></p><h2 id="项目配置"><a href="#项目配置" class="headerlink" title="项目配置"></a>项目配置</h2><h3 id="plugin-xml"><a href="#plugin-xml" class="headerlink" title="plugin.xml"></a>plugin.xml</h3><p>看代码，相信能看懂的：</p><pre><code class="xml">    &lt;idea-plugin&gt;      &lt;id&gt;cn.joylau.plugins.translation&lt;/id&gt;      &lt;name&gt;joylau-translation&lt;/name&gt;      &lt;version&gt;1.0&lt;/version&gt;      &lt;vendor email=&quot;2587038142.liu@gmail&quot; url=&quot;http://www.joylau.cn&quot;&gt;JoyLau&lt;/vendor&gt;      &lt;description&gt;&lt;![CDATA[          Plugin for translate English to Chinese.&lt;br&gt;          &lt;li&gt;1. Choose the word you want translate.&lt;/li&gt;          &lt;li&gt;2. Press Ctrl + NUMPAD0.&lt;/li&gt;          &lt;li&gt;3. Fork ECTranslation Change ApiKey and KeyFrom&lt;/li&gt;        ]]&gt;&lt;/description&gt;      &lt;change-notes&gt;&lt;![CDATA[          &lt;li&gt;Change ApiKey and KeyFrom for myself&lt;/li&gt;          &lt;li&gt;Change KeyMap to Ctrl + NumPad 0&lt;/li&gt;        ]]&gt;      &lt;/change-notes&gt;      &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/build_number_ranges.html for description --&gt;      &lt;idea-version since-build=&quot;141.0&quot;/&gt;      &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/plugin_compatibility.html           on how to target different products --&gt;      &lt;!-- uncomment to enable plugin in all products      &lt;depends&gt;com.intellij.modules.lang&lt;/depends&gt;      --&gt;      &lt;extensions defaultExtensionNs=&quot;com.intellij&quot;&gt;        &lt;!-- Add your extensions here --&gt;      &lt;/extensions&gt;      &lt;actions&gt;        &lt;!-- Add your actions here --&gt;        &lt;action id=&quot;ECTranslation&quot; class=&quot;cn.joylau.plugins.translation.ECTranslation&quot; text=&quot;Translate&quot;&gt;          &lt;add-to-group group-id=&quot;EditMenu&quot; anchor=&quot;first&quot;/&gt;          &lt;add-to-group group-id=&quot;EditorPopupMenu&quot; anchor=&quot;first&quot;/&gt;          &lt;keyboard-shortcut keymap=&quot;$default&quot; first-keystroke=&quot;ctrl NUMPAD0&quot;/&gt;        &lt;/action&gt;      &lt;/actions&gt;    &lt;/idea-plugin&gt;</code></pre><p>只有一个action ，调用的类是<code>ECTranslation</code>，快捷键设置的<code>ctrl + NumPad 0</code></p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p><strong><em>代码都是人家的，我就没好意思往IDEA的仓库里上传了…</em></strong></p><blockquote><blockquote><p>如果你想使用这个插件： <a href="https://github.com/JoyLau/joylau-translation/releases" target="_blank" rel="noopener">点击查看</a>  或  <a href="http://image.joylau.cn/plugins/joylau-translation.1.0.REALEASE.jar" target="_blank" rel="noopener">点击下载</a></p></blockquote></blockquote>]]></content>
      
      
      <categories>
          
          <category> IntelliJ IDEA篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IntelliJ IDEA </tag>
            
            <tag> Plugins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis主从复制 --- 实现读写分离</title>
      <link href="/2017/04/27/Redis-Master-Slave/"/>
      <url>/2017/04/27/Redis-Master-Slave/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/Redis-Master&Slave.jpg" alt="Redis-Master&amp;Slave"></p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><pre><code class="bash">    ################################# REPLICATION #################################    # Master-Slave replication. Use slaveof to make a Redis instance a copy of    # another Redis server. A few things to understand ASAP about Redis replication.    #    # 1) Redis replication is asynchronous, but you can configure a master to    #    stop accepting writes if it appears to be not connected with at least    #    a given number of slaves.    # 2) Redis slaves are able to perform a partial resynchronization with the    #    master if the replication link is lost for a relatively small amount of    #    time. You may want to configure the replication backlog size (see the next    #    sections of this file) with a sensible value depending on your needs.    # 3) Replication is automatic and does not need user intervention. After a    #    network partition slaves automatically try to reconnect to masters    #    and resynchronize with them.    #    slaveof xx.xx.xx.xx 6379    # If the master is password protected (using the &quot;requirepass&quot; configuration    # directive below) it is possible to tell the slave to authenticate before    # starting the replication synchronization process, otherwise the master will    # refuse the slave request.    #    masterauth xx    # When a slave loses its connection with the master, or when the replication    # is still in progress, the slave can act in two different ways:    #    # 1) if slave-serve-stale-data is set to &#39;yes&#39; (the default) the slave will    #    still reply to client requests, possibly with out of date data, or the    #    data set may just be empty if this is the first synchronization.    #    # 2) if slave-serve-stale-data is set to &#39;no&#39; the slave will reply with    #    an error &quot;SYNC with master in progress&quot; to all the kind of commands    #    but to INFO and SLAVEOF.    #    slave-serve-stale-data yes    # You can configure a slave instance to accept writes or not. Writing against    # a slave instance may be useful to store some ephemeral data (because data    # written on a slave will be easily deleted after resync with the master) but    # may also cause problems if clients are writing to it because of a    # misconfiguration.    #    # Since Redis 2.6 by default slaves are read-only.    #    # Note: read only slaves are not designed to be exposed to untrusted clients    # on the internet. It&#39;s just a protection layer against misuse of the instance.    # Still a read only slave exports by default all the administrative commands    # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve    # security of read only slaves using &#39;rename-command&#39; to shadow all the    # administrative / dangerous commands.    slave-read-only no</code></pre><h2 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h2><ul><li><code>slaveof</code> ： Slave库配置Master的ip地址和端口号</li><li><code>masterauth</code> ：如果Master配置了密码，那么这里设置密码</li><li><code>slave-serve-stale-data</code> ： 如果Master宕机了，Salve是否继续提供服务</li><li><code>slave-read-only</code> ： Slave 是否是只读模式，默认为是</li></ul><h2 id="部分配置项解释"><a href="#部分配置项解释" class="headerlink" title="部分配置项解释"></a>部分配置项解释</h2><pre><code class="bash">    daemonize yes #是否以后台进程运行，默认为no     pidfile /var/run/redis.pid #如以后台进程运行，则需指定一个pid，默认为/var/run/redis.pid     bind 127.0.0.1 #绑定主机IP，默认值为127.0.0.1（注释）     port 6379 #监听端口，默认为6379     timeout 300 #超时时间，默认为300（秒）     loglevel notice #日志记slave-serve-stale-data yes：在master服务器挂掉或者同步失败时，从服务器是否继续提供服务。录等级，有4个可选值，debug，verbose（默认值），notice，warning     logfile /var/log/redis.log #日志记录方式，默认值为stdout     databases 16 #可用数据库数，默认值为16，默认数据库为0     save 900 1 #900秒（15分钟）内至少有1个key被改变     save 300 10 #300秒（5分钟）内至少有300个key被改变     save 60 10000 #60秒内至少有10000个key被改变     rdbcompression yes #存储至本地数据库时是否压缩数据，默认为yes     dbfilename dump.rdb #本地数据库文件名，默认值为dump.rdb     dir ./ #本地数据库存放路径，默认值为 ./    slaveof 10.0.0.12 6379 #当本机为从服务时，设置主服务的IP及端口（注释）     masterauth elain #当本机为从服务时，设置主服务的连接密码（注释）     slave-serve-stale-data yes #在master服务器挂掉或者同步失败时，从服务器是否继续提供服务。     requirepass elain #连接密码（注释）    maxclients 128 #最大客户端连接数，默认不限制（注释）     maxmemory #设置最大内存，达到最大内存设置后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理后，任到达最大内存设置，将无法再进行写入操作。（注释）     appendonly no #是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认值为no     appendfilename appendonly.aof #更新日志文件名，默认值为appendonly.aof（注释）     appendfsync everysec #更新日志条件，共有3个可选值。no表示等操作系统进行数据缓存同步到磁盘，always表示每次更新操作后手动调用fsync()将数据写到磁盘，everysec表示每秒同步一次（默认值）。    really-use-vm yes     vm-enabled yes #是否使用虚拟内存，默认值为no     vm-swap-file /tmp/redis.swap #虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享     vm-max-memory 0 #vm大小限制。0：不限制，建议60-80% 可用内存大小。     vm-page-size 32 #根据缓存内容大小调整，默认32字节。     vm-pages 134217728 #page数。每 8 page，会占用1字节内存。     vm-page-size #vm-pages 等于 swap 文件大小     vm-max-threads 4 #vm 最大io线程数。注意： 0 标志禁止使用vm     hash-max-zipmap-entries 512     hash-max-zipmap-value 64    list-max-ziplist-entries 512     list-max-ziplist-value 64     set-max-intset-entries 512     activerehashing yes</code></pre><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><ul><li>如果设置了一个Slave，无论是第一次连接还是重连到Master，它都会发出一个SYNC命令；</li><li>当Master收到SYNC命令之后，会做两件事：<br>  a) Master执行BGSAVE，即在后台保存数据到磁盘（rdb快照文件）；<br>  b) Master同时将新收到的写入和修改数据集的命令存入缓冲区（非查询类）；</li><li>当Master在后台把数据保存到快照文件完成之后，Master会把这个快照文件传送给Slave，而Slave则把内存清空后，加载该文件到内存中；</li><li>而Master也会把此前收集到缓冲区中的命令，通过Reids命令协议形式转发给Slave，Slave执行这些命令，实现和Master的同步；</li><li>Master/Slave此后会不断通过异步方式进行命令的同步，达到最终数据的同步一致；</li><li>需要注意的是Master和Slave之间一旦发生重连都会引发全量同步操作。但在2.8之后版本，也可能是部分同步操作。</li></ul><p>部分复制</p><ul><li>2.8开始，当Master和Slave之间的连接断开之后，他们之间可以采用持续复制处理方式代替采用全量同步。<br>  Master端为复制流维护一个内存缓冲区（in-memory backlog），记录最近发送的复制流命令；同时，Master和Slave之间都维护一个复制偏移量(replication offset)和当前Master服务器ID（Master run id）。当网络断开，Slave尝试重连时：<br>  a. 如果MasterID相同（即仍是断网前的Master服务器），并且从断开时到当前时刻的历史命令依然在Master的内存缓冲区中存在，则Master会将缺失的这段时间的所有命令发送给Slave执行，然后复制工作就可以继续执行了；<br>  b. 否则，依然需要全量复制操作；</li><li>Redis 2.8 的这个部分重同步特性会用到一个新增的 PSYNC 内部命令， 而 Redis 2.8 以前的旧版本只有 SYNC 命令， 不过， 只要从服务器是 Redis 2.8 或以上的版本， 它就会根据主服务器的版本来决定到底是使用 PSYNC 还是 SYNC ：<br>  如果主服务器是 Redis 2.8 或以上版本，那么从服务器使用 PSYNC 命令来进行同步。<br>  如果主服务器是 Redis 2.8 之前的版本，那么从服务器使用 SYNC 命令来进行同步。</li></ul><h2 id="同步机制"><a href="#同步机制" class="headerlink" title="同步机制"></a>同步机制</h2><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><blockquote><blockquote><p>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：<br>   　　1）从服务器连接主服务器，发送SYNC命令；<br>   　　2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；<br>   　　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；<br>   　　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；<br>   　　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；<br>   　　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</p></blockquote></blockquote><h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3><blockquote><blockquote><p>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。<br>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。</p></blockquote></blockquote><h2 id="Redis主从同步策略"><a href="#Redis主从同步策略" class="headerlink" title="Redis主从同步策略"></a>Redis主从同步策略</h2><p>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><ul><li>参考文章：<a href="http://blog.csdn.net/sk199048/article/details/50725369" target="_blank" rel="noopener">http://blog.csdn.net/sk199048/article/details/50725369</a></li><li>参考文章：<a href="http://blog.csdn.net/stubborn_cow/article/details/50442950" target="_blank" rel="noopener">http://blog.csdn.net/stubborn_cow/article/details/50442950</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud --- 构建开发环境</title>
      <link href="/2017/04/24/SpringCloud-Building/"/>
      <url>/2017/04/24/SpringCloud-Building/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/SpringEureka.png" alt="emoji"></p><h2 id="来个简单的小例子"><a href="#来个简单的小例子" class="headerlink" title="来个简单的小例子"></a>来个简单的小例子</h2><p>2个项目先来测试一下：</p><ul><li>eureka-server</li><li>eureka-service</li></ul><h2 id="eureka-server"><a href="#eureka-server" class="headerlink" title="eureka-server"></a>eureka-server</h2><h3 id="pom-配置"><a href="#pom-配置" class="headerlink" title="pom 配置"></a>pom 配置</h3><pre><code class="xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;        xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;cn.joylau.cloud.eureka.server&lt;/groupId&gt;        &lt;artifactId&gt;eureka-server&lt;/artifactId&gt;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;packaging&gt;jar&lt;/packaging&gt;        &lt;name&gt;eureka-server&lt;/name&gt;        &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;        &lt;parent&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;            &lt;version&gt;1.5.0.RELEASE&lt;/version&gt;            &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;        &lt;/parent&gt;        &lt;properties&gt;            &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;            &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;            &lt;java.version&gt;1.8&lt;/java.version&gt;        &lt;/properties&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;                &lt;scope&gt;test&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;        &lt;dependencyManagement&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                    &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                    &lt;version&gt;Dalston.RELEASE&lt;/version&gt;                    &lt;type&gt;pom&lt;/type&gt;                    &lt;scope&gt;import&lt;/scope&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/dependencyManagement&gt;        &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/build&gt;    &lt;/project&gt;</code></pre><h3 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a>application.properties</h3><pre><code class="bash">    server.port=8080    eureka.client.register-with-eureka=false    eureka.client.fetch-registry=false    eureka.client.serviceUrl.defaultZone=http://localhost:${server.port}/eureka/</code></pre><h3 id="EurekaServerApplication"><a href="#EurekaServerApplication" class="headerlink" title="EurekaServerApplication"></a>EurekaServerApplication</h3><pre><code class="java">    package cn.joylau.cloud.eureka.server;    import org.springframework.boot.SpringApplication;    import org.springframework.boot.autoconfigure.SpringBootApplication;    import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;    @SpringBootApplication    @EnableEurekaServer    public class EurekaServerApplication {        public static void main(String[] args) {            SpringApplication.run(EurekaServerApplication.class, args);        }    }</code></pre><h2 id="eureka-service"><a href="#eureka-service" class="headerlink" title="eureka-service"></a>eureka-service</h2><h3 id="pom-配置-1"><a href="#pom-配置-1" class="headerlink" title="pom 配置"></a>pom 配置</h3><pre><code class="xml">    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;    &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;        xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;        &lt;groupId&gt;cn.joylau.cloud.eureka.service&lt;/groupId&gt;        &lt;artifactId&gt;eureka-service&lt;/artifactId&gt;        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;packaging&gt;jar&lt;/packaging&gt;        &lt;name&gt;eureka-service&lt;/name&gt;        &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;        &lt;parent&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;            &lt;version&gt;1.5.0.RELEASE&lt;/version&gt;            &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;        &lt;/parent&gt;        &lt;properties&gt;            &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;            &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;            &lt;java.version&gt;1.8&lt;/java.version&gt;        &lt;/properties&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;                &lt;scope&gt;test&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;        &lt;dependencyManagement&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                    &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                    &lt;version&gt;Brixton.RELEASE&lt;/version&gt;                    &lt;type&gt;pom&lt;/type&gt;                    &lt;scope&gt;import&lt;/scope&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/dependencyManagement&gt;        &lt;build&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/build&gt;    &lt;/project&gt;</code></pre><h3 id="application-properties-1"><a href="#application-properties-1" class="headerlink" title="application.properties"></a>application.properties</h3><pre><code class="bash">    spring.application.name=eureka-service    server.port=8888    eureka.client.serviceUrl.defaultZone=http://localhost:8080/eureka/</code></pre><h3 id="EurekaServerApplication-1"><a href="#EurekaServerApplication-1" class="headerlink" title="EurekaServerApplication"></a>EurekaServerApplication</h3><pre><code class="java">    package cn.joylau.cloud.eureka.service;    import org.springframework.boot.SpringApplication;    import org.springframework.boot.autoconfigure.SpringBootApplication;    import org.springframework.cloud.client.discovery.EnableDiscoveryClient;    @EnableDiscoveryClient    @SpringBootApplication    public class EurekaServiceApplication {        public static void main(String[] args) {            SpringApplication.run(EurekaServiceApplication.class, args);        }    }</code></pre><h3 id="ComputeController"><a href="#ComputeController" class="headerlink" title="ComputeController"></a>ComputeController</h3><pre><code class="java">    package cn.joylau.cloud.eureka.service;    import org.apache.log4j.Logger;    import org.springframework.beans.factory.annotation.Autowired;    import org.springframework.cloud.client.ServiceInstance;    import org.springframework.cloud.client.discovery.DiscoveryClient;    import org.springframework.web.bind.annotation.RequestMapping;    import org.springframework.web.bind.annotation.RequestMethod;    import org.springframework.web.bind.annotation.RequestParam;    import org.springframework.web.bind.annotation.RestController;    /**     * Created by JoyLau on 4/14/2017.     * cn.joylau.cloud.eureka.service     */    @RestController    public class ComputeController {        private final Logger logger = Logger.getLogger(getClass());        @Autowired        private DiscoveryClient client;        @RequestMapping(value = &quot;/add&quot; ,method = RequestMethod.GET)        public Integer add(@RequestParam Integer a, @RequestParam Integer b) {            ServiceInstance instance = client.getLocalServiceInstance();            Integer r = a + b;            logger.info(&quot;/add, host:&quot; + instance.getHost() + &quot;, service_id:&quot; + instance.getServiceId() + &quot;, result:&quot; + r);            return r;        }    }</code></pre><h2 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h2><ul><li><code>@EnableEurekaServer</code> ： 开启服务发现</li><li>eureka是一个高可用的组件，它没有后端缓存，每一个实例注册之后需要向注册中心发送心跳（因此可以在内存中完成），在默认情况下eureka server也是一个eureka client ,必须要指定一个 server</li><li>当client向server注册时，它会提供一些元数据，例如主机和端口，URL，主页等。Eureka server 从每个client实例接收心跳消息。 如果心跳超时，则通常将该实例从注册server中删除</li><li><code>@EnableDiscoveryClient</code> ： 注册一个微服务</li><li><code>spring.application.name</code> ：应用名</li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringCloud篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> SpringCloud </tag>
            
            <tag> Eureka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JoyLau-MyBatis 使用说明</title>
      <link href="/2017/04/06/MyBatis-Joylau-MyBatis/"/>
      <url>/2017/04/06/MyBatis-Joylau-MyBatis/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="关于joylau-mybatis的说明"><a href="#关于joylau-mybatis的说明" class="headerlink" title="关于joylau-mybatis的说明"></a>关于joylau-mybatis的说明</h2><ul><li>该项目来源自  <a href="https://github.com/abel533/Mapper" target="_blank" rel="noopener">https://github.com/abel533/Mapper</a>  详细信息和源代码可fork查看</li><li>我封装之后项目地址  <a href="https://github.com/JoyLau/joylau-mybatis" target="_blank" rel="noopener">https://github.com/JoyLau/joylau-mybatis</a></li><li>我自己整合通用Mapper，分页，以及排序功能，使用起来无缝结合，丝般顺滑</li><li>我对其封装了所有的通用mapper，并整合本项目添加了自己的方法，详细请查看下文或者在线查看api文档： <a href="http://api.joylau.cn/" target="_blank" rel="noopener">http://api.joylau.cn/</a></li><li>文档你主要需要查看function的类注释</li><li>下面我来逐一介绍：</li></ul><h3 id="BaseController"><a href="#BaseController" class="headerlink" title="BaseController"></a>BaseController</h3><p>继承FunctionController，目前有2个抽象方法，getSession()和getContextPath()，一看就知道是干嘛的，不多说。想要扩展很简单，继续写自己的方法即可</p><h3 id="BaseMapper"><a href="#BaseMapper" class="headerlink" title="BaseMapper"></a>BaseMapper</h3><ul><li>集成了MySQL所使用的绝大部分通用Mapper，包括BaseMapper，ExampleMapper，RowBoundsMapper，MySqlMapper，IdsMapper…等等，详细可查看API文档，或者下载源码查看</li><li>所有的单表及简单的多表操作都在这里面啦，基本上你是不需要扩展啦，好不好用，敲起mapper再点一下你就知道了</li></ul><h3 id="BaseService"><a href="#BaseService" class="headerlink" title="BaseService"></a>BaseService</h3><ul><li>得益于Spring项目的强大支持，在Spring4.x后，支持泛型注入，这使得我们封装的更加简单了</li><li>现在，不必再调用到Mapper层，现在在Service层就可以完美使用，封装了3个插入方法，4个更新方法，5个删除方法，13个查询方法</li><li>内容涵盖了单条记录CRUD；根据ID或者属性或者条件CRUD；批量删除，插入；分页查询</li><li>说下分页查询怎么使用：调用selectPage可以进行单表分页查询，调用selectPageByExample可以进行条件分页查询</li></ul><h3 id="BaseServiceImpl"><a href="#BaseServiceImpl" class="headerlink" title="BaseServiceImpl"></a>BaseServiceImpl</h3><ul><li>继承的FunctionServiceImpl已经实现了上述所有的通用CURD方法</li><li>在继承的FunctionServiceImpl类里我提供了获取mapper的方法，由此方法，可以进行很方便的扩展，你懂得~~</li></ul><h3 id="BaseModel"><a href="#BaseModel" class="headerlink" title="BaseModel"></a>BaseModel</h3><ul><li>添加每个实体都会用到的id属性</li><li>添加了createTime和updateTime属性，虽然在业务上可能没有什么用处，但是对于开发和运维的作用相当大，谁用谁知道</li></ul><h2 id="我的接口解释"><a href="#我的接口解释" class="headerlink" title="我的接口解释"></a>我的接口解释</h2><pre><code class="java">    /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 保存一个实体，null的属性也会保存，不会使用数据库默认值         */        int insert(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 保存一个实体，null的属性不会保存，会使用数据库默认值         */        int insertSelective(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 批量插入，支持批量插入的数据库可以使用，另外该接口限制实体包含`id`属性并且必须为自增列         */        int insertList(List&lt;T&gt; list);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键更新实体全部字段，null值会被更新         */        int updateByPrimaryKey(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键更新属性不为null的值         */        int updateByPrimaryKeySelective(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件更新实体`model`包含的全部属性，null值会被更新         */        int updateByExample(T model, Object example);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件更新实体`model`包含的不是null的属性值         */        int updateByExampleSelective(T model, Object example);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体属性作为条件进行删除，查询条件使用等号         */        int delete(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体id删除         */        int deleteById(int id);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件删除数据         */        int deleteByExample(Object example);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键字符串进行删除，类中只有存在一个带有@Id注解的字段         *         * @param ids 如 &quot;1,2,3,4&quot;         */        int deleteByIds(String ids);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键字段进行删除，方法参数必须包含完整的主键属性         */        int deleteByPrimaryKey(Object key);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体中的属性值进行查询，查询条件使用等号         */        List&lt;T&gt; select(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体中的id查询实体         */        T selectById(int id);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 查询全部结果         */        List&lt;T&gt; selectAll();        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件进行查询         */        List&lt;T&gt; selectByExample(Object example);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据example条件和RowBounds进行分页查询         */        List&lt;T&gt; selectByExampleAndRowBounds(Object example, RowBounds rowBounds);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键字符串进行查询，类中只有存在一个带有@Id注解的字段         *         * @param ids 如 &quot;1,2,3,4&quot;         */        List&lt;T&gt; selectByIds(String ids);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据主键字段进行查询，方法参数必须包含完整的主键属性，查询条件使用等号         */        T selectByPrimaryKey(Object key);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体中的属性查询总数，查询条件使用等号         */        int selectCount(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件进行查询总数         */        int selectCountByExample(Object example);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体中的属性进行查询，只能有一个返回值，有多个结果是抛出异常，查询条件使用等号         */        T selectOne(T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据实体属性和RowBounds进行分页查询         */        List&lt;T&gt; selectByRowBounds(T model, RowBounds rowBounds);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 单表分页查询         */        PageInfo selectPage(int pageNum, int pageSize, T model);        /**         * Created by JoyLau on 4/6/2017.         * 2587038142.liu@gmail.com         * 根据Example条件进行分页查询         */        PageInfo selectPageByExample(int pageNum, int pageSize, Object example);</code></pre><h2 id="怎么使用？"><a href="#怎么使用？" class="headerlink" title="怎么使用？"></a>怎么使用？</h2><p>很简单</p><ul><li>你的Mapper继承BaseMapper</li><li>你的Service继承BaseService</li><li>你的ServiceImpl实现你的Service借口，再继承BaseServiceImpl</li><li>你的Model继承BaseModel</li></ul><h2 id="来试一下"><a href="#来试一下" class="headerlink" title="来试一下"></a>来试一下</h2><ul><li>在你的ServiceImpl里点一下方法试试? 是不是很棒???</li><li>在你的Mapper里再点一下方法试试?? 6666…</li></ul><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><ul><li>能想到的我都写了，BaseMapper和BaseServiceImpl基本上不需要扩展了，有不明白的可以联系我</li><li>欢迎指正，共同学习</li></ul>]]></content>
      
      
      <categories>
          
          <category> MyBatis篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis有多快??? --- 基准性能测试</title>
      <link href="/2017/04/01/Redis-Benchmark/"/>
      <url>/2017/04/01/Redis-Benchmark/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/Redis-Benchmark.jpg" alt="Redis-Benchmark"></p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ul><li>redis默认提供了性能测试的工具</li><li>在linux下文件是redis-benchmark</li><li>在windows下文件是redis-benchmark.exe</li></ul><h2 id="参数查看"><a href="#参数查看" class="headerlink" title="参数查看"></a>参数查看</h2><ul><li><p><code>redis-benchmark -h</code></p><pre><code class="bash">  Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-  k &lt;boolean&gt;]   -h &lt;hostname&gt;      Server hostname (default 127.0.0.1)   -p &lt;port&gt;          Server port (default 6379)   -s &lt;socket&gt;        Server socket (overrides host and port)   -a &lt;password&gt;      Password for Redis Auth   -c &lt;clients&gt;       Number of parallel connections (default 50)   -n &lt;requests&gt;      Total number of requests (default 100000)   -d &lt;size&gt;          Data size of SET/GET value in bytes (default 2)   -dbnum &lt;db&gt;        SELECT the specified db number (default 0)   -k &lt;boolean&gt;       1=keep alive 0=reconnect (default 1)   -r &lt;keyspacelen&gt;   Use random keys for SET/GET/INCR, random values for SADD    Using this option the benchmark will expand the string __rand_int__    inside an argument with a 12 digits number in the specified range    from 0 to keyspacelen-1. The substitution changes every time a command    is executed. Default tests use this to hit random keys in the    specified range.   -P &lt;numreq&gt;        Pipeline &lt;numreq&gt; requests. Default 1 (no pipeline).   -q                 Quiet. Just show query/sec values   --csv              Output in CSV format   -l                 Loop. Run the tests forever   -t &lt;tests&gt;         Only run the comma separated list of tests. The test                      names are the same as the ones produced as output.   -I                 Idle mode. Just open N idle connections and wait.  Examples:   Run the benchmark with the default configuration against 127.0.0.1:6379:     $ redis-benchmark   Use 20 parallel clients, for a total of 100k requests, against 192.168.1.1:     $ redis-benchmark -h 192.168.1.1 -p 6379 -n 100000 -c 20   Fill 127.0.0.1:6379 with about 1 million keys only using the SET test:     $ redis-benchmark -t set -n 1000000 -r 100000000   Benchmark 127.0.0.1:6379 for a few commands producing CSV output:     $ redis-benchmark -t ping,set,get -n 100000 --csv   Benchmark a specific command line:     $ redis-benchmark -r 10000 -n 10000 eval &#39;return redis.call(&quot;ping&quot;)&#39; 0   Fill a list with 10000 random elements:     $ redis-benchmark -r 10000 -n 10000 lpush mylist __rand_int__   On user specified command lines __rand_int__ is replaced with a random integer   with a range of values selected by the -r option.</code></pre></li></ul><h2 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h2><ul><li>搞清了参数的含义，可以进行测试了</li><li>本次配置为Redis的默认配置，默认的配置项已经有足够好的性能表现了，不需要调优</li><li><code>redis-benchmark -h joylau.cn -p 6379 -a XXX -t get,set -n 1000 -c 400 -q</code><br>  我是模仿了我自己现在公司的业务需求，测试了我直接服务器上的Redis，向redis服务器发送1000个请求，每个请求附带400个并发客户端，以静默显示<br>  <img src="//image.joylau.cn/blog/redis-joylau-test-q.png" alt="redis-joylau-test-q"><br>  可以看到，set操作每秒处理17241次，get操作每秒处理17543次</li><li><code>redis-benchmark -h joylau.cn -p 6379 -a XXX -t get,set -n 1000 -c 400</code><br>  同上，以标准格式显示<br>  <img src="//image.joylau.cn/blog/redis-joylau-test.png" alt="redis-joylau-test"><br>  可以看到，set操作每秒处理17857次，get操作每秒处理18518次</li><li><strong><em>我自己也开了本地的服务器做测试，每秒操作次数可达100000次</em></strong></li></ul><h2 id="一些参数说明"><a href="#一些参数说明" class="headerlink" title="一些参数说明"></a>一些参数说明</h2><ul><li>-t : 可以选择你需要运行的测试用例</li><li>-r : 设置随机数来SET/GET/INCR</li><li>-P : 一次性执行多条命令，记得在多条命令需要处理时候使用 pipelining。</li></ul><h2 id="陷阱和错误的认识"><a href="#陷阱和错误的认识" class="headerlink" title="陷阱和错误的认识"></a>陷阱和错误的认识</h2><blockquote><blockquote><p>第一点是显而易见的：基准测试的黄金准则是使用相同的标准。 用相同的任务量测试不同版本的 Redis，或者用相同的参数测试测试不同版本 Redis。 如果把 Redis 和其他工具测试，那就需要小心功能细节差异。</p></blockquote></blockquote><ul><li>Redis 是一个服务器：所有的命令都包含网络或 IPC 消耗。这意味着和它和 SQLite， Berkeley DB， Tokyo/Kyoto Cabinet 等比较起来无意义， 因为大部分的消耗都在网络协议上面。</li><li>Redis 的大部分常用命令都有确认返回。有些数据存储系统则没有（比如 MongoDB 的写操作没有返回确认）。把 Redis 和其他单向调用命令存储系统比较意义不大。<br>简单的循环操作 Redis 其实不是对 Redis 进行基准测试，而是测试你的网络（或者 IPC）延迟。想要真正测试 Redis，需要使用多个连接（比如 redis-benchmark)， 或者使用 pipelining 来聚合多个命令，另外还可以采用多线程或多进程。</li><li>Redis 是一个内存数据库，同时提供一些可选的持久化功能。 如果你想和一个持久化服务器（MySQL, PostgreSQL 等等） 对比的话， 那你需要考虑启用 AOF 和适当的 fsync 策略。</li><li>Redis 是单线程服务。它并没有设计为多 CPU 进行优化。如果想要从多核获取好处， 那就考虑启用多个实例吧。将单实例 Redis 和多线程数据库对比是不公平的。</li></ul><h2 id="影响-Redis-性能的因素"><a href="#影响-Redis-性能的因素" class="headerlink" title="影响 Redis 性能的因素"></a>影响 Redis 性能的因素</h2><blockquote><blockquote><p>有几个因素直接决定 Redis 的性能。它们能够改变基准测试的结果， 所以我们必须注意到它们。一般情况下，Redis 默认参数已经可以提供足够的性能， 不需要调优。</p></blockquote></blockquote><ul><li>网络带宽和延迟通常是最大短板。建议在基准测试之前使用 ping 来检查服务端到客户端的延迟。根据带宽，可以计算出最大吞吐量。 比如将 4 KB 的字符串塞入 Redis，吞吐量是 100000 q/s，那么实际需要 3.2 Gbits/s 的带宽，所以需要 10 GBits/s 网络连接， 1 Gbits/s 是不够的。 在很多线上服务中，Redis 吞吐会先被网络带宽限制住，而不是 CPU。 为了达到高吞吐量突破 TCP/IP 限制，最后采用 10 Gbits/s 的网卡， 或者多个 1 Gbits/s 网卡。</li><li>CPU 是另外一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU， 而不是多核。这种场景下面，比较推荐 Intel CPU。AMD CPU 可能只有 Intel CPU 的一半性能（通过对 Nehalem EP/Westmere EP/Sandy 平台的对比）。 当其他条件相当时候，CPU 就成了 redis-benchmark 的限制因素。</li><li>在小对象存取时候，内存速度和带宽看上去不是很重要，但是对大对象（&gt; 10 KB）， 它就变得重要起来。不过通常情况下面，倒不至于为了优化 Redis 而购买更高性能的内存模块。</li><li>Redis 在 VM 上会变慢。虚拟化对普通操作会有额外的消耗，Redis 对系统调用和网络终端不会有太多的 overhead。建议把 Redis 运行在物理机器上， 特别是当你很在意延迟时候。在最先进的虚拟化设备（VMWare）上面，redis-benchmark 的测试结果比物理机器上慢了一倍，很多 CPU 时间被消费在系统调用和中断上面。</li><li>如果服务器和客户端都运行在同一个机器上面，那么 TCP/IP loopback 和 unix domain sockets 都可以使用。对 Linux 来说，使用 unix socket 可以比 TCP/IP loopback 快 50%。 默认 redis-benchmark 是使用 TCP/IP loopback。 当大量使用 pipelining 时候，unix domain sockets 的优势就不那么明显了。</li><li>当大量使用 pipelining 时候，unix domain sockets 的优势就不那么明显了。</li><li>当使用网络连接时，并且以太网网数据包在 1500 bytes 以下时， 将多条命令包装成 pipelining 可以大大提高效率。事实上，处理 10 bytes，100 bytes， 1000 bytes 的请求时候，吞吐量是差不多的</li></ul><h2 id="我想说"><a href="#我想说" class="headerlink" title="我想说"></a>我想说</h2><ul><li>我分别测试我之前在腾讯云上的Redis服务器 <strong>(Windows Server 2008R2)</strong>  和现在在阿里云上的服务器  <strong>(Linux CentOS 7.2)</strong> 及 局域网下同事的Redis服务器，和本机Redis的服务器<br>速度最快的本机服务器，其次是同事的服务器，再次是阿里云上的服务器，最后是腾讯云上的服务器</li><li>测试差异之大除了在硬件上的差别外，最客观的因素在网络带宽上，我自己2个位于云上的服务器都是1M的带宽，如此测试，正如上面所说，远远不达不到数据传输所需要的带宽值</li></ul><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><ul><li>参考文章：<a href="http://www.redis.cn/topics/benchmarks.html" target="_blank" rel="noopener">http://www.redis.cn/topics/benchmarks.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker常用命令备忘</title>
      <link href="/2017/03/22/Docker-Command/"/>
      <url>/2017/03/22/Docker-Command/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><ul><li>安装： <code>yum install docker</code></li><li>卸载： <code>yum remove docker</code></li><li>启动： <code>systemctl start docker</code></li><li>开机自启： <code>systemctl enable docker</code></li></ul><h3 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h3><pre><code class="bash">    FROM java:8    MAINTAINER joylau    ADD joyalu-0.0.1-SNAPSHOT.jar joylau.jar    EXPOSE 8080    ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/joylau.jar&quot;]</code></pre><h3 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h3><ul><li>编译镜像: <code>docker build –t joylau/docker .</code></li><li>查看镜像： <code>docker images</code></li><li>删除镜像： <code>docker rmi name/id</code></li></ul><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><ul><li>运行: <code>docker run –d --name joylau –p 8080:8080 joylau/docker</code></li><li>停止容器： <code>docker stop id/name</code></li><li>查看运行中的容器 ：  <code>docker ps</code></li><li>查看所有容器：  <code>docker ps -a</code></li><li>删除容器：  <code>docker rm id/name</code></li></ul><h2 id="2018-07-05-16-05-00-更新"><a href="#2018-07-05-16-05-00-更新" class="headerlink" title="2018-07-05 16:05:00 更新"></a>2018-07-05 16:05:00 更新</h2><p>拉取docker镜像</p><p>docker pull image_name<br>查看宿主机上的镜像，Docker镜像保存在/var/lib/docker目录下:</p><p>docker images</p><p>删除镜像</p><p>docker rmi  docker.io/tomcat:7.0.77-jre7   或者  docker rmi b39c68b7af30<br>查看当前有哪些容器正在运行</p><p>docker ps<br>查看所有容器</p><p>docker ps -a<br>启动、停止、重启容器命令：</p><p>docker start container_name/container_id<br>docker stop container_name/container_id<br>docker restart container_name/container_id<br>后台启动一个容器后，如果想进入到这个容器，可以使用attach命令：</p><p>docker attach container_name/container_id<br>删除容器的命令：</p><p>docker rm container_name/container_id<br>删除所有停止的容器：</p><p>docker rm $(docker ps -a -q)<br>查看当前系统Docker信息</p><p>docker info<br>从Docker hub上下载某个镜像:</p><p>docker pull centos:latest<br>docker pull centos:latest<br>查找Docker Hub上的nginx镜像</p><p>docker search nginx<br>执行docker pull centos会将Centos这个仓库下面的所有镜像下载到本地repository。</p><h2 id="2018-07-09-14-02-25-更新"><a href="#2018-07-09-14-02-25-更新" class="headerlink" title="2018-07-09 14:02:25 更新"></a>2018-07-09 14:02:25 更新</h2><p>docker search xxx : 在docker仓库查找镜像<br>docker images | grep xxx : 在本地仓库查找镜像</p><h2 id="2018-07-12-09-44-40-更新"><a href="#2018-07-12-09-44-40-更新" class="headerlink" title="2018-07-12 09:44:40 更新"></a>2018-07-12 09:44:40 更新</h2><p>进入容器： <code>docker exec -it 容器的ID或者NAME /bin/bash</code></p><h2 id="2020-04-12-12-30-25-更新"><a href="#2020-04-12-12-30-25-更新" class="headerlink" title="2020-04-12 12:30:25 更新"></a>2020-04-12 12:30:25 更新</h2><p>查找自定义属性</p><pre><code class="bash">    docker ps -a --format &quot;table {{.ID}}\t{{.Image}}\t{{.Names}}\t{{.Status}}&quot;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 批处理SpringBatch</title>
      <link href="/2017/03/21/SpringBoot-SpringBatch/"/>
      <url>/2017/03/21/SpringBoot-SpringBatch/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/SpringBatch.jpg" alt="SpringBatch"></p><h2 id="组成部分"><a href="#组成部分" class="headerlink" title="组成部分"></a>组成部分</h2><ul><li><code>JobRepository</code>: 用来注册<strong>Job</strong>的容器</li><li><code>JobLauncher</code>: 用来启动<strong>Job</strong>的接口</li><li><code>Job</code> : 我要实际执行的任务，包含一个或多个Step</li><li><code>Step</code> : Step-步骤包含<strong>ItemReader</strong>，<strong>ItemProcessor</strong>，<strong>ItemWrite</strong></li><li><code>ItemReader</code> : 用来读取数据的接口</li><li><code>ItemProcessor</code> : 用来处理数据的接口</li><li><code>ItemWrite</code> : 用来输出数据的接口</li></ul><h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><blockquote><blockquote><p>SpringBoot 整合 SpringBatch 只需要引入依赖并注册成Spring 的 Bean 即可，若是想开启批处理的支持还需要在该配置类上添加 <strong>@EnableBatchProcessing</strong></p></blockquote></blockquote><pre><code class="xml">    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt;        &lt;!-- SpringBatch会自动加载hsqldb，我们去除即可 --&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;groupId&gt;org.hsqldb&lt;/groupId&gt;                &lt;artifactId&gt;hsqldb&lt;/artifactId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;</code></pre><p>来看代码 ：</p><pre><code class="java">    @Configuration    @EnableBatchProcessing    public class BatchConfig {    @Bean        public JobRepository jobRepository(DataSource dataSource, PlatformTransactionManager transactionManager)                throws Exception {            JobRepositoryFactoryBean jobRepositoryFactoryBean = new JobRepositoryFactoryBean();            jobRepositoryFactoryBean.setDataSource(dataSource);            jobRepositoryFactoryBean.setTransactionManager(transactionManager);            jobRepositoryFactoryBean.setDatabaseType(&quot;oracle&quot;);            return jobRepositoryFactoryBean.getObject();        }        @Bean        public SimpleJobLauncher jobLauncher(DataSource dataSource, PlatformTransactionManager transactionManager)                throws Exception {            SimpleJobLauncher jobLauncher = new SimpleJobLauncher();            jobLauncher.setJobRepository(jobRepository(dataSource, transactionManager));            return jobLauncher;        }        @Bean        public Job importJob(JobBuilderFactory jobs, Step s1) {            return jobs.get(&quot;importJob&quot;)                    .incrementer(new RunIdIncrementer())                    .flow(s1)                     .end()                    .listener(csvJobListener())                    .build();        }        @Bean        public Step step1(StepBuilderFactory stepBuilderFactory, ItemReader&lt;Person&gt; reader, ItemWriter&lt;Person&gt; writer,                ItemProcessor&lt;Person,Person&gt; processor) {            return stepBuilderFactory                    .get(&quot;step1&quot;)                    .&lt;Person, Person&gt;chunk(65000) //1                    .reader(reader)                    .processor(processor)                    .writer(writer)                    .build();        }        //接口分别实现        @Bean            public ItemReader&lt;Person&gt; reader() throws Exception {                    //                    return reader;            }            @Bean            public ItemProcessor&lt;Person, Person&gt; processor() {                //                return processor;            }            @Bean            public ItemWriter&lt;Person&gt; writer(DataSource dataSource) {//1                //                return writer;            }    }</code></pre><p><strong>貌似就这么简单的完成了……</strong></p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul><li>监听Job的执行情况，自定义类实现<code>JobExecutionListener</code></li><li>执行计划任务，在普通的计划任务方法中执行JobLauncher的run方法即可</li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
            <tag> SpringBatch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为网站添加emoji表情支持</title>
      <link href="/2017/03/21/MySQL-Emoji/"/>
      <url>/2017/03/21/MySQL-Emoji/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/emoji.jpg" alt="emoji"></p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>MySQL5.5.3+</li><li>mysql-connector-java5.1.13+</li></ul><h2 id="有异常"><a href="#有异常" class="headerlink" title="有异常"></a>有异常</h2><pre><code class="bash">    java.sql.SQLException: Incorrect string value: &#39;\xF0\x9F\x92\x94&#39; for colum n &#39;name&#39; at row 1     at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1073)     at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3593)     at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3525)     at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1986)     at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2140)     at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2620)     at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1662)     at com.mysql.jdbc.StatementImpl.executeUpdate(StatementImpl.java:1581)</code></pre><h2 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h2><pre><code class="bash">    [client]    default-character-set = utf8mb4    [mysql]    default-character-set = utf8mb4    [mysqld]    character-set-client-handshake = FALSE    character-set-server = utf8mb4    collation-server = utf8mb4_unicode_ci</code></pre><ul><li>数据库字符集：<code>utf8mb4 -- UTF-8 Unicode</code></li><li>排序规则：<code>utf8mb4_general_ci</code></li></ul><h2 id="多样的浏览器兼容"><a href="#多样的浏览器兼容" class="headerlink" title="多样的浏览器兼容"></a>多样的浏览器兼容</h2><pre><code class="javascript">    &lt;link href=&quot;http://cdn.staticfile.org/emoji/0.2.2/emoji.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;    &lt;script src=&quot;http://cdn.staticfile.org/jquery/2.1.0/jquery.min.js&quot;&gt;&lt;/script&gt;    &lt;script src=&quot;http://cdn.staticfile.org/emoji/0.2.2/emoji.js&quot;&gt;&lt;/script&gt;    var $text = $(&#39;.emojstext&#39;);    var html = $text.html().trim().replace(/\n/g, &#39;&lt;br/&gt;&#39;);    $text.html(jEmoji.unifiedToHTML(html));</code></pre>]]></content>
      
      
      <categories>
          
          <category> MySQL篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> emoji </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven --- 发布自己的构件到中央仓库</title>
      <link href="/2017/03/17/Maven-Release-Component/"/>
      <url>/2017/03/17/Maven-Release-Component/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/sonatype.png" alt="Sonatype"></p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ul><li>个人感觉第一次发布的步骤非常复杂，我在第一次操作的时候来来回回发布了7,8个版本，最后都是校验失败，导致构件不能关闭（因为我遇到了个大坑）</li><li>第一次发布成功之后后面的更新和添加新的构件都相对来说要容易一些（groupid不变的情况下）</li></ul><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h3 id="账户注册"><a href="#账户注册" class="headerlink" title="账户注册"></a>账户注册</h3><ul><li>注册地址 ： <a href="https://issues.sonatype.org/secure/Signup!default.jspa" target="_blank" rel="noopener">https://issues.sonatype.org/secure/Signup!default.jspa</a>  ,这一步需要注意的是记住用户名和密码，后面配置文件会用到<br><img src="//image.joylau.cn/blog/sonatype-register.png" alt="注册"></li></ul><h3 id="创建并提交工单"><a href="#创建并提交工单" class="headerlink" title="创建并提交工单"></a>创建并提交工单</h3><p><img src="//image.joylau.cn/blog/sonatype_issue.PNG" alt="创建工单"></p><ul><li>Project和issue Type的填写如上图所示，不能填写错了</li><li>创建完成之后就等待网站工作人员的审核就可以了，不知道为什么，我等待的时间非常短，2分钟都不到，工作人员就回复我了，可能是我的运气比较好吧，但是上个星期买房摇号我却没摇到<img src="////image.joylau.cn/aodamiao/18.gif" alt="伤心欲绝"></li><li>当issue 的 state 变为 <code>RESOLVED</code>时就可继续操作了，同时下面的活动区会给你发消息<br><img src="//image.joylau.cn/blog/issue-activity.png" alt="Comment"></li></ul><h3 id="gpg生成密钥对"><a href="#gpg生成密钥对" class="headerlink" title="gpg生成密钥对"></a>gpg生成密钥对</h3><ul><li><p>下载安装：<a href="https://www.gpg4win.org/download.html" target="_blank" rel="noopener">https://www.gpg4win.org/download.html</a><br><strong><em>安装时注意的是，只安装主体组件和加密解密窗口的组件就可以了，其他的不需要<del>~</del></em></strong></p></li><li><p>查看是否安装成功:<code>gpg --version</code><br><img src="//image.joylau.cn/blog/gpg-version.png" alt="version"></p></li><li><p>生成密钥对:<code>gpg --gen-key</code><br><img src="//image.joylau.cn/blog/gpg-2.png" alt="gpg --gen-key"><br><img src="//image.joylau.cn/blog/gpg-2.png" alt="gpg --gen-key"></p></li><li><p>之后往下，会让你输入用户名和邮箱，还有一个Passphase，相当于密钥库密码，不要忘记。</p></li><li><p>查看公钥:<code>gpg --list-keys</code></p></li><li><p>将公钥发布到 PGP 密钥服务器</p><pre><code class="bash">  gpg --keyserver hkp://pool.sks-keyservers.net --send-keys C990D076  //可能由于网络问题，有点慢，多重试几次  //查看发布是否成功  gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys C990D076 </code></pre></li></ul><h3 id="配置setting-xml文件和pom-xml文件"><a href="#配置setting-xml文件和pom-xml文件" class="headerlink" title="配置setting.xml文件和pom.xml文件"></a>配置setting.xml文件和pom.xml文件</h3><ul><li><p>setting.xml文件</p><pre><code class="xml">      &lt;servers&gt;          &lt;server&gt;            //记住id，需要和pom文件里的id一致            &lt;id&gt;oss&lt;/id&gt;            &lt;username&gt;username&lt;/username&gt;            &lt;password&gt;password&lt;/password&gt;          &lt;/server&gt;        &lt;/servers&gt;</code></pre></li><li><p>pom.xml文件</p><pre><code class="xml">      &lt;!--        ~ The MIT License (MIT)        ~        ~ Copyright (c) 2017 2587038142@qq.com        ~        ~ Permission is hereby granted, free of charge, to any person obtaining a copy        ~ of this software and associated documentation files (the &quot;Software&quot;), to deal        ~ in the Software without restriction, including without limitation the rights        ~ to use, copy, modify, merge, publish, distribute, sublicense, and/or sell        ~ copies of the Software, and to permit persons to whom the Software is        ~ furnished to do so, subject to the following conditions:        ~        ~ The above copyright notice and this permission notice shall be included in        ~ all copies or substantial portions of the Software.        ~        ~ THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR        ~ IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,        ~ FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE        ~ AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER        ~ LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,        ~ OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN        ~ THE SOFTWARE.        --&gt;      &lt;project xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;               xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;          &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;          &lt;groupId&gt;cn.joylau.code&lt;/groupId&gt;          &lt;artifactId&gt;joylau-echarts&lt;/artifactId&gt;          &lt;version&gt;1.0&lt;/version&gt;          &lt;packaging&gt;jar&lt;/packaging&gt;          &lt;name&gt;joylau-echarts&lt;/name&gt;          &lt;description&gt;Configure the most attribute for ECharts3.0+ by Gson&lt;/description&gt;          &lt;url&gt;http://code.joylau.cn&lt;/url&gt;          &lt;parent&gt;              &lt;groupId&gt;org.sonatype.oss&lt;/groupId&gt;              &lt;artifactId&gt;oss-parent&lt;/artifactId&gt;              &lt;version&gt;7&lt;/version&gt;          &lt;/parent&gt;          &lt;licenses&gt;              &lt;license&gt;                  &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;                  &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;              &lt;/license&gt;          &lt;/licenses&gt;          &lt;developers&gt;              &lt;developer&gt;                  &lt;name&gt;JoyLau&lt;/name&gt;                  &lt;email&gt;2587038142@qq.com&lt;/email&gt;                  &lt;url&gt;http://joylau.cn&lt;/url&gt;              &lt;/developer&gt;          &lt;/developers&gt;          &lt;scm&gt;              &lt;connection&gt;scm:git:git@github.com:JoyLau/joylau-echarts.git&lt;/connection&gt;              &lt;developerConnection&gt;scm:git:git@github.com:JoyLau/joylau-echarts.git&lt;/developerConnection&gt;              &lt;url&gt;git@github.com:JoyLau/joylau-echarts&lt;/url&gt;          &lt;/scm&gt;          &lt;properties&gt;              &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;          &lt;/properties&gt;          &lt;dependencies&gt;              &lt;dependency&gt;                  &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;                  &lt;artifactId&gt;gson&lt;/artifactId&gt;                  &lt;version&gt;2.5&lt;/version&gt;                  &lt;scope&gt;compile&lt;/scope&gt;                  &lt;optional&gt;true&lt;/optional&gt;              &lt;/dependency&gt;          &lt;/dependencies&gt;          &lt;build&gt;              &lt;testResources&gt;                  &lt;testResource&gt;                      &lt;directory&gt;src/test/resources&lt;/directory&gt;                  &lt;/testResource&gt;                  &lt;testResource&gt;                      &lt;directory&gt;src/test/java&lt;/directory&gt;                  &lt;/testResource&gt;              &lt;/testResources&gt;          &lt;/build&gt;          &lt;profiles&gt;              &lt;profile&gt;                  &lt;id&gt;release&lt;/id&gt;                  &lt;build&gt;                      &lt;plugins&gt;                          &lt;!--Compiler--&gt;                          &lt;plugin&gt;                              &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                              &lt;configuration&gt;                                  &lt;source&gt;1.7&lt;/source&gt;                                  &lt;target&gt;1.7&lt;/target&gt;                              &lt;/configuration&gt;                          &lt;/plugin&gt;                          &lt;!-- Source --&gt;                          &lt;plugin&gt;                              &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                              &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;                              &lt;version&gt;2.2.1&lt;/version&gt;                              &lt;executions&gt;                                  &lt;execution&gt;                                      &lt;phase&gt;package&lt;/phase&gt;                                      &lt;goals&gt;                                          &lt;goal&gt;jar-no-fork&lt;/goal&gt;                                      &lt;/goals&gt;                                  &lt;/execution&gt;                              &lt;/executions&gt;                          &lt;/plugin&gt;                          &lt;!-- Javadoc --&gt;                          &lt;plugin&gt;                              &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                              &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;                              &lt;version&gt;2.9.1&lt;/version&gt;                              &lt;executions&gt;                                  &lt;execution&gt;                                      &lt;phase&gt;package&lt;/phase&gt;                                      &lt;goals&gt;                                          &lt;goal&gt;jar&lt;/goal&gt;                                      &lt;/goals&gt;                                  &lt;/execution&gt;                              &lt;/executions&gt;                          &lt;/plugin&gt;                          &lt;!-- GPG --&gt;                          &lt;plugin&gt;                              &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                              &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt;                              &lt;version&gt;1.6&lt;/version&gt;                              &lt;executions&gt;                                  &lt;execution&gt;                                      &lt;phase&gt;verify&lt;/phase&gt;                                      &lt;goals&gt;                                          &lt;goal&gt;sign&lt;/goal&gt;                                      &lt;/goals&gt;                                  &lt;/execution&gt;                              &lt;/executions&gt;                          &lt;/plugin&gt;                      &lt;/plugins&gt;                  &lt;/build&gt;                  &lt;distributionManagement&gt;                      &lt;snapshotRepository&gt;                          &lt;id&gt;oss&lt;/id&gt;                          &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt;                      &lt;/snapshotRepository&gt;                      &lt;repository&gt;                          &lt;id&gt;oss&lt;/id&gt;                          &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;                      &lt;/repository&gt;                  &lt;/distributionManagement&gt;              &lt;/profile&gt;          &lt;/profiles&gt;      &lt;/project&gt;</code></pre></li></ul><h3 id="上传构件到-OSS-中"><a href="#上传构件到-OSS-中" class="headerlink" title="上传构件到 OSS 中"></a>上传构件到 OSS 中</h3><pre><code class="xml">    mvn clean deploy -P release    &lt;--! jdk1.8后再生成javadoc时语法较为严格，这时去除javadoc即可 !--&gt;    mvn clean deploy -P release -Dmaven.javadoc.skip=true</code></pre><p>在上传之前会自动弹出一个对话框，需要输入上面提到的 Passphase，它就是刚才设置的 GPG 密钥库的密码。<br>随后会看到大量的 upload 信息，因为在国内网络的缘故，时间有点久，耐心等待吧。</p><h3 id="在-OSS-中发布构件"><a href="#在-OSS-中发布构件" class="headerlink" title="在 OSS 中发布构件"></a>在 OSS 中发布构件</h3><ul><li>在 OSS 中，使用自己的 Sonatype 账号登录后，可在 Staging Repositories 中查看刚才已上传的构件，这些构件目前是放在 Staging 仓库中，可进行模糊查询，快速定位到自己的构件。</li><li>此时，该构件的状态为 Open，需要勾选它，然后点击 Close 按钮。系统会自动验证该构件是否满足指定要求，当验证完毕后，状态会变为 Closed。<br><img src="//static.dexcoder.com/images/201501/VvtDdbqdERgRv1qn.png" alt="1"></li><li>最后，点击 Release 按钮来发布该构件，这一步没有截图，将就看吧知道就行：<br><img src="//static.dexcoder.com/images/201501/2gPUnClPeYP1Vjbb.png" alt="2"></li></ul><h3 id="等待构件审批通过"><a href="#等待构件审批通过" class="headerlink" title="等待构件审批通过"></a>等待构件审批通过</h3><p>这个，又只能等待了，当然他们晚上上班，还是第二天看。当审批通过后，将会收到邮件通知。</p><h3 id="从中央仓库中搜索构件"><a href="#从中央仓库中搜索构件" class="headerlink" title="从中央仓库中搜索构件"></a>从中央仓库中搜索构件</h3><p>这时，就可以在maven的中央仓库中搜索到自己发布的构件了，以后可以直接在pom.xml中使用了！</p><p>中央仓库搜索网站：<a href="http://search.maven.org/" target="_blank" rel="noopener">http://search.maven.org/</a></p><p>第一次成功发布之后，以后就不用这么麻烦了，可以直接使用Group Id发布任何的构件，当然前提是Group Id没有变。</p><p>以后的发布流程：</p><p>a）构件完成后直接使用maven在命令行上传构建；</p><p>b）在<a href="https://oss.sonatype.org/" target="_blank" rel="noopener">https://oss.sonatype.org/</a> close并release构件；</p><p>c)等待同步好（大约2小时多）之后，就可以使用了</p><h2 id="遇坑记录"><a href="#遇坑记录" class="headerlink" title="遇坑记录"></a>遇坑记录</h2><ul><li>安装GPG时候，没有安装弹框组件，导致gpg密码框弹不出来</li><li>一开始所有的命令行都在git下操作，每次部署的时候都是提示没有私钥错误，后来发现git生成的gpg密钥对在user更目录下，切换到CMD操作，是生成在AppData下。经查看有私钥，问题解决</li></ul><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><ul><li>前一部分为自己实践所写</li><li>后面上传构件，发布版本参考：<a href="http://blog.csdn.net/hj7jay/article/details/51130398" target="_blank" rel="noopener">http://blog.csdn.net/hj7jay/article/details/51130398</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Maven篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Maven </tag>
            
            <tag> GPG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序员，那些年吹过的牛逼，最后都自己加班了</title>
      <link href="/2017/03/14/Programmer-Boast/"/>
      <url>/2017/03/14/Programmer-Boast/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>有一部分程序员中的老司机，他们善于找各种借口，少干活，少背锅，多拿钱。但是，更多的程序员坦诚、直白、意气用事。<br>那些年吹过的牛逼都实现了吗？还是随风而去？</p><p><strong>这个功能简单，一天就能搞完</strong><br><img src="//img.mp.itc.cn/upload/20170313/f5e38c95009545c19e2b90c4b7b5f847.jpeg" alt="Images"><br>程序员拿到一个新功能，心里暗暗发笑，这剧情我见过啊。于是脱口而出，这功能简单，一天就能做完，明天上线肯定没问题。<br>结果，眼看着到自己设定的截止日期了，还有一部分代码没有写完，怎么办？<br>很简单啊，又不是生死状，又不要命。解决办法很简单，加班～～～<br>程序员，那些年吹过的牛逼，最后都自己加班了。</p><p><strong>这段代码肯定没bug，我都测试过了</strong><br><img src="//img.mp.itc.cn/upload/20170313/12a3cbfcb0e84455b6d88fd703138a09_th.jpeg" alt="Images"><br>功能开发完了，拿去测试吧，拿去玩耍吧，上线吧，部署吧，发给客户吧，肯定没问题的。<br>结果，很多时候还没发布。要么测试发现bug，要么产品发现bug，要么老板发现bug。<br>你的第一反应就是：是特么你们不会用老子开发的功能吧？你乐呵呵的看着bug复现，怎么办呢？<br>很简单啊，紧急修复bug，重新发布。时间来不及了？加班啊～～～<br>程序员，那些年吹过的牛逼，最后都自己加班了。</p><p><strong>我用的是最现在最流行的技术，某某大公司也用这个</strong><br><img src="//img.mp.itc.cn/upload/20170313/45cadc5ce7b647efacbf3bfb97419c19_th.jpeg" alt="Images"><br>在技术讨论会上，你侃侃而谈，我精心设计的前后端分离的框架，我使用了现在最流行的界面库，我们用的技术某某独角兽公司都在使用，肯定是最好的。<br>结果呢，使用的技术太新。Github上很少有相关的开源项目，Stack Overflow上很少有这方面的问答。你被一个问题搞的昏天暗地，只能默默的看官方文档，而且是英文的（这是好事儿）。<br>啊？项目着急上线怎么办呢？加班啊～～～<br>程序员，那些年吹过的牛逼，最后都自己加班了。</p><p><strong>重构代码，很快就能完成</strong><br><img src="//img.mp.itc.cn/upload/20170313/6f7b00b3323943c99cb9dffef860c60b.gif" alt="Images"></p><ul><li>何为Code refactoring<blockquote><p>Code refactoring is the process of restructuring existing computer code—changing the factoring—without changing its external behavior.</p></blockquote></li></ul><p>之前为了快速迭代，忽略了代码的结构和质量。正好最近这两天没有什么新功能开发，我要重构一下现有的代码，绝对没问题。<br>结果呢，两天的空窗期没搞定。明天就要开发新的功能了，怎么办呢？加班啊～～～<br>程序员，那些年吹过的牛逼，最后都自己加班了。</p><p><strong>向外行介绍程序员工作的复杂程度</strong><br>在工作中经常能听到这样的话「不就加个按钮么？怎么要做两天时天？」。那么，作为程序员如何解释自己的工作复杂度呢？<br>如果你的老板是技术出身，那你很庆幸，他能理解你实现一个小小功能，修改一个小小功能所付出的辛苦劳动。<br>如果你的老板不懂技术，也许你就要无穷无尽的加班了。给你的忠告就是：做正确的事儿，等着被开除。这是一位谷歌工程师说的话。<br>如果你的产品经理懂技术，那么你既是幸运的也是不幸的。<br>幸运的是，他可以理解程序员工作的复杂度。但是“不幸”的是，你再也不能为了偷懒找借口。<br>当产品经理提出一个方案时，你再也不敢坚定地说“技术不可行”。因为你害怕产品经理自己写好了代码给你，那是多么尴尬的境地。</p><ul><li>下面是 Channing Walton 的用泡茶的例子来解释，非常形象。<br>　　- 请他们描述泡出一杯茶需要哪些步骤，他们会这么说：<br>　　- 烧水<br>　　- 把茶叶放到茶壶里<br>　　- 水烧开后倒入茶壶<br>　　- 等待5分钟<br>　　- 把茶倒进杯子<br>　　- 加牛奶<br>　　- 喝<br>　　- 现在，有趣的开始了。你要开始问这样的问题:<br>　　- 烧水?<br>　　- 水哪来的？<br>　　- 热水壶在哪里？<br>　　- 你怎么把水倒进热水壶？<br>　　- 你怎么知道热水壶壶里要倒多少水？<br>　　- 如果没有水/热水壶/电怎么办呢?<br>　　- 假如加水传感器失效怎么办?<br>　　- 假如煮水传感器失效怎么办？<br>　　- 茶叶放到茶壶里?<br>　　- 茶壶在哪里，如果没有茶壶怎么办？烧水之前我们应该考虑到这些问题吗?<br>　　- 茶叶在哪里，要用哪一种茶叶？我们是否应该先问清楚，或许如果没有对应的茶叶，我们甚至都不应该开始泡茶?<br>　　- 关于加水和传感器也可以有类似的问题要问<br>　　- 倒开水?<br>　　- 你确定水已经开了么？你怎么能确保“倒水”的机器从热水壶那收到“烧水完成”的信号呢?<br>　　- 你如何确保倒水的机器知道热水壶在哪里?<br>　　- 如果热水壶在倒水的过程翻了怎么办呢?</li></ul><p>程序员代码提交中的骂声<br>正如你工作中看到的，写代码会让你骂骂咧咧，经常爆粗口。<br>另外有数据统计，写 C++ 程序，会比写 PHP 或 Python 程序所遭到的骂声更多。<br>Andrew Vos在找一个周末项目，于是决定在 GitHub 上抓取100百万条提交信息（commit），并扫描其中的脏话。<br><img src="//img.mp.itc.cn/upload/20170313/be133d300641446aa7c0f7ec1485c7f6_th.jpeg" alt="Images">　　</p><ul><li>而且程序员最喜欢的一句是：<br>　　“<strong>去TMD，咱们就这样发布。</strong>”</li></ul>]]></content>
      
      
      <categories>
          
          <category> 程序员篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 程序员 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JS数组去重最简单方法</title>
      <link href="/2017/03/14/JavaScript-The-Easiest-Way-to-Repeat-of-Array/"/>
      <url>/2017/03/14/JavaScript-The-Easiest-Way-to-Repeat-of-Array/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><pre><code class="javascript">    let arr = [1, 1, 2, 2]    arr = Array.prototype.slice.call(new Set(arr))    alert(arr)    //output: 1, 2</code></pre>]]></content>
      
      
      <categories>
          
          <category> JavaScript篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 环境集成</title>
      <link href="/2017/03/14/SpringBoot-Integrate/"/>
      <url>/2017/03/14/SpringBoot-Integrate/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/SpringBoot-build-better-enterprise.png" alt="build-better-enterprise"></p><h2 id="SpringBoot文章推荐"><a href="#SpringBoot文章推荐" class="headerlink" title="SpringBoot文章推荐"></a>SpringBoot文章推荐</h2><ul><li><a href="/2017/03/13/SpringBoot-Basic/">重剑无锋,大巧不工 SpringBoot — 基础篇</a></li><li><a href="/2017/03/14/SpringBoot-Research/">重剑无锋,大巧不工 SpringBoot — 探索篇</a></li><li><a href="/2017/03/14/SpringBoot-Integrate/">重剑无锋,大巧不工 SpringBoot — 环境集成</a></li><li><a href="/2017/03/21/SpringBoot-SpringBatch/">重剑无锋,大巧不工 SpringBoot — 批处理SpringBatch</a></li><li><a href="/2017/06/12/SpringBoot-RequestBody/">重剑无锋,大巧不工 SpringBoot — @RequestBody JSON参数处理</a></li><li><a href="/2017/06/12/SpringBoot-Question-Tips/">重剑无锋,大巧不工 SpringBoot — 项目问题汇总及解决</a></li><li><a href="/2017/06/13/SpringBoot-ConfigurationProperties/">重剑无锋,大巧不工 SpringBoot — 属性注入</a></li><li><a href="/2017/06/16/SpringBoot-RabbitMQ/">重剑无锋,大巧不工 SpringBoot — 整合RabbitMQ</a></li><li><a href="/2017/06/18/SpringBoot-RESTfulAPI/">重剑无锋,大巧不工 SpringBoot — RESTful API</a></li><li><a href="/2017/07/18/SpringBoot-MongoDB/">重剑无锋,大巧不工 SpringBoot — 整合使用MongoDB</a></li><li><a href="/2017/09/19/SpringBoot-CaffeineCache/">重剑无锋,大巧不工 SpringBoot — 推荐使用CaffeineCache</a></li></ul><h2 id="SpringBoot项目实战"><a href="#SpringBoot项目实战" class="headerlink" title="SpringBoot项目实战"></a>SpringBoot项目实战</h2><ul><li><a href="/2017/07/24/SpringBoot-JoyMedia/">重剑无锋,大巧不工 SpringBoot — 实战项目 JoyMedia （ 分析篇 ）</a></li><li><a href="/2017/07/29/SpringBoot-JoyMedia-Node/">重剑无锋,大巧不工 SpringBoot — 实战项目 JoyMedia （ Node篇 ）</a></li><li><a href="/2017/08/06/SpringBoot-JoyMedia-Search/">重剑无锋,大巧不工 SpringBoot — 实战项目 JoyMedia （ 搜索篇 ）</a></li><li><a href="/2017/08/20/SpringBoot-JoyMedia-MV/">重剑无锋,大巧不工 SpringBoot — 实战项目 JoyMedia （ MV 篇 ）</a></li><li><a href="/2017/08/29/SpringBoot-JoyMedia-NoReferer/">重剑无锋,大巧不工 SpringBoot — 实战项目 JoyMedia （ NoReferer篇 ）</a></li></ul><blockquote><p>不啰嗦，直接上代码</p></blockquote><h2 id="集成Druid"><a href="#集成Druid" class="headerlink" title="集成Druid"></a>集成Druid</h2><h3 id="DruidConfig"><a href="#DruidConfig" class="headerlink" title="DruidConfig:"></a>DruidConfig:</h3><pre><code class="java">    /**     * Created by LiuFa on 2016/9/14.     * cn.lfdevelopment.www.sys.druid     * DevelopmentApp     */    @Configuration    public class DruidConfig{        private Logger logger = LoggerFactory.getLogger(getClass());        @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;close&quot;)        @ConfigurationProperties(prefix=&quot;spring.datasource&quot;)        public DataSource druidDataSource(){            return new DruidDataSource() {                @Override                public void setUsername(String username) {                    try {                        username = ConfigTools.decrypt(username);                    } catch (Exception e) {                        e.printStackTrace();                    }                    super.setUsername(username);                }                @Override                public void setUrl(String jdbcUrl) {                    try {                        jdbcUrl = ConfigTools.decrypt(jdbcUrl);                    } catch (Exception e) {                        e.printStackTrace();                    }                    super.setUrl(jdbcUrl);                }            };        }    }</code></pre><h3 id="DruidStatViewConfig"><a href="#DruidStatViewConfig" class="headerlink" title="DruidStatViewConfig:"></a>DruidStatViewConfig:</h3><pre><code class="java">    /**     * Created by LiuFa on 2016/8/8.     * cn.lfdevelopment.www.sys.druid     * DevelopmentApp     * 这样的方式不需要添加注解：@ServletComponentScan     */    @Configuration    public class DruidStatViewConfig {        @Value(&quot;${spring.druid.loginUsername}&quot;)        private String loginUsername;        @Value(&quot;${spring.druid.loginPassword}&quot;)        private String loginPassword;        /**         * 注册一个StatViewServlet         * 使用Druid的内置监控页面         */        @Bean        public ServletRegistrationBean DruidStatViewServlet() {            ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new StatViewServlet(),                    &quot;/druid/*&quot;);            //添加初始化参数：initParams            //白名单            //ip配置规则            //配置的格式            //&lt;IP&gt; 或者 &lt;IP&gt;/&lt;SUB_NET_MASK_size&gt; 多个ip地址用逗号隔开            //其中            //128.242.127.1/24            //24表示，前面24位是子网掩码，比对的时候，前面24位相同就匹配。            //由于匹配规则不支持IPV6，配置了allow或者deny之后，会导致IPV6无法访问。            servletRegistrationBean.addInitParameter(&quot;allow&quot;, &quot;&quot;);            //deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝。            //如果allow没有配置或者为空，则允许所有访问            //IP黑名单 (存在共同时，deny优先于allow) : 如果满足deny的话提示:Sorry, you are not permitted to view this page.            servletRegistrationBean.addInitParameter(&quot;deny&quot;, &quot;&quot;);            //登录查看信息的账号密码.            try {                servletRegistrationBean.addInitParameter(&quot;loginUsername&quot;, ConfigTools.decrypt(loginUsername));                servletRegistrationBean.addInitParameter(&quot;loginPassword&quot;, ConfigTools.decrypt(loginPassword));            } catch (Exception e) {                e.printStackTrace();            }            //是否能够重置数据.            servletRegistrationBean.addInitParameter(&quot;resetEnable&quot;, &quot;true&quot;);            return servletRegistrationBean;        }        /**         * 注册一个：filterRegistrationBean         * 内置监控中的Web关联监控的配置         */        @Bean        public FilterRegistrationBean druidStatFilter() {            FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter());            //添加过滤规则.            filterRegistrationBean.addUrlPatterns(&quot;/*&quot;);            //排除一些不必要的url            filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;);            //缺省sessionStatMaxCount是1000个,这里设置了3000个            filterRegistrationBean.addInitParameter(&quot;sessionStatMaxCount&quot;, &quot;3000&quot;);            //可以配置principalCookieName，使得druid知道指定的sessionName是谁    //        filterRegistrationBean.addInitParameter(&quot;principalSessionName&quot;, &quot;sessionId&quot;);            //druid 0.2.7版本开始支持profile，配置profileEnable能够监控单个url调用的sql列表。            filterRegistrationBean.addInitParameter(&quot;profileEnable&quot;, &quot;true&quot;);            return filterRegistrationBean;        }        /**         * 注册一个:druidStatInterceptor         */        /*@Bean        public DruidStatInterceptor druidStatInterceptor(){            return new DruidStatInterceptor();        }*/        /**         * 注册一个：beanNameAutoProxyCreator         * 内置监控中的spring关联监控的配置         * 该方法使用的是按照BeanId来拦截配置，还有2种方法，分别是         * 按类型拦截配置         * 方法名正则匹配拦截配置         */        /*@Bean        public BeanNameAutoProxyCreator beanNameAutoProxyCreator(){            BeanNameAutoProxyCreator beanNameAutoProxyCreator = new BeanNameAutoProxyCreator();            beanNameAutoProxyCreator.setProxyTargetClass(true);            beanNameAutoProxyCreator.setBeanNames(&quot;*Controller&quot;);            beanNameAutoProxyCreator.setInterceptorNames(&quot;druidStatInterceptor&quot;);            return beanNameAutoProxyCreator;        }*/    }</code></pre><h3 id="application-dev"><a href="#application-dev" class="headerlink" title="application-dev:"></a>application-dev:</h3><pre><code class="properties">    #druid配置    spring.datasource.type=com.alibaba.druid.pool.DruidDataSource    spring.datasource.driver-class-name=com.mysql.jdbc.Driver    spring.datasource.url=G11Jor+OrLz9MFztdkOfqRnrJKVrFCDdBbYJFmB0qGjUARxPr2tiyRzUn4xbnk/XqPgM8PMjdIJ/pO8UF4aeVg==    spring.datasource.username=bNVOqb7WKLX5Bjnw+LMv92taj25KOxDimXxILPQjw42wgv+1lHzOH8kr97xDwWdhpY67QuYCS7sWN4W46YbkFA==    spring.datasource.password=l65GeQaXVXxx2ogcQeZLAFM7VcPwgzc9202vxql4hjCbjM8dVm/sD4osdvaBdVkC+BiYdnYL2EzpaCysXAZ5Gw==    # 下面为连接池的补充设置，应用到上面所有数据源中    # 初始化大小，最小，最大    spring.datasource.initialSize=10    spring.datasource.minIdle=25    spring.datasource.maxActive=250    # 配置获取连接等待超时的时间    spring.datasource.maxWait=60000    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒    spring.datasource.timeBetweenEvictionRunsMillis=1200000    # 配置一个连接在池中最小生存的时间，单位是毫秒    spring.datasource.minEvictableIdleTimeMillis=1800000    spring.datasource.validationQuery=SELECT &#39;x&#39;    #建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。    spring.datasource.testWhileIdle=true    #申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。    spring.datasource.testOnBorrow=false    #归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能    spring.datasource.testOnReturn=false    # 打开PSCache，并且指定每个连接上PSCache的大小  如果用Oracle，则把poolPreparedStatements配置为true，mysql可以配置为false。分库分表较多的数据库，建议配置为false 在mysql5.5以下的版本中没有PSCache功能，建议关闭掉。5.5及以上版本有PSCache，建议开启。    spring.datasource.poolPreparedStatements=true    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&#39;wall&#39;用于防火墙,&#39;stat&#39;用于监控，‘log4j’用于日志,&#39;config&#39;是指ConfigFilter    spring.datasource.filters=wall,stat,config    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录,超过3秒就是慢sql    spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=3000;config.decrypt=true    # 合并多个DruidDataSource的监控数据,缺省多个DruidDataSource的监控数据是各自独立的，在Druid-0.2.17版本之后，支持配置公用监控数据    spring.datasource.useGlobalDataSourceStat=true    #druid登陆用户名    spring.druid.loginUsername=lCzd9geWAuAuJtLhpaG/J+d28H8KiMFAWopxXkYpMNdUai6Xe/LsPqMQeg5MIrmvtMa+hzycdRhWs29ZUPU1IQ==    #druid登录密码    spring.druid.loginPassword=hf96/2MU+Q12fdb9oZN9ghub1OHmUBa8YuW7NJf8Pll/sawcaRVscHTpr4t5SB39+KbJn31Lqy76uEDvj+sgMw==</code></pre><h2 id="集成Mybatis"><a href="#集成Mybatis" class="headerlink" title="集成Mybatis"></a>集成Mybatis</h2><h3 id="MyBatisConfig"><a href="#MyBatisConfig" class="headerlink" title="MyBatisConfig"></a>MyBatisConfig</h3><pre><code class="java">    /**     * Created by LiuFa on 2016/8/8.     * cn.lfdevelopment.www.sys.mybatis     * DevelopmentApp     * DataSource 交由Druid自动根据配置创建     */    @Configuration    @EnableTransactionManagement    public class MyBatisConfig implements TransactionManagementConfigurer {        @Autowired        private DataSource dataSource;        @Bean        public SqlSessionFactory sqlSessionFactory() throws Exception {            SqlSessionFactoryBean bean = new SqlSessionFactoryBean();            bean.setDataSource(dataSource);            bean.setTypeAliasesPackage(&quot;cn.lfdevelopment.www.app.**.pojo&quot;);            //支持属性使用驼峰的命名,mapper配置不需要写字段与属性的配置，会自动映射。            org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();            configuration.setMapUnderscoreToCamelCase(true);            bean.setConfiguration(configuration);            //分页插件            PageHelper pageHelper = new PageHelper();            Properties properties = new Properties();            /* 3.3.0版本可用 - 分页参数合理化，默认false禁用             启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页             禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据             在EXTjs里面配置与否无所谓，因为在前台传过来的分页数据已经进行合理化了 */            properties.setProperty(&quot;reasonable&quot;, &quot;true&quot;);            properties.setProperty(&quot;supportMethodsArguments&quot;, &quot;true&quot;);            properties.setProperty(&quot;returnPageInfo&quot;, &quot;check&quot;);           /* 3.5.0版本可用 - 为了支持startPage(Object params)方法             增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值             可以配置pageNum,pageSize,count,pageSizeZero,reasonable,orderBy,不配置映射的用默认值             不理解该含义的前提下，不要随便复制该配置 --&gt;*/    //        properties.setProperty(&quot;params&quot;, &quot;count=countSql&quot;);            pageHelper.setProperties(properties);            //添加插件            bean.setPlugins(new Interceptor[]{pageHelper});            //添加XML目录            ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();            try {                bean.setMapperLocations(resolver.getResources(&quot;classpath*:mapperxml/**/*Mapper.xml&quot;));                return bean.getObject();            } catch (Exception e) {                e.printStackTrace();                throw new RuntimeException(e);            }        }        @Bean        public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) {            return new SqlSessionTemplate(sqlSessionFactory);        }        @Bean        @Override        public PlatformTransactionManager annotationDrivenTransactionManager() {            try {                return new DataSourceTransactionManager(dataSource);            } catch (Exception e) {                e.printStackTrace();                return null;            }        }    }</code></pre><h3 id="MyBatisMapperScannerConfig"><a href="#MyBatisMapperScannerConfig" class="headerlink" title="MyBatisMapperScannerConfig"></a>MyBatisMapperScannerConfig</h3><pre><code class="java">    /**     * MyBatis扫描接口，使用的tk.mybatis.spring.mapper.MapperScannerConfigurer，如果你不使用通用Mapper，可以改为org.xxx...     */    @Configuration    //由于MapperScannerConfigurer执行的比较早    public class MyBatisMapperScannerConfig {        @Bean        public static MapperScannerConfigurer mapperScannerConfigurer() {            MapperScannerConfigurer mapperScannerConfigurer = new MapperScannerConfigurer();            mapperScannerConfigurer.setSqlSessionFactoryBeanName(&quot;sqlSessionFactory&quot;);            mapperScannerConfigurer.setBasePackage(&quot;cn.lfdevelopment.www.app.**.mapper&quot;);            Properties properties = new Properties();            properties.setProperty(&quot;mappers&quot;, &quot;cn.lfdevelopment.www.sys.base.BaseMapper&quot;);            properties.setProperty(&quot;notEmpty&quot;, &quot;false&quot;);            properties.setProperty(&quot;IDENTITY&quot;, &quot;MYSQL&quot;);            mapperScannerConfigurer.setProperties(properties);            return mapperScannerConfigurer;        }    }</code></pre><h2 id="集成Redis"><a href="#集成Redis" class="headerlink" title="集成Redis"></a>集成Redis</h2><h3 id="RedisConfig"><a href="#RedisConfig" class="headerlink" title="RedisConfig"></a>RedisConfig</h3><pre><code class="java">/** * Created by LiuFa on 2016/9/5. * cn.lfdevelopment.www.sys.redis * DevelopmentApp */@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport {    @Bean    public KeyGenerator keyGenerator() {        return (target, method, params) -&gt; {            StringBuilder sb = new StringBuilder();            sb.append(target.getClass().getName());            sb.append(method.getName());            for (Object obj : params) {                sb.append(obj.toString());            }            return sb.toString();        };    }    @Bean    public CacheManager cacheManager(RedisTemplate redisTemplate) {        return new RedisCacheManager(redisTemplate);    }    /**     * StringRedisTemplate     * @param factory     * @return     */    @Bean    public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) {        StringRedisTemplate template = new StringRedisTemplate(factory);        Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);        template.setValueSerializer(jackson2JsonRedisSerializer);        template.afterPropertiesSet();        return template;    }    /**     * redisTemplateForShiro     * @param factory     * @return     */    @Bean    public RedisTemplate&lt;byte[], Object&gt; redisTemplateForShiro(RedisConnectionFactory factory) {        RedisTemplate&lt;byte[], Object&gt; redisTemplateForShiro = new RedisTemplate&lt;&gt;();        redisTemplateForShiro.setConnectionFactory(factory);        return redisTemplateForShiro;    }}</code></pre><h2 id="集成Shiro"><a href="#集成Shiro" class="headerlink" title="集成Shiro"></a>集成Shiro</h2><h3 id="ShiroConfiguration"><a href="#ShiroConfiguration" class="headerlink" title="ShiroConfiguration"></a>ShiroConfiguration</h3><pre><code class="java">    /**     * Created by LiuFa on 2016/9/13.     * cn.lfdevelopment.www.sys.shiro     * DevelopmentApp     */    @Configuration    public class ShiroConfiguration {        /**         * FilterRegistrationBean         * @return         */        @Autowired        private RedisTemplate redisTemplate;        @Bean        public FilterRegistrationBean filterRegistrationBean() {            FilterRegistrationBean filterRegistration = new FilterRegistrationBean();            filterRegistration.setFilter(new DelegatingFilterProxy(&quot;shiroFilter&quot;));            filterRegistration.addInitParameter(&quot;targetFilterLifecycle&quot;,&quot;true&quot;);            filterRegistration.addUrlPatterns(&quot;/*&quot;);            filterRegistration.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;);    //        filterRegistration.setAsyncSupported(true);            filterRegistration.setDispatcherTypes(DispatcherType.REQUEST);            return filterRegistration;        }        /**         * @see org.apache.shiro.spring.web.ShiroFilterFactoryBean         * @return         */        @Bean(name = &quot;shiroFilter&quot;)        public ShiroFilterFactoryBean shiroFilter(){            ShiroFilterFactoryBean bean = new ShiroFilterFactoryBean();            bean.setSecurityManager(securityManager());            bean.setLoginUrl(&quot;/login&quot;);            bean.setSuccessUrl(&quot;/main&quot;);            //验证不具备权限后的转向页面            bean.setUnauthorizedUrl(&quot;/main&quot;);            Map&lt;String, Filter&gt; filters = new LinkedHashMap&lt;&gt;();            filters.put(&quot;authc&quot;,shiroFormAuthenticationFilter());            filters.put(&quot;session&quot;,sessionFilter());            filters.put(&quot;rolesOr&quot;,rolesAuthorizationFilter());            bean.setFilters(filters);            Map&lt;String, String&gt; chains = new LinkedHashMap&lt;&gt;();            chains.put(&quot;/favicon.ico&quot;,&quot;anon&quot;);            chains.put(&quot;/&quot;,&quot;anon&quot;);            chains.put(&quot;/index&quot;,&quot;anon&quot;);            chains.put(&quot;/blog&quot;,&quot;anon&quot;);            chains.put(&quot;/blog/**&quot;,&quot;anon&quot;);            chains.put(&quot;/weixin&quot;,&quot;anon&quot;);            chains.put(&quot;/weixin/**&quot;,&quot;anon&quot;);            chains.put(&quot;/static/**&quot;, &quot;anon&quot;);            chains.put(&quot;/getGifCode&quot;,&quot;anon&quot;);            chains.put(&quot;/404&quot;, &quot;anon&quot;);            chains.put(&quot;/druid/**&quot;,&quot;anon&quot;);            chains.put(&quot;/logout&quot;, &quot;logout&quot;);            chains.put(&quot;/login&quot;, &quot;authc&quot;);            chains.put(&quot;/main&quot;,&quot;authc&quot;);            chains.put(&quot;/**&quot;, &quot;session,user&quot;);            bean.setFilterChainDefinitionMap(chains);            return bean;        }        /**         * @see org.apache.shiro.mgt.SecurityManager         * @return         */        @Bean(name=&quot;securityManager&quot;)        public DefaultWebSecurityManager securityManager() {            DefaultWebSecurityManager manager = new DefaultWebSecurityManager();            manager.setRealm(userRealm());            manager.setCacheManager(redisCacheManager());            manager.setSessionManager(defaultWebSessionManager());            return manager;        }        /**         * @see DefaultWebSessionManager         * @return         */        @Bean(name=&quot;sessionManager&quot;)        public DefaultWebSessionManager defaultWebSessionManager() {            DefaultWebSessionManager sessionManager = new DefaultWebSessionManager();            sessionManager.setCacheManager(redisCacheManager());            sessionManager.setGlobalSessionTimeout(1800000);            sessionManager.setDeleteInvalidSessions(true);            sessionManager.setSessionValidationSchedulerEnabled(true);            sessionManager.setSessionValidationInterval(600000);            sessionManager.setSessionIdUrlRewritingEnabled(false);            return sessionManager;        }        /**         * @return         */        @Bean        @DependsOn(value={&quot;lifecycleBeanPostProcessor&quot;, &quot;shrioRedisCacheManager&quot;})        public AuthorizingRealm userRealm() {            AuthorizingRealm userRealm = new AuthorizingRealm();            userRealm.setCacheManager(redisCacheManager());            userRealm.setCachingEnabled(true);            userRealm.setAuthenticationCachingEnabled(true);            userRealm.setAuthorizationCachingEnabled(true);            return userRealm;        }        @Bean(name=&quot;shrioRedisCacheManager&quot;)        @DependsOn(value=&quot;redisTemplate&quot;)        public ShrioRedisCacheManager redisCacheManager() {            ShrioRedisCacheManager cacheManager = new ShrioRedisCacheManager(redisTemplate);            return cacheManager;        }        @Bean        public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() {            return new LifecycleBeanPostProcessor();        }        @Bean(name = &quot;authcFilter&quot;)        public FormAuthenticationFilter shiroFormAuthenticationFilter(){            return new AuthcFilter();        }        @Bean        public SessionFilter sessionFilter(){            return new SessionFilter();        }        @Bean(name = &quot;rolesOrFilter&quot;)        public RolesAuthorizationFilter rolesAuthorizationFilter(){            return new RolesAuthorizationFilter() {                @Override                public boolean isAccessAllowed(ServletRequest request,                                               ServletResponse response, Object mappedValue) throws IOException {                    Subject subject = getSubject(request, response);                    String[] rolesArray = (String[]) mappedValue;                    if ((rolesArray == null) || (rolesArray.length == 0)) {                        return true;                    }                    for (String aRolesArray : rolesArray) {                        if (subject.hasRole(aRolesArray)) {                            //用户只要拥有任何一个角色则验证通过                            return true;                        }                    }                    return false;                }            };        }    }</code></pre><h3 id="ShiroRedisCache"><a href="#ShiroRedisCache" class="headerlink" title="ShiroRedisCache"></a>ShiroRedisCache</h3><pre><code class="java">    /**     * Created by LiuFa on 2016/9/13.     * cn.lfdevelopment.www.sys.shiro     * DevelopmentApp     */    public class ShrioRedisCache&lt;K, V&gt; implements Cache&lt;K, V&gt; {        private org.slf4j.Logger log = LoggerFactory.getLogger(getClass());        @Autowired        private RedisTemplate&lt;byte[], V&gt; redisTemplate;        private String prefix = &quot;shiro_redis:&quot;;        public ShrioRedisCache(RedisTemplate&lt;byte[], V&gt; redisTemplate) {            this.redisTemplate = redisTemplate;        }        public ShrioRedisCache(RedisTemplate&lt;byte[], V&gt; redisTemplate, String prefix) {            this(redisTemplate);            this.prefix = prefix;        }        @Override        public V get(K key) throws CacheException {            if(log.isDebugEnabled()) {                log.debug(&quot;Key: {}&quot;, key);            }            if(key == null) {                return null;            }            byte[] bkey = getByteKey(key);            return redisTemplate.opsForValue().get(bkey);        }        @Override        public V put(K key, V value) throws CacheException {            if(log.isDebugEnabled()) {                log.debug(&quot;Key: {}, value: {}&quot;, key, value);            }            if(key == null || value == null) {                return null;            }            byte[] bkey = getByteKey(key);            redisTemplate.opsForValue().set(bkey, value);            return value;        }        @Override        public V remove(K key) throws CacheException {            if(log.isDebugEnabled()) {                log.debug(&quot;Key: {}&quot;, key);            }            if(key == null) {                return null;            }            byte[] bkey = getByteKey(key);            ValueOperations&lt;byte[], V&gt; vo = redisTemplate.opsForValue();            V value = vo.get(bkey);            redisTemplate.delete(bkey);            return value;        }        @Override        public void clear() throws CacheException {            redisTemplate.getConnectionFactory().getConnection().flushDb();        }        @Override        public int size() {            Long len = redisTemplate.getConnectionFactory().getConnection().dbSize();            return len.intValue();        }        @SuppressWarnings(&quot;unchecked&quot;)        @Override        public Set&lt;K&gt; keys() {            byte[] bkey = (prefix+&quot;*&quot;).getBytes();            Set&lt;byte[]&gt; set = redisTemplate.keys(bkey);            Set&lt;K&gt; result = new HashSet&lt;&gt;();            if(CollectionUtils.isEmpty(set)) {                return Collections.emptySet();            }            for(byte[] key: set) {                result.add((K)key);            }            return result;        }        @Override        public Collection&lt;V&gt; values() {            Set&lt;K&gt; keys = keys();            List&lt;V&gt; values = new ArrayList&lt;&gt;(keys.size());            for(K k: keys) {                byte[] bkey = getByteKey(k);                values.add(redisTemplate.opsForValue().get(bkey));            }            return values;        }        private byte[] getByteKey(K key){            if(key instanceof String){                String preKey = this.prefix + key;                return preKey.getBytes();            }else{                return SerializeUtils.serialize(key);            }        }        public String getPrefix() {            return prefix;        }        public void setPrefix(String prefix) {            this.prefix = prefix;        }    }</code></pre><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><ul><li>本文暂未完结，后续将持续集成更多第三方框架，或接着更新，或另起新篇</li><li>详细代码内容可在GitHub上follow</li></ul>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 探索篇</title>
      <link href="/2017/03/14/SpringBoot-Research/"/>
      <url>/2017/03/14/SpringBoot-Research/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/SpringBootStart-Main.png-image1" alt="SpringBootStart-Main"></p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>我们开发任何一个Spring Boot项目，都会用到如下的启动类</p><pre><code class="java">        @SpringBootApplication        public class JoylauApplication {            public static void main(String[] args) {                SpringApplication.run(JoylauApplication.class, args);            }        }</code></pre><p>从上面代码可以看出，Annotation定义（@SpringBootApplication）和类定义（SpringApplication.run）最为耀眼，所以要揭开SpringBoot的神秘面纱，我们要从这两位开始就可以了。</p><h2 id="SpringBootApplication背后的秘密"><a href="#SpringBootApplication背后的秘密" class="headerlink" title="SpringBootApplication背后的秘密"></a>SpringBootApplication背后的秘密</h2><pre><code class="java">    @Target({ElementType.TYPE})    @Retention(RetentionPolicy.RUNTIME)    @Documented    @Inherited    @SpringBootConfiguration    @EnableAutoConfiguration    @ComponentScan(        excludeFilters = {@Filter(        type = FilterType.CUSTOM,        classes = {TypeExcludeFilter.class}    ), @Filter(        type = FilterType.CUSTOM,        classes = {AutoConfigurationExcludeFilter.class}    )}    )    public @interface SpringBootApplication {        @AliasFor(            annotation = EnableAutoConfiguration.class,            attribute = &quot;exclude&quot;        )        Class&lt;?&gt;[] exclude() default {};        @AliasFor(            annotation = EnableAutoConfiguration.class,            attribute = &quot;excludeName&quot;        )        String[] excludeName() default {};        @AliasFor(            annotation = ComponentScan.class,            attribute = &quot;basePackages&quot;        )        String[] scanBasePackages() default {};        @AliasFor(            annotation = ComponentScan.class,            attribute = &quot;basePackageClasses&quot;        )        Class&lt;?&gt;[] scanBasePackageClasses() default {};    }</code></pre><p>虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：</p><ul><li><code>@Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）</code></li><li><code>@EnableAutoConfiguration</code></li><li><code>@ComponentScan</code><br>所以，如果我们使用如下的SpringBoot启动类，整个SpringBoot应用依然可以与之前的启动类功能对等：<pre><code class="java">  @Configuration  @EnableAutoConfiguration  @ComponentScan  public class JoylauApplication {      public static void main(String[] args) {          SpringApplication.run(Application.class, args);      }  }</code></pre></li></ul><p>每次写这3个比较累，所以写一个@SpringBootApplication方便点。接下来分别介绍这3个Annotation。</p><h3 id="Configuration"><a href="#Configuration" class="headerlink" title="@Configuration"></a>@Configuration</h3><p>这里的@Configuration对我们来说不陌生，它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。<br>举几个简单例子回顾下，XML跟config配置方式的区别：</p><ul><li>表达形式层面<br>基于XML配置的方式是这样：<pre><code class="xml">  &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;  &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd&quot;       default-lazy-init=&quot;true&quot;&gt;    &lt;!--bean定义--&gt;  &lt;/beans&gt;</code></pre>而基于JavaConfig的配置方式是这样：<pre><code class="java">  @Configuration  public class MockConfiguration{    //bean定义  }</code></pre></li></ul><p>任何一个标注了@Configuration的Java类定义都是一个JavaConfig配置类。</p><ul><li>注册bean定义层面<br>基于XML的配置形式是这样：<pre><code class="xml">  &lt;bean id=&quot;mockService&quot; class=&quot;..MockServiceImpl&quot;&gt;    ...  &lt;/bean&gt;</code></pre></li></ul><p>而基于JavaConfig的配置形式是这样的：</p><pre><code class="java">    @Configuration    public class MockConfiguration{      @Bean      public MockService mockService(){          return new MockServiceImpl();      }    }</code></pre><p>任何一个标注了@Bean的方法，其返回值将作为一个bean定义注册到Spring的IoC容器，方法名将默认成该bean定义的id。</p><ul><li><p>表达依赖注入关系层面<br>为了表达bean与bean之间的依赖关系，在XML形式中一般是这样：</p><pre><code class="xml">  &lt;bean id=&quot;mockService&quot; class=&quot;..MockServiceImpl&quot;&gt;      &lt;propery name =&quot;dependencyService&quot; ref=&quot;dependencyService&quot; /&gt;  &lt;/bean&gt;  &lt;bean id=&quot;dependencyService&quot; class=&quot;DependencyServiceImpl&quot;&gt;&lt;/bean&gt;</code></pre><p>而基于JavaConfig的配置形式是这样的:</p><pre><code class="java">  @Configuration  public class MockConfiguration{      @Bean      public MockService mockService(){          return new MockServiceImpl(dependencyService());      }      @Bean      public DependencyService dependencyService(){          return new DependencyServiceImpl();      }  }</code></pre></li></ul><p>如果一个bean的定义依赖其他bean,则直接调用对应的JavaConfig类中依赖bean的创建方法就可以了。</p><h3 id="ComponentScan"><a href="#ComponentScan" class="headerlink" title="@ComponentScan"></a>@ComponentScan</h3><p>@ComponentScan这个注解在Spring中很重要，它对应XML配置中的<a href="context:component-scan">context:component-scan</a>元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。</p><p>我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。</p><blockquote><p>注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。</p></blockquote><h3 id="EnableAutoConfiguration"><a href="#EnableAutoConfiguration" class="headerlink" title="@EnableAutoConfiguration"></a>@EnableAutoConfiguration</h3><p>个人感觉@EnableAutoConfiguration这个Annotation最为重要，所以放在最后来解读，大家是否还记得Spring框架提供的各种名字为@Enable开头的Annotation定义？比如@EnableScheduling、@EnableCaching、@EnableMBeanExport等，@EnableAutoConfiguration的理念和做事方式其实一脉相承，简单概括一下就是，借助@Import的支持，收集和注册特定场景相关的bean定义。</p><ul><li>@EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。</li><li>@EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。<br>而@EnableAutoConfiguration也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器，仅此而已！</li></ul><p>@EnableAutoConfiguration作为一个复合Annotation,其自身定义关键信息如下：</p><pre><code class="java">    @SuppressWarnings(&quot;deprecation&quot;)    @Target(ElementType.TYPE)    @Retention(RetentionPolicy.RUNTIME)    @Documented    @Inherited    @AutoConfigurationPackage    @Import(EnableAutoConfigurationImportSelector.class)    public @interface EnableAutoConfiguration {        ...    }</code></pre><p>其中，最关键的要属@Import(EnableAutoConfigurationImportSelector.class)，借助EnableAutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。就像一只“八爪鱼”一样</p><h3 id="深入探索SpringApplication执行流程"><a href="#深入探索SpringApplication执行流程" class="headerlink" title="深入探索SpringApplication执行流程"></a>深入探索SpringApplication执行流程</h3><p>SpringApplication的run方法的实现是我们本次旅程的主要线路，该方法的主要流程大体可以归纳如下：</p><p>1） 如果我们使用的是SpringApplication的静态run方法，那么，这个方法里面首先要创建一个SpringApplication对象实例，然后调用这个创建好的SpringApplication的实例方法。在SpringApplication实例初始化的时候，它会提前做几件事情：</p><ul><li>根据classpath里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为Web应用使用的ApplicationContext类型。</li><li>使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitializer。</li><li>使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationListener。</li><li>推断并设置main方法的定义类。<br>2） SpringApplication实例初始化完成并且完成设置后，就开始执行run方法的逻辑了，方法执行伊始，首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener。调用它们的started()方法，告诉这些SpringApplicationRunListener，“嘿，SpringBoot应用要开始执行咯！”。</li></ul><p>3） 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。</p><p>4） 遍历调用所有SpringApplicationRunListener的environmentPrepared()的方法，告诉他们：“当前SpringBoot应用使用的Environment准备好了咯！”。</p><p>5） 如果SpringApplication的showBanner属性被设置为true，则打印banner。</p><p>6） 根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成，然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader，当然，最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用。</p><p>7） ApplicationContext创建好之后，SpringApplication会再次借助Spring-FactoriesLoader，查找并加载classpath中所有可用的ApplicationContext-Initializer，然后遍历调用这些ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。</p><p>8） 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。</p><p>9） 最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext。</p><p>10） 遍历调用所有SpringApplicationRunListener的contextLoaded()方法。</p><p>11） 调用ApplicationContext的refresh()方法，完成IoC容器可用的最后一道工序。</p><p>12） 查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。</p><p>13） 正常情况下，遍历执行SpringApplicationRunListener的finished()方法、（如果整个过程出现异常，则依然调用所有SpringApplicationRunListener的finished()方法，只不过这种情况下会将异常信息一并传入处理）<br>去除事件通知点后，整个流程如下：<br><img src="//image.joylau.cn/blog/SpringBoot-start-model.jpg" alt="SpringBoot-start-model"></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>大部分参考了《SpringBoot揭秘快速构建为服务体系》这本书</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重剑无锋,大巧不工 SpringBoot --- 基础篇</title>
      <link href="/2017/03/13/SpringBoot-Basic/"/>
      <url>/2017/03/13/SpringBoot-Basic/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/springbootstart.png" alt="SpringBoot-Start"></p><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><blockquote><ul><li>玄铁重剑是神雕侠侣中杨过的兵器，外表看似笨重无比，但内在却精致有细。</li><li>在脚本语言和敏捷开发大行其道的时代，JavaEE的开发显得尤为笨重，这使得很多开发人员本应该如此，Spring在提升JavaEE的开发效率上从未停止过努力，SpringBoot的出现时具有颠覆性和划时代意义的。</li></ul></blockquote><h2 id="开始准备"><a href="#开始准备" class="headerlink" title="开始准备"></a>开始准备</h2><ul><li>JDK1.7+</li><li>Maven3.x+</li><li>Tomcat8.5+</li><li>Spring4.3.x+</li><li>IntelliJ IDEA / MyEclipse（强烈推荐IDEA，我认为IDEA目前所有 IDE 中最具备沉浸式的 IDE，<strong>没有之一</strong>）</li></ul><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li><code>习惯优于配置</code>：使用SpringBoot只需要很少的配置，在绝大部分时候我们只需要使用默认配置</li><li>项目极速搭建，可无配置整合其他第三方框架,极大提高开发效率</li><li>完全不使用XML配置，只使用自动配置和JavaConfig</li><li>内嵌Servlet容器，可打成jar包独立运行</li><li>强大的运行时监控</li><li>浑然天成的集成云计算</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li><img src="//tb2.bdstatic.com/tb/editor/images/face/i_f10.png?t=20140803" alt="流汗">没有</li></ul><h2 id="优雅的开始"><a href="#优雅的开始" class="headerlink" title="优雅的开始"></a>优雅的开始</h2><ul><li>Spring 官方网站搭建<ol><li>访问：<a href="http://start.spring.io/" target="_blank" rel="noopener">http://start.spring.io/</a></li><li>选择构建工具Maven Project、Spring Boot版本1.5.1以及一些工程基本信息，可参考下图所示<br> <img src="//image.joylau.cn/blog/SpringInitializr.png" alt="SpringInitializr"></li><li>点击Generate Project下载项目压缩包</li><li>导入到你的工程，如果是IDEA，则需要：<br>a.菜单中选择<code>File–&gt;New–&gt;Project from Existing Sources...</code><br>b.选择解压后的项目文件夹，点击OK<br>c.点击<code>Import project from external model</code>并选择Maven，点击Next到底为止。<br>d.若你的环境有多个版本的JDK，注意到选择Java SDK的时候请选择Java 7以上的版本</li></ol></li></ul><ul><li>IntelliJ IDEA创建（<strong>强烈推荐</strong>）<br>在File菜单里面选择 New &gt; Project,然后选择Spring Initializr，接着如下图一步步操作即可。<br><img src="//image.joylau.cn/blog/SpringInitializr-IDEA.png" alt="SpringInitializr"><br><img src="//image.joylau.cn/blog/SpringInitializr-IDEA-2.png" alt="SpringInitializr-2"><br><img src="//image.joylau.cn/blog/SpringInitializr-IDEA-3.png" alt="SpringInitializr-3"><br><img src="//image.joylau.cn/blog/SpringInitializr-IDEA-4.png" alt="SpringInitializr-4"></li></ul><p>若上述步骤步骤没有出现网络错误导致的无法搭建，基本上已经没有什么问题了</p><h3 id="项目目录"><a href="#项目目录" class="headerlink" title="项目目录"></a>项目目录</h3><p>根据上面的操作已经初始化了一个Spring Boot的框架了，项目结构如下：<br><img src="//image.joylau.cn/blog/SpringBootProject-view.png" alt="SpringBootProject-view"></p><p>项目里面基本没有代码，除了几个空目录外，还包含如下几样东西。</p><ul><li><code>pom.xml</code>：Maven构建说明文件。</li><li><code>JoylauApplication.java</code>：一个带有main()方法的类，用于启动应用程序（关键）。</li><li><code>JoylauApplicationTests.java</code>：一个空的Junit测试类，它加载了一个使用Spring Boot字典配置功能的Spring应用程序上下文。</li><li><code>application.properties</code>：一个空的properties文件，你可以根据需要添加配置属性。(还推荐一种yml文件的配置方式)</li></ul><h3 id="项目文件"><a href="#项目文件" class="headerlink" title="项目文件"></a>项目文件</h3><p>我们来看pom.xml文件<br>    <code>xml        &lt;parent&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;            &lt;version&gt;1.5.0.RELEASE&lt;/version&gt;            &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;        &lt;/parent&gt;</code><br>这块配置就是Spring Boot父级依赖，有了这个，当前的项目就是Spring Boot项目了，spring-boot-starter-parent是一个特殊的starter,它用来提供相关的Maven默认依赖，使用它之后，常用的包依赖可以省去version标签。</p><p>并不是每个人都喜欢继承自spring-boot-starter-parent POM。也有可能我们需要使用的自己的公司标准parent，或者我们更喜欢显式声明所有的Maven配置。<br>如果不想使用spring-boot-starter-parent，仍然可以通过使用scope = import依赖关系来保持依赖关系管理：<br>    <code>xml        &lt;dependencyManagement&gt;             &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;!-- Import dependency management from Spring Boot --&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                    &lt;version&gt;1.5.0.RELEASE&lt;/version&gt;                    &lt;type&gt;pom&lt;/type&gt;                    &lt;scope&gt;import&lt;/scope&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/dependencyManagement&gt;</code></p><p>该设置不允许使用<code>spring-boot-dependencies</code>所述的属性(properties)覆盖各个依赖项，要实现相同的结果，需要在<code>spring-boot-dependencies</code>项之前的项目的dependencyManagement中添加一个配置，例如，要升级到另一个Spring Data版本系列，可以将以下内容添加到pom.xml中。<br>    <code>xml    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;!-- Override Spring Data release train provided by Spring Boot --&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;                &lt;artifactId&gt;spring-data-releasetrain&lt;/artifactId&gt;                &lt;version&gt;Fowler-SR2&lt;/version&gt;                &lt;scope&gt;import&lt;/scope&gt;                &lt;type&gt;pom&lt;/type&gt;            &lt;/dependency&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                &lt;version&gt;1.5.1.RELEASE&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;</code></p><h3 id="项目依赖"><a href="#项目依赖" class="headerlink" title="项目依赖"></a>项目依赖</h3><h4 id="起步依赖-spring-boot-starter-xx"><a href="#起步依赖-spring-boot-starter-xx" class="headerlink" title="起步依赖 spring-boot-starter-xx"></a>起步依赖 spring-boot-starter-xx</h4><p>Spring Boot提供了很多”开箱即用“的依赖模块，都是以spring-boot-starter-xx作为命名的。举个例子来说明一下这个起步依赖的好处，比如组装台式机和品牌机，自己组装的话需要自己去选择不同的零件，最后还要组装起来，期间有可能会遇到零件不匹配的问题。耗时又消力，而品牌机就好一点，买来就能直接用的，后续想换零件也是可以的。相比较之下，后者带来的效果更好点（这里就不讨论价格问题哈），起步依赖就像这里的品牌机，自动给你封装好了你想要实现的功能的依赖。就比如我们之前要实现web功能，引入了spring-boot-starter-web这个起步依赖。我们来看看spring-boot-starter-web到底依赖了哪些,如下图：<br><img src="//image.joylau.cn/blog/SpringBoot-starter-web-dependencies.png" alt="SpringBoot-starter-web-dependencies"></p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><h3 id="项目启动的三种方式"><a href="#项目启动的三种方式" class="headerlink" title="项目启动的三种方式"></a>项目启动的三种方式</h3><ol><li><code>main</code>方法<br><img src="//image.joylau.cn/blog/SpringBoot-Start1.png" alt="SpringBoot-Start1"></li><li>使用命令 <code>mvn spring-boot:run</code>在命令行启动该应用，IDEA中该命令在如下位置<br><img src="//image.joylau.cn/blog/SpringBoot-Start2.png" alt="SpringBoot-Start2"></li><li>运行<code>mvn package</code>进行打包时，会打包成一个可以直接运行的 JAR 文件，使用<code>java -jar</code>命令就可以直接运行<br><img src="//image.joylau.cn/blog/SpringBoot-Start3.png" alt="SpringBoot-Start3"><br><img src="//image.joylau.cn/blog/SpringBoot-Start4.png" alt="SpringBoot-Start4"></li></ol>]]></content>
      
      
      <categories>
          
          <category> SpringBoot篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- 视图界面</title>
      <link href="/2017/02/23/Linux-GUI/"/>
      <url>/2017/02/23/Linux-GUI/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/desktop.png" alt="MATE Desktop"></p><blockquote><p>上面的截图是我安装好之后界面，安装的是MATE桌面</p></blockquote><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li>1.阿里云官网默认的Linux Centos7系统镜像，都是没有安装桌面环境的，用户如果要使用桌面，需要自己在服务器上进行安装</li><li>2.生产环境下不要安装桌面，毕竟生产环境下的资源都是很紧张的</li><li><code>groups</code>是Centos7才有的命令</li></ul><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><ul><li><p>登录服务器，执行命令安装桌面环境（537M）</p><pre><code class="bash">      yum groups install &quot;MATE Desktop&quot;</code></pre></li><li><p>安装好MATE Desktop 后，再安装X Window System（19M） </p><pre><code class="bash">      yum groups install &quot;X Window System&quot;</code></pre></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li>设置服务器默认启动桌面 <pre><code class="bash">      systemctl  set-default  graphical.target</code></pre></li></ul><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><ul><li>重启服务器 <pre><code class="bash">  reboot</code></pre></li></ul><p>在ECS控制台,用管理终端登录服务器,进入到服务器系统登录界面，用root密码登录服务器。</p><h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><pre><code class="bash">    yum groupremove &#39;X Window System&#39; -y    yum groupremove &#39;MATE Desktop&#39; -y    // 恢复至默认启动界面    systemctl set-default multi-user.target</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> MATE Desktop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- 常用命令备忘</title>
      <link href="/2017/02/23/Linux-Command/"/>
      <url>/2017/02/23/Linux-Command/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><pre><code>``` bash    ////////////////////////////////////////////////////////////////////    //                          _ooOoo_                               //    //                         o8888888o                              //    //                         88&quot; . &quot;88                              //    //                         (| ^_^ |)                              //    //                         O\  =  /O                              //    //                      ____/`---&#39;\____                           //    //                    .&#39;  \\|     |//  `.                         //    //                   /  \\|||  :  |||//  \                        //    //                  /  _||||| -:- |||||-  \                       //    //                  |   | \\\  -  /// |   |                       //    //                  | \_|  &#39;&#39;\---/&#39;&#39;  |   |                       //    //                  \  .-\__  `-`  ___/-. /                       //    //                ___`. .&#39;  /--.--\  `. . ___                     //    //              .&quot;&quot; &#39;&lt;  `.___\_&lt;|&gt;_/___.&#39;  &gt;&#39;&quot;&quot;.                  //    //            | | :  `- \`.;`\ _ /`;.`/ - ` : | |                 //    //            \  \ `-.   \_ __\ /__ _/   .-` /  /                 //    //      ========`-.____`-.___\_____/___.-`____.-&#39;========         //    //                           `=---=&#39;                              //    //      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^        //    //                    佛祖保佑       永无BUG                        //    ////////////////////////////////////////////////////////////////////```</code></pre><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li>有一些命令是centos7特有的，在低版本的可能无法使用</li></ul><h3 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h3><ul><li>查看防火墙状态：  <code>systemctl status firewalld</code></li><li>开启防火墙 ：  <code>systemctl start  firewalld</code></li><li>停止防火墙：  <code>systemctl disable firewalld</code></li><li>重启防火墙：  <code>systemctl restart firewalld.service</code></li><li>开启80端口：  <code>firewall-cmd --zone=public --add-port=80/tcp --permanent</code></li><li>禁用防火墙：  <code>systemctl stop firewalld</code></li><li>查看防火墙开放的端口号：  <code>firewall-cmd --list-ports</code></li></ul><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><ul><li>查看tomcat运行状态：<code>ps -ef |grep tomcat</code></li><li>看到tomcat的pid之后：<code>kill -9 pid</code> 可以强制杀死tomcat的进程</li></ul><h3 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h3><ul><li>查看cpu及内存使用情况：<code>top</code>(停止刷新 <code>-q</code>)</li><li>查看内存使用情况 ：<code>free</code></li></ul><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><ul><li>删除文件里机器子文件夹的内容：<code>rm -rf /var/lib/mysql</code></li><li>查找某个文件所在目录：<code>find / -name filename</code></li></ul><h3 id="压缩与解压缩"><a href="#压缩与解压缩" class="headerlink" title="压缩与解压缩"></a>压缩与解压缩</h3><ul><li>解压zip压缩文件：<code>unzip file.zip</code>，相反的，压缩文件 zip file （需安装<code>yum install unzip zip</code>,），解压到指定目录可加参数-d,如：<code>unzip file.zip -d /root/</code></li><li>将 test.txt 文件压缩为 test.zip，<code>zip test.zip test.txt</code>,当然也可以指定压缩包的目录，例如 /root/test.zip ,后面的test.txt也可以换成文件夹</li><li>linux下是不支持直接解压rar压缩文件，建议将要传输的文件压缩成zip文件</li><li><code>yum install p7zip</code> 安装7z解压，支持更多压缩格式（卸载<code>yum remove p7zip</code>）</li></ul><h3 id="快速删除文件夹-文件"><a href="#快速删除文件夹-文件" class="headerlink" title="快速删除文件夹/文件"></a>快速删除文件夹/文件</h3><ul><li>有时我们的文件夹里有很多文件，默认的删除方式是递归删除，文件夹深了及文件多了，删除会非常的慢，这时候：</li><li>先建立一个空目录<br><code>mkdir /data/blank</code></li><li>用rsync删除目标目录<br><code>rsync–delete-before -d /data/blank/ /var/spool/clientmqueue/</code></li><li>同样的对于大文件：创建空文件<br><code>touch /data/blank.txt</code></li><li>用rsync清空文件<br><code>rsync-a –delete-before –progress –stats /root/blank.txt /root/nohup.out</code></li></ul><h3 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h3><ul><li>查看6379端口是否占用：<code>netstat -tunpl | grep 6379</code> (注意，redis服务需要 root 权限才能查看，不然只能检查到6379被某个进程占用，但是看不到进程名称。)</li></ul><h3 id="主机"><a href="#主机" class="headerlink" title="主机"></a>主机</h3><ul><li>修改主机名：<code>hostnamectl set-hostname 新主机名</code></li></ul><h3 id="yum"><a href="#yum" class="headerlink" title="yum"></a>yum</h3><ul><li>列出所有可更新的软件清单命令：<code>yum check-update</code></li><li>更新所有软件命令：<code>yum update</code></li><li>仅安装指定的软件命令：<code>yum install &lt;package_name&gt;</code></li><li>仅更新指定的软件命令：<code>yum update &lt;package_name&gt;</code></li><li>列出所有可安裝的软件清单命令：<code>yum list</code></li><li>删除软件包命令：<code>yum remove &lt;package_name&gt;</code></li><li>查找软件包 命令：<code>yum search &lt;keyword&gt;</code></li><li>清除缓存命令:   </li><li><code>yum clean packages</code>: 清除缓存目录下的软件包</li><li><code>yum clean headers</code>: 清除缓存目录下的 headers</li><li><code>yum clean oldheaders</code>: 清除缓存目录下旧的 headers</li></ul><h3 id="systemctl"><a href="#systemctl" class="headerlink" title="systemctl"></a>systemctl</h3><ul><li><code>systemctl restart nginx</code> : 重启nginx</li><li><code>systemctl start nginx</code> : 开启nginx</li><li><code>systemctl stop nginx</code> : 关闭nginx</li><li><code>systemctl enable nginx</code> : nginx开机启动</li><li><code>systemctl disable nginx</code> : 禁用nginx开机启动</li><li><code>systemctl status nginx</code> : 查看nginx服务信息</li><li><code>systemctl is-enabled nginx</code> ： 查看服务是否开机启动</li><li><code>systemctl list-unit-files|grep enabled</code> ： 查看已启动的服务列表</li><li><code>systemctl --failed</code> ： 查看启动失败的服务列表</li><li><code>systemctl daemon-reload</code> ： 重新加载service文件</li><li><code>systemctl reboot</code> : 重启</li><li><code>systemctl poweroff</code> : 关机</li></ul><h3 id="压缩解压命令"><a href="#压缩解压命令" class="headerlink" title="压缩解压命令"></a>压缩解压命令</h3><h4 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h4><ul><li>tar –cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg</li><li>tar –czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</li><li>tar –cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2</li><li>tar –cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z</li><li>rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux</li><li>zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux</li></ul><h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><ul><li>tar –xvf file.tar //解压 tar包</li><li>tar -xzvf file.tar.gz //解压tar.gz</li><li>tar -xjvf file.tar.bz2   //解压 tar.bz2</li><li>tar –xZvf file.tar.Z   //解压tar.Z</li><li>unrar e file.rar //解压rar</li><li>unzip file.zip //解压zip</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li>.tar 用 tar –xvf 解压</li><li>.gz 用 gzip -d或者gunzip 解压</li><li>.tar.gz和*.tgz 用 tar –xzf 解压</li><li>.bz2 用 bzip2 -d或者用bunzip2 解压</li><li>.tar.bz2用tar –xjf 解压</li><li>.Z 用 uncompress 解压</li><li>.tar.Z 用tar –xZf 解压</li><li>.rar 用 unrar e解压</li><li>.zip 用 unzip 解压</li></ul><h3 id="yum更换为阿里源"><a href="#yum更换为阿里源" class="headerlink" title="yum更换为阿里源"></a>yum更换为阿里源</h3><ul><li><p>备份 ：mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</p></li><li><p>下载新的CentOS-Base.repo 到/etc/yum.repos.d/</p></li></ul><pre><code class="shell">    ## CentOS 5 ：    wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo    ## 或者    curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo    ## CentOS 6 ：     wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo    ## 或者    curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo    ## CentOS 7 ：     wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo    ## 或者    curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code></pre><ul><li>之后运行 yum makecache 生成缓存</li></ul><h2 id="创建用户，权限，密码等"><a href="#创建用户，权限，密码等" class="headerlink" title="创建用户，权限，密码等"></a>创建用户，权限，密码等</h2><ul><li>adduser es -s /bin/bash  : 创建用户为 es ,shell指定为bash</li><li>passwd es 更改 es 用户的密码</li><li>chown -R es:es /project/elasticsearch-5.6.3 循环遍历更改 /project/elasticsearch-5.6.3 目录下的文件拥有者及用户组</li><li>su - es : 切换成es用户重新登录系统</li><li>su es : 表示与 es 建立一个连接，通过 es 来执行命令</li></ul><p>注： 以上命令在安装 elasticsearch 时都会用的到</p><h2 id="2018-06-22-更新"><a href="#2018-06-22-更新" class="headerlink" title="2018-06-22 更新"></a>2018-06-22 更新</h2><ol><li><p>vim 永久显示行号 vim /etc/vimrc 添加 <code>set nu</code> 或者 <code>set number</code></p></li><li><p>最小化安装 centos 是没有 tab 键补全提示的， 需要安装 <code>yum install bash-completion</code></p></li><li><p>tab 补全提示不区分大小写 ： vim /etc/inputrc 添加 <code>set completion-ignore-case on</code></p></li></ol><p>注： 以上 增加配置是全局的，只对当前用户的话，可以在当前目录下新建相应的文件，再添加配置，例如： ~/.inputrc</p><h2 id="2018-9-12-更新"><a href="#2018-9-12-更新" class="headerlink" title="2018-9-12 更新"></a>2018-9-12 更新</h2><ol><li>killall -9 nginx : 批量结束指定进程，比如不小心运行了 nginx，会产生1个master和n个work进程，这时候一个个结束不实际，killall就是最好的方式</li><li>有时候我们安装 rpm 安装包会出现某些依赖库找不到，比如<br> <code>libSM.so.6: cannot open shared object file: No such file or directory</code><br> 这时候我们使用 <code>yum provides libSM.so.6</code> 来寻找包含的动态库</li></ol><pre><code class="shell">    Loaded plugins: fastestmirror    Loading mirror speeds from cached hostfile    gperftools-libs-2.6.1-1.el7.i686 : Libraries provided by gperftools    Repo        : Private-Base    Matched from:    Provides    : libprofiler.so.0</code></pre><p>找到后安装即可 <code>yum install gperftools-libs</code></p><h2 id="2018-12-20-更新"><a href="#2018-12-20-更新" class="headerlink" title="2018-12-20 更新"></a>2018-12-20 更新</h2><ol><li><code>/dev/null 2&gt;&amp;1</code> 解释<br> <code>&gt;</code> 覆盖原来的内容<br> <code>&gt;&gt;</code> 在原来的内容上追加新的内容<br> 0是标准输入    <code>使用&lt;或&lt;&lt;</code><br> 1是标准输出   <code>使用&gt;或&gt;&gt;</code><br> 2是标准错误输出  <code>使用2&gt;或2&gt;&gt;</code><br> <code>&gt;/dev/null 2&gt;&amp;1</code>  即错误输出与标准输出全部重定向到空,可以写成 <code>1&gt;/dev/null 2&gt;/dev/null</code><br> 标准输入0和标准输出1可以省略。（当其出现重定向符号左侧时)<br> 文件描述符在重定向符号左侧时直接写即可，在右侧时前面加&amp;<br> 文件描述符与重定向符号之间不能有空格</li></ol><h2 id="2019-01-23-更新"><a href="#2019-01-23-更新" class="headerlink" title="2019-01-23 更新"></a>2019-01-23 更新</h2><ol start="0"><li>在命令后加个<code>&amp;</code> 代表该命令在后台运行, shell 的控制台会立即释放,但是和守护进程又不一样, shell 断开会终止运行</li><li><code>command &gt; file.log 2&gt;&amp;1</code> 等价于 <code>command 2&gt;file.log 1&gt;&amp;2</code> 前一个指的是标准错误重定向到标准输出,标准输出在重定向到文件 file.log 中, 其中 1 省略了;后一个指的是标准输出重定向到标准错误,标准错误又重定向到文件 file.log, 其中2 不能省略</li><li>shell 脚本中无法报命令不存在的错误: 在 shell 脚本第一行使用 <code>#!/usr/bin/env bash</code> 或者 <code>#!/usr/bin/bash</code> 或者 <code>#!/bin/bash</code></li><li>如果运行还是命令不存在的话: 创建一个软连接 <code>ln -s command /usr/bin/command</code>, 参数 -s 创建了个符号链接,相当于快捷方式,不加参数 -s 就是创建硬链接,相当于文件拷贝</li></ol><h2 id="2019-03-07-更新"><a href="#2019-03-07-更新" class="headerlink" title="2019-03-07 更新"></a>2019-03-07 更新</h2><p>没有联网的机器做时间服务器,写了个接口获取网络的时间,然后服务器使用 crontab 定时设置时间<br>java:</p><pre><code class="java">    /**     * 同步时间     */    @GetMapping(&quot;traffic/syncDateTime&quot;)    public String syncDateTime() {        String taobaoTime = &quot;http://api.m.taobao.com/rest/api.do?api=mtop.common.getTimestamp&quot;;        String suningTime = &quot;http://quan.suning.com/getSysTime.do&quot;;        JSONObject jsonObject;        jsonObject = getDateTime(taobaoTime);        if (null != jsonObject &amp;&amp; jsonObject.containsKey(&quot;data&quot;)) {            String time = jsonObject.getJSONObject(&quot;data&quot;).getString(&quot;t&quot;);            return LocalDateTime.ofEpochSecond(Long.parseLong(time) / 1000, 0, ZoneOffset.ofHours(8))                    .format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;));        }        jsonObject = getDateTime(suningTime);        if (null != jsonObject &amp;&amp; jsonObject.containsKey(&quot;sysTime2&quot;)) {            return jsonObject.getString(&quot;sysTime2&quot;);        }        return null;    }    private JSONObject getDateTime(String url){        return restTemplate.getForObject(url,JSONObject.class);    }</code></pre><p>shell:</p><pre><code class="bash">    #!/usr/bin/env bash    time=$(curl -G -s http://34.0.7.227:9338/traffic/syncDateTime)    if [ ! -n &quot;$time&quot; ]; then      echo &quot;time is null....&quot;      else      date -s &quot;${time}&quot;      hwclock -w    fi</code></pre><h2 id="2019-03-15-更新"><a href="#2019-03-15-更新" class="headerlink" title="2019-03-15 更新"></a>2019-03-15 更新</h2><ol><li>shell 修改文件固定行的内容</li></ol><pre><code class="bash">    sed -i &quot;108c &#39;update content&#39;&quot; filename</code></pre><h2 id="2019-03-18-更新"><a href="#2019-03-18-更新" class="headerlink" title="2019-03-18 更新"></a>2019-03-18 更新</h2><h4 id="删除-Ubuntu-多余内核"><a href="#删除-Ubuntu-多余内核" class="headerlink" title="删除 Ubuntu 多余内核"></a>删除 Ubuntu 多余内核</h4><ol><li><code>dpkg --get-selections|grep linux</code> : 查看全部安装的内核</li><li>确定当前使用的内核,一般为版本号最新的内核,删除旧内核: <code>sudo apt remove linux-headers-4.15.0-43    linux-headers-4.15.0-43-generic linux-image-4.15.0-43-generic linux-modules-4.15.0-43-generic linux-modules-extra-4.15.0-43-generic</code></li><li>再次输入第一步的命令查看现在的内核信息,现在会看到刚才删除的内核会出现 <code>deinstall</code> 的状态</li><li>删除 <code>deinstall</code> 状态的内核: <code>sudo dpkg -P xxxxxx</code></li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CMD </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- 生产环境的搭建</title>
      <link href="/2017/02/23/Linux-BuildingEnvironment/"/>
      <url>/2017/02/23/Linux-BuildingEnvironment/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/server.jpg" alt="Server"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul><li>本次搭建<code>Java</code>和<code>Tomcat</code>的运行环境，后续将接着搭建Mysql，Git,Nginx,Redis,Docker…环境</li></ul><h2 id="Java环境搭建"><a href="#Java环境搭建" class="headerlink" title="Java环境搭建"></a>Java环境搭建</h2><ul><li><p>1.在/usr/目录下创建java目录</p><pre><code class="bash">      [root@JoyLau ~]# mkdir/usr/java      [root@JoyLau ~]# cd /usr/java</code></pre></li><li><p>2.官网下载jdk,拷贝到服务器上，然后解压</p><pre><code class="bash">         [root@JoyLau java]# tar -zxvf jdk-8u121-linux-x64.gz</code></pre></li><li><p>3.设置环境变量</p><pre><code class="bash">          [root@JoyLau java]# vi /etc/profile</code></pre></li><li><p>4.在profile中添加如下内容:</p><pre><code class="bash">    #set java environment    JAVA_HOME=/usr/java/jdk1.8.0_121    JRE_HOME=/usr/java/jdk1.8.0_121    CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib    PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin    export JAVA_HOME JRE_HOME CLASS_PATH PATH</code></pre></li><li><p>5.让修改生效:</p><pre><code class="bash">    [root@JoyLau java]# source /etc/profile</code></pre></li><li><p>6.验证</p><pre><code class="bash">      [root@JoyLau ~]# java --version      java version &quot;1.8.0_121&quot;      Java(TM) SE Runtime Environment (build 1.8.0_121-b13)      Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)</code></pre></li><li><p>还有2中方法可以安装jdk：</p><ul><li>1.用<code>yum</code>安装jdk</li><li>2.<code>Ubuntu</code> 上使用<code>apt-get</code>安装jdk</li></ul></li></ul><h3 id="yum-安装jdk"><a href="#yum-安装jdk" class="headerlink" title="yum 安装jdk"></a>yum 安装jdk</h3><ul><li>yum search jdk ： 查看yum源上的jdk版本信息</li><li>选择一个jdk8的来安装： yum install java-1.8.0-openjdk.x86_64</li><li>等待即可</li></ul><p>注意的是默认安装的只是 Java JRE，而不是 JDK，为了开发方便，我们还是需要通过 yum 进行安装 JDK<br>yum install java-1.8.0-openjdk-devel.x86_64</p><p>之后就可以直接使用 Java javac 命令了</p><p>配置 JAVA_HOME变量:</p><p>vim ~/.bashrc<br>在文件最后面添加如下单独一行（指向 JDK 的安装位置），并保存：<br>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk<br>接着还需要让该环境变量生效，执行如下代码：<br>source ~/.bashrc    # 使变量设置生效<br>设置好后我们来检验一下是否设置正确：<br>echo $JAVA_HOME     # 检验变量值<br>java -version<br>$JAVA_HOME/bin/java -version  # 与直接执行 java -version 一样<br>如果设置正确的话，$JAVA_HOME/bin/java -version 会输出 java 的版本信息，且和 java -version 的输出结果一样</p><h3 id="rpm-安装jdk"><a href="#rpm-安装jdk" class="headerlink" title="rpm 安装jdk"></a>rpm 安装jdk</h3><ol><li>官网下载 jdk rpm包</li><li>rpm -ivh jdk_xxxxx.rpm</li><li>配置环境变量（和上述配置一致）</li><li>卸载： rpm -qa|grep jdk ， 查出什么，就使用 rpm -e –nodeps java_xxx 来卸载</li></ol><h2 id="Tomcat环境搭建"><a href="#Tomcat环境搭建" class="headerlink" title="Tomcat环境搭建"></a>Tomcat环境搭建</h2><h3 id="先配置"><a href="#先配置" class="headerlink" title="先配置"></a>先配置</h3><ul><li><p>配置catalina.sh,加入以下配置</p><pre><code class="bash">      #add JAVA and TOMCAT config      JAVA_OPTS=&quot;-Xms512m -Xmx1024m -Xss1024K -XX:PermSize=512m -XX:MaxPermSize=1024m&quot;      export TOMCAT_HOME=/project/apache-tomcat-8.5.11      export CATALINA_HOME=/project/apache-tomcat-8.5.11      export JRE_HOME=/usr/java/jdk1.8.0_121/jre      export JAVA_HOME=/usr/java/jdk1.8.0_121      #add tomcat pid      CATALINA_PID=&quot;$TOMCAT_HOME/tomcat.pid&quot;</code></pre></li></ul><ul><li><p>增加tomcat.service在<code>/usr/lib/systemd/system</code>目录下增加<code>tomcat.service</code>，目录必须是绝对目录。</p><pre><code class="bash">      [Unit]      Description=Tomcat      After=syslog.target network.target remote-fs.target nss-lookup.target      [Service]      Type=forking      PIDFile=/project/apache-tomcat-8.5.11/tomcat.pid      ExecStart=/project/apache-tomcat-8.5.11/bin/startup.sh       ExecReload=/bin/kill -s HUP $MAINPID      ExecStop=/bin/kill -s QUIT $MAINPID      PrivateTmp=true      [Install]      WantedBy=multi-user.target </code></pre><h3 id="再使用"><a href="#再使用" class="headerlink" title="再使用"></a>再使用</h3></li><li><p>配置开机启动 <code>systemctl enable tomcat</code></p></li><li><p>启动tomcat <code>systemctl start tomcat</code></p></li><li><p>停止tomcat <code>systemctl stop tomcat</code></p></li><li><p>重启tomcat <code>systemctl restart tomcat</code></p></li></ul><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ul><li>因为配置pid，在启动的时候会再tomcat根目录生成tomcat.pid文件，停止之后删除</li><li>同时tomcat在启动时候，执行start不会启动两个tomcat，保证始终只有一个tomcat服务在运行</li><li>多个tomcat可以配置在多个目录下，互不影响。</li></ul><h3 id="遇到2个很尴尬的问题"><a href="#遇到2个很尴尬的问题" class="headerlink" title="遇到2个很尴尬的问题"></a>遇到2个很尴尬的问题</h3><ul><li>这个问题我尝试过很多次，那就是Tomcat启动的特别慢，后来查看日志发现是部署项目的时候花费时间特别长，详细看<a href="http://bbs.qcloud.com/thread-25271-1-1.html" target="_blank" rel="noopener">这里</a></li><li>遇到无法启动的问题，最后是<code>startup.sh</code>没有权限，你知道该怎么做的~~</li></ul><h3 id="使用yum安装的tomcat注意"><a href="#使用yum安装的tomcat注意" class="headerlink" title="使用yum安装的tomcat注意"></a>使用yum安装的tomcat注意</h3><ul><li>安装位置   <em>/etc/tomcat</em></li><li>主程序/软件存放webapp位置   <em>/var/lib/tomcat/webapps</em></li><li>在Centos使用yum安装后，Tomcat相关的目录都已采用符号链接到/usr/share/tomcat6目录，包含webapps等，这很方便我们配置管理   <em>/usr/share/tomcat</em></li><li>日志记录位置   <em>/var/log/tomcat</em></li><li>查看全部tomcat安装目录   <em>rpm -ql tomcat6 | cat -n</em></li></ul><h2 id="Mysql5-7数据库安装"><a href="#Mysql5-7数据库安装" class="headerlink" title="Mysql5.7数据库安装"></a>Mysql5.7数据库安装</h2><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><ul><li>mysql主要有2种方式安装<ul><li>1.本文要说明的</li><li>2.<a href="http://blog.sina.com.cn/s/blog_16392bde40102wol6.html" target="_blank" rel="noopener">点击这里查看</a></li></ul></li></ul><h3 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h3><ul><li>在mysql的官网上找到mysql的源链接</li></ul><p><img src="//image.joylau.cn/blog/mysqlsourceLink.jpg" alt="Mysql官网截图"></p><ul><li>找到原链接：<code>https://repo.mysql.com//mysql57-community-release-el7-9.noarch.rpm</code></li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li><p>安装命令</p><pre><code class="bash">      # wget https://repo.mysql.com//mysql57-community-release-el7-9.noarch.rpm      # rpm -ivh mysql57-community-release-el7-9.noarch.rpm      # yum install mysql-community-server</code></pre></li><li><p>安装过程中有确认操作，一律<strong><em>y</em></strong></p></li><li><p>接下来就是漫长的下载，只需要等待即可。</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3></li><li><p>安装完成后： <code>systemctl start mysqld</code> 启动mysqld服务</p></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li>查看<code>/var/log/mysqld.log</code>里的日志(可以查找<strong>password</strong>关键字)<br><img src="//image.joylau.cn/blog/mysqllog.jpg" alt="mysqlLog"></li><li>可以看到创建的临时密码</li><li>登录MySQL：<code>mysql -u root -p</code></li><li>输入刚才在日志里看到的临时密码</li><li>这个时候我输入任何的命令都会提示<code>You must reset your password using ALTER USER statement before executing this statement.</code><br><img src="//image.joylau.cn/blog/alertTips.jpg" alt="alterTips"></li><li>通过 <code>alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;root&#39;</code> 命令，修改 root 用户的密码为 root，注意修改的密码不能过于简单</li><li>退出，重新以root用户和刚设置的密码进行登录即可</li></ul><h3 id="MySql配置文件"><a href="#MySql配置文件" class="headerlink" title="MySql配置文件"></a>MySql配置文件</h3><ul><li><p>将所有权限赋给root用户并提供外网访问</p><pre><code class="bash">      grant all privileges on *.* to root@&#39;%&#39;identified by &#39;root&#39;;</code></pre></li><li><p>紧接着就可以在自己的机器上用<strong>Navicat</strong>了</p></li><li><p>配置my.cnf：<code>/etc/my.cnf</code></p><pre><code class="bash">      [mysqld]      #      # Remove leading # and set to the amount of RAM for the most important data      # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.      # innodb_buffer_pool_size = 128M      #      # Remove leading # to turn on a very important data integrity option: logging      # changes to the binary log between backups.      # log_bin      #      # Remove leading # to set options mainly useful for reporting servers.      # The server defaults are faster for transactions and fast SELECTs.      # Adjust sizes as needed, experiment to find the optimal values.      # join_buffer_size = 128M      # sort_buffer_size = 2M      # read_rnd_buffer_size = 2M      datadir=/var/lib/mysql      socket=/var/lib/mysql/mysql.sock      //设置端口号      port= 3333      //设置服务器端编码      character-set-server=utf8      //Linux下表名是严格区分大小写的，设置为0表示区分，设置为1表示不区分      lower_case_table_names= 1      # Disabling symbolic-links is recommended to prevent assorted security risks      symbolic-links=0      log-error=/var/log/mysqld.log      pid-file=/var/run/mysqld/mysqld.pid</code></pre></li></ul><h3 id="MySQL卸载"><a href="#MySQL卸载" class="headerlink" title="MySQL卸载"></a>MySQL卸载</h3><ul><li><code>yum remove  mysql mysql-server mysql-libs mysql-server;</code></li><li><code>rpm -qa|grep mysql</code>(查询出来的东西yum remove掉)</li><li><code>find / -name mysql</code> (将找到的相关东西delete掉；)</li></ul><h3 id="值得注意的是："><a href="#值得注意的是：" class="headerlink" title="值得注意的是："></a>值得注意的是：</h3><ul><li>1.<code>show variables like &#39;character%&#39;;</code>可以看到数据库的编码方式<ul><li><code>其中，character_set_client为客户端编码方式；</code></li><li><code>character_set_connection为建立连接使用的编码；</code></li><li><code>character_set_database数据库的编码；</code></li><li><code>character_set_results结果集的编码；</code></li><li><code>character_set_server数据库服务器的编码；</code></li><li><code>只要保证以上四个采用的编码方式一样，就不会出现乱码问题。</code></li></ul></li><li>2.暂时能配置只有这些，以后有更新，我会加上的</li></ul><h2 id="Redis的安装"><a href="#Redis的安装" class="headerlink" title="Redis的安装"></a>Redis的安装</h2><h3 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h3><h4 id="Linux安装redis是需要在官网下载redis的源码然后再编译的"><a href="#Linux安装redis是需要在官网下载redis的源码然后再编译的" class="headerlink" title="Linux安装redis是需要在官网下载redis的源码然后再编译的"></a>Linux安装redis是需要在官网下载redis的源码然后再编译的</h4><ul><li>redis的官网：<a href="https://redis.io/" target="_blank" rel="noopener">https://redis.io/</a></li><li>redis中文网：<a href="http://www.redis.cn/" target="_blank" rel="noopener">http://www.redis.cn/</a></li><li>我已将编译好直接可以使用的Redis上传到GitHub: <a href="https://github.com/JoyLau/Redis-3.2.8-Linux" target="_blank" rel="noopener">https://github.com/JoyLau/Redis-3.2.8-Linux</a></li><li>请结合本篇博客和项目里的README文件使用</li></ul><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><ul><li>下载linux版的压缩包,截止到我写博客的时间，官网给的稳定版是3.2.8，我们就下载<code>redis-3.2.8.tar.gz</code></li><li><code>tar -zxvf redis-3.2.8.tar.gz</code></li><li>进入src目录：<code>cd redis-3.2.8/src</code></li><li><code>make</code> 编译</li><li>这时我们不执行<code>make intsall</code>,因为该操作会把编译生成的<strong><em>重要的文件</em></strong>拷贝到<code>user/local/bin</code>下，我们想要自定义配置路径</li></ul><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><ul><li><p>中间可能报<code>/bin/sh: cc:未找到命令</code>,对于这样的情况只需要</p><pre><code class="bash">      yum install gcc       yum install gcc-c++ </code></pre></li><li><p>这里的重要文件指的是下图所示的8个文件，在redis以前版本好像是7个文件（没具体试过）</p></li><li><p>注意文件和文件夹的权限</p></li></ul><h3 id="路径配置"><a href="#路径配置" class="headerlink" title="路径配置"></a>路径配置</h3><ul><li><code>ls</code>查看src下的文件，你会看到有些文件是绿色的，这些事重要的文件，也正是我们所需要的，我们将这些文件单独存下来<br><img src="//image.joylau.cn/blog/redisimportantfile.png" alt="Redis源码编译后的重要文件"></li><li>我们来看看编译出来的几个程序分别是干什么的：<pre><code>redis-server：顾名思义，redis服务redis-cli：redis client，提供一个redis客户端，以供连接到redis服务，进行增删改查等操作redis-sentinel：redis实例的监控管理、通知和实例失效备援服务redis-benchmark：redis的性能测试工具redis-check-aof：若以AOF方式产生日志，当意外发生时用来快速修复redis-check-rdb：若以RDB方式产生日志，当意外发生时用来快速修复</code></pre></li><li>保存好之后我们的路径如下：<br><img src="//image.joylau.cn/blog/redisfloder.png" alt="Redis根目录"><br><img src="//image.joylau.cn/blog/redisbin.png" alt="Redis-bin"><br><img src="//image.joylau.cn/blog/redisetc.png" alt="Redis-etc"></li></ul><h3 id="配置文件配置"><a href="#配置文件配置" class="headerlink" title="配置文件配置"></a>配置文件配置</h3><ul><li><p>redis.conf我只修改了以下配置</p><ul><li><code>port</code> : 端口</li><li><code>requirepass</code> 密码</li><li><code>bind 0.0.0.0</code> ： 配置外网可访问</li><li><code>daemonize yes</code> : 将redis服务作为守护进程,作为开机启动</li></ul></li><li><p>有了基本配置，redis还需要有一个管理启动、关闭、重启的一个脚本。redis源码里其实已经提供了一个初始化脚本<code>redis_init_script</code>,这是我的配置</p><pre><code class="bash">      #!/bin/sh      # chkconfig: 2345 90 10       # description: Redis is a persistent key-value database      # Simple Redis init.d script conceived to work on Linux systems      # as it does use of the /proc filesystem.      # 如果redis设置了密码，则$CLIEXEC -a $PASSWORD -p $REDISPORT shutdown 需要加一个参数      REDISPORT=6379      PASSWORD=123      EXEC=/project/redis3.2.8/bin/redis-server      CLIEXEC=/project/redis3.2.8/bin/redis-cli      PIDFILE=/var/run/redis_${REDISPORT}.pid      CONF=/project/redis3.2.8/etc/redis.conf      case &quot;$1&quot; in          start)              if [ -f $PIDFILE ]              then                      echo &quot;$PIDFILE exists, process is already running or crashed&quot;              else                      echo &quot;Starting Redis server...&quot;                      $EXEC $CONF              fi              ;;          stop)              if [ ! -f $PIDFILE ]              then                      echo &quot;$PIDFILE does not exist, process is not running&quot;              else                      PID=$(cat $PIDFILE)                      echo &quot;Stopping ...&quot;                      $CLIEXEC -a $PASSWORD -p $REDISPORT shutdown                      while [ -x /proc/${PID} ]                      do                          echo &quot;Waiting for Redis to shutdown ...&quot;                          sleep 1                      done                      echo &quot;Redis stopped&quot;              fi              ;;          *)              echo &quot;Please use start or stop as first argument&quot;              ;;      esac</code></pre></li><li><p>头部的chkconfig的添加是为了保证<code>chkconfig redis on</code>能够执行</p></li><li><p>接着将<strong>redis_init_script</strong>脚本拷贝到<strong>/etc/init.d/redis</strong>，这里重命名为redis</p><pre><code class="bash">      # cp /project/redis-3.2.8/utils/redis_init_script /etc/init.d/redis</code></pre></li><li><p>现在还缺一个系统启动时的配置:<code>chkconfig redis on</code></p></li><li><p>执行之后，redis便是以系统服务启动、关闭了</p><pre><code class="bash">      systemctl start redis;      systemctl stop redis;      systemctl restart redis;</code></pre></li></ul><h2 id="FTP-服务端安装"><a href="#FTP-服务端安装" class="headerlink" title="FTP 服务端安装"></a>FTP 服务端安装</h2><ol><li>yum install vsftpd</li><li>修改 vim /etc/vsftpd/vsftpd.conf<br> <code>anonymous_enable=NO</code> : 不允许匿名用户登录<br> <code>chroot_local_user=YES</code> : 用户不能跳出当前的 home 目录</li><li>安装好之后其实已经创建了个 ftp 的用户了,可以查看 /etc/passwd 文件,只是没有密码,这个时候使用 ftp 工具来登录是可以看到目录的,默认 ftp 的 home 目录在 /var/ftp/ 下    </li><li>修改 ftp 用户密码 passwd ftp</li><li>这时使用 ftp 用户登录,发现不能 上传文件和删除文件,有 553 错误</li></ol><h3 id="解决不能上传和删除文件"><a href="#解决不能上传和删除文件" class="headerlink" title="解决不能上传和删除文件"></a>解决不能上传和删除文件</h3><ol><li><p>首先 selinux 会默认拦截 vsftp,想要不被拦截的话,可以关闭 selinux, 但是关闭后安全性得不到保障,可能会出现其他的问题,这里我们不关闭,可以开放权限</p><pre><code class="shell">     setenforce 0 #暂时让SELinux进入Permissive模式     getsebool -a | grep ftpd #查看 ftpd 的权限     ftpd_anon_write --&gt; off     ftpd_connect_all_unreserved --&gt; off     ftpd_connect_db --&gt; off     ftpd_full_access --&gt; on     ftpd_use_cifs --&gt; off     ftpd_use_fusefs --&gt; off     ftpd_use_nfs --&gt; off     ftpd_use_passive_mode --&gt; off     setsebool -P ftpd_full_access 1 # 设置ftpd_full_access的权限为 on     setenforce 1 # 开启 selinux</code></pre></li><li><p>这时 selinux 已经开放了 vsftpd 的权限</p></li><li><p>给 ftp 用户的 home 目录赋予写的权限 chmod a+w /var/ftp</p></li><li><p>vsftpd 在新版本时,如果检测到用户不能跳出当前的 home 目录,那么用户的 home 不能有写的权限,会报 500 OOPS: vsftpd: refusing to run with writable root inside chroot() 错误,这时就尴尬了</p></li><li><p>解决方式: 在配置文件中添加: allow_writeable_chroot=YES</p></li><li><p>重启 vsftpd</p></li></ol><h3 id="无法连接-FTP-服务器"><a href="#无法连接-FTP-服务器" class="headerlink" title="无法连接 FTP 服务器"></a>无法连接 FTP 服务器</h3><p>使用 FTP 工具连接失败,报如下错误:</p><pre><code class="bash">   状态:     连接建立，等待欢迎消息...   状态:     不安全的服务器，不支持 FTP over TLS。   命令:     USER ftp   响应:     331 Please specify the password.   命令:     PASS ******   响应:     530 Login incorrect.   错误:     严重错误: 无法连接到服务器   状态:     已从服务器断开</code></pre><p>解决方法: 找到 <code>/etc/pam.d/vsftpd</code> 注释掉 <code>#auth       required    pam_shells.so</code></p><h2 id="RabbitMQ-服务端安装"><a href="#RabbitMQ-服务端安装" class="headerlink" title="RabbitMQ 服务端安装"></a>RabbitMQ 服务端安装</h2><ol><li>yum install rabbitmq-server</li><li>rabbitmq-plugins enable rabbitmq_management</li><li>systemctl start rabbitmq-server</li></ol><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol><li>当主机的 hostname 不是 localhost 时, 启动会报错: <code>unable to connect to epmd (port 4369) on 68: badarg (unknown POSIX error)</code> , 这时在文件中 <code>/etc/rabbitmq/rabbitmq-env.conf</code> 写入 <code>NODENAME=rabbit@localhost</code> 保存重启.</li></ol><h2 id="MariaDB-的安装"><a href="#MariaDB-的安装" class="headerlink" title="MariaDB 的安装"></a>MariaDB 的安装</h2><ol><li><code>yum install mariadb-server</code></li><li>登入 mariadb <code>mysql -uroot -p</code> , 第一次登陆是 root 用户没有密码,直接进入即可</li><li>初始化设置: <code>mysql_secure_installation</code> ,可以设置 root 密码,移除匿名账号等等…</li><li>设置 root 可远程登录: <ol><li><code>mysql -uroot -p</code> 登录</li><li><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39;IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;</code> 授权 root 账户,密码 123456</li><li><code>flush privileges;</code></li></ol></li><li>继续后续操作</li></ol><h3 id="Mybatis-连接-MariaDB-中文乱码问题"><a href="#Mybatis-连接-MariaDB-中文乱码问题" class="headerlink" title="Mybatis 连接 MariaDB 中文乱码问题"></a>Mybatis 连接 MariaDB 中文乱码问题</h3><p>MariaDB的默认编码是latin1，插入中文会乱码，因此需要将编码改为utf8</p><ol><li><p>首先设置数据库的编码都为 utf8</p><ol><li><code>SHOW VARIABLES LIKE &#39;character%&#39;;</code> 查看编码</li><li>修改 /etc/my.cnf.d/client.cnf , 在 <code>[client]</code> 里加入 <code>default-character-set=utf8</code></li><li>修改 /etc/my.cnf.d/server.cnf , 在 <code>[mysqld]</code> 里加入 <code>character-set-server=utf8</code></li><li><code>systemctl restart mariadb</code> 重启生效</li><li>再次查看 <code>SHOW VARIABLES LIKE &#39;character%&#39;;</code> 查看编码</li></ol></li><li><p>建库,建表,表里的 varchar 字段的字符集都用 <code>utf8</code>, 排序规则都用 <code>utf8_unicode_ci</code></p></li><li><p>至此服务端就配置完成了</p></li><li><p>连接数据配置文件,加上参数</p></li></ol><pre><code class="yml">      datasource:        druid:          url: jdbc:mysql://34.0.7.183:3306/traffic-service?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false</code></pre><h2 id="DNS-服务安装"><a href="#DNS-服务安装" class="headerlink" title="DNS 服务安装"></a>DNS 服务安装</h2><ol><li><code>yum install bind</code> 安装完成后服务名为 <code>named</code></li><li><code>vim /etc/named.conf</code></li></ol><pre><code class="bash">    options {            listen-on port 53 { 34.0.7.183; };            listen-on-v6 port 53 { ::1; };            directory       &quot;/var/named&quot;;            dump-file       &quot;/var/named/data/cache_dump.db&quot;;            statistics-file &quot;/var/named/data/named_stats.txt&quot;;            memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;;            recursing-file  &quot;/var/named/data/named.recursing&quot;;            secroots-file   &quot;/var/named/data/named.secroots&quot;;            allow-query     { any; };            /*              - If you are building an AUTHORITATIVE DNS server, do NOT enable recursion.             - If you are building a RECURSIVE (caching) DNS server, you need to enable                recursion.              - If your recursive DNS server has a public IP address, you MUST enable access                control to limit queries to your legitimate users. Failing to do so will               cause your server to become part of large scale DNS amplification                attacks. Implementing BCP38 within your network would greatly               reduce such attack surface             */            recursion yes;            dnssec-enable yes;            dnssec-validation yes;            /* Path to ISC DLV key */            bindkeys-file &quot;/etc/named.iscdlv.key&quot;;            managed-keys-directory &quot;/var/named/dynamic&quot;;            pid-file &quot;/run/named/named.pid&quot;;            session-keyfile &quot;/run/named/session.key&quot;;    };    logging {            channel default_debug {                    file &quot;data/named.run&quot;;                    severity dynamic;            };    };    zone &quot;.&quot; IN {            type hint;            file &quot;named.ca&quot;;    };    include &quot;/etc/named.rfc1912.zones&quot;;    include &quot;/etc/named.root.key&quot;;</code></pre><p><code>listen-on port 53 { 127.0.0.1; };</code>       # 指定服务监听的端口，建议写本机IP，减少服务器消耗<br><code>allow-query     { any; };</code>               # 允许哪些客户端访问DNS服务，此处改为“any”，表示任意主机</p><p>修改这2项配置即可</p><h3 id="配置自定义域名解析"><a href="#配置自定义域名解析" class="headerlink" title="配置自定义域名解析"></a>配置自定义域名解析</h3><p><code>include &quot;/etc/named.rfc1912.zones&quot;;</code>    # include代表该文件是子配置文件</p><ol><li><code>vim /etc/named.rfc1912.zones</code> , 添加一个我们自定义的域名配置,这里我使用的是 <code>baidu.com</code></li></ol><pre><code class="bash">    zone &quot;baidu.com&quot; IN {            type master;            file &quot;data/baidu.com.zone&quot;;            allow-update { none; };    };</code></pre><p>上述文件默认的目录在 <code>/var/named/data</code> 目录下</p><ol start="2"><li><code>vim /var/named/data/baidu.com.zone</code></li></ol><p>配置如下: 注意格式</p><pre><code class="bash">    $TTL 1D    @       IN SOA         baidu.com. root (                                            1       ; serial                                            1D      ; refresh                                            1H      ; retry                                            1W      ; expire                                            0 )     ; minimum    @       IN      NS      ns.baidu.com.    ns      IN      A       34.0.7.183    @       IN      A       34.0.7.183    test    IN      A       34.0.7.183    liufa   IN      A       34.0.7.227</code></pre><p>注意第一条记录 <code>ns.baidu.com.</code> 的解析必须添加否则会报错,添加之后,再加一条 ns 子域名的解析,直接指向自己即可</p><p>这里附上一些配置的解释:</p><ul><li>serial：序列号。可以供从服务器判断何时获取新数据的，这里我设成今天的日期。更新数据文件必须要更新这个序列号，否则从服务器将不更新</li><li>refresh：指定多长时间从服务器要与主服务器进行核对</li><li>retry：如果从服务器试图检查主服务器的序列号时，主服务器没有响应，则经过这个时间后将重新进行检查</li><li>expire：将决定从服务器在没有主服务器的情况下权威地持续提供域数据服务的时间长短</li><li>minimum：高速缓存否定回答的存活时间</li><li>SOA记录：每个区仅有一个SOA记录，该区一直延伸到遇见另一个SOA记录为止。SOA记录包括区的名字，一个技术联系人和各种不同的超时值</li><li>IN记录：使用“IN”，对应的是internet</li><li>A记录：是DNS数据库的核心。一个主机必须为它的每个网络接口得到一条A记录</li><li>NS记录：识别对一个区有权威性的服务器（即所有主服务器和从服务器），并把子域委托给其他机构。</li><li>MX记录：电子邮件系统就是使用MX记录来更有效的路由邮件。</li><li>PTR记录：从IP地址到主机名的反向映射。与A记录一样，必须为每个网络接口有一条PTR记录。</li></ul><ol start="3"><li><code>chown root:named baidu.com.zone</code> 修改权限</li><li><code>systemctl restart named</code></li></ol><h2 id="PostgreSQL-安装"><a href="#PostgreSQL-安装" class="headerlink" title="PostgreSQL 安装"></a>PostgreSQL 安装</h2><h3 id="说明-3"><a href="#说明-3" class="headerlink" title="说明"></a>说明</h3><p>yum 安装的版本可能比较低,对于一些应用来说可能不好,这里使用官网的安装包</p><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><ol><li>打开 <a href="https://www.postgresql.org/download/linux/redhat/" target="_blank" rel="noopener">https://www.postgresql.org/download/linux/redhat/</a></li><li>选择版本</li><li>安装源,我这里以 10 为例, <code>yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm</code></li><li>安装程序, <code>yum install postgresql10</code> , <code>yum install postgresql10-server</code></li><li>初始化数据库 <code>/usr/pgsql-10/bin/postgresql-10-setup initdb</code></li><li>开机启动 <code>systemctl enable postgresql-10;systemctl start postgresql-10</code></li></ol><h3 id="修改管理员密码"><a href="#修改管理员密码" class="headerlink" title="修改管理员密码"></a>修改管理员密码</h3><p>数据库的默认管理员用户是 postgres, 在 PostgreSQL 安装好后会创建用户 postgres</p><ol><li>切换到 postgres 用户 <code>su postgres</code></li><li>执行 <code>psql</code> 登陆数据库</li><li>修改密码: <code>ALTER USER postgres WITH PASSWORD &#39;postgres&#39;;</code></li></ol><h3 id="配置远程访问"><a href="#配置远程访问" class="headerlink" title="配置远程访问"></a>配置远程访问</h3><ol><li>修改 <code>postgresql.conf</code> 文件的 <code>listen_address = *</code></li><li>用户授权: 修改 <code>pg_hba.conf</code> 添加 <code>host all all 0.0.0.0/0 password</code> 一行</li></ol><p>说明:</p><ul><li>ident: 系统用户和数据库用户对于即可访问</li><li>md5: md5 加密的密码认证</li><li>password: 明文密码</li><li>trust: 无需密码</li><li>reject: 拒接认证</li></ul><h3 id="修改数据存放目录"><a href="#修改数据存放目录" class="headerlink" title="修改数据存放目录"></a>修改数据存放目录</h3><ol><li>修改 <code>/usr/lib/systemd/system/postgresql-10.service</code> 的 <code>PGDATA</code></li><li><code>systemctl daemon-reload</code></li><li><code>postgresql-step initdb</code> 初始化数据库,遇到权限问题,先创建好目录<ol><li>chrow -R postgres:postgres /…</li><li>chmod -R 700 /…</li><li>实在不行就使用 postgres 的身份操作</li></ol></li><li>如果之前数据库有数据,可以直接拷贝数据目录,之后目录的权限设定好即可</li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> JDK </tag>
            
            <tag> Tomcat </tag>
            
            <tag> MySQL </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux菜鸟到熟悉 --- 数据盘的格式化和挂载</title>
      <link href="/2017/02/23/Linux-MountDisk/"/>
      <url>/2017/02/23/Linux-MountDisk/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/Thymeleaf.png" alt="Thymeleaf"></p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>云服务器 <strong>ECS</strong> 仅支持对<strong>数据盘</strong>进行二次分区，而不支持对 <strong>系统盘</strong> 进行二次分区（不管是 <strong>Windows</strong> 还是 <strong>Linux</strong> 系统）</li><li>强行使用第三方工具对系统盘进行二次分区操作，可能引发未知风险，如系统崩溃、数据丢失等。</li><li>对新购的数据盘可以选择分区或者不分区，这个根据自身的情况而定</li><li>下面内容的<code>xvdb</code>和 <code>vdb</code>分别对应非 I/O优化I/O 优化；非 I/O 优化和 I/O 优化的区别在于，前者比后者多一个字母 x</li><li>新数据盘的挂载可以自定义文件夹，本示例中用的是/mnt</li></ul><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><ul><li>运行 <code>fdisk -l</code> 命令查看数据盘。注意：在没有分区和格式化数据盘之前，使用 <code>df -h</code> 命令是无法看到数据盘的。在下面的示例中，有一个 5 GB 的数据盘需要挂载。</li><li>如果执行了 <code>fdisk -l</code> 命令后，没有发现 /dev/xvdb，则表示您的实例没有数据盘，因此无需挂载</li></ul><p><img src="//image.joylau.cn/blog/linux1.jpg" alt="Image1"></p><h3 id="需要进行分区的情况"><a href="#需要进行分区的情况" class="headerlink" title="需要进行分区的情况"></a>需要进行分区的情况</h3><ul><li>运行 <code>fdisk /dev/xvdb</code>，对数据盘进行分区。根据提示，依次输入 n，p，1，两次回车，wq，分区就开始了。</li></ul><p><img src="//image.joylau.cn/blog/linux2.jpg" alt="Image2"></p><ul><li>运行 <code>fdisk -l</code> 命令，查看新的分区。新分区 xvdb1 已经创建好。如下面示例中的/dev/xvdb1。</li></ul><p><img src="//image.joylau.cn/blog/linux3.jpg" alt="Image3"></p><h3 id="不需要进行分区的情况"><a href="#不需要进行分区的情况" class="headerlink" title="不需要进行分区的情况"></a>不需要进行分区的情况</h3><blockquote><p>一般情况下我都是直接格式化一整块数据盘，然后挂载的。</p></blockquote><ul><li>运行 <code>mkfs.ext3 /dev/xvdb1</code>，对新分区进行格式化。格式化所需时间取决于数据盘大小。您也可自主决定选用其他文件格式，如 <code>ext4</code> 等。</li></ul><p><img src="//image.joylau.cn/blog/linux4.jpg" alt="Image4"></p><ul><li>运行 <code>echo /dev/xvdb1 /mnt ext3 defaults 0 0 &gt;&gt; /etc/fstab</code> 写入新分区信息。完成后，可以使用 <code>cat /etc/fstab</code> 命令查看。</li></ul><p><img src="//image.joylau.cn/blog/linux5.jpg" alt="Image5"></p><blockquote><p>Ubuntu 12.04 不支持 barrier，所以对该系统正确的命令是：<code>echo /dev/xvdb1 /mnt ext3 defaults 0 0 &gt;&gt; /etc/fstab</code><br>  如果需要把数据盘单独挂载到某个文件夹，比如单独用来存放网页，可以修改以上命令中的 /mnt 部分。</p></blockquote><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><ul><li><p>运行   <code>mount /dev/xvdb1 /mnt</code> 挂载新分区，然后执行 <code>df -h</code> 查看分区。如果出现数据盘信息，说明挂载成功，可以使用新分区了。</p><pre><code class="bash">       mount /dev/xvdb1 /mnt       df -h       Filesystem      Size  Used Avail Use% Mounted on       /dev/xvda1       40G  1.5G   36G   4% /       tmpfs           498M     0  498M   0% /dev/shm       /dev/xvdb1      5.0G  139M  4.6G   3% /mnt</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 磁盘挂载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新拾起我曾抛弃的Thymeleaf</title>
      <link href="/2017/02/20/Thymeleaf/"/>
      <url>/2017/02/20/Thymeleaf/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/Thymeleaf.png" alt="Thymeleaf"></p><h2 id="历史篇"><a href="#历史篇" class="headerlink" title="历史篇"></a>历史篇</h2><h3 id="曾经交往过"><a href="#曾经交往过" class="headerlink" title="曾经交往过"></a>曾经交往过</h3><ul><li>说是历史，也就是在去年，但我感觉已经过了很久。去年我在写<code>SpringBoot</code>项目的时候，想找一套前端的模板引擎，看到<code>SpringBoot</code>官网推荐使用<code>Thymeleaf</code>，就用了它</li><li>在写了几个页面之后，我在项目里写下了这样一段话<br><img src="//image.joylau.cn/blog/thyemeleafhistory.png" alt="曾经学习的历史记录"></li></ul><h3 id="没好印象，我甩了她"><a href="#没好印象，我甩了她" class="headerlink" title="没好印象，我甩了她"></a>没好印象，我甩了她</h3><ul><li>可以看到我放弃了它，选择了我熟悉的 <code>Freemarker</code>（不要问我为什么不选择JSP）</li></ul><h2 id="重逢篇"><a href="#重逢篇" class="headerlink" title="重逢篇"></a>重逢篇</h2><h3 id="相遇在spring"><a href="#相遇在spring" class="headerlink" title="相遇在spring"></a>相遇在spring</h3><ul><li><code>Spring</code>一直都是我崇尚和追求的项目，没事都会翻翻<code>Spring</code>的文档查阅查阅</li><li>无意中我发现<code>Spring</code>的官方文档，很多都是用<code>Thymeleaf</code>渲染的，这使我重新提起了兴趣</li></ul><h2 id="交往篇"><a href="#交往篇" class="headerlink" title="交往篇"></a>交往篇</h2><h3 id="决定重新尝试交往"><a href="#决定重新尝试交往" class="headerlink" title="决定重新尝试交往"></a>决定重新尝试交往</h3><ul><li>我决定重新学习一下</li></ul><h3 id="深入了解"><a href="#深入了解" class="headerlink" title="深入了解"></a>深入了解</h3><ul><li><code>Thymeleaf</code> 官网: <a href="http://www.thymeleaf.org/" target="_blank" rel="noopener">http://www.thymeleaf.org/</a></li><li><code>Thymeleaf</code>是一个页面模板，类似于<code>Freemarker</code>、<code>Velocity</code>等，但<code>Thymeleaf</code>可以在服务器环境和静态环境下都能正常运行的页面模板，深受前后端分离开发的团队人员的青睐。</li><li><code>Thymeleaf</code>的数据展现全部通过以th:开头的html自定义标签来完成。当运行在服务器环境时将会按规则替换th:对应的地方显示出服务器上的数据，当运行在静态环境时，html会自动过虑th:开头的属性，显示默认的数据，从而达到两者都能正常运行。</li><li>整合SpringBoot<pre><code class="bash">              &lt;dependency&gt;                  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                  &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;              &lt;/dependency&gt;</code></pre>如此简单</li></ul><p>……..  未完待更   ……..</p>]]></content>
      
      
      <categories>
          
          <category> 模板引擎篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Thymeleaf </tag>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSL证书部署</title>
      <link href="/2017/02/20/SSL/"/>
      <url>/2017/02/20/SSL/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/https.jpg" alt="SSL"></p><h2 id="Apache-2-x-证书部署"><a href="#Apache-2-x-证书部署" class="headerlink" title="Apache 2.x 证书部署"></a>Apache 2.x 证书部署</h2><h3 id="文件准备"><a href="#文件准备" class="headerlink" title="文件准备"></a>文件准备</h3><p><img src="//image.joylau.cn/blog/apachessl.png" alt="Apache"></p><h3 id="获取证书"><a href="#获取证书" class="headerlink" title="获取证书"></a>获取证书</h3><ul><li>Apache文件夹内获得证书文件 1_root_bundle.crt，2_<a href="http://www.domain.com_cert.crt" target="_blank" rel="noopener">www.domain.com_cert.crt</a> 和私钥文件 3_<a href="http://www.domain.com.key" target="_blank" rel="noopener">www.domain.com.key</a>,</li><li>1_root_bundle.crt 文件包括一段证书代码 “—–BEGIN CERTIFICATE—–”和“—–END CERTIFICATE—–”,</li><li>2_<a href="http://www.domain.com_cert.crt" target="_blank" rel="noopener">www.domain.com_cert.crt</a> 文件包括一段证书代码 “—–BEGIN CERTIFICATE—–”和“—–END CERTIFICATE—–”,</li><li>3_<a href="http://www.domain.com.key" target="_blank" rel="noopener">www.domain.com.key</a> 文件包括一段私钥代码“—–BEGIN RSA PRIVATE KEY—–”和“—–END RSA PRIVATE KEY—–”。</li></ul><h3 id="证书安装"><a href="#证书安装" class="headerlink" title="证书安装"></a>证书安装</h3><ul><li><p>编辑Apache根目录下 conf/httpd.conf 文件，</p></li><li><p>找到 #LoadModule ssl_module modules/mod_ssl.so 和 #Include conf/extra/httpd-ssl.conf，去掉前面的#号注释；</p></li><li><p>编辑Apache根目录下 conf/extra/httpd-ssl.conf 文件，修改如下内容：</p><pre><code class="bash">      &lt;VirtualHost www.domain.com:443&gt;          DocumentRoot &quot;/var/www/html&quot;          ServerName www.domain.com          SSLEngine on          SSLCertificateFile /usr/local/apache/conf/2_www.domain.com_cert.crt          SSLCertificateKeyFile /usr/local/apache/conf/3_www.domain.com.key          SSLCertificateChainFile /usr/local/apache/conf/1_root_bundle.crt      &lt;/VirtualHost&gt;</code></pre></li><li><p>配置完成后，重新启动 Apache 就可以使用<a href="https://www.domain.com" target="_blank" rel="noopener">https://www.domain.com</a>来访问了<br>注：</p><ul><li><code>SSLEngine on</code> ： 启用SSL功能</li><li><code>SSLCertificateFile</code> ：证书文件</li><li><code>SSLCertificateKeyFile</code> ： 私钥文件</li><li><code>SSLCertificateChainFile</code> : 证书链文件</li></ul></li></ul><h2 id="Nginx-证书部署"><a href="#Nginx-证书部署" class="headerlink" title="Nginx 证书部署"></a>Nginx 证书部署</h2><h3 id="文件准备-1"><a href="#文件准备-1" class="headerlink" title="文件准备"></a>文件准备</h3><p><img src="//image.joylau.cn/blog/Nginxssl.png" alt="Nginx"></p><h3 id="获取证书-1"><a href="#获取证书-1" class="headerlink" title="获取证书"></a>获取证书</h3><ul><li>Nginx文件夹内获得SSL证书文件 1_<a href="http://www.domain.com_bundle.crt" target="_blank" rel="noopener">www.domain.com_bundle.crt</a> 和私钥文件 2_<a href="http://www.domain.com.key" target="_blank" rel="noopener">www.domain.com.key</a>,</li><li>1_<a href="http://www.domain.com_bundle.crt" target="_blank" rel="noopener">www.domain.com_bundle.crt</a> 文件包括两段证书代码 “—–BEGIN CERTIFICATE—–”和“—–END CERTIFICATE—–”,</li><li>2_<a href="http://www.domain.com.key" target="_blank" rel="noopener">www.domain.com.key</a> 文件包括一段私钥代码“—–BEGIN RSA PRIVATE KEY—–”和“—–END RSA PRIVATE KEY—–”。</li></ul><h3 id="证书安装-1"><a href="#证书安装-1" class="headerlink" title="证书安装"></a>证书安装</h3><ul><li><p>将域名 <a href="http://www.domain.com" target="_blank" rel="noopener">www.domain.com</a> 的证书文件1_<a href="http://www.domain.com_bundle.crt" target="_blank" rel="noopener">www.domain.com_bundle.crt</a> 、私钥文件2_<a href="http://www.domain.com.key保存到同一个目录，例如/usr/local/nginx/conf目录下。" target="_blank" rel="noopener">www.domain.com.key保存到同一个目录，例如/usr/local/nginx/conf目录下。</a></p></li><li><p>更新Nginx根目录下 conf/nginx.conf 文件如下：</p><pre><code class="bash">      server {              listen 443;              server_name www.domain.com; #填写绑定证书的域名              ssl on;              ssl_certificate 1_www.domain.com_bundle.crt;              ssl_certificate_key 2_www.domain.com.key;              ssl_session_timeout 5m;              ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置              ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置              ssl_prefer_server_ciphers on;              location / {                  root   html; #站点目录                  index  index.html index.htm;              }          }</code></pre></li><li><p>配置完成后，先用bin/nginx –t来测试下配置是否有误，正确无误的话，重启nginx。就可以使 <a href="https://www.domain.com" target="_blank" rel="noopener">https://www.domain.com</a> 来访问了。<br>注：</p><ul><li><code>listen 443</code>    SSL访问端口号为443</li><li><code>ssl on</code>    启用SSL功能</li><li><code>ssl_certificate</code>    证书文件</li><li><code>ssl_certificate_key</code>    私钥文件</li><li><code>ssl_protocols</code>    使用的协议</li><li><code>ssl_ciphers</code>    配置加密套件，写法遵循openssl标准</li></ul></li></ul><h3 id="使用全站加密，http自动跳转https（可选）"><a href="#使用全站加密，http自动跳转https（可选）" class="headerlink" title="使用全站加密，http自动跳转https（可选）"></a>使用全站加密，http自动跳转https（可选）</h3><ul><li>对于用户不知道网站可以进行https访问的情况下，让服务器自动把http的请求重定向到https。</li><li>在服务器这边的话配置的话，可以在页面里加js脚本，也可以在后端程序里写重定向，当然也可以在web服务器来实现跳转。Nginx是支持rewrite的（只要在编译的时候没有去掉pcre）</li><li>在http的server里增加<code>rewrite ^(.*) https://$host$1 permanent</code>;</li><li>这样就可以实现80进来的请求，重定向为https了。</li></ul><h2 id="Tomcat-证书部署"><a href="#Tomcat-证书部署" class="headerlink" title="Tomcat 证书部署"></a>Tomcat 证书部署</h2><h3 id="文件准备-2"><a href="#文件准备-2" class="headerlink" title="文件准备"></a>文件准备</h3><p><img src="//image.joylau.cn/blog/Tomcatssl.png" alt="Nginx"></p><h3 id="获取证书-2"><a href="#获取证书-2" class="headerlink" title="获取证书"></a>获取证书</h3><ul><li>如果申请证书时有填写私钥密码，下载可获得Tomcat文件夹，其中有密钥库 <a href="http://www.domain.com.jks；" target="_blank" rel="noopener">www.domain.com.jks；</a></li><li>如果没有填写私钥密码，不提供Tomcat证书文件的下载，需要用户手动转换格式生成。</li><li>可以通过 Nginx 文件夹内证书文件和私钥文件生成jks格式证书</li><li>转换工具：<a href="https://www.trustasia.com/tools/cert-converter.htm" target="_blank" rel="noopener">https://www.trustasia.com/tools/cert-converter.htm</a></li><li>使用工具时注意填写 密钥库密码 ，安装证书时配置文件中需要填写。</li></ul><h3 id="证书安装-2"><a href="#证书安装-2" class="headerlink" title="证书安装"></a>证书安装</h3><ul><li>配置SSL连接器，将<a href="http://www.domain.com.jks文件存放到conf目录下，然后配置同目录下的server.xml文件：">www.domain.com.jks文件存放到conf目录下，然后配置同目录下的server.xml文件：</a><pre><code class="bash">      &lt;Connector port=&quot;443&quot; protocol=&quot;HTTP/1.1&quot; SSLEnabled=&quot;true&quot;          maxThreads=&quot;150&quot; scheme=&quot;https&quot; secure=&quot;true&quot;          keystoreFile=&quot;conf\www.domain.com.jks&quot;          keystorePass=&quot;changeit&quot;          clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt;</code></pre>注：</li><li><code>clientAuth</code>        如果设为true，表示Tomcat要求所有的SSL客户出示安全证书，对SSL客户进行身份验证</li><li><code>keystoreFile</code>    指定keystore文件的存放位置，可以指定绝对路径，也可以指定相对于 （Tomcat安装目录）环境变量的相对路径。如果此项没有设定，默认情况下，Tomcat将从当前操作系统用户的用户目录下读取名为 “.keystore”的文件。</li><li><code>keystorePass</code>    密钥库密码，指定keystore的密码。（如果申请证书时有填写私钥密码，密钥库密码即私钥密码）</li><li><code>sslProtocol</code>     指定套接字（Socket）使用的加密/解密协议，默认值为TLS</li></ul><h3 id="http自动跳转https的安全配置"><a href="#http自动跳转https的安全配置" class="headerlink" title="http自动跳转https的安全配置"></a>http自动跳转https的安全配置</h3><ul><li><p>到conf目录下的web.xml。在</welcome-file-list>后面，</web-app>，也就是倒数第二段里，加上这样一段</p><pre><code class="bash">      &lt;web-resource-collection &gt;          &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt;          &lt;url-pattern&gt;/*&lt;/url-pattern&gt;      &lt;/web-resource-collection&gt;      &lt;user-data-constraint&gt;          &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt;      &lt;/user-data-constraint&gt;</code></pre></li><li><p>这步目的是让非ssl的connector跳转到ssl的connector去。所以还需要前往server.xml进行配置：</p><pre><code class="bash">      &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;          connectionTimeout=&quot;20000&quot;          redirectPort=&quot;443&quot; /&gt;</code></pre></li><li><p>redirectPort改成ssl的connector的端口443，重启后便会生效。</p></li></ul><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><ul><li>由于我域名是托管到腾讯云上的，各个服务器的SSL文件均在腾讯云平台上下载的。</li><li>各个服务器亲测可用</li></ul>]]></content>
      
      
      <categories>
          
          <category> 服务器篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
            <tag> Tomcat </tag>
            
            <tag> SSL </tag>
            
            <tag> HTTPS </tag>
            
            <tag> Apache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat服务器添加多个Root项目</title>
      <link href="/2017/02/20/TomcatMulti-Root/"/>
      <url>/2017/02/20/TomcatMulti-Root/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/tomcat.jpg" alt="Tomcat"></p><h2 id="事发起因"><a href="#事发起因" class="headerlink" title="事发起因"></a>事发起因</h2><ul><li>只有一台云服务器</li><li>服务器配置较低，只能开一台Server</li><li>对外只想提供80及443端口</li><li>想把2个项目放到一个更目录下</li><li>2个项目想用不同的二级域名来访问：<ul><li><a href="http://www.joylau.cn" target="_blank" rel="noopener">http://www.joylau.cn</a>想放我的个人主页</li><li><a href="http://blog.joylau.cn">http://blog.joylau.cn</a>想放我的博客</li><li><a href="http://life.joylau.cn" target="_blank" rel="noopener">http://life.joylau.cn</a>想放我的生活站</li></ul></li></ul><h2 id="事发经过"><a href="#事发经过" class="headerlink" title="事发经过"></a>事发经过</h2><h3 id="建立文件夹"><a href="#建立文件夹" class="headerlink" title="建立文件夹"></a>建立文件夹</h3><ul><li>在Tomcat的根目录下建立blog文件夹<br><img src="//image.joylau.cn/blog/floder1.png" alt="blog文件夹"></li><li>在blog文件夹下建立ROOT文件夹，用作新项目的根路径<br><img src="//image.joylau.cn/blog/folder2.png" alt="ROOT文件夹"></li></ul><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><ul><li><p>修改server.xml配置文件,多加一对<Host></Host>配置</p><pre><code class="bash">      &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;            &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt;              &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot;                     resourceName=&quot;UserDatabase&quot;/&gt;            &lt;/Realm&gt;            &lt;Host name=&quot;localhost&quot;  appBase=&quot;webapps&quot;                  unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;              &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;                     prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;                     pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;            &lt;/Host&gt;            &lt;Host name=&quot;blog.joylau.cn&quot;  appBase=&quot;blog&quot;                  unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;              &lt;/Host&gt;          &lt;/Engine&gt;</code></pre></li></ul><h2 id="事发结果"><a href="#事发结果" class="headerlink" title="事发结果"></a>事发结果</h2><ul><li>重启服务器，问题解决。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>建立新的文件夹的时候一定要保证和webapps在同一级目录，以备在server.xml文件里路径被识别</li></ul><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="Tomcat开启压缩资源文件功能"><a href="#Tomcat开启压缩资源文件功能" class="headerlink" title="Tomcat开启压缩资源文件功能"></a>Tomcat开启压缩资源文件功能</h3><ul><li><p>原理<br>HTTP 压缩可以大大提高浏览网站的速度，它的原理是，在客户端请求服务器对应资源后，从服务器端将资源文件压缩，再输出到客户端，由客户端的浏览器负责解压缩并浏览。相对于普通的浏览过程HTML ,CSS,Javascript , Text ，它可以节省40%左右的流量。更为重要的是，它可以对动态生成的，包括CGI、PHP , JSP , ASP , Servlet,SHTML等输出的网页也能进行压缩，压缩效率也很高。</p></li><li><p>配置</p><pre><code class="bash">      &lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;                     connectionTimeout=&quot;20000&quot;                     redirectPort=&quot;443&quot; compression=&quot;on&quot;                          compressionMinSize=&quot;2048&quot;                          noCompressionUserAgents=&quot;gozilla,traviata&quot;                          compressableMimeType=&quot;text/html,text/xml,text/javascript,application/x-javascript,application/javascript,text/css,text/plain&quot;/&gt;</code></pre></li><li><p>参数说明</p><ul><li>compression=”on” 打开压缩功能</li><li>compressionMinSize=”50” 启用压缩的输出内容大小，默认为2KB </li><li>noCompressionUserAgents=”gozilla, traviata” 对于以下的浏览器，不启用压缩 </li><li>compressableMimeType=”text/html,text/xml,text/javascript,text/css,text/plain”　哪些资源类型需要压缩</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 服务器篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
            <tag> GZIP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2017/01/01/HelloWorld/"/>
      <url>/2017/01/01/HelloWorld/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="//image.joylau.cn/blog/world.jpg" alt="HelloWorld"></p><h2 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h2><h3 id="搭建一个自己博客的想法"><a href="#搭建一个自己博客的想法" class="headerlink" title="搭建一个自己博客的想法"></a>搭建一个自己博客的想法</h3><ul><li>其实在老早以前自己就有搭建一个自己博客的想法，中途也搭建尝试自己动手操作过，但是好几次都半途而废了。<br>在这期间主要的原因是自己平时没有那么多的时间，这也许跟我自己的想法有关系，原先我认为搭建一个博客就类似于开发一套管理系统，要有前台页面，后台管理…</li><li>我本身是做Java后端开发的，虽然说在实际的项目中大部分都是Web项目，但是要我自己真正的写一套前台页面，对我来说真的是很难。</li><li>我也从网站找过很多的博客类模板，并自己动手开发过，花了不少的时间，时间越久，发现很多都是不符合自己的想法的。这时我意识到之前的想法错了，或者说过于陈旧了。</li></ul><h3 id="WordPress"><a href="#WordPress" class="headerlink" title="WordPress"></a>WordPress</h3><ul><li>再后来自己动手搭过很出名的<a href="https://cn.wordpress.org/" target="_blank" rel="noopener">WordPress</a>博客系统，<a href="https://cn.wordpress.org/" target="_blank" rel="noopener">WordPress</a>是基于<code>PHP</code>开发的。<br>期间还研究了一段时间的<code>PHP</code>，搭好过后换着主题玩了一段时间，后来想二次开发一些自己的东西，但是无从下手啊…..于是这个就没再玩了…</li></ul><h3 id="Solo"><a href="#Solo" class="headerlink" title="Solo"></a>Solo</h3><ul><li><a href="https://github.com/b3log/solo" target="_blank" rel="noopener">Solo</a>这个词儿肯定很熟悉，当然了不是LOL里面的solo，这个一个完全开源的Java博客系统，在GitHub上找一下就知道，<br>Solo 是目前 GitHub 上关注度最高的 Java 开源博客系统，在GitHub上是start最多的。clone下来用着还真算不错。后来在里面发现一款主题，和我现在博客使用的很像。<br>顺藤摸瓜，于是有了现在的这套博客系统….</li></ul><h3 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h3><ul><li>Hexo 的中文官网：<a href="http://hexo.io/zh-cn/" target="_blank" rel="noopener">http://hexo.io/zh-cn/</a></li><li>官网的介绍是这样的：<blockquote><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p></blockquote></li><li>而我是这么理解的：<blockquote><p>用Github + Hexo + Nodejs搭建的博客,把逼格一下提到了凡人不可企及的高度。</p></blockquote></li><li>当我打开官网的文档查阅后，发现了这个很有意思的搭建方式，不需要花那么多的时间去做开发，直接专注的写好自己的技术博客就可以，而且还可以基于<code>Bootstrap</code>生成移动端和网页端都可以兼容的页面。</li><li>我觉得很有搞头，于是决定马上动手搭建起来……</li></ul><h2 id="动手干活"><a href="#动手干活" class="headerlink" title="动手干活"></a>动手干活</h2><h3 id="所需工具软件"><a href="#所需工具软件" class="headerlink" title="所需工具软件"></a>所需工具软件</h3><ul><li>git : <a href="http://git-scm.com/" target="_blank" rel="noopener">http://git-scm.com/</a></li><li>Nodejs : <a href="http://nodejs.org/" target="_blank" rel="noopener">http://nodejs.org/</a></li><li>Hexo ： <a href="http://hexo.io/zh-cn/" target="_blank" rel="noopener">http://hexo.io/zh-cn/</a></li></ul><h3 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h3><ul><li>git和Nodejs的下载和安装过程就不说了</li></ul><ul><li><p>Node.js 官方源默认是：<a href="http://registry.npmjs.org，" target="_blank" rel="noopener">http://registry.npmjs.org，</a>  但是由于在国外，说不定你使用的时候就抽风无法下载任何软件。所以我们决定暂时使用淘宝提供的源，淘宝源官网：<a href="http://npm.taobao.org/，" target="_blank" rel="noopener">http://npm.taobao.org/，</a> (然而比较坑爹的是公司的网络将与taobao相关的域名都和谐掉了)<br>在 Git Bash 中我们执行下面这一句</p><pre><code class="bash">alias cnpm=&quot;npm --registry=https://registry.npm.taobao.org \--cache=$HOME/.npm/.cache/cnpm \--disturl=https://npm.taobao.org/dist \--userconfig=$HOME/.cnpmrc&quot;</code></pre></li><li><p>接下来就是使用cnmp命令了，值得注意的是：cnmp这个命令是临时的，当窗口关闭下次再打开就不会再生效了，于是每次你都需要执行以下这个命令。</p></li><li><p>检测安装是否成功 <code>cnpm info express</code>,若成功会有一大串的信息提示。</p></li><li><p>安装Hexo</p><pre><code class="bash">      cnpm install -g hexo-cli</code></pre></li><li><p>创建Hexo项目</p><pre><code class="bash">      //打开到hexo的根目录      cd h:/hexo      hexo init      cnpm install</code></pre></li><li><p>启动Hexo服务</p><pre><code class="bash">      hexo server</code></pre></li></ul><h3 id="搭建完成"><a href="#搭建完成" class="headerlink" title="搭建完成"></a>搭建完成</h3><ul><li>浏览器访问：<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></li><li>搭建结束搭建完之后可以修改自定义的配置文件 <code>_config.yml</code> ，以及更换成自己想要的主题 <code>themes</code>。</li></ul><h3 id="文章置顶"><a href="#文章置顶" class="headerlink" title="文章置顶"></a>文章置顶</h3><ul><li><p>编辑这个文件：<code>node_modules/hexo-generator-index/lib/generator.js</code></p></li><li><p>覆盖原文件内容，采用下面内容：</p><pre><code class="javascript">      &#39;use strict&#39;;      var pagination = require(&#39;hexo-pagination&#39;);      module.exports = function(locals){        var config = this.config;        var posts = locals.posts;          posts.data = posts.data.sort(function(a, b) {              if(a.top &amp;&amp; b.top) { // 两篇文章top都有定义                  if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排                  else return b.top - a.top; // 否则按照top值降序排              }              else if(a.top &amp;&amp; !b.top) { // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）                  return -1;              }              else if(!a.top &amp;&amp; b.top) {                  return 1;              }              else return b.date - a.date; // 都没定义按照文章日期降序排          });        var paginationDir = config.pagination_dir || &#39;page&#39;;        return pagination(&#39;&#39;, posts, {          perPage: config.index_generator.per_page,          layout: [&#39;index&#39;, &#39;archive&#39;],          format: paginationDir + &#39;/%d/&#39;,          data: {            __index: true          }        });      };</code></pre></li><li><p>然后在文章头部的：Front-matter 位置加上一个：top: 1000 的内容。数值越大，越靠前</p></li></ul><h3 id="文章推送"><a href="#文章推送" class="headerlink" title="文章推送"></a>文章推送</h3><ul><li>安装git插件 ： npm install hexo-deployer-git –save</li><li>配置文件</li></ul><pre><code class="xml">    deploy:      type: git      repository: https://github.com/JoyLau/blog-public.git      branch: master</code></pre><ul><li>使用方式： hexo g -d ,会自动推送到上面配置的github地址,分支名为 master 默认的分支名为gh-page</li></ul><h2 id="博客建设"><a href="#博客建设" class="headerlink" title="博客建设"></a>博客建设</h2><h3 id="博客用途"><a href="#博客用途" class="headerlink" title="博客用途"></a>博客用途</h3><ul><li>整理一些在项目中用到的小知识或者技术点做一个总结及叙述，希望通过这些记录，能够将自己的学习成果归纳出来，与大家分享交流，同时能够对这些技术进行备忘，以便日后查询</li></ul><h3 id="以后建设"><a href="#以后建设" class="headerlink" title="以后建设"></a>以后建设</h3><ul><li>这个博客只用作技术记录。</li><li>自己打算再开一个专门记录生活的博客站，域名都起好了：<a href="http://life.joylau.cn" target="_blank" rel="noopener">http://life.joylau.cn</a>  (<strong><code>已弃用</code></strong>，发现真心没那么多时间去搞很多东西)</li></ul>]]></content>
      
      
      <categories>
          
          <category> 开始篇 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
            <tag> Hexo </tag>
            
            <tag> Nodejs </tag>
            
            <tag> Bootstrap </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
